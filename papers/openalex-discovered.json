{
  "source": {
    "slug": "openalex-discovery",
    "name": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
    "url": "https://api.openalex.org"
  },
  "papers": [
    {
      "id": "openalex-w7124358543",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "MLIR-Forge: A Modular Framework for Language Smiths",
      "authors": [
        {
          "name": "Berke Ates",
          "affiliation": ""
        },
        {
          "name": "Philipp Schaad",
          "affiliation": ""
        },
        {
          "name": "Timo Schneider",
          "affiliation": ""
        },
        {
          "name": "Alexandru Calotoiu",
          "affiliation": ""
        },
        {
          "name": "Torsten Hoefler",
          "affiliation": ""
        }
      ],
      "year": "2026",
      "publication": "ArXiv.org",
      "venue": "ArXiv.org",
      "type": "research-paper",
      "abstract": "Optimizing compilers are essential for the efficient and correct execution of software across various scientific fields. Domain-specific languages (DSL) typically use higher level intermediate representations (IR) in their compiler pipelines for domain-specific optimizations. As these IRs add to complexity, it is crucial to test them thoroughly. Random program generators have proven to be an effective tool to test compilers through differential and fuzz testing. However, developing specialized program generators for compiler IRs is not straightforward and demands considerable resources. We introduce MLIR-Forge, a novel random program generator framework that leverages the flexibility of MLIR, aiming to simplify the creation of specialized program generators. MLIR-Forge achieves this by splitting the generation process into fundamental building blocks that are language specific, and reusable program creation logic that constructs random programs from these building blocks. This hides complexity and furthermore, even the language specific components can be defined using a set of common tools. We demonstrate MLIR-Forge's capabilities by generating MLIR with built-in dialects, WebAssembly, and a data-centric program representation, DaCe -- requiring less than a week of development time in total for each of them. Using the generated programs we conduct differential testing and find 9 MLIR, 15 WebAssembly, and 774 DaCe groups of bugs with the corresponding program generators, after running them until the rate of new bugs stagnates.",
      "paperUrl": "https://arxiv.org/pdf/2601.09583",
      "sourceUrl": "http://arxiv.org/abs/2601.09583",
      "tags": [
        "Optimizations",
        "IR",
        "Testing",
        "MLIR"
      ],
      "keywords": [
        "Optimizations",
        "IR",
        "Testing",
        "MLIR",
        "Intermediate Representation",
        "Fuzzing",
        "Differential Testing",
        "MLIR Forge",
        "Specialized Program Generators",
        "Domain Specific",
        "Random Program",
        "Building Blocks",
        "Language Specific",
        "Language Smiths"
      ],
      "matchedAuthors": [
        "Alexandru Calotoiu",
        "Berke Ates",
        "Timo Schneider",
        "Torsten Hoefler"
      ]
    },
    {
      "id": "openalex-w7125821619",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "KeyMemRT Compiler and Runtime: Unlocking Memory-Scalable FHE",
      "authors": [
        {
          "name": "Eymen Ünay",
          "affiliation": ""
        },
        {
          "name": "Björn Franke",
          "affiliation": ""
        },
        {
          "name": "Jackson Woodruff",
          "affiliation": ""
        }
      ],
      "year": "2026",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Fully Homomorphic Encryption (FHE) enables privacy preserving computation but it suffers from high latency and memory consumption. The computations are secured with special keys called rotation keys which often take up the majority of memory. In complex FHE applications, these rotation keys can cause a large memory bottleneck limiting program throughput. Existing compilers make little effort to solve this problem, instead relying on systems with massive memory availability. This resource requirement is a barrier to FHE uptake because optimizing FHE programs by hand is challenging due to their scale, complexity and expertise required. In this work, we present KeyMemRT; an MLIR based compiler and runtime framework that individually manages rotation key lifetimes to lower memory utilization and to allow arbitrary number of rotation indices to be supported without memory bloating. KeyMemRT relies on dataflow analysis to determine key lifetimes and is the first FHE compiler to provide automatic key management, handle fine-grained key-mangement and manage boostrap keys. We implement frontends for Orion and HEIR and show improvements over state-of-the-art FHE compilers. KeyMemRT achieves memory reduction of 1.74x and a speedup of 1.20x over ANT-ACE, and memory reduction of 1.16x and a speedup of 1.73x over memory-optimized compiler Fhelipe. We provide KeyMemRT as a post-optimizing compiler that can be targeted by any FHE compiler.",
      "paperUrl": "https://doi.org/10.48550/arxiv.2601.18445",
      "sourceUrl": "",
      "tags": [
        "Static Analysis",
        "MLIR"
      ],
      "keywords": [
        "Static Analysis",
        "MLIR",
        "Dataflow Analysis",
        "Memory Reduction",
        "Keymemrt Compiler",
        "Rotation Keys",
        "Fhe Compiler",
        "Key Lifetimes",
        "Memory Scalable Fhe",
        "Runtime Unlocking Memory",
        "Unlocking Memory Scalable"
      ],
      "matchedAuthors": [
        "Björn Franke",
        "Jackson Woodruff"
      ]
    },
    {
      "id": "openalex-w7126021253",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Converting Binary Floating‐Point Numbers to Shortest Decimal Strings: An Experimental Review",
      "authors": [
        {
          "name": "Jaël Champagne Gareau",
          "affiliation": "Université du Québec à Montréal"
        },
        {
          "name": "Daniel Lemire",
          "affiliation": "Université du Québec à Montréal"
        }
      ],
      "year": "2026",
      "publication": "Software Practice and Experience",
      "venue": "Software Practice and Experience",
      "type": "research-paper",
      "abstract": "ABSTRACT Background When sharing or logging numerical data, we must convert binary floating‐point numbers into their decimal string representations. For example, the number π might become 3.1415927. Engineers have perfected many algorithms for producing such accurate, short strings. Aims We present an empirical comparison across diverse hardware architectures and datasets. Methods We benchmarked several established and recent algorithms for converting binary floating‐point numbers (IEEE 754 double‐precision) to their decimal string representations. We executed the conversions across multiple CPU microarchitectures, including recent Intel (Alder Lake, Skylake), AMD (Zen 3, Zen 4), and ARM (Apple M1/M2, Neoverse) processors, using recent versions of GCC, Clang, and platform‐specific compilers and several datasets. Results and Conclusions Cutting‐edge techniques like Schubfach and Dragonbox achieve up to a tenfold speedup over Steele and White's Dragon4, executing as few as 210 instructions per conversion compared to Dragon4's 1500–5000 instructions. Often per their specification, none of the implementations we surveyed consistently produced the shortest possible strings—some generate outputs up to 30% longer than optimal. We find that standard library implementations in languages such as C++ and Swift execute significantly more instructions than the fastest methods, with performance gaps varying across CPU architectures and compilers. We suggest some optimization targets for future research.",
      "paperUrl": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/spe.70056",
      "sourceUrl": "https://doi.org/10.1002/spe.70056",
      "tags": [
        "Performance",
        "Clang",
        "Optimizations",
        "Swift"
      ],
      "keywords": [
        "Performance",
        "Clang",
        "Optimizations",
        "Swift",
        "Binary Floating Point",
        "Floating Point Numbers",
        "Converting Binary Floating",
        "Decimal String Representations",
        "Shortest Decimal Strings",
        "Recent",
        "CPU",
        "Dragon4"
      ],
      "matchedAuthors": [
        "Daniel Lemire"
      ]
    },
    {
      "id": "openalex-w4408979192",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "VConv: Autotiling Convolution Algorithm Based on MLIR for Multi-core Vector accelerators",
      "authors": [
        {
          "name": "Xiaorong Chen",
          "affiliation": "National University of Defense Technology"
        },
        {
          "name": "Cheng Li",
          "affiliation": "National University of Defense Technology"
        },
        {
          "name": "Zhong Liu",
          "affiliation": "National University of Defense Technology"
        }
      ],
      "year": "2025",
      "publication": "Lecture notes in computer science",
      "venue": "Lecture notes in computer science",
      "type": "research-paper",
      "abstract": "No abstract available in discovery metadata.",
      "paperUrl": "https://doi.org/10.1007/978-981-96-2830-8_14",
      "sourceUrl": "",
      "tags": [
        "MLIR"
      ],
      "keywords": [
        "MLIR",
        "Core Vector Accelerators",
        "Multi Core Vector",
        "Vconv Autotiling Convolution"
      ],
      "matchedAuthors": [
        "Cheng Li"
      ]
    },
    {
      "id": "openalex-w4410747805",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Thetis-lathe: Guidance on Reducing Residual Safety Obstacle in System Software from Rust Source Codes",
      "authors": [
        {
          "name": "Renshuang Jiang",
          "affiliation": "National Defense University"
        },
        {
          "name": "Pan Dong",
          "affiliation": "Milli Savunma Üniversitesi"
        },
        {
          "name": "Yan Ding",
          "affiliation": "National University of Defense Technology"
        },
        {
          "name": "Ran Wei",
          "affiliation": "Lancaster University"
        },
        {
          "name": "Zhe Jiang",
          "affiliation": "University of Cambridge"
        }
      ],
      "year": "2025",
      "publication": "ACM Transactions on Embedded Computing Systems",
      "venue": "ACM Transactions on Embedded Computing Systems | Vol. 24 (Issue 4)",
      "type": "research-paper",
      "abstract": "Programming languages play a crucial role in ensuring the safety of the Operating System (OS). Traditional low-level languages (e.g., C, C++), while high-performance, usually offer very limited protections on safety, and their vulnerability patches (e.g., AddressSanitizer, DangSan), while effective in mitigating some issues, are often too expensive. Rust language combines memory safety with performance, providing a fresh paradigm for constructing efficient, reliable, and dependable. However, existing Rust rely on unsafe code fragments to interface with low-level hardware and other programming languages, introducing critical issues: (1) compromised system-wide safety due to the presence of unsafe code, (2) inaccurate defect detection because of unavoidable interactions between unsafe and safe code; and (3) difficulty in finding an optimal balance between accuracy and efficiency of defect detection and elimination. In contrast to the previous work, we believe — “ prevention is always better than cure ”. Therefore, we propose a new methodology (namely Thetis) to detect and guide the minimization of unsafe fragments in Rust source code. For unsafe code detection, Thetis designs an automated inspection method based on feature extraction. For unsafe code elimination based on Unsafe Rust types and interchangeability, Thetis prop defect optimization suggestions and designs a framework to automatically provide safer code recommendations. We have designed and implemented a new tool called Thetis-lathe based on Thetis and have also ported Thetis-lathe to three mainstream Rust applications, i.e., BlogOS, rCore, and Miri Failure Set. Evaluations show that our tool improved the accuracy of defects and decreased the amount of unsafe code by 35% and undefined behavior by approximately 50%. Furthermore, Thetis-lathe speeds up the run-time about 5x compared with the sanitizer and LMbench results indicate that our approach introduces 7.6% (average) performance overhead on the entire system.",
      "paperUrl": "https://doi.org/10.1145/3736729",
      "sourceUrl": "",
      "tags": [
        "Security",
        "Performance",
        "Optimizations",
        "Embedded",
        "Programming Languages",
        "Testing",
        "Rust"
      ],
      "keywords": [
        "Security",
        "Performance",
        "Optimizations",
        "Embedded",
        "Programming Languages",
        "Testing",
        "Rust",
        "Sanitizers",
        "Memory Safety",
        "Thetis Lathe Guidance",
        "Unsafe",
        "Reducing Residual Safety",
        "Defect",
        "Defect Detection"
      ],
      "matchedAuthors": [
        "Ran Wei",
        "Yan Ding"
      ]
    },
    {
      "id": "openalex-w4415332835",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Tech-ASan: Two-stage check for Address Sanitizer",
      "authors": [
        {
          "name": "Yunhe Cao",
          "affiliation": "Shenzhen University"
        },
        {
          "name": "Yuanhua Feng",
          "affiliation": "Shenzhen University"
        },
        {
          "name": "Huafeng Li",
          "affiliation": "Shenzhen University"
        },
        {
          "name": "C. Huang",
          "affiliation": "Shenzhen University"
        },
        {
          "name": "Fangcao Jian",
          "affiliation": "Shenzhen University"
        },
        {
          "name": "Haoran Li",
          "affiliation": "Shenzhen University"
        },
        {
          "name": "Xu Wang",
          "affiliation": "Shenzhen University"
        }
      ],
      "year": "2025",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Address Sanitizer (ASan) is a sharp weapon for detecting memory safety violations, including temporal and spatial errors hidden in C/C++ programs during execution. However, ASan incurs significant runtime overhead, which limits its efficiency in testing large software. The overhead mainly comes from sanitizer checks due to the frequent and expensive shadow memory access. Over the past decade, many methods have been developed to speed up ASan by eliminating and accelerating sanitizer checks, however, they either fail to adequately eliminate redundant checks or compromise detection capabilities. To address this issue, this paper presents Tech-ASan, a two-stage check based technique to accelerate ASan with safety assurance. First, we propose a novel two-stage check algorithm for ASan, which leverages magic value comparison to reduce most of the costly shadow memory accesses. Second, we design an efficient optimizer to eliminate redundant checks, which integrates a novel algorithm for removing checks in loops. Third, we implement Tech-ASan as a memory safety tool based on the LLVM compiler infrastructure. Our evaluation using the SPEC CPU2006 benchmark shows that Tech-ASan outperforms the state-of-the-art methods with 33.70% and 17.89% less runtime overhead than ASan and ASan--, respectively. Moreover, Tech-ASan detects 56 fewer false negative cases than ASan and ASan-- when testing on the Juliet Test Suite under the same redzone setting.",
      "paperUrl": "https://doi.org/10.1145/3755881.3755918",
      "sourceUrl": "",
      "tags": [
        "Security",
        "Testing",
        "Infrastructure"
      ],
      "keywords": [
        "Security",
        "Testing",
        "Infrastructure",
        "LLVM",
        "Sanitizers",
        "Memory Safety",
        "Tech Asan Two",
        "Two Stage Check",
        "Eliminate Redundant Checks",
        "Sanitizer Checks",
        "Shadow Memory",
        "Address Sanitizer",
        "Runtime Overhead",
        "Asan Two Stage"
      ],
      "matchedAuthors": [
        "Haoran Li"
      ]
    },
    {
      "id": "openalex-w7117851087",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "TL: Automatic End-to-End Compiler of Tile-Based Languages for Spatial Dataflow Architectures",
      "authors": [
        {
          "name": "Wei Li",
          "affiliation": ""
        },
        {
          "name": "Zhenyu Bai",
          "affiliation": ""
        },
        {
          "name": "Heru Wang",
          "affiliation": ""
        },
        {
          "name": "Pranav Dangi",
          "affiliation": ""
        },
        {
          "name": "Zhiqiang Zhang",
          "affiliation": ""
        },
        {
          "name": "Cheng Tan",
          "affiliation": ""
        },
        {
          "name": "Huiying Lan",
          "affiliation": ""
        },
        {
          "name": "Weng-Fai Wong",
          "affiliation": ""
        },
        {
          "name": "Tulika Mitra",
          "affiliation": ""
        }
      ],
      "year": "2025",
      "publication": "ArXiv.org",
      "venue": "ArXiv.org",
      "type": "research-paper",
      "abstract": "Spatial dataflow accelerators are a promising direction for next-generation computer systems because they can reduce the memory bottlenecks of traditional von Neumann machines such as CPUs and GPUs. They do so by organizing computation around explicit, compiler-managed data movement over the on-chip network, allowing operands to be directly forwarded between processing elements and reducing reliance on high-latency, bandwidth-limited global shared memory. Such localized communications can provide higher throughput and efficiency compared to repeated off-chip memory accesses. However, their end-to-end performance depends strongly on how workloads are mapped to the hardware. Naive mappings can perform very poorly, and most users rely on hand-tuned vendor libraries. In practice, although existing spatial-dataflow accelerators have strong potential for high performance, energy- and cost-efficiency, their limited programmability remains a major barrier to their wider adoption. This paper presents TL, an end-to-end framework that compiles tile-based programs (such as Triton kernels) onto spatial dataflow architectures. Unlike most existing compiler frameworks that focus on optimizing code generation within a single tile, TL addresses the central challenge of distributing tile instances across spatially distributed cores and exploiting the on-chip network and distributed memories to increase data reuse and reduce communications. TL proposes a hardware representation that captures interconnect topology, memory hierarchy, and compute capabilities, enabling both specialized architecture-specific optimizations and support for diverse spatial dataflow targets. TL is built on the MLIR ecosystem and defines a generic entry point for different front-ends and an end point for different back-ends.",
      "paperUrl": "https://arxiv.org/pdf/2512.22168",
      "sourceUrl": "http://arxiv.org/abs/2512.22168",
      "tags": [
        "Backend",
        "Performance",
        "Optimizations",
        "GPU",
        "Libraries",
        "MLIR"
      ],
      "keywords": [
        "Backend",
        "Performance",
        "Optimizations",
        "GPU",
        "Libraries",
        "MLIR",
        "Code Generation",
        "Spatial Dataflow Architectures",
        "Memory",
        "Spatial Dataflow Accelerators",
        "Chip Network",
        "Hardware"
      ],
      "matchedAuthors": [
        "Cheng Tan",
        "Wei Li"
      ]
    },
    {
      "id": "openalex-w4415274655",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Synergy-Guided Compiler Auto-Tuning of Nested LLVM Pass Pipelines",
      "authors": [
        {
          "name": "Hongming Pan",
          "affiliation": ""
        },
        {
          "name": "Jung-Song Dong",
          "affiliation": ""
        },
        {
          "name": "Mingjie Xing",
          "affiliation": ""
        },
        {
          "name": "Yanjun Wu",
          "affiliation": ""
        }
      ],
      "year": "2025",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Compiler optimization relies on sequences of passes to improve program performance. Selecting and ordering these passes automatically, known as compiler auto-tuning, is challenging due to the large and complex search space. Existing approaches generally assume a linear sequence of passes, a model compatible with legacy compilers but fundamentally misaligned with the hierarchical design of the LLVM New Pass Manager. This misalignment prevents them from guaranteeing the generation of syntactically valid optimization pipelines. In this work, we present a new auto-tuning framework built from the ground up for the New Pass Manager. We introduce a formal grammar to define the space of valid nested pipelines and a forest-based data structure for their native representation. Upon this foundation, we develop a structure-aware Genetic Algorithm whose operators manipulate these forests directly, ensuring that all candidate solutions are valid by construction. The framework first mines synergistic pass relationships to guide the search. An optional refinement stage further explores subtle performance variations arising from different valid structural arrangements. We evaluate our approach on seven benchmark datasets using LLVM 18.1.6. The discovered pipelines achieve an average of 13.62% additional instruction count reduction compared to the standard opt -Oz optimization level, showing that our framework is capable of navigating this complex, constrained search space to identify valid and effective pass pipelines.",
      "paperUrl": "https://arxiv.org/pdf/2510.13184",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2510.13184",
      "tags": [
        "Performance",
        "Optimizations"
      ],
      "keywords": [
        "Performance",
        "Optimizations",
        "LLVM",
        "Pass Pipelines",
        "Compiler Auto Tuning",
        "LLVM Pass Pipelines",
        "Passes",
        "Search Space",
        "Pass Manager",
        "Guided Compiler Auto",
        "Nested LLVM Pass",
        "Synergy Guided Compiler"
      ],
      "matchedAuthors": [
        "Mingjie Xing",
        "Yanjun Wu"
      ]
    },
    {
      "id": "openalex-w4407632846",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Seamless acceleration of Fortran intrinsics via AMD AI engines",
      "authors": [
        {
          "name": "Nick Brown",
          "affiliation": ""
        },
        {
          "name": "Gabriel Rodríguez Canal",
          "affiliation": ""
        }
      ],
      "year": "2025",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "A major challenge that the HPC community faces is how to continue delivering the performance demanded by scientific programmers, whilst meeting an increased emphasis on sustainable operations. Specialised architectures, such as FPGAs and AMD's AI Engines (AIEs), have been demonstrated to provide significant energy efficiency advantages, however a major challenge is that to most effectively program these architectures requires significant expertise and investment of time which is a major blocker. Fortran in the lingua franca of scientific computing, and in this paper we explore automatically accelerating Fortran intrinsics via the AIEs in AMD's Ryzen AI CPU. Leveraging the open source Flang compiler and MLIR ecosystem, we describe an approach that lowers the MLIR linear algebra dialect to AMD's AIE dialects, and demonstrate that for suitable workloads the AIEs can provide significant performance advantages over the CPU without any code modifications required by the programmer.",
      "paperUrl": "https://arxiv.org/pdf/2502.10254",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2502.10254",
      "tags": [
        "Performance",
        "AI",
        "Flang",
        "MLIR"
      ],
      "keywords": [
        "Performance",
        "AI",
        "Flang",
        "MLIR",
        "Fortran Intrinsics",
        "Provide Significant",
        "Major Challenge",
        "CPU",
        "Seamless Acceleration"
      ],
      "matchedAuthors": [
        "Nick Brown"
      ]
    },
    {
      "id": "openalex-w7128574628",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "SORS/WomenInBSC: Open-source high-level synthesis research for automated FPGA/ASIC acceleration",
      "authors": [
        {
          "name": "Serena Curzel",
          "affiliation": ""
        }
      ],
      "year": "2025",
      "publication": "UPCommons institutional repository (Universitat Politècnica de Catalunya)",
      "venue": "UPCommons institutional repository (Universitat Politècnica de Catalunya)",
      "type": "research-paper",
      "abstract": "The talk presents the latest advances in open-source high-level synthesis (HLS) for FPGA and ASIC design, focusing on the Bambu HLS tool developed at Politecnico di Milano. The presentation explores compiler-driven innovation via the integration of Bambu with MLIR, enabling high-level optimization and synthesis of machine learning applications. Further, it describes customizable floating-point formats, an HLS extension for parallel multi-threaded accelerators written in OpenMP, and a novel system-level co-simulation environment. The seminar concludes with insights into future work on ASIC support and architectural simulation integration via gem5.",
      "paperUrl": "https://hdl.handle.net/2117/454306",
      "sourceUrl": "",
      "tags": [
        "Optimizations",
        "ML",
        "MLIR"
      ],
      "keywords": [
        "Optimizations",
        "ML",
        "MLIR",
        "Synthesis",
        "HLS",
        "Automated Fpga Asic",
        "Fpga Asic Acceleration",
        "Sors Womeninbsc Open"
      ],
      "matchedAuthors": [
        "Serena Curzel"
      ]
    },
    {
      "id": "openalex-w4406668084",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Review of intermediate representations for quantum computing",
      "authors": [
        {
          "name": "F. Javier Cardama",
          "affiliation": "Center for Research in Molecular Medicine and Chronic Diseases"
        },
        {
          "name": "Jorge Vázquez-Pérez",
          "affiliation": "Center for Research in Molecular Medicine and Chronic Diseases"
        },
        {
          "name": "César Piñeiro",
          "affiliation": "Universidade de Santiago de Compostela"
        },
        {
          "name": "Juan C. Pichel",
          "affiliation": "Universidade de Santiago de Compostela"
        },
        {
          "name": "Tomás F. Pena",
          "affiliation": "Universidade de Santiago de Compostela"
        },
        {
          "name": "Andrés Gómez",
          "affiliation": "Centro de Supercomputación de Galicia"
        }
      ],
      "year": "2025",
      "publication": "The Journal of Supercomputing",
      "venue": "The Journal of Supercomputing | Vol. 81 (Issue 2)",
      "type": "research-paper",
      "abstract": "Abstract Intermediate representations (IRs) are fundamental to classical and quantum computing, bridging high-level quantum programming languages and the hardware-specific instructions required for execution. This paper reviews the development of quantum IRs, focusing on their evolution and the need for abstraction layers that facilitate portability and optimization. Monolithic quantum IRs, such as QIR (Lubinski et al. in Front Phys 10:940293, 2022. https://doi.org/10.3389/fphy.2022.940293), QSSA (Peduri et al. in Proceedings of the 31st ACM SIGPLAN international conference on compiler construction. CC 2022. Association for Computing Machinery, New York, 2022), or Q-MLIR (McCaskey and Nguyen in Proceedings-2021 IEEE International Conference on Quantum Computing and Engineering, QCE, 2021), their effectiveness in handling abstractions, and their hybrid support between quantum-classical operations are evaluated. However, a key limitation is their inability to address qubit locality, an essential feature for distributed quantum computing (DQC). To overcome this, InQuIR (Nishio and Wakizaka in InQuIR: Intermediate Representation for Interconnected Quantum Computers, 2023. https://arxiv.org/abs/2302.00267) was introduced as an IR specifically designed for distributed systems, providing explicit control over qubit locality and inter-node communication. While effective in managing qubit distribution, InQuIR’s dependence on manual manipulation of communication protocols increases complexity for developers. NetQIR (Vázquez-Pérez et al. in NetQIR: An Extension of QIR for Distributed Quantum Computing, 2024. https://arxiv.org/abs/2408.03712), an extension of QIR for DQC, emerges as a solution to achieve the abstraction of quantum communications protocols. This review emphasizes the need for further advancements in IRs for distributed quantum systems, which will play a crucial role in the scalability and usability of future quantum networks.",
      "paperUrl": "https://link.springer.com/content/pdf/10.1007/s11227-024-06892-2.pdf",
      "sourceUrl": "https://doi.org/10.1007/s11227-024-06892-2",
      "tags": [
        "Optimizations",
        "IR",
        "Programming Languages",
        "Quantum Computing",
        "MLIR"
      ],
      "keywords": [
        "Optimizations",
        "IR",
        "Programming Languages",
        "Quantum Computing",
        "MLIR",
        "Intermediate Representation",
        "Quantum Compilation",
        "Distributed Quantum Computing",
        "Intermediate Representations",
        "Inquir",
        "Quantum Irs",
        "Qubit Locality"
      ],
      "matchedAuthors": [
        "F. Javier Cardama",
        "Tomás F. Pena"
      ]
    },
    {
      "id": "openalex-w4416435943",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "QiMeng-NeuComBack: Self-Evolving Translation from IR to Assembly Code",
      "authors": [
        {
          "name": "Hang Fang",
          "affiliation": ""
        },
        {
          "name": "Yuanbo Wen",
          "affiliation": ""
        },
        {
          "name": "Jun Bi",
          "affiliation": ""
        },
        {
          "name": "Yihan Wang",
          "affiliation": ""
        },
        {
          "name": "Tian-Xiao He",
          "affiliation": ""
        },
        {
          "name": "Yiming Tang",
          "affiliation": ""
        },
        {
          "name": "Di Huang",
          "affiliation": ""
        },
        {
          "name": "Jia‐Ming Guo",
          "affiliation": ""
        },
        {
          "name": "Rui Zhang",
          "affiliation": ""
        },
        {
          "name": "Qi Guo",
          "affiliation": ""
        },
        {
          "name": "Yunji Chen",
          "affiliation": ""
        }
      ],
      "year": "2025",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Compilers, while essential, are notoriously complex systems that demand prohibitively expensive human expertise to develop and maintain. The recent advancements in Large Language Models (LLMs) offer a compelling new paradigm: Neural Compilation, which could potentially simplify compiler development for new architectures and facilitate the discovery of innovative optimization techniques. However, several critical obstacles impede its practical adoption. Firstly, a significant lack of dedicated benchmarks and robust evaluation methodologies hinders objective assessment and tracking of progress in the field. Secondly, systematically enhancing the reliability and performance of LLM-generated assembly remains a critical challenge. Addressing these challenges, this paper introduces NeuComBack, a novel benchmark dataset specifically designed for IR-to-assembly compilation. Leveraging this dataset, we first define a foundational Neural Compilation workflow and conduct a comprehensive evaluation of the capabilities of recent frontier LLMs on Neural Compilation, establishing new performance baselines. We further propose a self-evolving prompt optimization method that enables LLMs to iteratively evolve their internal prompt strategies by extracting insights from prior self-debugging traces, thereby enhancing their neural compilation capabilities. Experiments demonstrate that our method significantly improves both the functional correctness and the performance of LLM-generated assembly code. Compared to baseline prompts, the functional correctness rates improved from 44% to 64% on x86_64 and from 36% to 58% on aarch64, respectively. More significantly, among the 16 correctly generated x86_64 programs using our method, 14 (87.5%) surpassed clang-O3 performance.",
      "paperUrl": "https://arxiv.org/pdf/2511.01183",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2511.01183",
      "tags": [
        "Performance",
        "Clang",
        "Optimizations",
        "IR"
      ],
      "keywords": [
        "Performance",
        "Clang",
        "Optimizations",
        "IR",
        "Neural Compilation",
        "Llm Generated Assembly",
        "Neucomback Self Evolving",
        "Functional Correctness",
        "Qimeng Neucomback Self"
      ],
      "matchedAuthors": [
        "Yunji Chen"
      ]
    },
    {
      "id": "openalex-w4416937041",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Partial Cross-Compilation and Mixed Execution for Accelerating Dynamic Binary Translation",
      "authors": [
        {
          "name": "Yuhao Gu",
          "affiliation": ""
        },
        {
          "name": "Zaosong Zheng",
          "affiliation": ""
        },
        {
          "name": "Nong Xiao",
          "affiliation": ""
        },
        {
          "name": "Yutong Lu",
          "affiliation": ""
        },
        {
          "name": "Xianwei Zhang",
          "affiliation": ""
        }
      ],
      "year": "2025",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "With the growing diversity of instruction set architectures (ISAs), cross-ISA program execution has become common. Dynamic binary translation (DBT) is the main solution but suffers from poor performance. Cross-compilation avoids emulation costs but is constrained by an \"all-or-nothing\" model-programs are either fully cross-compiled or entirely emulated. Complete cross-compilation is often unfeasible due to ISA-specific code or missing dependencies, leaving programs with high emulation overhead. We propose a hybrid execution system that combines compilation and emulation, featuring a selective function offloading mechanism. This mechanism establishes cross-environment calling channels, offloading eligible functions to the host for native execution to reduce DBT overhead. Key optimizations address offloading costs, enabling efficient hybrid operation. Built on LLVM and QEMU, the system works automatically for both applications and libraries. Evaluations show it achieves up to 13x speedups over existing DBT, with strong practical value.",
      "paperUrl": "https://arxiv.org/pdf/2512.00487",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2512.00487",
      "tags": [
        "Performance",
        "Optimizations",
        "GPU",
        "Libraries"
      ],
      "keywords": [
        "Performance",
        "Optimizations",
        "GPU",
        "Libraries",
        "LLVM",
        "Offloading",
        "Binary Translation",
        "Partial Cross Compilation",
        "Emulation",
        "ISA",
        "Mixed Execution"
      ],
      "matchedAuthors": [
        "Xianwei Zhang",
        "Zaosong Zheng"
      ]
    },
    {
      "id": "openalex-w7125608094",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "OpenMP Offloading on AMD and NVIDIA GPUs: Programmability and Performance Analysis",
      "authors": [
        {
          "name": "Ezhilmathi Krishnaamy",
          "affiliation": "University of Luxembourg"
        },
        {
          "name": "Pascal Bouvry",
          "affiliation": "University of Luxembourg"
        }
      ],
      "year": "2025",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "The introduction of Graphics Processing Units (GPUs) to scientific computing has led to the development of various programming models designed to maximize their computational capabilities. Over the past few decades, GPU vendors have matured, resulting in a diverse array of GPU programming models and continuous advancements in compiler technologies that support these developments. Among these options, Open Multi-Processing (OpenMP) Offloading has emerged as a particularly promising programming model that targets GPUs from NVIDIA, AMD, and Intel. This study investigates the effectiveness of OpenMP Offloading on NVIDIA (H100) and AMD (MI250X) GPUs, which utilize different interconnect technologies—Peripheral Component Interconnect Express (PCIe) Gen5 for NVIDIA and Infinity Fabric (IF) for AMD. Using vendor-specific compiler toolchains, namely NVHPC (version 23.7-0) for NVIDIA and Cray Clang (version 17.0.1) for AMD, we evaluate performance across key linear algebra operations, focusing on kernel execution efficiency and data transfer strategies between the host CPU and the GPU. Additionally, this work includes a comparative analysis of OpenMP Offloading against cuBLAS and hipBLAS. Our results indicate that OpenMP Offloading offers performance comparable to the best numerical library versions for BLAS level 1 and 2 operations on H100 and MI250X (except matrix-vector multiplication). Furthermore, Infinity Fabric provides approximately 1.5 times the bandwidth of PCIe Gen5, according to our measurements. We also recommend utilizing low-level Application Programming Interfaces (APIs) to achieve improved performance for data movement between the CPU and GPU.",
      "paperUrl": "https://doi.org/10.1145/3774949.3774956",
      "sourceUrl": "",
      "tags": [
        "Performance",
        "Clang",
        "GPU"
      ],
      "keywords": [
        "Performance",
        "Clang",
        "GPU",
        "Offloading",
        "OpenMP Offloading",
        "Nvidia",
        "Nvidia Gpus Programmability",
        "Infinity Fabric",
        "Pcie Gen5",
        "CPU",
        "H100",
        "Mi250x"
      ],
      "matchedAuthors": [
        "Pascal Bouvry"
      ]
    },
    {
      "id": "openalex-w7117078552",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Multi-Language Benchmark Generation via L-Systems",
      "authors": [
        {
          "name": "Vinícius Francisco da Silva",
          "affiliation": ""
        },
        {
          "name": "Heitor Leite",
          "affiliation": ""
        },
        {
          "name": "Fernando Magno Quintão Pereira",
          "affiliation": ""
        }
      ],
      "year": "2025",
      "publication": "ArXiv.org",
      "venue": "ArXiv.org",
      "type": "research-paper",
      "abstract": "L-systems are a mathematical formalism proposed by biologist Aristid Lindenmayer with the aim of simulating organic structures such as trees, snowflakes, flowers, and other branching phenomena. They are implemented as a formal language that defines how patterns can be iteratively rewritten. This paper describes how such a formalism can be used to create artificial programs written in programming languages such as C, C++, Julia and Go. These programs, being large and complex, can be used to test the performance of compilers, operating systems, and computer architectures. This paper demonstrates the usefulness of these benchmarks through multiple case studies. These case studies include a comparison between clang and gcc; a comparison between C, C++, Julia and Go; a study of the historical evolution of gcc in terms of code quality; a look into the effects of profile guided optimizations in gcc; an analysis of the asymptotic behavior of the different phases of clang's compilation pipeline; and a comparison between the many data structures available in the Gnome Library (GLib). These case studies demonstrate the benefits of the L-System approach to create benchmarks, when compared with fuzzers such as CSmith, which were designed to uncover bugs in compilers, rather than evaluating their performance.",
      "paperUrl": "https://arxiv.org/pdf/2512.17616",
      "sourceUrl": "http://arxiv.org/abs/2512.17616",
      "tags": [
        "Performance",
        "Clang",
        "Optimizations",
        "Programming Languages",
        "Testing"
      ],
      "keywords": [
        "Performance",
        "Clang",
        "Optimizations",
        "Programming Languages",
        "Testing",
        "Fuzzing",
        "GCC",
        "Studies",
        "Multi Language"
      ],
      "matchedAuthors": [
        "Fernando Magno Quintão Pereira"
      ]
    },
    {
      "id": "openalex-w4415274658",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Isolating Compiler Bugs through Compilation Steps Analysis",
      "authors": [
        {
          "name": "Yujie Liu",
          "affiliation": ""
        },
        {
          "name": "Mingxuan Zhu",
          "affiliation": ""
        },
        {
          "name": "Shiqiang Cheng",
          "affiliation": ""
        },
        {
          "name": "Dan Hao",
          "affiliation": ""
        }
      ],
      "year": "2025",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Compilers are essential to software systems, and their bugs can propagate to dependent software. Ensuring compiler correctness is critical. However, isolating compiler bugs remains challenging due to the internal complexity of compiler execution. Existing techniques primarily mutate compilation inputs to generate passing and failing tests, but often lack causal analysis of internal steps, limiting their effectiveness. To address this limitation, we propose CompSCAN, a novel compiler bug isolation technique that applies analysis over the sequence of compilation steps. CompSCAN follows a three-stage process: (1) extracting the array of compilation steps that leads to the original failure, (2) identifying bug-causing steps and collecting corresponding compiler code elements, and (3) calculating suspicious scores for each code element and outputting a suspicious ranking list as the bug isolation result. We evaluate CompSCAN on 185 real-world LLVM and GCC bugs. Results show that CompSCAN outperforms state-of-the-art techniques in both effectiveness and efficiency. CompSCAN successfully isolates 50, 85, 100, and 123 bugs within the Top-1/3/5/10 ranks, respectively. Compared with ETEM and ODFL, two state-of-the-art compiler bug isolation techniques, CompSCAN achieves relative improvements of 44.51% / 50.18% / 36.24% / 24.49% over ETEM, and 31.58% / 49.12% / 44.93% / 21.78% over ODFL on those metrics. Moreover, CompSCAN runs faster on average per bug than both baselines.",
      "paperUrl": "https://arxiv.org/pdf/2510.13128",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2510.13128",
      "tags": [],
      "keywords": [
        "LLVM",
        "Compscan",
        "Compilation Steps",
        "Compiler Bug Isolation",
        "Isolating Compiler Bugs"
      ],
      "matchedAuthors": [
        "Dan Hao",
        "Mingxuan Zhu"
      ]
    },
    {
      "id": "openalex-w7125968550",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Interleaved Learning and Exploration: A Self-Adaptive Fuzz Testing Framework for MLIR",
      "authors": [
        {
          "name": "Zeyu Sun",
          "affiliation": "Chinese Academy of Sciences"
        },
        {
          "name": "Liang Jing-jing",
          "affiliation": "Shanghai Key Laboratory of Trustworthy Computing"
        },
        {
          "name": "Wu Wang",
          "affiliation": "Chinese Academy of Sciences"
        },
        {
          "name": "Chenyao Suo",
          "affiliation": "Tianjin University"
        },
        {
          "name": "Junjie Chen",
          "affiliation": "Tianjin University"
        },
        {
          "name": "Fanjiang Xu",
          "affiliation": "Chinese Academy of Sciences"
        }
      ],
      "year": "2025",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "MLIR (Multi-Level Intermediate Representation) has rapidly become a foundational technology for modern compiler frameworks, enabling extensibility across diverse domains. However, ensuring the correctness and robustness of MLIR itself remains challenging. Existing fuzzing approaches—based on manually crafted templates or rule-based mutations—struggle to generate sufficiently diverse and semantically valid test cases, making it difficult to expose subtle or deep-seated bugs within MLIR’s complex and evolving code space. In this paper, we present FLEX, a novel self-adaptive fuzzing framework for MLIR. FLEX leverages neural networks for program generation, a perturbed sampling strategy to encourage diversity, and a feedback-driven augmentation loop that iteratively improves its model using both crashing and non-crashing test cases. Starting from a limited seed corpus, FLEX progressively learns valid syntax and semantics and autonomously produces high-quality test inputs. We evaluate FLEX on the upstream MLIR compiler against four state-of-the-art fuzzers. In a 30-day campaign, FLEX discovers 80 previously unknown bugs—including multiple new root causes and parser bugs—while in 24-hour fixed-revision comparisons, it detects 53× bugs (over 3.5 as many as the best baseline) and achieves 28.2% code coverage, outperforming the next-best tool by 42%. Ablation studies further confirm the critical role of both perturbed generation and diversity augmentation in FLEX’s effectiveness.",
      "paperUrl": "https://doi.org/10.1109/ase63991.2025.00196",
      "sourceUrl": "",
      "tags": [
        "IR",
        "Testing",
        "ML",
        "MLIR"
      ],
      "keywords": [
        "IR",
        "Testing",
        "ML",
        "MLIR",
        "Intermediate Representation",
        "Fuzzing",
        "Self Adaptive Fuzz",
        "Adaptive Fuzz Testing",
        "Interleaved Learning"
      ],
      "matchedAuthors": [
        "Chenyao Suo",
        "Junjie Chen"
      ]
    },
    {
      "id": "openalex-w7125909708",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "IncrFuzz: LLM-Driven Incremental Fuzz Driver Generation for Library APIs",
      "authors": [
        {
          "name": "Xiao Feng",
          "affiliation": "Southeast University"
        },
        {
          "name": "Taotao Gu",
          "affiliation": "Tsinghua University"
        },
        {
          "name": "Shuaibing Lu",
          "affiliation": ""
        },
        {
          "name": "Xiaohui Kuang",
          "affiliation": "Southeast University"
        }
      ],
      "year": "2025",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "Library fuzzing requires a fuzz driver (or harness) to convert fuzzer-generated bytes into valid API calls with correct ordering and resource handling. However, writing such drivers is time-consuming, error-prone, and difficult to scale, often becoming a bottleneck in applying fuzzing to new libraries. This paper presents IncrFuzz, an incremental driver-generation framework that couples multi-dimensional function prioritization with large language model (LLM)-based iterative repair. The framework begins by ranking functions with a composite score derived from coverage data and code attributes to pinpoint high-value targets. It then enriches LLM prompts with project-specific test context to synthesize semantically correct libFuzzer drivers, and employs a compile-feedback “generate-validate-repair” loop to improve buildability. Experiments on 6 OSS-Fuzz libraries demonstrate that IncrFuzz elevates the average compilation success rate to 65.75%, produces 1.4 to over <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$25 \\times$</tex> more newly covered lines than a random baseline, and uncovers 623 and 2,140 additional lines in cJSON and libpcap, respectively. These results indicate that IncrFuzz can significantly extend existing driver coverage without manual effort, providing a practical path toward LLM-enabled large-scale library fuzzing.",
      "paperUrl": "https://doi.org/10.1109/dsc67331.2025.00093",
      "sourceUrl": "",
      "tags": [
        "Testing",
        "Libraries"
      ],
      "keywords": [
        "Testing",
        "Libraries",
        "Fuzzing",
        "Driver Generation",
        "Incrfuzz Llm Driven",
        "Library Apis",
        "Fuzz Driver Generation",
        "Library Fuzzing",
        "Driven Incremental Fuzz",
        "Incremental Fuzz Driver",
        "Llm Driven Incremental"
      ],
      "matchedAuthors": [
        "Shuaibing Lu",
        "Taotao Gu",
        "Xiaohui Kuang"
      ]
    },
    {
      "id": "openalex-w4416071090",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "HEC: Equivalence Verification Checking for Code Transformation via Equality Saturation",
      "authors": [
        {
          "name": "Jiaqi Yin",
          "affiliation": ""
        },
        {
          "name": "Song Zhan",
          "affiliation": ""
        },
        {
          "name": "Nícolas Bohm Agostini",
          "affiliation": ""
        },
        {
          "name": "Antonino Tumeo",
          "affiliation": ""
        },
        {
          "name": "Cunxi Yu",
          "affiliation": ""
        }
      ],
      "year": "2025",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "In modern computing systems, compilation employs numerous optimization techniques to enhance code performance. Source-to-source code transformations, which include control flow and datapath transformations, have been widely used in High-Level Synthesis (HLS) and compiler optimization. While researchers actively investigate methods to improve performance with source-to-source code transformations, they often overlook the significance of verifying their correctness. Current tools cannot provide a holistic verification of these transformations. This paper introduces HEC, a framework for equivalence checking that leverages the e-graph data structure to comprehensively verify functional equivalence between programs. HEC utilizes the MLIR as its frontend and integrates MLIR into the e-graph framework. Through the combination of dynamic and static e-graph rewriting, HEC facilitates the validation of comprehensive code transformations. We demonstrate effectiveness of HEC on PolyBenchC benchmarks, successfully verifying loop unrolling, tiling, and fusion transformations. HEC processes over 100,000 lines of MLIR code in 40 minutes with predictable runtime scaling. Importantly, HEC identified two critical compilation errors in mlir-opt: loop boundary check errors causing unintended executions during unrolling, and memory read-after-write violations in loop fusion that alter program semantics. These findings demonstrate HEC practical value in detecting real-world compiler bugs and highlight the importance of formal verification in optimization pipelines.",
      "paperUrl": "https://arxiv.org/pdf/2506.02290",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2506.02290",
      "tags": [
        "Frontend",
        "Performance",
        "Optimizations",
        "Loop transformations",
        "MLIR"
      ],
      "keywords": [
        "Frontend",
        "Performance",
        "Optimizations",
        "Loop transformations",
        "MLIR",
        "Loop Optimization",
        "Formal Verification",
        "Hec Equivalence Verification",
        "Equivalence Verification Checking",
        "Graph",
        "Compilation",
        "Equality Saturation"
      ],
      "matchedAuthors": [
        "Antonino Tumeo",
        "Nícolas Bohm Agostini"
      ]
    },
    {
      "id": "openalex-w4408151455",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "HDCC: A Hierarchical Dataflow-Oriented CGRA Compiler for Complex Applications",
      "authors": [
        {
          "name": "S.L. Li",
          "affiliation": "Institute of Software"
        },
        {
          "name": "Mingjie Xing",
          "affiliation": "Institute of Software"
        },
        {
          "name": "Yanjun Wu",
          "affiliation": "University of Chinese Academy of Sciences"
        }
      ],
      "year": "2025",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "CGRA(Coarse-Grained Reconfigurable Architecture) is characterized by high energy efficiency and reconfigurability, plays an important role in various complex applications. However, current CGRA compilers only handle simple inner loops and struggle with complex nested loops, making it hard to deploy large-scale complex applications on CGRA for acceleration. Therefore, we proposed a hierarchical dataflow compiler HDCC based on MLIR[1] to deal with complex loop structures in layers and developed a tool for generating dataflow graphs from MLIR intermediate code to capture the dataflow of complex loop structures. We also propose a method to deploy large-scale applications to CPU-CGRA with HDCC.The experimental results show that HDCC is capable of deploying large-scale complex applications such as neural network tasks and cryptographic tasks onto CGRA, achieving up to 11.4× performance improvement on these tasks.",
      "paperUrl": "https://doi.org/10.1145/3658617.3697563",
      "sourceUrl": "",
      "tags": [
        "Performance",
        "ML",
        "MLIR"
      ],
      "keywords": [
        "Performance",
        "ML",
        "MLIR",
        "Complex Loop Structures",
        "Dataflow Oriented CGRA",
        "Hierarchical Dataflow Oriented",
        "Scale Complex",
        "Oriented CGRA Compiler"
      ],
      "matchedAuthors": [
        "Mingjie Xing",
        "Yanjun Wu"
      ]
    },
    {
      "id": "openalex-w4417436230",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Galápagos: Automated N-Version Programming with LLMs",
      "authors": [
        {
          "name": "Javier Ron",
          "affiliation": "KTH Royal Institute of Technology"
        },
        {
          "name": "Diogo Gaspar",
          "affiliation": "KTH Royal Institute of Technology"
        },
        {
          "name": "Javier Cabrera-Arteaga",
          "affiliation": "KTH Royal Institute of Technology"
        },
        {
          "name": "Benoît Baudry",
          "affiliation": "Université de Montréal"
        },
        {
          "name": "Martin Monperrus",
          "affiliation": "KTH Royal Institute of Technology"
        }
      ],
      "year": "2025",
      "publication": "ACM Transactions on Software Engineering and Methodology",
      "venue": "ACM Transactions on Software Engineering and Methodology",
      "type": "research-paper",
      "abstract": "N-Version Programming is a well-known methodology for developing fault-tolerant systems. It achieves fault detection and correction at runtime by adding diverse redundancy into programs, minimizing fault mode overlap between redundant program variants. In this work, we propose the automated generation of program variants using large language models. We design, develop and evaluate Galápagos : a tool for generating program variants using LLMs, validating their correctness and equivalence, and using them to assemble N-Version binaries. We evaluate Galápagos by creating N-Version components of real-world C code. Our original results show that Galápagos can produce program variants that are proven to be functionally equivalent, even when the variants are written in a different programming language. Our systematic diversity measurement indicates that functionally equivalent variants produced by Galápagos , are statically different after compilation, and present diverging internal behavior at runtime. We demonstrate that the variants produced by Galápagos can protect C code against real miscompilation bugs which affect the Clang compiler. Overall, our paper shows that producing N-Version software can be drastically automated by advanced usage of practical formal verification and generative language models.",
      "paperUrl": "https://doi.org/10.1145/3785363",
      "sourceUrl": "",
      "tags": [
        "Clang",
        "Programming Languages"
      ],
      "keywords": [
        "Clang",
        "Programming Languages",
        "Formal Verification",
        "Evaluate Gal Pagos",
        "Program Variants",
        "Version Programming",
        "Functionally Equivalent",
        "Variants Produced",
        "Gal Pagos Automated"
      ],
      "matchedAuthors": [
        "Martin Monperrus"
      ]
    },
    {
      "id": "openalex-w4415274631",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "GRACE: Globally-Seeded Representation-Aware Cluster-Specific Evolution for Compiler Auto-Tuning",
      "authors": [
        {
          "name": "Hongming Pan",
          "affiliation": ""
        },
        {
          "name": "Chen Zha",
          "affiliation": ""
        },
        {
          "name": "Jiankai Dong",
          "affiliation": ""
        },
        {
          "name": "Mingjie Xing",
          "affiliation": ""
        },
        {
          "name": "Yanjun Wu",
          "affiliation": ""
        }
      ],
      "year": "2025",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Compiler pass selection and phase ordering present a significant challenge in achieving optimal program performance, particularly for objectives like code size reduction. Standard compiler heuristics offer general applicability but often yield suboptimal, program-specific results due to their one-size-fits-all nature. While iterative compilation can find tailored solutions, its prohibitive search cost limits practical use. Machine learning approaches promise faster inference but frequently struggle with generalization to unseen programs. This paper introduces GRACE, a novel framework for compiler auto-tuning, demonstrated for LLVM IR instruction count optimization. GRACE effectively curtails the search space by leveraging pass synergies and a weighted scoring method to generate initial high-quality candidate sequences and a pass pool. It then employs contrastive learning, using pass sequence-based data augmentation, to create program embeddings that facilitate similarity-aware clustering. Evolutionary search within these clusters yields a coreset of $k$ specialized pass sequences designed for robust generalization to unseen programs. At test time, GRACE efficiently selects the best coreset sequence and refines it using lightweight techniques. Experimental results on seven diverse datasets show that GRACE reduces LLVM IR instruction count by an average of 10.09% on LLVM 10.0.0 and 10.19% on LLVM 18.1.6 compared to opt -Oz, while incurring an average tuning time of less than 1s per program, demonstrating its state-of-the-art performance and practical effectiveness.",
      "paperUrl": "https://arxiv.org/pdf/2510.13176",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2510.13176",
      "tags": [
        "Performance",
        "Optimizations",
        "IR",
        "ML"
      ],
      "keywords": [
        "Performance",
        "Optimizations",
        "IR",
        "ML",
        "LLVM",
        "Intermediate Representation",
        "LLVM IR Instruction",
        "Compiler Auto Tuning",
        "IR Instruction Count",
        "Search",
        "Unseen Programs",
        "Generalization",
        "Aware Cluster Specific",
        "Cluster Specific Evolution"
      ],
      "matchedAuthors": [
        "Mingjie Xing",
        "Yanjun Wu"
      ]
    },
    {
      "id": "openalex-w4415008688",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Fuzzing C++ Compilers via Type-Driven Mutation",
      "authors": [
        {
          "name": "Bo Wang",
          "affiliation": "Beijing Jiaotong University"
        },
        {
          "name": "Chong Chen",
          "affiliation": "Beijing Jiaotong University"
        },
        {
          "name": "Ming Deng",
          "affiliation": "Beijing Jiaotong University"
        },
        {
          "name": "Junjie Chen",
          "affiliation": "Tianjin University"
        },
        {
          "name": "Xing Zhang",
          "affiliation": "Peking University"
        },
        {
          "name": "Youfang Lin",
          "affiliation": "Beijing Jiaotong University"
        },
        {
          "name": "Dan Hao",
          "affiliation": "Peking University"
        },
        {
          "name": "Jun Sun",
          "affiliation": "Singapore Management University"
        }
      ],
      "year": "2025",
      "publication": "Proceedings of the ACM on Programming Languages",
      "venue": "Proceedings of the ACM on Programming Languages | Vol. 9 (Issue OOPSLA2)",
      "type": "research-paper",
      "abstract": "C++ is a system-level programming language for modern software development, which supports multiple programming paradigms, including object-oriented, generic, and functional programming. The intrinsic complexity of these paradigms and their interactions grants C++ powerful expressiveness while posing significant challenges for compilers in correctly implementing its type system. A type system encompasses various aspects such as type inference, type checking, subtyping, type conversions, generics, scoping, and binding. However, systematic testing of the type systems of C++ compilers remains largely underexplored in existing studies. In this work, we present TyMut, the first approach specifically designed to test the C++ type system. TyMut is a mutation-based compiler fuzzer equipped with advanced type-driven mutation operators, carefully crafted to target intricate type-related features such as template generics, type conversions, and inheritance. Beyond differential testing, TyMut introduces enhanced test oracles through a must analysis that partially confirms the validity of generated programs. Specifically, mutation operators are classified into well-formed and not-well-formed: Programs generated by well-formed mutation operators are valid and must be accepted by compilers. Programs generated by not-well-formed operators are validated against a set of well-formedness rules. Any violation indicates the program is invalid and must be rejected. For programs that pass the rules but lack a definitive oracle, TyMut applies differential testing to identify behavioral inconsistencies across compilers. The testing campaign took about 32 hours to generate and test 250584 programs. The must analysis provides definite test oracles for nearly 80% of all generated programs. TyMut uncovered 102 bugs in the recent versions of GCC and Clang, with 56 confirmed as new bugs by compiler developers. Among the confirmed bugs, 26 of them cause compiler crashes, and more than 50% cause miscompilation. Additionally, 7 of them had remained hidden for over 20 years, 22 for over 10 years, and 39 for over 5 years. One long-standing bug discovered by TyMut was later confirmed as the root cause of a real-world issue in TensorFlow. Before submitting this paper, 13 bugs were fixed, most of which were fixed within 60 days. Notably, some unconfirmed bugs have led to in-depth discussions among developers. For instance, one bug led a compiler developer to submit a new issue to the C++ language standard, showing that we uncovered ambiguities in the language specification.",
      "paperUrl": "https://doi.org/10.1145/3763094",
      "sourceUrl": "",
      "tags": [
        "Clang",
        "Programming Languages",
        "Testing"
      ],
      "keywords": [
        "Clang",
        "Programming Languages",
        "Testing",
        "Type Inference",
        "Fuzzing",
        "Differential Testing",
        "Mutation Operators",
        "Type Driven Mutation",
        "Generated Programs",
        "Programs Generated",
        "Type Conversions"
      ],
      "matchedAuthors": [
        "Bo Wang",
        "Chong Chen",
        "Dan Hao",
        "Jun Sun",
        "Junjie Chen",
        "Youfang Lin"
      ]
    },
    {
      "id": "openalex-w7125902190",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Finding Bugs in MLIR Compiler Infrastructure via Lowering Space Exploration",
      "authors": [
        {
          "name": "Liang Jing-jing",
          "affiliation": "Shanghai Key Laboratory of Trustworthy Computing"
        },
        {
          "name": "Shan Huang",
          "affiliation": "Shanghai Key Laboratory of Trustworthy Computing"
        },
        {
          "name": "Ting Su",
          "affiliation": "Shanghai Key Laboratory of Trustworthy Computing"
        }
      ],
      "year": "2025",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "MLIR is a widely adopted compiler infrastructure that supports multi-level IRs and reusable components. Ensuring its correctness is critical, as bugs can propagate to downstream systems. MLIR provides a lowering mechanism that transforms high-level programs into low-level representations through configurable sequences of passes, and allows multiple valid lowering paths for a given program. This gives rise to a lowering equivalence property: all valid lowering paths for the same MLIR program should produce semantically equivalent results. In this paper, we leverage this property and propose lowering space exploration, to effectively test the MLIR infrastructure. Our approach dynamically constructs diverse lowering paths in an adaptive, stepwise manner using a feedback-based scheduling mechanism. It finds bugs by comparing the execution results across these paths. Any inconsistencies indicate potential bugs in the MLIR infrastructure. To the best of our knowledge, this is the first work to test MLIR from the perspective of exploring its compilation space. We implement our approach in a tool named LOBE and evaluate it on latest MLIR versions. LOBE discovers 38 previously unknown bugs, including 8 miscompilations and 30 crash bugs, with 25 confirmed/fixed.",
      "paperUrl": "https://doi.org/10.1109/ase63991.2025.00059",
      "sourceUrl": "",
      "tags": [
        "Infrastructure",
        "MLIR"
      ],
      "keywords": [
        "Infrastructure",
        "MLIR",
        "MLIR Infrastructure",
        "MLIR Compiler Infrastructure",
        "Valid Lowering Paths",
        "Lowering Space Exploration",
        "Finding Bugs"
      ],
      "matchedAuthors": [
        "Shan Huang",
        "Ting Su"
      ]
    },
    {
      "id": "openalex-w4409311173",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Fast Constraint Synthesis for C++ Function Templates",
      "authors": [
        {
          "name": "Shuo Ding",
          "affiliation": "Georgia Institute of Technology"
        },
        {
          "name": "Qirun Zhang",
          "affiliation": "Georgia Institute of Technology"
        }
      ],
      "year": "2025",
      "publication": "Proceedings of the ACM on Programming Languages",
      "venue": "Proceedings of the ACM on Programming Languages | Vol. 9 (Issue OOPSLA1)",
      "type": "research-paper",
      "abstract": "C++ templates are a powerful feature for generic programming and compile-time computations, but C++ compilers often emit overly verbose template error messages. Even short error messages often involve unnecessary and confusing implementation details, which are difficult for developers to read and understand. To address this problem, C++20 introduced constraints and concepts, which impose requirements on template parameters. The new features can define clearer interfaces for templates and can improve compiler diagnostics. However, manually specifying template constraints can still be non-trivial, which becomes even more challenging when working with legacy C++ projects or with frequent code changes. This paper bridges the gap and proposes an automatic approach to synthesizing constraints for C++ function templates. We utilize a lightweight static analysis to analyze the usage patterns within the template body and summarize them into constraints for each type parameter of the template. The analysis is inter-procedural and uses disjunctions of constraints to model function overloading. We have implemented our approach based on the Clang frontend and evaluated it on two C++ libraries chosen separately from two popular library sets: algorithm from the Standard Template Library (STL) and special functions from the Boost library, both of which extensively use templates. Our tool can process over 110k lines of C++ code in less than 1.5 seconds and synthesize non-trivial constraints for 30%-40% of the function templates. The constraints synthesized for algorithm align well with the standard documentation, and on average, the synthesized constraints can reduce error message lengths by 56.6% for algorithm and 63.8% for special functions.",
      "paperUrl": "https://doi.org/10.1145/3720422",
      "sourceUrl": "",
      "tags": [
        "Frontend",
        "Clang",
        "Static Analysis",
        "Programming Languages",
        "Libraries"
      ],
      "keywords": [
        "Frontend",
        "Clang",
        "Static Analysis",
        "Programming Languages",
        "Libraries",
        "Fast Constraint Synthesis",
        "Templates",
        "Library",
        "Error Messages",
        "Non Trivial"
      ],
      "matchedAuthors": [
        "Qirun Zhang"
      ]
    },
    {
      "id": "openalex-w4402953122",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Extending Polygeist to Generate OpenMP SIMD and GPU MLIR Code",
      "authors": [
        {
          "name": "Arun Thangamani",
          "affiliation": "Université de Strasbourg"
        },
        {
          "name": "Vincent Loechner",
          "affiliation": "Laboratoire des Sciences de l'Ingénieur, de l'Informatique et de l'Imagerie"
        },
        {
          "name": "Stéphane Genaud",
          "affiliation": "Université de Lorraine"
        }
      ],
      "year": "2025",
      "publication": "Lecture notes in computer science",
      "venue": "Lecture notes in computer science",
      "type": "research-paper",
      "abstract": "No abstract available in discovery metadata.",
      "paperUrl": "https://doi.org/10.1007/978-3-031-90203-1_36",
      "sourceUrl": "",
      "tags": [
        "GPU",
        "Autovectorization",
        "MLIR"
      ],
      "keywords": [
        "GPU",
        "Autovectorization",
        "MLIR",
        "SIMD",
        "Generate OpenMP Simd",
        "Extending Polygeist"
      ],
      "matchedAuthors": [
        "Vincent Loechner"
      ]
    },
    {
      "id": "openalex-w4413804064",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Enhancing Compiler Design for Machine Learning Workflows with MLIR",
      "authors": [
        {
          "name": "A.K. Tyagi",
          "affiliation": ""
        }
      ],
      "year": "2025",
      "publication": "International Journal of Science and Research Archive",
      "venue": "International Journal of Science and Research Archive | Vol. 16 (Issue 2)",
      "type": "research-paper",
      "abstract": "The rapidly changing world of machine learning (ML) workloads has added a tremendous burden on our conventional compiler infrastructures, and these systems frequently lack the flexibility, scalability, and optimization options needed to address the emerging, heterogeneous computing landscape. As ML frameworks continue to expand their support to a wide variety of hardware platforms (such as GPUs, TPUs, or FPGAs), it is critical that the corresponding compiler infrastructures accommodate the now-requisite levels of both high-level algorithmic abstractions and low-level hardware-specific optimizations. Google has developed the Multi-Level Intermediate Representation, the Multi-Level, which solves these problems by delivering a modular, extensible compiler infrastructure, optimized to the modern ML development workflow. MLIR facilitates the specification of domain-specific intermediate representations (IRs) and thus allows optimizations at many abstraction levels, including tensor algebra to hardware-specific instruction sets. This architecture enables control of code transformation at the finest grain, enables custom dialects, and has encouraged interoperability among popular ML frameworks (TensorFlow, PyTorch, JAX, and ONNX). Using MLIR as a compiler design aspect, developers gain both better portable compilation and higher optimization granularity, as well as time-reducing development. In addition, MLIR progresses in the realization of AI-specific compiler optimizations, including quantization, operator fusion, and parallel execution scheduling. Finally, MLIR is an important step in compiler design that will not only deliver more performance on ML applications, but also a more maintainable and extensible ecosystem for future AI-driven computing systems. This paper discusses the new paradigm offered by MLIR, its ability to redefine compiler infrastructure to satisfy the sophisticated needs of present ML workloads, and the avenue to more intelligent, flexible, and resource-efficient software-hardware integration.",
      "paperUrl": "https://doi.org/10.30574/ijsra.2025.16.2.2463",
      "sourceUrl": "",
      "tags": [
        "Performance",
        "Optimizations",
        "GPU",
        "IR",
        "AI",
        "Infrastructure",
        "ML",
        "MLIR"
      ],
      "keywords": [
        "Performance",
        "Optimizations",
        "GPU",
        "IR",
        "AI",
        "Infrastructure",
        "ML",
        "MLIR",
        "Intermediate Representation",
        "Heterogeneous Computing",
        "Hardware",
        "Hardware Specific",
        "Machine Learning Workflows",
        "Compiler Infrastructures"
      ],
      "matchedAuthors": [
        "A.K. Tyagi"
      ]
    },
    {
      "id": "openalex-w4406734799",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "ENOLA: Efficient Control-Flow Attestation for Embedded Systems",
      "authors": [
        {
          "name": "Md Armanuzzaman",
          "affiliation": ""
        },
        {
          "name": "Engin Kirda",
          "affiliation": ""
        },
        {
          "name": "Ziming Zhao",
          "affiliation": ""
        }
      ],
      "year": "2025",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Microcontroller-based embedded systems are vital in daily life, but are especially vulnerable to control-flow hijacking attacks due to hardware and software constraints. Control-Flow Attestation (CFA) aims to precisely attest the execution path of a program to a remote verifier. However, existing CFA solutions face challenges with large measurement and/or trace data, limiting these solutions to small programs. In addition, slow software-based measurement calculations limit their feasibility for microcontroller systems. In this paper, we present ENOLA, an efficient control-flow attestation solution for low-end embedded systems. ENOLA introduces a novel authenticator that achieves linear space complexity. Moreover, ENOLA capitalizes on the latest hardware-assisted message authentication code computation capabilities found in commercially-available devices for measurement computation. ENOLA employs a trusted execution environment, and allocates general-purpose registers to thwart memory corruption attacks. We have developed the ENOLA compiler through LLVM passes and attestation engine on the ARMv8.1-M architecture. Our evaluations demonstrate ENOLA's effectiveness in minimizing data transmission, while achieving lower or comparable performance to the existing works.",
      "paperUrl": "https://arxiv.org/pdf/2501.11207",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2501.11207",
      "tags": [
        "Performance",
        "Embedded"
      ],
      "keywords": [
        "Performance",
        "Embedded",
        "LLVM",
        "Control Flow Attestation",
        "Measurement",
        "Hardware"
      ],
      "matchedAuthors": [
        "Engin Kirda"
      ]
    },
    {
      "id": "openalex-w4416429512",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "DynVec: An End-to-End Framework for Efficient Vector-Dataflow Execution",
      "authors": [
        {
          "name": "Jiangnan Li",
          "affiliation": "Fudan University"
        },
        {
          "name": "Xianfeng Cao",
          "affiliation": "Fudan University"
        },
        {
          "name": "Kaixiang Zhu",
          "affiliation": "Fudan University"
        },
        {
          "name": "Wenbo Yin",
          "affiliation": "Fudan University"
        },
        {
          "name": "Lingli Wang",
          "affiliation": "Fudan University"
        }
      ],
      "year": "2025",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "High-performance computing (HPC) and hardware acceleration increasingly rely on dataflow architectures to achieve scalable parallelism and efficiency. High-level synthesis (HLS) facilitates accelerator design from high-level programs, but conventional tools often require intrusive source-level modifications and struggle to optimize irregular workloads. Dynamically scheduled HLS frameworks offer a promising direction for addressing control flow divergence and memory irregularity by generating dataflow accelerators. However, they lack compile-time parallelism optimizations such as vectorization and incur significant hardware overhead. Moreover, modern compilers can generate vectorized code using memory access and computational patterns. Nevertheless, in programs with irregular control flow or data-dependent behavior, such patterns are unknown until runtime, limiting the effectiveness of static vectorization strategies.To address these challenges, we propose DynVec, a unified vector-dataflow framework that integrates dynamic scheduling and vectorization to exploit runtime parallelism beyond conventional models. We address the vectorization of irregular kernels through an MLIR-based context-aware vectorizer that effectively identifies vectorizable operations and, through dataflow scheduling, generates a vector-dataflow execution graph that explicitly models control flow constructs, data and control interfaces, and memory operations. DynVec encapsulates high-level elastic units designed with built-in vectorization support, allowing customizable and adaptive execution behavior. Our compiler preserves the structural hierarchy of the kernel by combining vector and scalar operations in a bottom-up, type-safe manner. Experiments show that our approach achieves significant speedup compared to state-of-the-art HLS implementations across various regular and irregular applications. Moreover, compared to hybrid accelerators that separately support dynamic parallelism and vectorization, DynVec delivers superior performance.",
      "paperUrl": "https://doi.org/10.1109/iccad66269.2025.11240863",
      "sourceUrl": "",
      "tags": [
        "Performance",
        "Optimizations",
        "Autovectorization",
        "MLIR"
      ],
      "keywords": [
        "Performance",
        "Optimizations",
        "Autovectorization",
        "MLIR",
        "Vector Dataflow Execution",
        "Dynvec",
        "Control Flow",
        "Irregular",
        "Parallelism",
        "HLS",
        "Memory",
        "Operations",
        "Hardware"
      ],
      "matchedAuthors": [
        "Jiangnan Li",
        "Lingli Wang",
        "Wenbo Yin"
      ]
    },
    {
      "id": "openalex-w4411528186",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "DuoLingo-AutoDiff: In-Database Automatic Differentiation with MLIR",
      "authors": [
        {
          "name": "Kevin Gutjahr",
          "affiliation": "University of Bamberg"
        },
        {
          "name": "Clemens Ruck",
          "affiliation": "University of Bamberg"
        },
        {
          "name": "Maximilian E. Schüle",
          "affiliation": "University of Bamberg"
        }
      ],
      "year": "2025",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "Forward and reverse mode automatic differentiation evaluate the gradient of a model function efficiently by caching the results of partial derivatives. Just-in-time compilation improves the runtime of automatic differentiation by eliminating function calls and storing partial derivatives in virtual registers. This paper discusses the first open-source implementation of automatic differentiation with MLIR and LingoDB. The evaluation compares optimizations applied to forward and reverse modes. It showed that sub-expressions, that appear frequently within the calculation, will be reused after MLIR performs its optimization. Additionally, reverse mode outperforms forward mode due to less generated code.",
      "paperUrl": "https://dl.acm.org/doi/pdf/10.1145/3735654.3735943",
      "sourceUrl": "https://doi.org/10.1145/3735654.3735943",
      "tags": [
        "Optimizations",
        "MLIR"
      ],
      "keywords": [
        "Optimizations",
        "MLIR",
        "Database Automatic Differentiation",
        "Forward",
        "Reverse Mode",
        "Partial Derivatives",
        "Duolingo Autodiff"
      ],
      "matchedAuthors": [
        "Maximilian E. Schüle"
      ]
    },
    {
      "id": "openalex-w4416004081",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Distributed Sparse Tensor Computations in MLIR",
      "authors": [
        {
          "name": "Miheer Vaidya",
          "affiliation": "University of Utah"
        },
        {
          "name": "Shreya Singh",
          "affiliation": "University of Utah"
        },
        {
          "name": "Devanshu Mantri",
          "affiliation": "University of Utah"
        },
        {
          "name": "Michael Shannon Eydenberg",
          "affiliation": "Sandia National Laboratories"
        },
        {
          "name": "Brian E. Kelley",
          "affiliation": "Sandia National Laboratories"
        },
        {
          "name": "Sivasankaran Rajamanickam",
          "affiliation": "Sandia National Laboratories"
        },
        {
          "name": "Atanas Rountev",
          "affiliation": "The Ohio State University"
        },
        {
          "name": "P. Sadayappan",
          "affiliation": "University of Utah"
        }
      ],
      "year": "2025",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "MLIR (Multi-Level Intermediate Representation) is a popular framework for implementing domain-specific compilers for optimizing matrix/tensor computations. However, no support currently exists in MLIR for distributed sparse tensor computations. In this paper, we describe the design and implementation of a new MLIR dialect for high-level specification of distributed sparse tensor computations. This specification is then lowered to MPI-based code for distributed execution. We illustrate the expressiveness of the new dialect using a Graph Attention Network computation with multiple sparse tensor operators.",
      "paperUrl": "https://doi.org/10.1145/3731599.3767484",
      "sourceUrl": "",
      "tags": [
        "IR",
        "MLIR"
      ],
      "keywords": [
        "IR",
        "MLIR",
        "Intermediate Representation",
        "Distributed Sparse Tensor",
        "Sparse Tensor Computations"
      ],
      "matchedAuthors": [
        "Brian E. Kelley",
        "P. Sadayappan",
        "Sivasankaran Rajamanickam"
      ]
    },
    {
      "id": "openalex-w4407857946",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "DialEgg: Dialect-Agnostic MLIR Optimizer using Equality Saturation with Egglog",
      "authors": [
        {
          "name": "Abd-El-Aziz Zayed",
          "affiliation": "McGill University"
        },
        {
          "name": "Christophe Dubach",
          "affiliation": "McGill University"
        }
      ],
      "year": "2025",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "MLIR’s ability to optimize programs at multiple levels of abstraction is key to enabling domain-specific optimizing compilers. However, expressing optimizations remains tedious. Optimizations can interact in unexpected ways, making it hard to unleash full performance. Equality saturation promises to solve these challenges. First, it simplifies the expression of optimizations using rewrite rules. Secondly, it considers all possible optimization interactions, through saturation, selecting the best program variant. Despite these advantages, equality saturation remains absent from production compilers such as MLIR. This paper proposes to integrate Egglog, a recent equality saturation engine, with MLIR, in a dialect-agnostic manner. This paper shows how the main MLIR constructs such as operations, types or attributes can be modeled in Egglog. It also presents DialEgg, a tool that pre-defines a large set of common MLIR constructs in Egglog and automatically translates between the MLIR and Egglog program representations. Using a few use-cases, this paper demonstrates the potential for combining equality saturation and MLIR.",
      "paperUrl": "https://doi.org/10.1145/3696443.3708957",
      "sourceUrl": "",
      "tags": [
        "Performance",
        "Optimizations",
        "MLIR"
      ],
      "keywords": [
        "Performance",
        "Optimizations",
        "MLIR",
        "MLIR Constructs",
        "Equality Saturation",
        "Egglog",
        "Dialect Agnostic MLIR",
        "Agnostic MLIR Optimizer",
        "Dialegg Dialect Agnostic"
      ],
      "matchedAuthors": [
        "Christophe Dubach"
      ]
    },
    {
      "id": "openalex-w7128231099",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Device Offloading MemorySanitizer for SYCL",
      "authors": [
        {
          "name": "Yang Zhao",
          "affiliation": ""
        },
        {
          "name": "Maosu Zhao",
          "affiliation": ""
        },
        {
          "name": "Yingcong Wu",
          "affiliation": ""
        },
        {
          "name": "Wenju He",
          "affiliation": ""
        },
        {
          "name": "Ge Jin",
          "affiliation": ""
        },
        {
          "name": "Chunyang Dai",
          "affiliation": ""
        }
      ],
      "year": "2025",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "No abstract available in discovery metadata.",
      "paperUrl": "https://doi.org/10.1145/3731125.3731135",
      "sourceUrl": "",
      "tags": [
        "GPU"
      ],
      "keywords": [
        "GPU",
        "Offloading",
        "Device Offloading Memorysanitizer"
      ],
      "matchedAuthors": [
        "Chunyang Dai",
        "Ge Jin",
        "Maosu Zhao",
        "Wenju He",
        "Yang Zhao",
        "Yingcong Wu"
      ]
    },
    {
      "id": "openalex-w4406231129",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Decompiling for Constant-Time Analysis",
      "authors": [
        {
          "name": "Santiago Arranz Olmos",
          "affiliation": ""
        },
        {
          "name": "Gilles Barthe",
          "affiliation": ""
        },
        {
          "name": "Lionel Blatter",
          "affiliation": ""
        },
        {
          "name": "Sören van der Wall",
          "affiliation": ""
        },
        {
          "name": "Zhiyuan Zhang",
          "affiliation": ""
        },
        {
          "name": "Zhang, Zhiyuan",
          "affiliation": ""
        }
      ],
      "year": "2025",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Cryptographic libraries are a main target of timing side-channel attacks. A practical means to protect against these attacks is to adhere to the constant-time (CT) policy. However, it is hard to write constant-time code, and even constant-time code can be turned vulnerable by mainstream compilers. So how can we verify that binary code is constant-time? The obvious answer is to use binary-level CT tools. To do so, a common approach is to use decompilers or lifters as a front-end for CT analysis tools operating on source code or IR. Unfortunately, this approach is problematic with current decompilers. To illustrate this fact, we use the recent Clangover vulnerability and other constructed examples to show that five popular decompilers eliminate CT violations, rendering them not applicable with the approach. In this paper, we develop foundations to asses whether a decompiler is fit for the Decompile-then-Analyze approach. We propose CT transparency, which states that a transformation neither eliminates nor introduces CT violations, and a general method for proving that a program transformation is CT transparent. Then, we build CT-RetDec, a CT analysis tool based on a modified version of the LLVM-based decompiler RetDec. We evaluate CT-RetDec on a benchmark of real-world vulnerabilities in binaries, and show that the modifications had significant impact on CT-RetDec's performance. As a contribution of independent interest, we found that popular tools for binary-level CT analysis rely on decompiler-like transformations before analysis. We show that two such tools employ transformations that are not CT transparent, and, consequently, that they incorrectly accept non-CT programs. While our examples are very specific and do not invalidate the general approach of these tools, we advocate that tool developers counter such potential issues by proving the transparency of such transformations.",
      "paperUrl": "https://arxiv.org/pdf/2501.04183",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2501.04183",
      "tags": [
        "Performance",
        "IR",
        "Libraries"
      ],
      "keywords": [
        "Performance",
        "IR",
        "Libraries",
        "LLVM",
        "Constant",
        "Retdec",
        "Binary",
        "Decompilers",
        "Transformations"
      ],
      "matchedAuthors": [
        "Gilles Barthe"
      ]
    },
    {
      "id": "openalex-w4407197237",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Debugger Toolchain Validation via Cross-Level Debugging",
      "authors": [
        {
          "name": "Yibiao Yang",
          "affiliation": "Nanjing University"
        },
        {
          "name": "Maolin Sun",
          "affiliation": "Nanjing University"
        },
        {
          "name": "Jiangchang Wu",
          "affiliation": "Nanjing University"
        },
        {
          "name": "Qingyang Li",
          "affiliation": "Nanjing University"
        },
        {
          "name": "Yuming Zhou",
          "affiliation": "Nanjing University"
        }
      ],
      "year": "2025",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "Ensuring the correctness of debugger toolchains is of paramount importance, as they play a vital role in understanding and resolving programming errors during software development. Bugs hidden within these toolchains can significantly mislead developers. Unfortunately, comprehensive testing of debugger toolchains is lacking due to the absence of effective test oracles. Existing studies on debugger toolchain validation have primarily focused on validating the debug information within optimized executables by comparing the traces between debugging optimized and unoptimized executables (i.e., different executables) in the debugger, under the assumption that the traces obtained from debugging unoptimized executables serve as a reliable oracle. However, these techniques suffer from inherent limitations, as compiler optimizations can drastically alter source code elements, variable representations, and instruction order, rendering the traces obtained from debugging different executables incomparable and failing to uncover bugs in debugger toolchains when debugging unoptimized executables. To address these limitations, we propose a novel concept called Cross-Level Debugging (CLD) for validating the debugger toolchain. CLD compares the traces obtained from debugging the same executable using source-level and instruction-level strategies within the same debugger. The core insight of CLD is that the execution traces obtained from different debugging levels for the same executable should adhere to specific relationships, regardless of whether the executable is generated with or without optimization. We formulate three key relations in CLD: reachability preservation of program locations, order preservation for reachable program locations, and value consistency at program locations, which apply to traces at different debugging levels. We implement Devil, a practical framework that employs these relations for debugger toolchain validation. We evaluate the effectiveness of Devil using two widely used production debugger toolchains, GDB and LLDB. Ultimately, Devil successfully identified 27 new bug reports, of which 18 have been confirmed and 12 have been fixed by developers.",
      "paperUrl": "https://doi.org/10.1145/3669940.3707271",
      "sourceUrl": "",
      "tags": [
        "Optimizations",
        "LLDB",
        "Testing",
        "Infrastructure",
        "Debug Information"
      ],
      "keywords": [
        "Optimizations",
        "LLDB",
        "Testing",
        "Infrastructure",
        "Debug Information",
        "Debugger Toolchains",
        "Debugging Unoptimized Executables",
        "Traces Obtained",
        "Debugger Toolchain Validation",
        "Program Locations",
        "Debugging Levels",
        "Same Executable"
      ],
      "matchedAuthors": [
        "Jiangchang Wu",
        "Maolin Sun",
        "Qingyang Li",
        "Yibiao Yang",
        "Yuming Zhou"
      ]
    },
    {
      "id": "openalex-w4403012200",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "DSP-MLIR: A Domain-Specific Language and MLIR Dialect for Digital Signal Processing",
      "authors": [
        {
          "name": "Abhinav Kumar",
          "affiliation": "Arizona State University"
        },
        {
          "name": "Atharva Khedkar",
          "affiliation": "Arizona State University"
        },
        {
          "name": "Aviral Shrivastava",
          "affiliation": "Yonsei University"
        },
        {
          "name": "Megan Kuo",
          "affiliation": "Arizona State University"
        },
        {
          "name": "Ameya Gurjar",
          "affiliation": "Arizona State University"
        },
        {
          "name": "Partha Biswas",
          "affiliation": "MathWorks (United States)"
        }
      ],
      "year": "2025",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Traditional Digital Signal Processing ( DSP ) compilers work at low level ( C-level / assembly level ) and hence lose much of the optimization opportunities present at high-level ( domain-level ). The emerging multi-level compiler infrastructure MLIR ( Multi-level Intermediate Representation ) allows to specify optimizations at higher level. In this paper, we utilize MLIR framework to introduce a DSP Dialect and perform domain-specific optimizations at dialect -level ( high-level ) and show the usefulness of these optimizations on sample DSP apps. In particular, we develop a compiler for DSP and a DSL (Domain Specific Language) to ease the development of apps. We show the performance improvement in execution time for these sample apps by upto 10x which would have been difficult if the IR were at C/ affine level.",
      "paperUrl": "https://dl.acm.org/doi/pdf/10.1145/3735452.3735527",
      "sourceUrl": "https://doi.org/10.1145/3735452.3735527",
      "tags": [
        "Performance",
        "Optimizations",
        "IR",
        "Infrastructure",
        "MLIR"
      ],
      "keywords": [
        "Performance",
        "Optimizations",
        "IR",
        "Infrastructure",
        "MLIR",
        "Intermediate Representation",
        "Domain Specific Language",
        "Digital Signal Processing",
        "MLIR Dialect"
      ],
      "matchedAuthors": [
        "Aviral Shrivastava"
      ]
    },
    {
      "id": "openalex-w4414988639",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "DESIL: Detecting Silent Bugs in MLIR Compiler Infrastructure",
      "authors": [
        {
          "name": "Chenyao Suo",
          "affiliation": "Tianjin University"
        },
        {
          "name": "Jianrong Wang",
          "affiliation": "Tianjin University"
        },
        {
          "name": "Y. F. Wang",
          "affiliation": "Tianjin University"
        },
        {
          "name": "Jiajun Jiang",
          "affiliation": "Tianjin University"
        },
        {
          "name": "Qingchao Shen",
          "affiliation": "Tianjin University"
        },
        {
          "name": "Junjie Chen",
          "affiliation": "Tianjin University"
        }
      ],
      "year": "2025",
      "publication": "Proceedings of the ACM on Programming Languages",
      "venue": "Proceedings of the ACM on Programming Languages | Vol. 9 (Issue OOPSLA2)",
      "type": "research-paper",
      "abstract": "MLIR (Multi-Level Intermediate Representation) compiler infrastructure provides an efficient framework for introducing a new abstraction level for programming languages and domain-specific languages. It has attracted widespread attention in recent years and has been applied in various domains, such as deep learning compiler construction. Recently, several MLIR compiler fuzzing techniques, such as MLIRSmith and MLIRod, have been proposed. However, none of them can detect silent bugs, i.e., bugs that incorrectly optimize code silently. The difficulty in detecting silent bugs arises from two main aspects: (1) UB-Free Program Generation: Generates programs that are free from undefined behaviors to suit the non-UB assumptions required by compiler optimizations. (2) Lowering Support: Converts the given MLIR program into an executable form with a suitable lowering path that reduces redundant lowering passes and improves the efficiency of fuzzing. To address the above issues, we propose DESIL. DESIL enables silent bug detection by defining a set of UB-elimination rules based on the MLIR documentation and applying them to input programs. To convert dialects in the MLIR program into executable form, DESIL designs a lowering path optimization strategy to convert the dialects in the given MLIR program into executable form. Furthermore, DESIL incorporates the differential testing for silent bug detection. It introduces an operation-aware optimization recommendation strategy into the compilation process to generate diverse executable files. We applied DESIL to the latest revisions of the MLIR compiler infrastructure. It detected 23 silent bugs and 19 crash bugs, of which 17/16 have been confirmed or fixed.",
      "paperUrl": "https://doi.org/10.1145/3763161",
      "sourceUrl": "",
      "tags": [
        "Optimizations",
        "IR",
        "Programming Languages",
        "Testing",
        "Infrastructure",
        "ML",
        "MLIR"
      ],
      "keywords": [
        "Optimizations",
        "IR",
        "Programming Languages",
        "Testing",
        "Infrastructure",
        "ML",
        "MLIR",
        "Intermediate Representation",
        "Fuzzing",
        "Differential Testing",
        "MLIR Compiler",
        "Detecting Silent Bugs",
        "MLIR Compiler Infrastructure",
        "Executable Form"
      ],
      "matchedAuthors": [
        "Chenyao Suo",
        "Jiajun Jiang",
        "Junjie Chen"
      ]
    },
    {
      "id": "openalex-w4411144230",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Cross-Architecture Binary Code Similarity Detection Based on Hybrid Neural Networks",
      "authors": [
        {
          "name": "Hongjuan Pei",
          "affiliation": "Shanghai Jiao Tong University"
        },
        {
          "name": "Yuanfang Chen",
          "affiliation": "Hangzhou Dianzi University"
        },
        {
          "name": "Siyong Lu",
          "affiliation": "Shanghai Jiao Tong University"
        },
        {
          "name": "JinLiang Xue",
          "affiliation": "Shanghai Jiao Tong University"
        }
      ],
      "year": "2025",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "Binary code similarity detection is a technique that analyzes the semantic and structural features of binary code, compares it with known vulnerable code for similarity, and determines whether the tested code contains vulnerabilities. With the increasing complexity of firmware vulnerabilities in IoT devices, binary code similarity detection has become a core task in firmware security analysis. However, existing methods face challenges in accurately modeling binary code semantics across architectures(ARM/x86/MIPS) and compilers(GCC/Clang), resulting in low precision and accuracy. This paper proposes a novel hybrid model, CABech, which integrates a natural language processing module(DeBERTa-V3) with a Multi-Track Graph Convolutional Network(MTGCN) for semantic feature vector extraction. The model also incorporates Low-Rank Adaptation(LoRA) technology into the NLP module to reduce training parameters and computational costs. DeBERTa- V3 enhances semantic modeling of binary code through its decoupled attention mechanism.MTGCN mitigates the over-smoothing issue in traditional GCN by separating structural features of binary code via multi-track message passing. The low-rank adaptive matrix fine-tunes the parameters of DeBERTa- V3,making the model suitable for resource-constrained firmware analysis terminals. Experiments demonstrate that our model outperforms state-of-the-art methods in cross-architecture and cross-compiler tasks, achieving improvements of 3.4% in accuracy, 4.0% in precision, and 1.9% in F1-score.",
      "paperUrl": "https://doi.org/10.1109/icaace65325.2025.11020079",
      "sourceUrl": "",
      "tags": [
        "Security",
        "Clang",
        "ML"
      ],
      "keywords": [
        "Security",
        "Clang",
        "ML",
        "Binary",
        "Similarity Detection",
        "Cross Architecture Binary",
        "Deberta",
        "Firmware",
        "Semantic",
        "Multi Track",
        "Hybrid Neural Networks"
      ],
      "matchedAuthors": [
        "Yuanfang Chen"
      ]
    },
    {
      "id": "openalex-w4417097910",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "CompilerGPT: Leveraging Large Language Models for Analyzing and Acting on Compiler Optimization Reports",
      "authors": [
        {
          "name": "Peter Pirkelbauer",
          "affiliation": ""
        },
        {
          "name": "Chunhua Liao",
          "affiliation": ""
        }
      ],
      "year": "2025",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Current compiler optimization reports often present complex, technical information that is difficult for programmers to interpret and act upon effectively. This paper assesses the capability of large language models (LLM) to understand compiler optimization reports and automatically rewrite the code accordingly. To this end, the paper introduces CompilerGPT, a novel framework that automates the interaction between compilers, LLMs, and user defined test and evaluation harness. CompilerGPT's workflow runs several iterations and reports on the obtained results. Experiments with two leading LLM models (GPT-4o and Claude Sonnet), optimization reports from two compilers (Clang and GCC), and five benchmark codes demonstrate the potential of this approach. Speedups of up to 6.5x were obtained, though not consistently in every test. This method holds promise for improving compiler usability and streamlining the software optimization process.",
      "paperUrl": "https://arxiv.org/pdf/2506.06227",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2506.06227",
      "tags": [
        "Clang",
        "Optimizations"
      ],
      "keywords": [
        "Clang",
        "Optimizations",
        "Compiler Optimization Reports",
        "Compilergpt Leveraging"
      ],
      "matchedAuthors": [
        "Chunhua Liao"
      ]
    },
    {
      "id": "openalex-w4407863032",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Combining MLIR Dialects with Domain-Specific Architecture for Efficient Regular Expression Matching",
      "authors": [
        {
          "name": "Andrea Somaini",
          "affiliation": "Politecnico di Milano"
        },
        {
          "name": "Filippo Carloni",
          "affiliation": "Politecnico di Milano"
        },
        {
          "name": "Giovanni Agosta",
          "affiliation": "Politecnico di Milano"
        },
        {
          "name": "Marco D. Santambrogio",
          "affiliation": "Politecnico di Milano"
        },
        {
          "name": "Davide Conficconi",
          "affiliation": "Politecnico di Milano"
        }
      ],
      "year": "2025",
      "publication": "Virtual Community of Pathological Anatomy (University of Castilla La Mancha)",
      "venue": "Virtual Community of Pathological Anatomy (University of Castilla La Mancha)",
      "type": "research-paper",
      "abstract": "Pattern matching based on Regular Expressions (REs) is a pervasive and challenging computational kernel used in several applications to identify critical information in a data stream. Due to the sequential data dependency of REs and the increasing data volume growth, hardware acceleration is gaining attention to address the limitation of general-purpose architectures. RE-oriented Domain-Specific Architectures (DSAs) combine the flexibility of translating REs into binary code with the efficiency of a specialized architecture, filling the gap between frozen hardware accelerators and the versatility of CPUs/GPUs. However, existing DSAs focus mainly on the efficiency execution challenge while missing the optimization opportunities that a structured compilation infrastructure can provide. This paper proposes a RE-tailored multi-level intermediate representation strategy embodied by the MLIR framework at the compiler level to exploit different abstraction optimizations via two domain-specific dialects, one targeting the abstract representation of REs and the other targeting the underlying domain-specific ISA. Moreover, this paper proposes a novel architectural organization of an open-source state-of-the-art DSA to maximize the parallelization capabilities. Overall, the proposed approach significantly improves execution time by up to 2.26×, energy efficiency by up to 2.30×, and resource usage.",
      "paperUrl": "https://doi.org/10.1145/3696443.3708916",
      "sourceUrl": "",
      "tags": [
        "Optimizations",
        "GPU",
        "IR",
        "Infrastructure",
        "MLIR"
      ],
      "keywords": [
        "Optimizations",
        "GPU",
        "IR",
        "Infrastructure",
        "MLIR",
        "Intermediate Representation",
        "Domain Specific Architecture",
        "Efficiency",
        "Combining MLIR Dialects",
        "Hardware",
        "Regular Expression Matching"
      ],
      "matchedAuthors": [
        "Giovanni Agosta",
        "Marco D. Santambrogio"
      ]
    },
    {
      "id": "openalex-w4410582995",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "ChemComp: Compiling and Computing with Chemical Reaction Networks",
      "authors": [
        {
          "name": "Nícolas Bohm Agostini",
          "affiliation": "Pacific Northwest National Laboratory"
        },
        {
          "name": "Connah Johnson",
          "affiliation": "Pacific Northwest National Laboratory"
        },
        {
          "name": "William R. Cannon",
          "affiliation": "Pacific Northwest National Laboratory"
        },
        {
          "name": "Antonino Tumeo",
          "affiliation": "Pacific Northwest National Laboratory"
        }
      ],
      "year": "2025",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "The exponential growth in computing demands driven by scientific computing, data analytics, and artificial intelligence is pushing conventional CMOS-based high-performance computing systems to their physical and energy efficiency limits. As we approach the era of post-exascale computing, disruptive approaches are necessary to overcome these barriers and achieve substantial gains in energy efficiency. Analog and hybrid digital-analog computing systems have emerged as promising alternatives, offering the potential for orders-of-magnitude improvements in efficiency. Among these, biochemical computing stands out as a novel paradigm capable of leveraging the natural efficiency of chemical reactions, which have shown promise in solving optimization problems by converging to steady states. By scaling up reaction networks or reaction vessel sizes, biochemical systems present an opportunity to meet the high-performance demands of modern computing tasks. Despite their promise, significant theoretical and practical challenges remain, particularly in formulating and mapping computational problems to chemical reaction networks (CRNs) and designing viable biochemical computing devices. This paper addresses these challenges by introducing new ideas to ChemComp, a compilation and emulation framework for chemical computation. This work describes the mechanisms through which solutions to ordinary differential equations (ODEs) that can be represented as CRN systems can be achieved. Furthermore, we explain the design principles of an ODE dialect implemented as a multi-level intermediate representation (MLIR) compiler extension that will be coupled with existing infrastructure. We demonstrate the potential of our framework through a case study emulating a simplified chemical reservoir computing device. This work establishes foundational tools and methodologies necessary to harness the computational power of chemistry, paving the way for the development of energy-efficient, high-performance computing systems tailored to contemporary and future computational needs.",
      "paperUrl": "https://doi.org/10.23919/date64628.2025.10993207",
      "sourceUrl": "",
      "tags": [
        "Performance",
        "Optimizations",
        "IR",
        "AI",
        "Infrastructure",
        "MLIR"
      ],
      "keywords": [
        "Performance",
        "Optimizations",
        "IR",
        "AI",
        "Infrastructure",
        "MLIR",
        "Intermediate Representation",
        "Biochemical Computing",
        "Chemical Reaction Networks",
        "Efficiency",
        "Computational",
        "Energy Efficiency",
        "Performance Computing",
        "Chemcomp Compiling"
      ],
      "matchedAuthors": [
        "Antonino Tumeo",
        "Nícolas Bohm Agostini"
      ]
    },
    {
      "id": "openalex-w4416004001",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Characterizing the Performance of Parallel Data-Compression Algorithms across Compilers and GPUs",
      "authors": [
        {
          "name": "Brandon Alexander Burtchell",
          "affiliation": "Texas State University"
        },
        {
          "name": "Martin Burtscher",
          "affiliation": "Texas State University"
        }
      ],
      "year": "2025",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "Different compilers can generate code with notably different performance characteristics—even on the same system. Today, GPU developers have three popular options for compiling CUDA or HIP code for GPUs. First, CUDA code can be compiled by either NVCC or Clang for NVIDIA GPUs. Alternatively, AMD’s recently introduced HIP platform makes porting from CUDA to HIP relatively simple, enabling compilation for AMD and NVIDIA GPUs. This study compares the performance of 107,632 data-compression algorithms when compiling them with different compilers and running them on different GPUs from NVIDIA and AMD. We find that the relative performance of some of these codes changes significantly depending on the compiler and hardware used. For example, Clang tends to produce relatively slow compressors but relatively fast decompressors compared to NVCC and HIPCC.",
      "paperUrl": "https://doi.org/10.1145/3731599.3767369",
      "sourceUrl": "",
      "tags": [
        "Performance",
        "Clang",
        "GPU",
        "CUDA"
      ],
      "keywords": [
        "Performance",
        "Clang",
        "GPU",
        "CUDA",
        "HIP",
        "Nvidia Gpus"
      ],
      "matchedAuthors": [
        "Martin Burtscher"
      ]
    },
    {
      "id": "openalex-w4417143970",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Bootstrapping Fuzzers for Compilers of Low-Resource Language Dialects Using Language Models",
      "authors": [
        {
          "name": "Sairam Vaidya",
          "affiliation": ""
        },
        {
          "name": "Marcel Böhme",
          "affiliation": ""
        },
        {
          "name": "Loris D’Antoni",
          "affiliation": ""
        }
      ],
      "year": "2025",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Modern extensible compiler frameworks-such as MLIR-enable rapid creation of domain-specific language dialects. This flexibility, however, makes correctness harder to ensure as the same extensibility that accelerates development also complicates maintaining the testing infrastructure. Extensible languages require automated test generation that is both dialect-agnostic (works across dialects without manual adaptation) and dialect-effective (targets dialect-specific features to find bugs). Existing approaches typically sacrifice one of these goals by either requiring manually constructed seed corpora for each dialect, or by failing to be effective. We present a dialect-agnostic and dialect-effective grammar-based and coverage-guided fuzzing approach for extensible compilers that combines two key insights from existing work: (i) the grammars of dialects, which already encode the structural and type constraints, can often be extracted automatically from the dialect specification; and (ii) these grammars can be used in combination with pre-trained large language models to automatically generate representative and diverse seed inputs from the full dialect space without requiring any manual input or training data. These seeds can then be used to bootstrap coverage-guided fuzzers. We built this approach into a tool, Germinator. When evaluated on six MLIR projects spanning 91 dialects, Germinator generated seeds improve line coverage by 10-120% over grammar-based baselines. We compare against grammar-based baselines because they are the only class of existing automatic seed generators that can be applied uniformly across MLIR's heterogeneous dialect ecosystem. Germinator discovers 88 previously unknown bugs (40 confirmed), including 23 in dialects with no prior automated test generators, demonstrating effective and controllable testing of low-resource dialects at scale.",
      "paperUrl": "https://arxiv.org/pdf/2512.05887",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2512.05887",
      "tags": [
        "Testing",
        "Infrastructure",
        "MLIR"
      ],
      "keywords": [
        "Testing",
        "Infrastructure",
        "MLIR",
        "Fuzzing",
        "Resource Language Dialects",
        "Coverage Guided",
        "Extensible",
        "Germinator",
        "Grammar",
        "Dialect Agnostic",
        "Bootstrapping Fuzzers"
      ],
      "matchedAuthors": [
        "Loris D’Antoni"
      ]
    },
    {
      "id": "openalex-w4412884031",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Annotation‐Guided AoS‐to‐SoA Conversions and GPU Offloading With Data Views in C++",
      "authors": [
        {
          "name": "Pawel K. Radtke",
          "affiliation": "Durham University"
        },
        {
          "name": "Tobias Weinzierl",
          "affiliation": "Durham University"
        }
      ],
      "year": "2025",
      "publication": "Concurrency and Computation Practice and Experience",
      "venue": "Concurrency and Computation Practice and Experience | Vol. 37 (Issue 21-22)",
      "type": "research-paper",
      "abstract": "ABSTRACT The C++ programming language provides classes and structs as fundamental modeling entities. Consequently, C++ code tends to favor array‐of‐structs (AoS) for encoding data sequences, even though structure‐of‐arrays (SoA) yields better performance for some calculations. We propose a C++ language extension based on attributes that allows developers to guide the compiler in selecting memory arrangements, that is, to select the optimal choice between AoS and SoA dynamically depending on both the execution context and algorithm step. The compiler can then automatically convert data into the preferred format prior to the calculations and convert results back afterward. The compiler handles all the complexity of determining which data to convert and how to manage data transformations. Our implementation realizes the compiler‐extension for the new annotations in Clang and demonstrates their effectiveness through a smoothed particle hydrodynamics (SPH) code, which we evaluate on an Intel CPU, an ARM CPU, and a Grace‐Hopper GPU. While the separation of concerns between data structure and operators is elegant and provides performance improvements, the new annotations do not eliminate the need for performance engineering. Instead, they challenge conventional performance wisdom and necessitate rethinking approaches how to write efficient implementations.",
      "paperUrl": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/cpe.70199",
      "sourceUrl": "https://doi.org/10.1002/cpe.70199",
      "tags": [
        "Performance",
        "Clang",
        "GPU",
        "Programming Languages"
      ],
      "keywords": [
        "Performance",
        "Clang",
        "GPU",
        "Programming Languages",
        "Offloading",
        "Convert",
        "GPU Offloading",
        "CPU",
        "Annotation Guided Aos",
        "Soa Conversions"
      ],
      "matchedAuthors": [
        "Pawel K. Radtke",
        "Tobias Weinzierl"
      ]
    },
    {
      "id": "openalex-w4416004033",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "An MLIR pipeline for offloading Fortran to FPGAs via OpenMP",
      "authors": [
        {
          "name": "Gabriel Rodriguez‐Canal",
          "affiliation": "University of Edinburgh"
        },
        {
          "name": "Davids Kacs",
          "affiliation": "University of Edinburgh"
        },
        {
          "name": "Nick Brown",
          "affiliation": "University of Edinburgh"
        }
      ],
      "year": "2025",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "With the slowing of Moore's Law, heterogeneous computing platforms such as Field Programmable Gate Arrays (FPGAs) have gained increasing interest for accelerating HPC workloads. In this work we present, to the best of our knowledge, the first implementation of selective code offloading to FPGAs via the OpenMP target directive within MLIR. Our approach combines the MLIR OpenMP dialect with a High-Level Synthesis (HLS) dialect to provide a portable compilation flow targeting FPGAs. Unlike prior OpenMP FPGA efforts that rely on custom compilers, by contrast we integrate with MLIR and so support any MLIR-compatible front end, demonstrated here with Flang. Building upon a range of existing MLIR building blocks significantly reduces the effort required and demonstrates the composability benefits of the MLIR ecosystem. Our approach supports manual optimisation of offloaded kernels through standard OpenMP directives, and this work establishes a flexible and extensible path for directive-based FPGA acceleration integrated within the MLIR ecosystem.",
      "paperUrl": "https://doi.org/10.1145/3731599.3767485",
      "sourceUrl": "",
      "tags": [
        "GPU",
        "Flang",
        "MLIR"
      ],
      "keywords": [
        "GPU",
        "Flang",
        "MLIR",
        "Offloading",
        "Heterogeneous Computing",
        "MLIR Ecosystem",
        "OpenMP",
        "Offloading Fortran",
        "MLIR Pipeline"
      ],
      "matchedAuthors": [
        "Gabriel Rodriguez‐Canal",
        "Nick Brown"
      ]
    },
    {
      "id": "openalex-w4417515759",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "An Empirical Study: MEMS as a Static Performance Metric",
      "authors": [
        {
          "name": "Liwei Zhang",
          "affiliation": ""
        },
        {
          "name": "Baoquan Cui",
          "affiliation": ""
        },
        {
          "name": "Xutong Ma",
          "affiliation": ""
        },
        {
          "name": "Jian Zhang",
          "affiliation": ""
        }
      ],
      "year": "2025",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Static performance estimation is essential during compile-time analysis, yet traditional runtime-based methods are costly and platform-dependent. We investigate mems, the number of memory accesses, as a static and architecture-independent performance metric. We develop a Clang-based automated instrumentation tool that rewrites source code to insert path tracing and \\textit{mems} counting logic. This allows us to evaluate mems-based performance estimation across ten classical algorithm programs. Experimental results show that within the same program, execution paths with higher mems values consistently exhibit longer runtime. However, this correlation weakens between different programs, suggesting that mems is best suited for comparing performance of different execution paths in a program.",
      "paperUrl": "https://arxiv.org/pdf/2505.07208",
      "sourceUrl": "https://doi.org/10.18154/rwth-2025-05736",
      "tags": [
        "Performance",
        "Clang"
      ],
      "keywords": [
        "Performance",
        "Clang",
        "Performance Metric",
        "Execution Paths",
        "Performance Estimation"
      ],
      "matchedAuthors": [
        "Jian Zhang",
        "Liwei Zhang",
        "Xutong Ma"
      ]
    },
    {
      "id": "openalex-w4416050920",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "A Practical Guideline and Taxonomy to LLVM's Control Flow Integrity",
      "authors": [
        {
          "name": "Sabine Houy",
          "affiliation": ""
        },
        {
          "name": "Bruno Kreyssig",
          "affiliation": ""
        },
        {
          "name": "Timothée Riom",
          "affiliation": ""
        },
        {
          "name": "Alexandre Bartel",
          "affiliation": ""
        },
        {
          "name": "Patrick McDaniel",
          "affiliation": ""
        }
      ],
      "year": "2025",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Memory corruption vulnerabilities remain one of the most severe threats to software security. They often allow attackers to achieve arbitrary code execution by redirecting a vulnerable program's control flow. While Control Flow Integrity (CFI) has gained traction to mitigate this exploitation path, developers are not provided with any direction on how to apply CFI to real-world software. In this work, we establish a taxonomy mapping LLVM's forward-edge CFI variants to memory corruption vulnerability classes, offering actionable guidance for developers seeking to deploy CFI incrementally in existing codebases. Based on the Top 10 Known Exploited Vulnerabilities (KEV) list, we identify four high-impact vulnerability categories and select one representative CVE for each. We evaluate LLVM's CFI against each CVE and explain why CFI blocks exploitation in two cases while failing in the other two, illustrating its potential and current limitations. Our findings support informed deployment decisions and provide a foundation for improving the practical use of CFI in production systems.",
      "paperUrl": "https://arxiv.org/pdf/2508.15386",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2508.15386",
      "tags": [
        "Security"
      ],
      "keywords": [
        "Security",
        "LLVM",
        "CFI",
        "Control Flow Integrity",
        "Memory Corruption"
      ],
      "matchedAuthors": [
        "Sabine Houy"
      ]
    },
    {
      "id": "openalex-w4413845216",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "A Portable Auto-Tuning Framework for Quantum Compilation Optimization Based on D3QN",
      "authors": [
        {
          "name": "Yi Liu",
          "affiliation": "PLA Information Engineering University"
        },
        {
          "name": "Yun-Sik Jin",
          "affiliation": "PLA Information Engineering University"
        },
        {
          "name": "Jinchen Xu",
          "affiliation": "PLA Information Engineering University"
        }
      ],
      "year": "2025",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "This paper proposes a portable quantum compilation optimization framework based on D3QN (Double Dueling Deep Q-Network) to automate quantum circuit tuning. Addressing challenges in adapting fixed strategies to diverse algorithms, the framework integrates reinforcement learning (RL) with a quantum compiler environment. The RL agent dynamically selects optimization passes, guided by a reward function balancing gate count, circuit depth, and hardware constraints. Quantum circuits are encoded as DAGs, with D3QN estimating Q-values and standardizing action-space encoding, state representation, and constraint validation. Experiments on the MQTBench dataset (430 circuits across 18 algorithms) show the framework outperforms QCOR-O3 and random strategies, achieving an average 8.7% gate reduction. Implemented on QCOR's MLIR-based compiler, the modular design ensures portability. Results validate generalization across algorithms, though performance varies for underrepresented circuits. This work establishes a standardized, RL-driven framework for quantum compilation optimization in NISQ systems.",
      "paperUrl": "https://dl.acm.org/doi/pdf/10.1145/3746709.3746950",
      "sourceUrl": "https://doi.org/10.1145/3746709.3746950",
      "tags": [
        "Performance",
        "Optimizations",
        "Quantum Computing",
        "MLIR"
      ],
      "keywords": [
        "Performance",
        "Optimizations",
        "Quantum Computing",
        "MLIR",
        "Quantum Compilation",
        "Quantum Compilation Optimization",
        "D3qn",
        "Circuits",
        "Portable Auto Tuning"
      ],
      "matchedAuthors": [
        "Jinchen Xu"
      ]
    },
    {
      "id": "openalex-w4416460683",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "A Pattern Generation Language for MLIR Compiler Matching and Rewriting",
      "authors": [
        {
          "name": "Wesley Attrot",
          "affiliation": "Computing Center"
        },
        {
          "name": "Luciano Zago",
          "affiliation": "Universidade Estadual de Campinas (UNICAMP)"
        },
        {
          "name": "Marcio Pereira",
          "affiliation": "Universidade Estadual de Campinas (UNICAMP)"
        },
        {
          "name": "Vinícius Couto Espindola",
          "affiliation": "Universidade Estadual de Campinas (UNICAMP)"
        },
        {
          "name": "Hervé Yviquel",
          "affiliation": "Universidade Estadual de Campinas (UNICAMP)"
        },
        {
          "name": "Guido Araújo",
          "affiliation": "Universidade Estadual de Campinas (UNICAMP)"
        }
      ],
      "year": "2025",
      "publication": "ACM Transactions on Architecture and Code Optimization",
      "venue": "ACM Transactions on Architecture and Code Optimization",
      "type": "research-paper",
      "abstract": "Pattern Matching and Rewriting (PMR) is a compiler optimization step that identifies predefined code idioms and replaces them with optimized code, offering performance gains across various applications. Recent research advances have led to tools that expedite PMR optimizations. One such technique, Source Matching and Rewriting (SMR), employs a user-centric, source-code-based approach, thus eliminating the need for specialized compiler intervention. However, achieving comprehensive pattern-matching coverage with SMR requires the meticulous specification of as many idiom variations as possible by the user, which is a laborious and error-prone task. This paper introduces Pattern Generation Language (PGL), a framework designed to simplify the automatic generation of pattern variations. PGL is a high-level language that enables users to specify program patterns that can be matched and rewritten by SMR. This paper also proposes the Pattern Generation Compiler (PGC), an SMR-compatible tool that automates the creation of idiomatic variations and the synthesis of patterns written in the PGL language. While PGC primarily focuses on generating input patterns for SMR, its flexibility allows adaptation for other pattern-matching and rewriting systems. Experimental results show that PGL can identify 113% more patterns in Fortran and C code than in manual pattern specification. Matched patterns have been replaced with calls to an optimized BLAS library, enhancing program performance. Experiments using a linear algebra benchmark and a set of real-world programs revealed significant speedups.",
      "paperUrl": "https://doi.org/10.1145/3777905",
      "sourceUrl": "",
      "tags": [
        "Performance",
        "Optimizations",
        "MLIR"
      ],
      "keywords": [
        "Performance",
        "Optimizations",
        "MLIR",
        "Patterns",
        "Pattern Generation Language",
        "Pattern Matching",
        "Variations",
        "MLIR Compiler Matching"
      ],
      "matchedAuthors": [
        "Guido Araújo",
        "Hervé Yviquel",
        "Marcio Pereira",
        "Wesley Attrot"
      ]
    },
    {
      "id": "openalex-w4411552330",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "A Method for Co-Design of Compiler and Large-Scale HPC System Architecture",
      "authors": [
        {
          "name": "Yang Wei",
          "affiliation": "Chinese Academy of Sciences"
        },
        {
          "name": "Mingjie Xing",
          "affiliation": "Institute of Software"
        },
        {
          "name": "Yanjun Wu",
          "affiliation": "Chinese Academy of Sciences"
        },
        {
          "name": "Chen Zhao",
          "affiliation": "Institute of Software"
        }
      ],
      "year": "2025",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "The field of High-Performance Computing (HPC) is advancing towards large-scale systems, playing a crucial role in scientific research, engineering, and industrial applications by processing vast datasets and solving complex problems. It is essential to explore the design of large-scale HPC system architectures through simulation and to improve the performance of these designs using compilation techniques. To tackle the challenge of optimizing large-scale High-Performance Computing (HPC) system architectures and compiler designs, we propose a method that integrates Multi-Level Intermediate Representation (MLIR) with the Structural Simulation Toolkit (SST). This approach enables the concurrent design and simulation of large-scale HPC architectures and compilers, facilitating early-stage optimization. We extend an MLIR-based cryptographic algorithm compiler and validate the effectiveness of our method through its integration with SST. The example study demonstrates how this method can provide more comprehensive guidance in selecting the scale of high-performance architectures and task partitioning. This collaborative design process enables researchers and engineers to more efficiently develop HPC systems, advancing both compilation techniques and HPC system architectures.",
      "paperUrl": "https://doi.org/10.1109/cscwd64889.2025.11033468",
      "sourceUrl": "",
      "tags": [
        "Performance",
        "Optimizations",
        "IR",
        "MLIR"
      ],
      "keywords": [
        "Performance",
        "Optimizations",
        "IR",
        "MLIR",
        "Intermediate Representation",
        "Scale HPC",
        "Performance Computing HPC",
        "Simulation",
        "Compilation"
      ],
      "matchedAuthors": [
        "Chen Zhao",
        "Mingjie Xing",
        "Yanjun Wu"
      ]
    },
    {
      "id": "openalex-w4416004021",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "A Compute Graph Simulation and Implementation Framework Targeting AMD Versal AI Engines",
      "authors": [
        {
          "name": "Jonathan Strobl",
          "affiliation": "Technical University of Darmstadt"
        },
        {
          "name": "Leonardo Solis-Vasquez",
          "affiliation": "Technical University of Darmstadt"
        },
        {
          "name": "Yannick Lavan",
          "affiliation": "Technical University of Darmstadt"
        },
        {
          "name": "Andreas Koch",
          "affiliation": "Technical University of Darmstadt"
        }
      ],
      "year": "2025",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "We present a framework for developing compute graph-based applications targeting the AI Engine (AIE) array of AMD Versal SoCs. This framework enables users to embed AIE-based dataflow graph prototypes directly within existing C++ applications and automatically transform them into deployable AIE graph projects. It thereby eliminates the need to manually separate host and accelerator codebases, as required by the standard AMD Vitis workflow. The framework comprises two core components: (1) a compute graph simulation library that can be linked into existing C++ programs, and (2) a Clang-based source-to-source translator that extracts simulator-defined graphs and prepares them for compilation with AMD’s AIE toolchain. We evaluate our framework using AMD’s official example graphs and show that our generated AIE code achieves performance comparable to hand-optimized Vitis implementations. Additionally, we demonstrate how C++ compile-time code execution can be leveraged to simplify the implementation of source-to-source translation and static source analysis.",
      "paperUrl": "https://doi.org/10.1145/3731599.3767411",
      "sourceUrl": "",
      "tags": [
        "Performance",
        "Clang",
        "AI",
        "Infrastructure"
      ],
      "keywords": [
        "Performance",
        "Clang",
        "AI",
        "Infrastructure",
        "Compute Graph Simulation",
        "Targeting Amd Versal"
      ],
      "matchedAuthors": [
        "Andreas Koch"
      ]
    },
    {
      "id": "openalex-w4400375984",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "WizardMerge -- Save Us From Merging Without Any Clues",
      "authors": [
        {
          "name": "Qingyu Zhang",
          "affiliation": ""
        },
        {
          "name": "Junzhe Li",
          "affiliation": ""
        },
        {
          "name": "Jiayi Lin",
          "affiliation": ""
        },
        {
          "name": "Jie Ding",
          "affiliation": ""
        },
        {
          "name": "Lanteng Lin",
          "affiliation": ""
        },
        {
          "name": "Chenxiong Qian",
          "affiliation": ""
        }
      ],
      "year": "2024",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Modern software development necessitates efficient version-oriented collaboration among developers. While Git is the most popular version control system, it generates unsatisfactory version merging results due to textual-based workflow, leading to potentially unexpected results in the merged version of the project. Although numerous merging tools have been proposed for improving merge results, developers remain struggling to resolve the conflicts and fix incorrectly modified code without clues. We present WizardMerge, an auxiliary tool that leverages merging results from Git to retrieve code block dependency on text and LLVM-IR level and provide suggestions for developers to resolve errors introduced by textual merging. Through the evaluation, we subjected WizardMerge to testing on 227 conflicts within five large-scale projects. The outcomes demonstrate that WizardMerge diminishes conflict merging time costs, achieving a 23.85% reduction. Beyond addressing conflicts, WizardMerge provides merging suggestions for over 70% of the code blocks potentially affected by the conflicts. Notably, WizardMerge exhibits the capability to identify conflict-unrelated code blocks that require manual intervention yet are harmfully applied by Git during the merging.",
      "paperUrl": "https://arxiv.org/pdf/2407.02818",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2407.02818",
      "tags": [
        "IR",
        "Testing"
      ],
      "keywords": [
        "IR",
        "Testing",
        "LLVM",
        "Wizardmerge Save",
        "Conflicts",
        "Version",
        "Developers"
      ],
      "matchedAuthors": [
        "Chenxiong Qian",
        "Jiayi Lin",
        "Jie Ding",
        "Junzhe Li",
        "Lanteng Lin",
        "Qingyu Zhang"
      ]
    },
    {
      "id": "openalex-w4405182272",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "When Compiler Optimizations Meet Symbolic Execution: An Empirical Study",
      "authors": [
        {
          "name": "Yue Zhang",
          "affiliation": "Drexel University"
        },
        {
          "name": "Melih Sirlanci",
          "affiliation": "The Ohio State University"
        },
        {
          "name": "Ruoyu Wang",
          "affiliation": "Arizona State University"
        },
        {
          "name": "Zhiqiang Lin",
          "affiliation": "The Ohio State University"
        }
      ],
      "year": "2024",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "Compiler optimizations intend to transform a program into a semantic-equivalent one with improved performance, but it is unclear how these optimizations may impact the performance of dynamic symbolic execution (DSE) on binary code. To systematically understand the impact of compiler optimizations on two popular DSE techniques (i.e., symbolic exploration and symbolic tracing), this paper presents an empirical study that quantifies 209 GCC compilation flags and 73 Clang compilation flags to reveal both positive and negative optimizations to DSE. Our data set contains 992 unique test cases, which are produced from 3,449 source files in the GCC test suite. After analyzing 2,978,976 binary programs that we compiled with two compilers and various compilation flags, we found that although some optimizations make DSE faster, most optimizations will actually slow down DSE. Our analysis further reveals root causes behind these impacts. The most positive impacts that optimizations have on DSE come from the reduction of the number of instructions and program paths, whereas negative impacts are caused by a series of unexpected behaviors, including increased numbers of instructions or program paths, library function inlining preventing DSE engines from using function summaries, and arithmetic optimizations leading to more sophisticated constraints. Being the first in-depth analysis on why compiler flags influence the performance of DSE, this project sheds light on program transformations that can be applied before performing DSE tasks for better performance.",
      "paperUrl": "https://dl.acm.org/doi/pdf/10.1145/3658644.3670372",
      "sourceUrl": "https://doi.org/10.1145/3658644.3670372",
      "tags": [
        "Performance",
        "Clang",
        "Optimizations",
        "Dynamic Analysis"
      ],
      "keywords": [
        "Performance",
        "Clang",
        "Optimizations",
        "Dynamic Analysis",
        "Symbolic Execution",
        "Compiler Optimizations Meet",
        "Meet Symbolic Execution",
        "Compilation Flags",
        "Impacts",
        "Program Paths",
        "Binary",
        "GCC",
        "Optimizations Meet Symbolic"
      ],
      "matchedAuthors": [
        "Zhiqiang Lin"
      ]
    },
    {
      "id": "openalex-w4391046599",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Weak Memory Demands Model-based Compiler Testing",
      "authors": [
        {
          "name": "Luke Geeson",
          "affiliation": ""
        }
      ],
      "year": "2024",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "A compiler bug arises if the behaviour of a compiled concurrent program, as allowed by its architecture memory model, is not a behaviour permitted by the source program under its source model. One might reasonably think that most compiler bugs have been found in the decade since the introduction of the C/C++ memory model. We observe that processor implementations are increasingly exploiting the behaviour of relaxed architecture models. As such, compiled programs may exhibit bugs not seen on older hardware. To account for this we require model-based compiler testing. While this observation is not surprising, its implications are broad. Compilers and their testing tools will need to be updated to follow hardware relaxations, concurrent test generators will need to be improved, and assumptions of prior work will need revisiting. We explore these ideas using a compiler toolchain bug we reported in LLVM.",
      "paperUrl": "https://arxiv.org/pdf/2401.09474",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2401.09474",
      "tags": [
        "Testing",
        "Infrastructure"
      ],
      "keywords": [
        "Testing",
        "Infrastructure",
        "LLVM",
        "Weak Memory Demands",
        "Compiler Testing",
        "Behaviour",
        "Hardware"
      ],
      "matchedAuthors": [
        "Luke Geeson"
      ]
    },
    {
      "id": "openalex-w4412610590",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "VCNN: A compiler of CNNs based on MLIR for multi-core vector accelerators",
      "authors": [
        {
          "name": "Xiaorong Chen",
          "affiliation": "National University of Defense Technology"
        },
        {
          "name": "Cheng Li",
          "affiliation": "National University of Defense Technology"
        },
        {
          "name": "Zhong Liu B",
          "affiliation": "National University of Defense Technology"
        }
      ],
      "year": "2024",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "Convolutional Neural Network (CNN) is one of the representative algorithms of machine learning and deep learning. Multi-core vector accelerators are becoming increasingly popular due to their high performance and low power consumption. In the previous methods of deploying CNNs to vector accelerators, three issues are of concern. (1) Multi-core tasks are divided according to the image data dimension, which has limitations in low-latency real-time detection application scenarios. (2) Many memory optimization strategies only consider the impact of tensor size or tensor life, ignoring the inherent computational characteristics of operator types. (3) Manual mapping methods require a lot of engineering effort and are prone to introducing errors. Therefore, the VCNN proposed in this paper is a compiler based on MLIR for vector accelerators. The VCNN can automatically map CNN models to vector accelerators. It includes (1) a Multi-core Parallel Convolution algorithm (MPC) that is more suitable for low-latency real-time detection application scenarios. (2) An Adaptive Memory Reuse method (AMR). It not only considers the size or lifetime of tensors but also the inherent computational characteristics of operator types. (3) A quantization pass that quantizes the model and reshuffles the data. Experimental results show that the VCNN can effectively utilize the parallel processing capabilities of hardware when performing convolutions of different sizes, and achieve a parallel computing efficiency of up to 95.75%. In addition, we evaluated the performance of AlexNet, VGG16, and Yolov5s models. The results show that VCNN has a computational efficiency of more than 2X+ that of TVM, TensorRT, and OnnxRuntime, and a power efficiency of more than 7X+ that of them. Additionally, the VCNN inference model using Float16 is twice as energy efficient as that using Float32. Furthermore, the VCNN achieves a higher memory reuse rate compared to traditional memory reuse methods.",
      "paperUrl": "https://doi.org/10.1109/hpcc64274.2024.00024",
      "sourceUrl": "",
      "tags": [
        "Performance",
        "Optimizations",
        "ML",
        "MLIR"
      ],
      "keywords": [
        "Performance",
        "Optimizations",
        "ML",
        "MLIR",
        "Parallel Computing",
        "Core Vector Accelerators",
        "Multi Core Vector",
        "Memory Reuse",
        "Inherent Computational Characteristics",
        "Efficiency",
        "Latency Real",
        "Operator Types"
      ],
      "matchedAuthors": [
        "Cheng Li"
      ]
    },
    {
      "id": "openalex-w4405095028",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Unified Framework for Open-World Compositional Zero-shot Learning",
      "authors": [
        {
          "name": "Hirunima Jayasekara",
          "affiliation": ""
        },
        {
          "name": "Khoi Pham",
          "affiliation": ""
        },
        {
          "name": "Nirat Saini",
          "affiliation": ""
        },
        {
          "name": "Abhinav Shrivastava",
          "affiliation": ""
        }
      ],
      "year": "2024",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Open-World Compositional Zero-Shot Learning (OW-CZSL) addresses the challenge of recognizing novel compositions of known primitives and entities. Even though prior works utilize language knowledge for recognition, such approaches exhibit limited interactions between language-image modalities. Our approach primarily focuses on enhancing the inter-modality interactions through fostering richer interactions between image and textual data. Additionally, we introduce a novel module aimed at alleviating the computational burden associated with exhaustive exploration of all possible compositions during the inference stage. While previous methods exclusively learn compositions jointly or independently, we introduce an advanced hybrid procedure that leverages both learning mechanisms to generate final predictions. Our proposed model, achieves state-of-the-art in OW-CZSL in three datasets, while surpassing Large Vision Language Models (LLVM) in two datasets.",
      "paperUrl": "https://arxiv.org/pdf/2412.04083",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2412.04083",
      "tags": [],
      "keywords": [
        "LLVM",
        "Compositional Zero Shot",
        "Open World Compositional",
        "World Compositional Zero",
        "Zero Shot Learning",
        "Compositions",
        "Interactions"
      ],
      "matchedAuthors": [
        "Abhinav Shrivastava",
        "Hirunima Jayasekara",
        "Khoi Pham",
        "Nirat Saini"
      ]
    },
    {
      "id": "openalex-w4403536902",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "UFront: Toward A Unified MLIR Frontend for Deep Learning",
      "authors": [
        {
          "name": "Guoqing Bao",
          "affiliation": ""
        },
        {
          "name": "Heng Shi",
          "affiliation": "Shanghai Jiao Tong University"
        },
        {
          "name": "Cui Cheng-yi",
          "affiliation": ""
        },
        {
          "name": "Yalin Zhang",
          "affiliation": ""
        },
        {
          "name": "Jianguo Yao",
          "affiliation": "Shanghai Jiao Tong University"
        }
      ],
      "year": "2024",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "Automatic code generation for ML systems has gained popularity with the advent of compiler techniques like Multi-Level Intermediate Representation (Multi-Level IR, or MLIR). State-of-the-art MLIR frontends, including IREE-TF, Torch-MLIR, and ONNX-MLIR, aim to bridge the gap between ML frameworks and low-level hardware architectures through MLIR's progressive lowering pipeline. However, existing MLIR frontends encounter challenges such as inflexible high-level IR conversion, limited higher-level optimization opportunities, and reduced compatibility and efficiency, leading to software fragmentation and restricting their practical applications within the MLIR ecosystem. To address these challenges, we introduce UFront, a unified MLIR frontend employing a two-stage operator-to-operator compilation workflow. Unlike traditional frontends that compile model source code into binaries step by step with different MLIR transform passes, UFront decouples the process into two distinct stages. It first performs instantaneous model tracing, delegates traced computing nodes as standard Deep Neural Network (DNN) operators and transforms models written in different frameworks into unified high-level IR without relying on MLIR passes, enhancing conversion flexibility. Meanwhile, it performs high-level graph optimizations such as constant folding and operator fusion to produce more efficient high-level IR. In the second stage, UFront directly converts high-level IR into standard TOSA IR using proposed lowering patterns, eliminating transform redundancies and ensuring lower-level compatibility with existing ML compiler backends. This two-stage compilation approach enables consistent end-to-end code generation and optimization of various DNN models written in different formats within a single workflow. Extensive experiments on popular DNN models written in various frameworks demonstrate that UFront exhibits higher compatibility, faster end-to-end compilation, and is capable of producing more efficient binary execution compared to SOTA works.",
      "paperUrl": "https://doi.org/10.1145/3691620.3695002",
      "sourceUrl": "",
      "tags": [
        "Backend",
        "Frontend",
        "Optimizations",
        "IR",
        "ML",
        "MLIR"
      ],
      "keywords": [
        "Backend",
        "Frontend",
        "Optimizations",
        "IR",
        "ML",
        "MLIR",
        "Intermediate Representation",
        "Code Generation",
        "Unified MLIR Frontend",
        "Ufront",
        "Compatibility",
        "Compilation",
        "Frameworks",
        "MLIR Frontends"
      ],
      "matchedAuthors": [
        "Heng Shi",
        "Jianguo Yao"
      ]
    },
    {
      "id": "openalex-w4400600575",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "UEFI Vulnerability Signature Generation using Static and Symbolic Analysis",
      "authors": [
        {
          "name": "Md Shafiuzzaman",
          "affiliation": ""
        },
        {
          "name": "Achintya Desai",
          "affiliation": ""
        },
        {
          "name": "Laboni Sarker",
          "affiliation": ""
        },
        {
          "name": "Tevfik Bultan",
          "affiliation": ""
        }
      ],
      "year": "2024",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Since its major release in 2006, the Unified Extensible Firmware Interface (UEFI) has become the industry standard for interfacing a computer's hardware and operating system, replacing BIOS. UEFI has higher privileged security access to system resources than any other software component, including the system kernel. Hence, identifying and characterizing vulnerabilities in UEFI is extremely important for computer security. However, automated detection and characterization of UEFI vulnerabilities is a challenging problem. Static vulnerability analysis techniques are scalable but lack precision (reporting many false positives), whereas symbolic analysis techniques are precise but are hampered by scalability issues due to path explosion and the cost of constraint solving. In this paper, we introduce a technique called STatic Analysis guided Symbolic Execution (STASE), which integrates both analysis approaches to leverage their strengths and minimize their weaknesses. We begin with a rule-based static vulnerability analysis on LLVM bitcode to identify potential vulnerability targets for symbolic execution. We then focus symbolic execution on each target to achieve precise vulnerability detection and signature generation. STASE relies on the manual specification of reusable vulnerability rules and attacker-controlled inputs. However, it automates the generation of harnesses that guide the symbolic execution process, addressing the usability and scalability of symbolic execution, which typically requires manual harness generation to reduce the state space. We implemented and applied STASE to the implementations of UEFI code base. STASE detects and generates vulnerability signatures for 5 out of 9 recently reported PixieFail vulnerabilities and 13 new vulnerabilities in Tianocore's EDKII codebase.",
      "paperUrl": "https://arxiv.org/pdf/2407.07166",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2407.07166",
      "tags": [
        "Security",
        "Static Analysis",
        "Dynamic Analysis"
      ],
      "keywords": [
        "Security",
        "Static Analysis",
        "Dynamic Analysis",
        "LLVM",
        "Symbolic Execution",
        "Uefi Vulnerability Signature",
        "Vulnerabilities",
        "Vulnerability Signature Generation"
      ],
      "matchedAuthors": [
        "Achintya Desai",
        "Laboni Sarker",
        "Md Shafiuzzaman",
        "Tevfik Bultan"
      ]
    },
    {
      "id": "openalex-w4390784292",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "UBfuzz: Finding Bugs in Sanitizer Implementations",
      "authors": [
        {
          "name": "Shaohua Li",
          "affiliation": ""
        },
        {
          "name": "Zhendong Su",
          "affiliation": ""
        }
      ],
      "year": "2024",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "In this paper, we propose a testing framework for validating sanitizer implementations in compilers. Our core components are (1) a program generator specifically designed for producing programs containing undefined behavior (UB), and (2) a novel test oracle for sanitizer testing. The program generator employs Shadow Statement Insertion, a general and effective approach for introducing UB into a valid seed program. The generated UB programs are subsequently utilized for differential testing of multiple sanitizer implementations. Nevertheless, discrepant sanitizer reports may stem from either compiler optimization or sanitizer bugs. To accurately determine if a discrepancy is caused by sanitizer bugs, we introduce a new test oracle called crash-site mapping. We have incorporated our techniques into UBfuzz, a practical tool for testing sanitizers. Over a five-month testing period, UBfuzz successfully found 31 bugs in both GCC and LLVM sanitizers. These bugs reveal the serious false negative problems in sanitizers, where certain UBs in programs went unreported. This research paves the way for further investigation in this crucial area of study.",
      "paperUrl": "https://arxiv.org/pdf/2401.04538",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2401.04538",
      "tags": [
        "Optimizations",
        "Testing"
      ],
      "keywords": [
        "Optimizations",
        "Testing",
        "LLVM",
        "Sanitizers",
        "Differential Testing",
        "Ubfuzz Finding Bugs",
        "Program Generator",
        "Sanitizer Bugs"
      ],
      "matchedAuthors": [
        "Shaohua Li",
        "Zhendong Su"
      ]
    },
    {
      "id": "openalex-w4399837024",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "TroL: Traversal of Layers for Large Language and Vision Models",
      "authors": [
        {
          "name": "Byung‐Kwan Lee",
          "affiliation": ""
        },
        {
          "name": "Sangyun Chung",
          "affiliation": ""
        },
        {
          "name": "Chae Won Kim",
          "affiliation": ""
        },
        {
          "name": "Beomchan Park",
          "affiliation": ""
        },
        {
          "name": "Yong Man Ro",
          "affiliation": ""
        }
      ],
      "year": "2024",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Large language and vision models (LLVMs) have been driven by the generalization power of large language models (LLMs) and the advent of visual instruction tuning. Along with scaling them up directly, these models enable LLVMs to showcase powerful vision language (VL) performances by covering diverse tasks via natural language instructions. However, existing open-source LLVMs that perform comparably to closed-source LLVMs such as GPT-4V are often considered too large (e.g., 26B, 34B, and 110B parameters), having a larger number of layers. These large models demand costly, high-end resources for both training and inference. To address this issue, we present a new efficient LLVM family with 1.8B, 3.8B, and 7B LLM model sizes, Traversal of Layers (TroL), which enables the reuse of layers in a token-wise manner. This layer traversing technique simulates the effect of looking back and retracing the answering stream while increasing the number of forward propagation layers without physically adding more layers. We demonstrate that TroL employs a simple layer traversing approach yet efficiently outperforms the open-source LLVMs with larger model sizes and rivals the performances of the closed-source LLVMs with substantial sizes.",
      "paperUrl": "https://arxiv.org/pdf/2406.12246",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2406.12246",
      "tags": [],
      "keywords": [
        "LLVM",
        "Layers",
        "Vision",
        "Layer Traversing",
        "Trol Traversal"
      ],
      "matchedAuthors": [
        "Beomchan Park",
        "Byung‐Kwan Lee",
        "Chae Won Kim",
        "Yong Man Ro"
      ]
    },
    {
      "id": "openalex-w4402338269",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Towards reverse mode automatic differentiation of Kokkos-based codes",
      "authors": [
        {
          "name": "Kim Liegeois",
          "affiliation": "Sandia National Laboratories California"
        },
        {
          "name": "Brian E. Kelley",
          "affiliation": "Sandia National Laboratories California"
        },
        {
          "name": "Eric Phipps",
          "affiliation": "Sandia National Laboratories California"
        },
        {
          "name": "Sivasankaran Rajamanickam",
          "affiliation": "Sandia National Laboratories California"
        }
      ],
      "year": "2024",
      "publication": "OSTI OAI (U.S. Department of Energy Office of Scientific and Technical Information)",
      "venue": "OSTI OAI (U.S. Department of Energy Office of Scientific and Technical Information)",
      "type": "research-paper",
      "abstract": "Derivative computation is a key component of optimization, sensitivity analysis, uncertainty quantification, and the solving of nonlinear problems. Automatic differentiation (AD) is a powerful technique for evaluating such derivatives, and in recent years, has been integrated into programming environments such as Jax, PyTorch, and TensorFlow to support derivative computations needed for training of machine learning models, facilitating wide-spread use of these technologies. The C++ language has become the de facto standard for scientific computing due to numerous factors, yet language complexity has made the wide-spread adoption of AD technologies for C++ difficult, hampering the incorporation of powerful differentiable programming approaches into C++ scientific simulations. This is exacerbated by the increasing emergence of architectures, such as GPUs, with limited memory capabilities and requiring massive thread-level concurrency. C++ AD tools must effectively use these environments to bring novel scientific simulations to next-generation DOE experimental and observational facilities. In this project, we investigated source transformation-based automatic differentiation using LLVM compiler infrastructure to automatically generate portable and efficient gradient computations of Kokkos-based code. We have demonstrated that our proposed strategy is feasible by investigating the usage of a prototype LLVM-based source transformation tool to generate gradients of simple functions made of sequences of simple Kokkos parallel regions. Speedups of up to 500x compared to Sacado were observed on NVIDIA V100 GPU.",
      "paperUrl": "https://www.osti.gov/biblio/2430019",
      "sourceUrl": "https://doi.org/10.2172/2430019",
      "tags": [
        "Optimizations",
        "GPU",
        "Infrastructure",
        "ML"
      ],
      "keywords": [
        "Optimizations",
        "GPU",
        "Infrastructure",
        "ML",
        "LLVM",
        "Mode Automatic Differentiation",
        "Kokkos",
        "Scientific Simulations",
        "Wide Spread",
        "Reverse Mode"
      ],
      "matchedAuthors": [
        "Brian E. Kelley",
        "Eric Phipps",
        "Kim Liegeois",
        "Sivasankaran Rajamanickam"
      ]
    },
    {
      "id": "openalex-w4405029473",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Towards Supporting QIR: Steps for Adopting the Quantum Intermediate Representation",
      "authors": [
        {
          "name": "Yannick Stade",
          "affiliation": ""
        },
        {
          "name": "Lukas Burgholzer",
          "affiliation": ""
        },
        {
          "name": "Sunghye Park",
          "affiliation": ""
        }
      ],
      "year": "2024",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Intermediate representations (IRs) play a crucial role in the software stack of a quantum computer to facilitate efficient optimizations for executing an application on hardware. One of those IRs is the Quantum Intermediate Representation (QIR), which builds on the classical LLVM compiler infrastructure. In this article, we outline different approaches to how QIR can be adopted. This exploration culminates in a demonstration of what it takes to turn an existing quantum circuit simulator into a QIR runtime and that such a transition is less daunting than it might seem at first. We further show that switching to QIR does not entail any performance deficits compared to the original simulator. On the contrary, the presented steps effortlessly allow adding support for arbitrary classical control flow to any classical simulator. We conclude with an outlook on future directions using QIR. The implemented QIR runtime is available under https://github.com/munich-quantum-toolkit/core.",
      "paperUrl": "https://arxiv.org/pdf/2411.18682",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2411.18682",
      "tags": [
        "Performance",
        "Optimizations",
        "IR",
        "Infrastructure"
      ],
      "keywords": [
        "Performance",
        "Optimizations",
        "IR",
        "Infrastructure",
        "LLVM",
        "Intermediate Representation",
        "Quantum Intermediate Representation",
        "Classical",
        "Simulator",
        "Qir Runtime",
        "Supporting Qir Steps"
      ],
      "matchedAuthors": [
        "Lukas Burgholzer",
        "Yannick Stade"
      ]
    },
    {
      "id": "openalex-w4393146751",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Towards Automated Generation of Chiplet-Based Systems Invited Paper",
      "authors": [
        {
          "name": "Ankur Limaye",
          "affiliation": "Pacific Northwest National Laboratory"
        },
        {
          "name": "Claudio Barone",
          "affiliation": "Pacific Northwest National Laboratory"
        },
        {
          "name": "Nícolas Bohm Agostini",
          "affiliation": "Pacific Northwest National Laboratory"
        },
        {
          "name": "Marco Minutoli",
          "affiliation": "Pacific Northwest National Laboratory"
        },
        {
          "name": "Joseph Manzano",
          "affiliation": "Pacific Northwest National Laboratory"
        },
        {
          "name": "Vito Giovanni Castellana",
          "affiliation": "Pacific Northwest National Laboratory"
        },
        {
          "name": "Giovanni Gozzi",
          "affiliation": "Politecnico di Milano"
        },
        {
          "name": "Michele Fiorito",
          "affiliation": "Politecnico di Milano"
        },
        {
          "name": "Serena Curzel",
          "affiliation": "Politecnico di Milano"
        },
        {
          "name": "Fabrizio Ferrandi",
          "affiliation": "Politecnico di Milano"
        },
        {
          "name": "Antonino Tumeo",
          "affiliation": "Pacific Northwest National Laboratory"
        }
      ],
      "year": "2024",
      "publication": "Virtual Community of Pathological Anatomy (University of Castilla La Mancha)",
      "venue": "Virtual Community of Pathological Anatomy (University of Castilla La Mancha)",
      "type": "research-paper",
      "abstract": "The Software Defined Architectures (SODA) Synthesizer is an open-source compiler-based tool able to automatically generate domain-specialized systems targeting Application-Specific Integrated Circuits (ASICs) or Field Programmable Gate Arrays (FPGAs) starting from high-level programming. SODA is composed of a high-level frontend, SODA-OPT, which leverages the multilevel intermediate representation (MLIR) framework to interface with productive programming tools (e.g., machine learning frameworks), identify kernels suitable for acceleration, and perform high-level optimizations, and of a state-of-the-art high-level synthesis backend, Bambu from the PandA framework, to generate custom accelerators. One specific application of the SODA Synthesizer is the generation of accelerators to enable ultra-low latency inference and control on autonomous systems for scientific discovery (e.g., electron microscopes, sensors in particle accelerators, etc.). This talk will discuss ongoing work on the SODA synthesizer to enable no-human-in-the-loop generation and design space exploration of the chiplets for highly specialized artificial intelligence accelerators. Connecting these highly specialized chiplets to general-purpose cores or programmable accelerators will allow to quickly deploy autonomous systems for scientific discovery.",
      "paperUrl": "https://doi.org/10.1109/asp-dac58780.2024.10473980",
      "sourceUrl": "",
      "tags": [
        "Backend",
        "Frontend",
        "Optimizations",
        "IR",
        "AI",
        "ML",
        "MLIR"
      ],
      "keywords": [
        "Backend",
        "Frontend",
        "Optimizations",
        "IR",
        "AI",
        "ML",
        "MLIR",
        "Intermediate Representation",
        "Accelerators",
        "Soda Synthesizer",
        "Highly Specialized",
        "Scientific Discovery",
        "Automated Generation"
      ],
      "matchedAuthors": [
        "Ankur Limaye",
        "Antonino Tumeo",
        "Fabrizio Ferrandi",
        "Joseph Manzano",
        "Marco Minutoli",
        "Michele Fiorito",
        "Nícolas Bohm Agostini",
        "Serena Curzel",
        "Vito Giovanni Castellana"
      ]
    },
    {
      "id": "openalex-w4390939268",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "ToolPhet: Inference of Compiler Provenance From Stripped Binaries With Emerging Compilation Toolchains",
      "authors": [
        {
          "name": "Hohyeon Jang",
          "affiliation": "Sungkyunkwan University"
        },
        {
          "name": "Nozima Murodova",
          "affiliation": "Sungkyunkwan University"
        },
        {
          "name": "Hyungjoon Koo",
          "affiliation": "Sungkyunkwan University"
        }
      ],
      "year": "2024",
      "publication": "IEEE Access",
      "venue": "IEEE Access | Vol. 12",
      "type": "research-paper",
      "abstract": "Identifying compiler toolchain provenance serves as a basis for both benign and malicious binary analyses. A wealth of prior studies mostly focuses on the inference of a popular compiler toolchain for C and C&#x002B;&#x002B; languages from stripped binaries that are built with GCC or clang. Lately, the popularity of an emerging compiler is on the rise such as Rust, Go, and Nim programming languages that complement the downsides of C and C&#x002B;&#x002B; (e.g., security), which little has been explored on them. The main challenge arises when applying previous inference techniques for toolchain provenance because some emerging compilation toolchains adopt the same backend of traditional compilers. In this paper, we propose ToolPhet, an effective end-to-end BERT-based system for deducing the provenance of both traditional and emerging compiler toolchains. To this end, we thoroughly study the characteristics of both an emerging toolchain and an executable binary that is generated by that toolchain. We introduce two separate downstream tasks for the compiler toolchain inference with a (BERT-based) fine-tuning process, which produces 1) a toolchain classification model; and 2) a binary code similarity detection model. Our findings show that the classification model 1) may not suffice when producing a binary with the existing backend like Nim, which we adopt the detection model 2) that can infer underlying code semantics. We evaluate ToolPhet with the previous work including one signature-based tool and four machine-learning-based approaches, demonstrating its effectiveness by achieving higher F1 score s with the binaries compiled with emerging compilation toolchains.",
      "paperUrl": "https://ieeexplore.ieee.org/ielx7/6287639/6514899/10401926.pdf",
      "sourceUrl": "https://doi.org/10.1109/access.2024.3355098",
      "tags": [
        "Backend",
        "Security",
        "Clang",
        "Programming Languages",
        "Infrastructure",
        "Rust"
      ],
      "keywords": [
        "Backend",
        "Security",
        "Clang",
        "Programming Languages",
        "Infrastructure",
        "Rust",
        "Emerging Compilation Toolchains",
        "Inference",
        "Toolchain Provenance",
        "Compiler Toolchain",
        "Binary",
        "X002b",
        "Stripped Binaries",
        "Toolphet Inference"
      ],
      "matchedAuthors": [
        "Hyungjoon Koo"
      ]
    },
    {
      "id": "openalex-w4409328033",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "The Mutators Reloaded: Fuzzing Compilers with Large Language Model Generated Mutation Operators",
      "authors": [
        {
          "name": "Xianfei Ou",
          "affiliation": "Nanjing University"
        },
        {
          "name": "Cong Li",
          "affiliation": "Zhejiang University"
        },
        {
          "name": "Yanyan Jiang",
          "affiliation": "Nanjing University"
        },
        {
          "name": "Chang Xu",
          "affiliation": "Nanjing University"
        }
      ],
      "year": "2024",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "Crafting high-quality mutators-the core of mutation-based fuzzing that shapes the search space-is challenging. It requires human expertise and creativity, and their implementation demands knowledge of compiler internals. This paper presents MetaMut framework for developing new, useful mutators for compiler fuzzing. It integrates our compiler-domain knowledge into prompts and processes that can best harness the capabilities of a large language model. With MetaMut, we have successfully created 118 semantic-aware mutators at approximately $0.5 each, with only moderate human effort. With these mutators, our fuzzer uncovered 131 bugs in GCC and Clang, 129 of which were confirmed or fixed. The success of MetaMut suggests that the integration of AI into software and system engineering tasks traditionally thought to require expert human intervention could be a promising research direction.",
      "paperUrl": "https://dl.acm.org/doi/pdf/10.1145/3622781.3674171",
      "sourceUrl": "https://doi.org/10.1145/3622781.3674171",
      "tags": [
        "Clang",
        "Testing",
        "AI"
      ],
      "keywords": [
        "Clang",
        "Testing",
        "AI",
        "Fuzzing",
        "Mutators",
        "Mutators Reloaded Fuzzing",
        "Metamut",
        "Generated Mutation Operators",
        "Reloaded Fuzzing Compilers"
      ],
      "matchedAuthors": [
        "Yanyan Jiang"
      ]
    },
    {
      "id": "openalex-w4404346214",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Target-Aware Implementation of Real Expressions",
      "authors": [
        {
          "name": "Brett Saiki",
          "affiliation": ""
        },
        {
          "name": "Jackson Brough",
          "affiliation": ""
        },
        {
          "name": "Jonas Regehr",
          "affiliation": ""
        },
        {
          "name": "Jesús Ponce",
          "affiliation": ""
        },
        {
          "name": "Varun Pradeep",
          "affiliation": ""
        },
        {
          "name": "Aditya Akhileshwaran",
          "affiliation": ""
        },
        {
          "name": "Zachary Tatlock",
          "affiliation": ""
        },
        {
          "name": "Pavel Panchekha",
          "affiliation": ""
        }
      ],
      "year": "2024",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "New low-precision accelerators, vector instruction sets, and library functions make maximizing accuracy and performance of numerical code increasingly challenging. Two lines of work$\\unicode{x2013}$traditional compilers and numerical compilers$\\unicode{x2013}$attack this problem from opposite directions. Traditional compiler backends optimize for specific target environments but are limited in their ability to balance performance and accuracy. Numerical compilers trade off accuracy and performance, or even improve both, but ignore the target environment. We join aspects of both to produce Chassis, a target-aware numerical compiler. Chassis compiles mathematical expressions to operators from a target description, which lists the real expressions each operator approximates and estimates its cost and accuracy. Chassis then uses an iterative improvement loop to optimize for speed and accuracy. Specifically, a new instruction selection modulo equivalence algorithm efficiently searches for faster target-specific programs, while a new cost-opportunity heuristic supports iterative improvement. We demonstrate Chassis' capabilities on 9 different targets, including hardware ISAs, math libraries, and programming languages. Chassis finds better accuracy and performance trade-offs than both Clang (by 3.5x) or Herbie (by up to 2.0x) by leveraging low-precision accelerators, accuracy-optimized numerical helper functions, and library subcomponents.",
      "paperUrl": "https://arxiv.org/pdf/2410.14025",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2410.14025",
      "tags": [
        "Performance",
        "Clang",
        "Programming Languages",
        "Libraries"
      ],
      "keywords": [
        "Performance",
        "Clang",
        "Programming Languages",
        "Libraries",
        "Instruction Selection",
        "Accuracy",
        "Target Aware",
        "Chassis",
        "Numerical Compilers",
        "Real Expressions",
        "Iterative Improvement",
        "Precision Accelerators",
        "Unicode X2013"
      ],
      "matchedAuthors": [
        "Zachary Tatlock"
      ]
    },
    {
      "id": "openalex-w4404650280",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Static Reuse Profile Estimation for Array Applications",
      "authors": [
        {
          "name": "Abdur Razzak",
          "affiliation": ""
        },
        {
          "name": "Atanu Barai",
          "affiliation": ""
        },
        {
          "name": "Nandakishore Santhi",
          "affiliation": ""
        },
        {
          "name": "Abdel‐Hameed A. Badawy",
          "affiliation": ""
        }
      ],
      "year": "2024",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Reuse distance analysis is a widely recognized method for application characterization that illustrates cache locality. Although there are various techniques to calculate the reuse profile from dynamic memory traces, it is both time and space-consuming due to the requirement to collect dynamic memory traces at runtime. In contrast, static analysis reuse profile estimation is a promisingly faster approach since it is calculated at compile time without running the program or collecting memory traces. This work presents a static analysis technique to estimate the reuse profile of loop-based programs. For an input program, we generate a basic block-level control flow graph and the execution count by analyzing the LLVM IR of the program. We present the memory accesses of the application kernel in a compact bracketed format and use a recursive algorithm to predict the reuse distance histogram. We deploy a separate predictor that unrolls the loop(s) for smaller bounds and generates a temporary reuse distance profile for those small cases. Using these smaller profiles, the reuse profile is extrapolated for the actual loop bound(s). We use this reuse profile to predict the cache hit rate. Results show that our model can predict cache hit rates with an average accuracy of 95% relative to the dynamic reuse profile methods.",
      "paperUrl": "https://arxiv.org/pdf/2411.13854",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2411.13854",
      "tags": [
        "Static Analysis",
        "IR"
      ],
      "keywords": [
        "Static Analysis",
        "IR",
        "LLVM",
        "Intermediate Representation",
        "Control Flow Graph",
        "Reuse Profile Estimation",
        "Memory Traces",
        "Reuse Distance",
        "Predict",
        "Cache Hit"
      ],
      "matchedAuthors": [
        "Abdel‐Hameed A. Badawy",
        "Abdur Razzak",
        "Atanu Barai",
        "Nandakishore Santhi"
      ]
    },
    {
      "id": "openalex-w4399413197",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "ShadowBound: Efficient Heap Memory Protection Through Advanced Metadata Management and Customized Compiler Optimization",
      "authors": [
        {
          "name": "Zheng Yu",
          "affiliation": ""
        },
        {
          "name": "Ganxiang Yang",
          "affiliation": ""
        },
        {
          "name": "Xinyu Xing",
          "affiliation": ""
        }
      ],
      "year": "2024",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "In software development, the prevalence of unsafe languages such as C and C++ introduces potential vulnerabilities, especially within the heap, a pivotal component for dynamic memory allocation. Despite its significance, heap management complexities have made heap corruption pervasive, posing severe threats to system security. While prior solutions aiming for temporal and spatial memory safety exhibit overheads deemed impractical, we present ShadowBound, a unique heap memory protection design. At its core, ShadowBound is an efficient out-of-bounds defense that can work with various use-after-free defenses (e.g. MarkUs, FFMalloc, PUMM) without compatibility constraints. We harness a shadow memory-based metadata management mechanism to store heap chunk boundaries and apply customized compiler optimizations tailored for boundary checking. We implemented ShadowBound atop the LLVM framework and integrated three state-of-the-art use-after-free defenses. Our evaluations show that ShadowBound provides robust heap protection with minimal time and memory overhead, suggesting its effectiveness and efficiency in safeguarding real-world programs against prevalent heap vulnerabilities.",
      "paperUrl": "https://arxiv.org/pdf/2406.02023",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2406.02023",
      "tags": [
        "Security",
        "Optimizations"
      ],
      "keywords": [
        "Security",
        "Optimizations",
        "LLVM",
        "Memory Safety",
        "Heap Memory Protection",
        "Shadowbound",
        "Advanced Metadata Management",
        "Customized Compiler Optimization",
        "Free Defenses"
      ],
      "matchedAuthors": [
        "Xinyu Xing"
      ]
    },
    {
      "id": "openalex-w4393592471",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Revet: A Language and Compiler for Dataflow Threads",
      "authors": [
        {
          "name": "Alexander C. Rucker",
          "affiliation": "Stanford University"
        },
        {
          "name": "Shiv Sundram",
          "affiliation": "Stanford University"
        },
        {
          "name": "Coleman I. Smith",
          "affiliation": "Stanford University"
        },
        {
          "name": "Matthew Vilim",
          "affiliation": "Universitas Ratu Samban"
        },
        {
          "name": "Raghu Prabhakar",
          "affiliation": "Universitas Ratu Samban"
        },
        {
          "name": "Fredrik Kjølstad",
          "affiliation": "Stanford University"
        },
        {
          "name": "Kunle Olukotun",
          "affiliation": "Stanford University"
        }
      ],
      "year": "2024",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "Spatial dataflow architectures such as reconfigurable dataflow accelerators (RDA) can provide much higher performance and efficiency than CPUs and GPUs. In particular, vectorized reconfigurable dataflow accelerators (vRDA) in recent literature represent a design point that enhances the efficiency of dataflow architectures with vectorization. Today, vRDAs can be exploited using either hard-coded kernels or MapReduce languages like Spatial, which cannot vectorize data-dependent control flow. In contrast, CPUs and GPUs can be programmed using general-purpose threaded abstractions. The ideal combination would be the generality of a threaded programming model coupled with the efficient execution model of a vRDA. We introduce Revet: a programming model, compiler, and execution model that lets threaded applications run efficiently on vRDAs. The Revet programming language uses threads to support a broader range of applications than prior parallel-patterns approaches, and our MLIR-based compiler lowers this language to a generic dataflow backend that operates on streaming tensors. Finally, we show that mapping threads to dataflow out-performs GPUs, the current state-of-the-art for threaded accelerators, by 3.8×.",
      "paperUrl": "https://doi.org/10.1109/hpca57654.2024.00016",
      "sourceUrl": "",
      "tags": [
        "Backend",
        "Performance",
        "GPU",
        "Autovectorization",
        "Programming Languages",
        "MLIR"
      ],
      "keywords": [
        "Backend",
        "Performance",
        "GPU",
        "Autovectorization",
        "Programming Languages",
        "MLIR",
        "Reconfigurable Dataflow Accelerators",
        "Dataflow Threads",
        "Dataflow Architectures"
      ],
      "matchedAuthors": [
        "Fredrik Kjølstad"
      ]
    },
    {
      "id": "openalex-w4408793818",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Quantifying and Analyzing Speculative Execution Risks: A Quantitative Security Framework",
      "authors": [
        {
          "name": "Yusha Zhang",
          "affiliation": "Institute of Information Engineering"
        },
        {
          "name": "Ziyuan Zhu",
          "affiliation": "Institute of Information Engineering"
        },
        {
          "name": "Yuxin Liu",
          "affiliation": "Institute of Information Engineering"
        },
        {
          "name": "Rui Li",
          "affiliation": "Chinese Academy of Sciences"
        },
        {
          "name": "Wenjing Cai",
          "affiliation": "Institute of Information Engineering"
        },
        {
          "name": "Dan Meng",
          "affiliation": "Chinese Academy of Sciences"
        }
      ],
      "year": "2024",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "The disclosure of Spectre and Meltdown vulnerabilities has significantly challenged processor security, exposing inherent flaws in microarchitectural design and revealing the limitations of existing countermeasures. Despite extensive mitigation efforts, completely preventing information leakage resulting from speculative execution continues to pose a significant challenge. A significant gap remains in the lack of a quantitative evaluation framework that rigorously assesses the effectiveness of these mitigation strategies. In this research, the SPECTECTOR analytical framework is utilized to introduce two novel quantitative metrics: Relative Leakage Entropy (RLE) and Normalized Conditional Entropy (NCE). These metrics are designed to evaluate the relative information leakage between speculative and non-speculative execution traces, providing distinct insights on leakage quantification. By utilizing these metrics to assess 15 example programs compiled with Intel ICC and CLANG compilers across different optimization levels and mitigation strategies, the analysis reveals that compiler optimization strategies markedly affect the magnitude of information leakage. The results indicate that, despite advanced mitigation techniques, substantial information leakage persists, highlighting the need for more effective security architectures in future processors and software systems.",
      "paperUrl": "https://doi.org/10.1109/swc62898.2024.00163",
      "sourceUrl": "",
      "tags": [
        "Security",
        "Clang",
        "Optimizations"
      ],
      "keywords": [
        "Security",
        "Clang",
        "Optimizations",
        "Leakage",
        "Analyzing Speculative Execution",
        "Mitigation",
        "Quantitative",
        "Quantitative Security",
        "Metrics",
        "Mitigation Strategies",
        "Speculative Execution Risks"
      ],
      "matchedAuthors": [
        "Dan Meng",
        "Rui Li"
      ]
    },
    {
      "id": "openalex-w4403780251",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Phantom of Latent for Large Language and Vision Models",
      "authors": [
        {
          "name": "Byung‐Kwan Lee",
          "affiliation": ""
        },
        {
          "name": "Sangyun Chung",
          "affiliation": ""
        },
        {
          "name": "Chae Won Kim",
          "affiliation": ""
        },
        {
          "name": "Beomchan Park",
          "affiliation": ""
        },
        {
          "name": "Yong Man Ro",
          "affiliation": ""
        }
      ],
      "year": "2024",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "The success of visual instruction tuning has accelerated the development of large language and vision models (LLVMs). Following the scaling laws of instruction-tuned large language models (LLMs), LLVMs either have further increased their sizes, reaching 26B, 34B, and even 80B parameters. While this increase in model size has yielded significant performance gains, it demands substantially more hardware resources for both training and inference. Consequently, there naturally exists a strong need for efficient LLVMs that achieve the performance of larger models while being smaller in size. To achieve this need, we present a new efficient LLVM family with model sizes of 0.5B, 1.8B, 3.8B, and 7B parameters, Phantom, which significantly enhances learning capabilities within limited structures. By temporarily increasing the latent hidden dimension during multi-head self-attention (MHSA), we make LLVMs prepare to look and understand much more vision-language knowledge on the latent, without substantially increasing physical model sizes. To maximize its advantage, we introduce Phantom Optimization (PO) using both autoregressive supervised fine-tuning (SFT) and direct preference optimization (DPO)-like concept, which effectively follows correct answers while eliminating incorrect and ambiguous ones. Phantom outperforms numerous larger open- and closed-source LLVMs, positioning itself as a leading solution in the landscape of efficient LLVMs.",
      "paperUrl": "https://arxiv.org/pdf/2409.14713",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2409.14713",
      "tags": [
        "Performance",
        "Optimizations"
      ],
      "keywords": [
        "Performance",
        "Optimizations",
        "LLVM",
        "Phantom",
        "Latent",
        "Vision"
      ],
      "matchedAuthors": [
        "Beomchan Park",
        "Byung‐Kwan Lee",
        "Chae Won Kim",
        "Yong Man Ro"
      ]
    },
    {
      "id": "openalex-w4409053569",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Parallel, Portable Sparse Code Generation with MLIR and Kokkos",
      "authors": [
        {
          "name": "Brian Kelley",
          "affiliation": "Sandia National Laboratories"
        },
        {
          "name": "Kim Liegeois",
          "affiliation": "Sandia National Laboratories"
        },
        {
          "name": "Sivasankaran Rajamanickam",
          "affiliation": "Sandia National Laboratories"
        }
      ],
      "year": "2024",
      "publication": "OSTI OAI (U.S. Department of Energy Office of Scientific and Technical Information)",
      "venue": "OSTI OAI (U.S. Department of Energy Office of Scientific and Technical Information)",
      "type": "research-paper",
      "abstract": "No abstract available in discovery metadata.",
      "paperUrl": "https://www.osti.gov/servlets/purl/2540327",
      "sourceUrl": "https://doi.org/10.2172/2540327",
      "tags": [
        "Backend",
        "MLIR"
      ],
      "keywords": [
        "Backend",
        "MLIR",
        "Code Generation",
        "Parallel Portable Sparse"
      ],
      "matchedAuthors": [
        "Kim Liegeois",
        "Sivasankaran Rajamanickam"
      ]
    },
    {
      "id": "openalex-w4402426700",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Ownership in low-level intermediate representation",
      "authors": [
        {
          "name": "Siddharth Priya",
          "affiliation": ""
        },
        {
          "name": "Arie Gurfinkel",
          "affiliation": ""
        }
      ],
      "year": "2024",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "The concept of ownership in high level languages can aid both the programmer and the compiler to reason about the validity of memory operations. Previously, ownership semantics has been used successfully in high level automatic program verification to model a reference to data by a first order logic (FOL) representation of data instead of maintaining an address map. However, ownership semantics is not used in low level program verification. We have identified two challenges. First, ownership information is lost when a program is compiled to a low level intermediate representation (e.g., in LLVM IR). Second, pointers in low level programs point to bytes using an address map (e.g., in unsafe Rust) and thus the verification condition (VC) cannot always replace a pointer by its FOL abstraction. To remedy the situation, we develop ownership semantics for an LLVM like low level intermediate representation. Using these semantics, the VC can opportunistically model some memory accesses by a direct access of a pointer cache that stores byte representation of data. This scheme reduces instances where an address map must be maintained, especially for mostly safe programs that follow ownership semantics. For unsafe functionality, memory accesses are modelled by operations on an address map and we provide mechanisms to keep the address map and pointer cache in sync. We implement these semantics in SEABMC, a bit precise bounded model checker for LLVM. For evaluation, the source programs are assumed to be written in C. Since C does not have ownership built in, suitable macros are added that introduce and preserve ownership during translation to LLVM like IR for verification. This approach is evaluated on mature open source C code. For both handcrafted benchmarks and practical programs, we observe a speedup of $1.3x-5x$ during SMT solving.",
      "paperUrl": "https://arxiv.org/pdf/2408.04043",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2408.04043",
      "tags": [
        "IR",
        "Rust"
      ],
      "keywords": [
        "IR",
        "Rust",
        "LLVM",
        "Intermediate Representation",
        "Ownership",
        "Address Map",
        "Ownership Semantics",
        "LLVM Like",
        "Program Verification",
        "Memory Accesses",
        "Pointer Cache"
      ],
      "matchedAuthors": [
        "Arie Gurfinkel"
      ]
    },
    {
      "id": "openalex-w4407394441",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Open-Source MLIR-Based Intermediate Representation for Applica-tion-Specific Streaming Computers",
      "authors": [
        {
          "name": "Alexander Kamkin",
          "affiliation": ""
        },
        {
          "name": "Mikhail Yurievich Litvinov",
          "affiliation": ""
        },
        {
          "name": "Ivan Aleksandrovich Grigorov",
          "affiliation": ""
        }
      ],
      "year": "2024",
      "publication": "Proceedings of the Institute for System Programming of RAS",
      "venue": "Proceedings of the Institute for System Programming of RAS | Vol. 36 (Issue 5)",
      "type": "research-paper",
      "abstract": "Recently, heterogeneous computer systems have been widely used to solve computational tasks with strict constraints on performance (throughput) and power consumption. Typically, such systems consist of general-purpose microprocessors and FPGA-based hardware accelerators implementing the most expensive operations (which are usually application-specific ones). This article is devoted to the design automation of hardware accelerators for streaming data computing. The features of this type of accelerators (and the problems they solve) are as follows: (1) continuous (cycle-by-cycle) reception and production of data; (2) bounded (in time and memory) output-input dependence. Streaming data computing covers a wide range of applications, including digital signal processing, traffic encryption, numerical modeling, bioinformatics, etc. The paper introduces the concept of DFCIR (DataFlow Computer Intermediate Representation), а language for an intermediate representation of streaming data computing designs. The DFCIR language is based on the open compiler infrastructure MLIR (Multi-Level Intermediate Representation). RTL models of accelerators are built from DFCIR descriptions with the use of CIRCT (Circuit IR Compilers and Tools), a subproject of MLIR that combines tools for working with hardware designs.",
      "paperUrl": "https://ispranproceedings.elpub.ru/jour/article/download/1861/1704",
      "sourceUrl": "https://doi.org/10.15514/ispras-2024-36(5)-3",
      "tags": [
        "Performance",
        "IR",
        "Infrastructure",
        "MLIR",
        "CIRCT"
      ],
      "keywords": [
        "Performance",
        "IR",
        "Infrastructure",
        "MLIR",
        "CIRCT",
        "Intermediate Representation",
        "Accelerators",
        "Hardware Accelerators",
        "Applica Tion Specific",
        "Specific Streaming Computers",
        "Tion Specific Streaming"
      ],
      "matchedAuthors": [
        "Alexander Kamkin"
      ]
    },
    {
      "id": "openalex-w4392964311",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Modern High-Level Synthesis: Improving Productivity with a Multi-level Approach",
      "authors": [
        {
          "name": "Serena Curzel",
          "affiliation": "Politecnico di Milano"
        }
      ],
      "year": "2024",
      "publication": "SpringerBriefs in applied sciences and technology",
      "venue": "SpringerBriefs in applied sciences and technology",
      "type": "research-paper",
      "abstract": "Abstract High-Level Synthesis (HLS) tools simplify the design of hardware accelerators by automatically generating Verilog/VHDL code starting from a general-purpose software programming language. Because of the mismatch between the requirements of hardware descriptions and the characteristics of input languages, HLS tools still require hardware design knowledge and non-trivial design space exploration, which might be an obstacle for domain scientists seeking to accelerate applications written, for example, in Python-based programming frameworks. This research proposes a modern approach based on multi-level compiler technologies to bridge the gap between HLS and high-level frameworks, and to use domain-specific abstractions to solve domain-specific problems. The key enabling technology is the Multi-Level Intermediate Representation (MLIR), a framework that supports building reusable compiler infrastructure. The proposed approach uses MLIR to introduce new optimizations at appropriate levels of abstraction outside the HLS tool while still relying on years of HLS research in the low-level hardware generation steps; users and developers of HLS tools can thus increase their productivity, obtain accelerators with higher performance, and not be limited by the features of a specific (possibly closed-source) backend. The presented tools and techniques were designed, implemented, and tested to synthesize machine learning algorithms, but they are broadly applicable to any input specification written in a language that has a translation to MLIR. Generated accelerators can be deployed on Field Programmable Gate Arrays or Application-Specific Integrated Circuits, and they can reach high energy efficiency without any manual optimization of the code.",
      "paperUrl": "https://link.springer.com/content/pdf/10.1007/978-3-031-51500-2_2.pdf",
      "sourceUrl": "https://doi.org/10.1007/978-3-031-51500-2_2",
      "tags": [
        "Backend",
        "Performance",
        "Optimizations",
        "IR",
        "Programming Languages",
        "Infrastructure",
        "ML",
        "MLIR"
      ],
      "keywords": [
        "Backend",
        "Performance",
        "Optimizations",
        "IR",
        "Programming Languages",
        "Infrastructure",
        "ML",
        "MLIR",
        "Intermediate Representation",
        "HLS",
        "Hardware",
        "Specific",
        "Accelerators",
        "Domain Specific"
      ],
      "matchedAuthors": [
        "Serena Curzel"
      ]
    },
    {
      "id": "openalex-w4399114721",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Meteor: Mamba-based Traversal of Rationale for Large Language and Vision Models",
      "authors": [
        {
          "name": "Byung-Kwan Lee",
          "affiliation": ""
        },
        {
          "name": "Chae Won Kim",
          "affiliation": ""
        },
        {
          "name": "Beomchan Park",
          "affiliation": ""
        },
        {
          "name": "Yong Man Ro",
          "affiliation": ""
        }
      ],
      "year": "2024",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "The rapid development of large language and vision models (LLVMs) has been driven by advances in visual instruction tuning. Recently, open-source LLVMs have curated high-quality visual instruction tuning datasets and utilized additional vision encoders or multiple computer vision models in order to narrow the performance gap with powerful closed-source LLVMs. These advancements are attributed to multifaceted information required for diverse capabilities, including fundamental image understanding, real-world knowledge about common-sense and non-object concepts (e.g., charts, diagrams, symbols, signs, and math problems), and step-by-step procedures for solving complex questions. Drawing from the multifaceted information, we present a new efficient LLVM, Mamba-based traversal of rationales (Meteor), which leverages multifaceted rationale to enhance understanding and answering capabilities. To embed lengthy rationales containing abundant information, we employ the Mamba architecture, capable of processing sequential data with linear time complexity. We introduce a new concept of traversal of rationale that facilitates efficient embedding of rationale. Subsequently, the backbone multimodal language model (MLM) is trained to generate answers with the aid of rationale. Through these steps, Meteor achieves significant improvements in vision language performances across multiple evaluation benchmarks requiring diverse capabilities, without scaling up the model size or employing additional vision encoders and computer vision models.",
      "paperUrl": "https://arxiv.org/pdf/2405.15574",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2405.15574",
      "tags": [
        "Performance"
      ],
      "keywords": [
        "Performance",
        "LLVM",
        "Additional Vision Encoders",
        "Rationale",
        "Visual Instruction Tuning",
        "Meteor Mamba",
        "Traversal",
        "Diverse Capabilities",
        "Computer Vision"
      ],
      "matchedAuthors": [
        "Beomchan Park",
        "Byung‐Kwan Lee",
        "Chae Won Kim",
        "Yong Man Ro"
      ]
    },
    {
      "id": "openalex-w4401753413",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "MLIR-to-CGRA: A Versatile MLIR-Based Compiler Framework for CGRAs",
      "authors": [
        {
          "name": "Tianyi Yu",
          "affiliation": "University of Toronto"
        },
        {
          "name": "Omar Ragheb",
          "affiliation": "University of Toronto"
        },
        {
          "name": "Stephen Wicklund",
          "affiliation": "University of Toronto"
        },
        {
          "name": "Jason H. Anderson",
          "affiliation": "University of Toronto"
        }
      ],
      "year": "2024",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "Coarse-grained reconfigurable architectures (CGRAs) are programmable hardware platforms with coarse-grained programmable logic blocks and word-wide configurable interconnect. In this paper, we describe a high-level compilation framework tailored for CGRAs. The input to the framework is a C-language program and description of the available CG RA architectural features. This work primarily focuses on automatically handling sequential rectangular loop access patterns. It achieves this by running automated design space exploration (DSE) written within the MLIR compiler representation [7] to leverage both spatial and temporal parallelism inherent in CG RAs. Furthermore, the compiler is engineered to be architecture-agnostic. It employs standard loop (and other) compiler optimization passes alongside CG RA-specific passes to generate a data flow graph (DFG) tailored for a CG RA implementation. In an experimental study, we optimize kernels to increase CG RA mappability and show the impact of automated DSE on the kernel performance. Moreover, the framework eases the task of compilation from software to RISC-V+CGRA hybrid systems.",
      "paperUrl": "http://dx.doi.org/10.1109/asap61560.2024.00045",
      "sourceUrl": "https://doi.org/10.1109/asap61560.2024.00045",
      "tags": [
        "Performance",
        "Optimizations",
        "MLIR"
      ],
      "keywords": [
        "Performance",
        "Optimizations",
        "MLIR",
        "CGRAs",
        "Versatile MLIR",
        "Coarse Grained",
        "Compilation"
      ],
      "matchedAuthors": [
        "Jason H. Anderson"
      ]
    },
    {
      "id": "openalex-w4399723228",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "MLIR-Based Homomorphic Encryption Compiler for GPU",
      "authors": [
        {
          "name": "Ai Nozaki",
          "affiliation": "The University of Tokyo"
        },
        {
          "name": "Takuya Kojima",
          "affiliation": "The University of Tokyo"
        },
        {
          "name": "Hiroshi Nakamura",
          "affiliation": "The University of Tokyo"
        },
        {
          "name": "Hideki Takase",
          "affiliation": "The University of Tokyo"
        }
      ],
      "year": "2024",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "Homomorphic Encryption (HE) enables computing over encrypted data and has attracted attention as an approach to data protection with the spread of cloud computing. To tackle the expensive computational cost of HE, hardware accelerators have been studied. However, developing HE applications and accelerating them with hardware is challenging because it requires a deep understanding of both HE and hardware. Previous work proposed compilers to automate the development of HE applications, but most of them target CPUs, so automation for accelerators is not well established. This work proposes an MLIR-based HE compiler that automates the transformation of applications into HE and accelerates the process using GPU. This compiler enables users to perform GPU acceleration without requiring knowledge of GPU and its tools.",
      "paperUrl": "https://doi.org/10.1145/3665283.3665343",
      "sourceUrl": "",
      "tags": [
        "GPU",
        "MLIR"
      ],
      "keywords": [
        "GPU",
        "MLIR",
        "Homomorphic Encryption Compiler",
        "Hardware"
      ],
      "matchedAuthors": [
        "Takuya Kojima"
      ]
    },
    {
      "id": "openalex-w4399695942",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "LLAVIDAL: A Large LAnguage VIsion Model for Daily Activities of Living",
      "authors": [
        {
          "name": "Rajatsubhra Chakraborty",
          "affiliation": ""
        },
        {
          "name": "Arkaprava Sinha",
          "affiliation": ""
        },
        {
          "name": "Dominick Reilly",
          "affiliation": ""
        },
        {
          "name": "M. Govind",
          "affiliation": ""
        },
        {
          "name": "Pu Wang",
          "affiliation": ""
        },
        {
          "name": "François Brémond",
          "affiliation": ""
        },
        {
          "name": "Srijan Das",
          "affiliation": ""
        },
        {
          "name": "Das, Srijan",
          "affiliation": ""
        }
      ],
      "year": "2024",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Current Large Language Vision Models (LLVMs) trained on web videos perform well in general video understanding but struggle with fine-grained details, complex human-object interactions (HOI), and view-invariant representation learning essential for Activities of Daily Living (ADL). This limitation stems from a lack of specialized ADL video instruction-tuning datasets and insufficient modality integration to capture discriminative action representations. To address this, we propose a semi-automated framework for curating ADL datasets, creating ADL-X, a multiview, multimodal RGBS instruction-tuning dataset. Additionally, we introduce LLAVIDAL, an LLVM integrating videos, 3D skeletons, and HOIs to model ADL's complex spatiotemporal relationships. For training LLAVIDAL a simple joint alignment of all modalities yields suboptimal results; thus, we propose a Multimodal Progressive (MMPro) training strategy, incorporating modalities in stages following a curriculum. We also establish ADL MCQ and video description benchmarks to assess LLVM performance in ADL tasks. Trained on ADL-X, LLAVIDAL achieves state-of-the-art performance across ADL benchmarks. Code and data will be made publicly available at: https://adl-x.github.io/.",
      "paperUrl": "https://arxiv.org/pdf/2406.09390",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2406.09390",
      "tags": [
        "Performance"
      ],
      "keywords": [
        "Performance",
        "LLVM",
        "Llavidal",
        "Language Vision",
        "Instruction Tuning",
        "Daily Activities"
      ],
      "matchedAuthors": [
        "Arkaprava Sinha",
        "Dominick Reilly",
        "M. Govind",
        "Pu Wang",
        "Rajatsubhra Chakraborty",
        "Srijan Das"
      ]
    },
    {
      "id": "openalex-w4401476326",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Implementing OpenMP for Zig to Enable Its Use in HPC Context",
      "authors": [
        {
          "name": "Davids Kacs",
          "affiliation": "University of Edinburgh"
        },
        {
          "name": "Nick Brown",
          "affiliation": "University of Edinburgh"
        },
        {
          "name": "Joseph K. L. Lee",
          "affiliation": "University of Edinburgh"
        }
      ],
      "year": "2024",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "This extended abstract explores supporting OpenMP in the Zig programming language. Whilst, C and Fortran are currently the main languages used to implement HPC applications, Zig provides a similar level of performance complimented with several modern language features, such as enforcing memory safety. However, Zig lacks support for OpenMP which is the de facto threaded programming technology.<br/><br/>Leveraging Zig’s LLVM compiler tooling, we have added partial support for OpenMP to the Zig compiler and demonstrated that the performance attained by using Zig with OpenMP is comparable to, and in come cases exceeds, that of conventional HPC languages. Consequently we demonstrate that Zig is a viable and important programming technology to use for HPC, and this work paves the way for more HPC features to be added to Zig, ultimately providing HPC developers with the option of using a safer, more modern language for creating high performance applications.",
      "paperUrl": "https://doi.org/10.1145/3677333.3678273",
      "sourceUrl": "",
      "tags": [
        "Security",
        "Performance",
        "Programming Languages"
      ],
      "keywords": [
        "Security",
        "Performance",
        "Programming Languages",
        "LLVM",
        "Memory Safety",
        "HPC",
        "Implementing OpenMP",
        "Programming Technology"
      ],
      "matchedAuthors": [
        "Joseph K. L. Lee",
        "Nick Brown"
      ]
    },
    {
      "id": "openalex-w4408219739",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Hardware/software co-design and compiler techniques for efficient hardware acceleration of dense linear algebra kernels and machine learning applications:",
      "authors": [
        {
          "name": "Nícolas Bohm Agostini",
          "affiliation": ""
        }
      ],
      "year": "2024",
      "publication": "",
      "venue": "",
      "type": "thesis",
      "abstract": "Today's linear algebra and machine learning applications (ML) continue to grow in size and complexity, placing rapidly increasing demands on the underlying hardware and software systems. To address these issues, hardware designers have proposed using custom accelerators explicitly designed for these demanding workloads. However, realizing the full potential of custom accelerators requires effective hardware/software (HW/SW) co-design strategies that enable seamless integration and optimization across both domains, which is currently a major challenge in accelerator development. This thesis presents an integrated solution to facilitate HW/SW accelerator design. We also address issues in accelerator deployment, enabling rapid prototyping, integrated benchmarking, and comprehensive performance analysis of custom accelerators. In this thesis, we demonstrate the value of a lightweight system modeling library integrated into the build/execution environment of a production ML runtime engine, leveraging TensorFlow Lite for deployment. We explore custom accelerators performance by analyzing the trade-offs between various design choices, including parameter settings and accelerator configurations, from small to large scale, to identify the most effective combinations for specific workloads. Secondly, we employ the Multi-Level Intermediate Representation (MLIR) compiler framework to automatically partition host code from accelerator code, pre-optimizing the latter for improved high-level synthesis (HLS) designs and high-quality accelerated kernels. Lastly, we present compiler extensions to automate the generation and optimization of communication between the host CPU and AXI-based accelerators. We present novel solutions that enable more efficient and effective design space exploration, optimization, and deployment of custom accelerators. The utility of these approaches is demonstrated through experiments with specific accelerator designs and key linear algebra and ML workloads. Most importantly, these solutions empower high-level language users, such as domain scientists, to participate in the design of new accelerator features.--Author's abstract",
      "paperUrl": "https://repository.library.northeastern.edu/files/neu:ms36wj24q/fulltext.pdf",
      "sourceUrl": "https://doi.org/10.17760/d20699019",
      "tags": [
        "Performance",
        "Optimizations",
        "IR",
        "ML",
        "MLIR"
      ],
      "keywords": [
        "Performance",
        "Optimizations",
        "IR",
        "ML",
        "MLIR",
        "Intermediate Representation",
        "Custom Accelerators",
        "Hardware Acceleration",
        "Dense Linear Algebra",
        "Machine Learning",
        "Deployment",
        "Workloads",
        "Linear Algebra Kernels"
      ],
      "matchedAuthors": [
        "Nícolas Bohm Agostini"
      ]
    },
    {
      "id": "openalex-w4392088149",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Guac: Energy-Aware and SSA-Based Generation of Coarse-Grained Merged Accelerators from LLVM-IR",
      "authors": [
        {
          "name": "Iulian Brumar",
          "affiliation": ""
        },
        {
          "name": "Rodrigo Tumolin Rocha",
          "affiliation": ""
        },
        {
          "name": "Alex Bernat",
          "affiliation": ""
        },
        {
          "name": "Devashree Tripathy",
          "affiliation": ""
        },
        {
          "name": "D. Brooks",
          "affiliation": ""
        },
        {
          "name": "Gu-Yeon Wei",
          "affiliation": ""
        }
      ],
      "year": "2024",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Designing accelerators for resource- and power-constrained applications is a daunting task. High-level Synthesis (HLS) addresses these constraints through resource sharing, an optimization at the HLS binding stage that maps multiple operations to the same functional unit. However, resource sharing is often limited to reusing instructions within a basic block. Instead of searching globally for the best control and dataflow graphs (CDFGs) to combine, it is constrained by existing instruction mappings and schedules. Coarse-grained function merging (CGFM) at the intermediate representation (IR) level can reuse control and dataflow patterns without dealing with the post-scheduling complexity of mapping operations onto functional units, wires, and registers. The merged functions produced by CGFM can be translated to RTL by HLS, yielding Coarse Grained Merged Accelerators (CGMAs). CGMAs are especially profitable across applications with similar data- and control-flow patterns. Prior work has used CGFM to generate CGMAs without regard for which CGFM algorithms best optimize area, power, and energy costs. We propose Guac, an energy-aware and SSA-based (static single assignment) CGMA generation methodology. Guac implements a novel ensemble of cost models for efficient CGMA generation. We also show that CGFM algorithms using SSA form to merge control- and dataflow graphs outperform prior non-SSA CGFM designs. We demonstrate significant area, power, and energy savings with respect to the state of the art. In particular, Guac more than doubles energy savings with respect to the closest related work while using a strong resource-sharing baseline.",
      "paperUrl": "https://arxiv.org/pdf/2402.13513",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2402.13513",
      "tags": [
        "Optimizations",
        "IR"
      ],
      "keywords": [
        "Optimizations",
        "IR",
        "LLVM",
        "Intermediate Representation",
        "Static Single Assignment",
        "Guac Energy Aware",
        "Coarse Grained Merged",
        "SSA",
        "Resource Sharing",
        "Control",
        "Grained Merged Accelerators",
        "Dataflow Graphs",
        "HLS",
        "Area Power"
      ],
      "matchedAuthors": [
        "Gu-Yeon Wei"
      ]
    },
    {
      "id": "openalex-w4391212478",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Gray-Box Fuzzing via Gradient Descent and Boolean Expression Coverage (Technical Report)",
      "authors": [
        {
          "name": "Martin Jonáš",
          "affiliation": ""
        },
        {
          "name": "Jan Strejček",
          "affiliation": ""
        },
        {
          "name": "Marek Trtík",
          "affiliation": ""
        },
        {
          "name": "Lukáš Urban",
          "affiliation": ""
        }
      ],
      "year": "2024",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "We present a novel gray-box fuzzing algorithm monitoring executions of instructions converting numerical values to Boolean ones. An important class of such instructions evaluate predicates, e.g., *cmp in LLVM. That alone allows us to infer the input dependency (c.f. the taint analysis) during the fuzzing on-the-fly with reasonable accuracy, which in turn enables an effective use of the gradient descent on these instructions (to invert the result of their evaluation). Although the fuzzing attempts to maximize the coverage of the instructions, there is an interesting correlation with the standard branch coverage, which we are able to achieve indirectly. The evaluation on Test-Comp 2023 benchmarks shows that our approach, despite being a pure gray-box fuzzing, is able to compete with the leading tools in the competition, which combine fuzzing with other powerful techniques like model checking, symbolic execution, or abstract interpretation.",
      "paperUrl": "https://arxiv.org/pdf/2401.12643",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2401.12643",
      "tags": [
        "Testing",
        "Dynamic Analysis"
      ],
      "keywords": [
        "Testing",
        "Dynamic Analysis",
        "LLVM",
        "Symbolic Execution",
        "Model Checking",
        "Fuzzing",
        "Gray Box Fuzzing",
        "Boolean Expression Coverage",
        "Gradient Descent",
        "Coverage Technical Report",
        "Expression Coverage Technical"
      ],
      "matchedAuthors": [
        "Jan Strejček",
        "Martin Jonáš"
      ]
    },
    {
      "id": "openalex-w4405621186",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Galapagos: Automated N-Version Programming with LLMs",
      "authors": [
        {
          "name": "Javier Ron",
          "affiliation": ""
        },
        {
          "name": "Diogo Gaspar",
          "affiliation": ""
        },
        {
          "name": "Javier Cabrera-Arteaga",
          "affiliation": ""
        },
        {
          "name": "Benoît Baudry",
          "affiliation": ""
        },
        {
          "name": "Martin Monperrus",
          "affiliation": ""
        }
      ],
      "year": "2024",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "N-Version Programming is a well-known methodology for developing fault-tolerant systems. It achieves fault detection and correction at runtime by adding diverse redundancy into programs, minimizing fault mode overlap between redundant program variants. In this work, we propose the automated generation of program variants using large language models. We design, develop and evaluate Galápagos: a tool for generating program variants using LLMs, validating their correctness and equivalence, and using them to assemble N-Version binaries. We evaluate Galápagos by creating N-Version components of real-world C code. Our original results show that Galápagos can produce program variants that are proven to be functionally equivalent, even when the variants are written in a different programming language. Our systematic diversity measurement indicates that functionally equivalent variants produced by Galápagos, are statically different after compilation, and present diverging internal behavior at runtime. We demonstrate that the variants produced by Galápagos can protect C code against real miscompilation bugs which affect the Clang compiler. Overall, our paper shows that producing N-Version software can be drastically automated by advanced usage of practical formal verification and generative language models.",
      "paperUrl": "https://arxiv.org/pdf/2408.09536",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2408.09536",
      "tags": [
        "Clang",
        "Programming Languages"
      ],
      "keywords": [
        "Clang",
        "Programming Languages",
        "Formal Verification",
        "Evaluate Gal Pagos",
        "Program Variants",
        "Version Programming",
        "Functionally Equivalent",
        "Variants Produced",
        "Galapagos Automated"
      ],
      "matchedAuthors": [
        "Martin Monperrus"
      ]
    },
    {
      "id": "openalex-w4402457426",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Fuzzing MLIR Compiler Infrastructure via Operation Dependency Analysis",
      "authors": [
        {
          "name": "Chenyao Suo",
          "affiliation": "Tianjin University"
        },
        {
          "name": "Junjie Chen",
          "affiliation": "Tianjin University"
        },
        {
          "name": "Shuang Liu",
          "affiliation": "Renmin University of China"
        },
        {
          "name": "Jiajun Jiang",
          "affiliation": "Tianjin University"
        },
        {
          "name": "Yingquan Zhao",
          "affiliation": "Tianjin University"
        },
        {
          "name": "Jianrong Wang",
          "affiliation": "Tianjin University"
        }
      ],
      "year": "2024",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "MLIR (Multi-Level Intermediate Representation) compiler infrastructure has gained widespread popularity in recent years. It introduces dialects to accommodate various levels of abstraction within the representation. Due to its fundamental role in compiler construction, it is critical to ensure its correctness. Recently, a grammar-based fuzzing technique (i.e., MLIRSmith) has been proposed for it and achieves notable effectiveness. However, MLIRSmith generates test programs in a random manner, which restricts the exploration of the input space, thereby limiting the overall fuzzing effectiveness. In this work, we propose a novel fuzzing technique, called MLIR. As complicated or uncommon data/control dependencies among various operations are often helpful to trigger MLIR bugs, it constructs the operation dependency graph for an MLIR program and defines the associated operation dependency coverage to guide the fuzzing process. To drive the fuzzing process towards increasing operation dependency coverage, MLIR then designs a set of dependency-targeted mutation rules. By applying MLIR to the latest revisions of the MLIR compiler infrastructure, it detected 63 previously unknown bugs, among which 38/48 bugs have been fixed/confirmed by developers.",
      "paperUrl": "https://doi.org/10.1145/3650212.3680360",
      "sourceUrl": "",
      "tags": [
        "IR",
        "Testing",
        "Infrastructure",
        "MLIR"
      ],
      "keywords": [
        "IR",
        "Testing",
        "Infrastructure",
        "MLIR",
        "Intermediate Representation",
        "Fuzzing",
        "Fuzzing MLIR Compiler",
        "Fuzzing Process",
        "Operation Dependency Coverage",
        "MLIR Compiler Infrastructure"
      ],
      "matchedAuthors": [
        "Chenyao Suo",
        "Jiajun Jiang",
        "Junjie Chen",
        "Shuang Liu"
      ]
    },
    {
      "id": "openalex-w4394769544",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Fuzz4All: Universal Fuzzing with Large Language Models",
      "authors": [
        {
          "name": "Chunqiu Steven Xia",
          "affiliation": "Urbana University"
        },
        {
          "name": "Matteo Paltenghi",
          "affiliation": "University of Stuttgart"
        },
        {
          "name": "Jia Le Tian",
          "affiliation": "Urbana University"
        },
        {
          "name": "Michael Pradel",
          "affiliation": "University of Stuttgart"
        },
        {
          "name": "Lingming Zhang",
          "affiliation": "Urbana University"
        }
      ],
      "year": "2024",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "Fuzzing has achieved tremendous success in discovering bugs and vulnerabilities in various software systems. Systems under test (SUTs) that take in programming or formal language as inputs, e.g., compilers, runtime engines, constraint solvers, and software libraries with accessible APIs, are especially important as they are fundamental building blocks of software development. However, existing fuzzers for such systems often target a specific language, and thus cannot be easily applied to other languages or even other versions of the same language. Moreover, the inputs generated by existing fuzzers are often limited to specific features of the input language, and thus can hardly reveal bugs related to other or new features. This paper presents Fuzz4All, the first fuzzer that is universal in the sense that it can target many different input languages and many different features of these languages. The key idea behind Fuzz4All is to leverage large language models (LLMs) as an input generation and mutation engine, which enables the approach to produce diverse and realistic inputs for any practically relevant language. To realize this potential, we present a novel autoprompting technique, which creates LLM prompts that are well-suited for fuzzing, and a novel LLM-powered fuzzing loop, which iteratively updates the prompt to create new fuzzing inputs. We evaluate Fuzz4All on nine systems under test that take in six different languages (C, C++, Go, SMT2, Java, and Python) as inputs. The evaluation shows, across all six languages, that universal fuzzing achieves higher coverage than existing, language-specific fuzzers. Furthermore, Fuzz4All has identified 98 bugs in widely used systems, such as GCC, Clang, Z3, CVC5, OpenJDK, and the Qiskit quantum computing platform, with 64 bugs already confirmed by developers as previously unknown.",
      "paperUrl": "https://doi.org/10.1145/3597503.3639121",
      "sourceUrl": "",
      "tags": [
        "Clang",
        "Testing",
        "Quantum Computing",
        "Libraries"
      ],
      "keywords": [
        "Clang",
        "Testing",
        "Quantum Computing",
        "Libraries",
        "Fuzzing",
        "Quantum Compilation",
        "Fuzz4all",
        "Inputs",
        "Fuzz4all Universal Fuzzing",
        "Fuzzers",
        "Specific"
      ],
      "matchedAuthors": [
        "Lingming Zhang"
      ]
    },
    {
      "id": "openalex-w4391725335",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Facilitating Non-Intrusive In-Vivo Firmware Testing with Stateless Instrumentation",
      "authors": [
        {
          "name": "Jiameng Shi",
          "affiliation": ""
        },
        {
          "name": "Wenqiang Li",
          "affiliation": ""
        },
        {
          "name": "Wenwen Wang",
          "affiliation": ""
        },
        {
          "name": "Le Guan",
          "affiliation": ""
        }
      ],
      "year": "2024",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "Although numerous dynamic testing techniques have been developed, they can hardly be directly applied to firmware of deeply embedded (e.g., microcontroller-based) devices due to the tremendously different runtime environment and restricted resources on these devices.This work tackles these challenges by leveraging the unique position of microcontroller devices during firmware development.That is, firmware developers have to rely on a powerful engineering workstation that connects to the target device to program and debug code.Therefore, we develop a decoupled firmware testing framework named IPEA, which shifts the overhead of resource-intensive analysis tasks from the microcontroller to the workstation.Only lightweight \"needle probes\" are left in the firmware to collect internal execution information without processing it.We also instantiated this framework with a sanitizer based on pointer capability (IPEA-San) and a greybox fuzzer (IPEA-Fuzz).By comparing IPEA-San with a port of AddressSanitizer for microcontrollers, we show that IPEA-San reduces memory overhead by 62.75% in real-world firmware with better detection accuracy.Combining IPEA-Fuzz with IPEA-San, we found 7 zero-day bugs in popular IoT libraries (3) and peripheral driver code (4).",
      "paperUrl": "https://doi.org/10.14722/ndss.2024.23116",
      "sourceUrl": "",
      "tags": [
        "Embedded",
        "Testing",
        "Libraries"
      ],
      "keywords": [
        "Embedded",
        "Testing",
        "Libraries",
        "Fuzzing",
        "Sanitizers",
        "Vivo Firmware Testing",
        "Ipea San",
        "Devices",
        "Microcontroller",
        "Ipea Fuzz",
        "Facilitating Non Intrusive",
        "Stateless Instrumentation"
      ],
      "matchedAuthors": [
        "Wenwen Wang"
      ]
    },
    {
      "id": "openalex-w4404133713",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "FHE-CGRA: Enable Efficient Acceleration of Fully Homomorphic Encryption on CGRAs",
      "authors": [
        {
          "name": "M.-H. Jiang",
          "affiliation": "Shandong University"
        },
        {
          "name": "Yilan Zhu",
          "affiliation": "Shandong University"
        },
        {
          "name": "Honghui You",
          "affiliation": "Shandong University"
        },
        {
          "name": "Cheng Tan",
          "affiliation": "Google (United States)"
        },
        {
          "name": "Zhaoying Li",
          "affiliation": "National University of Singapore"
        },
        {
          "name": "Jiming Xu",
          "affiliation": ""
        },
        {
          "name": "Lei Ju",
          "affiliation": "Shandong University of Science and Technology"
        }
      ],
      "year": "2024",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "Fully Homomorphic Encryption (FHE) is an attractive privacy-preserving technique that allows computation directly on encrypted data without decryption. However, it incurs significant performance and memory costs due to intensive computations. In this work, we investigate the execution of FHE-enabled machine learning (ML) applications. We show that the runtime hardware reconfigurability of the underlying execution units of homomorphic operations is highly desirable for efficient hardware resource utilization during FHE-ML execution, due to the changing FHE encryption variants across different ML stages (e.g., the multiplicative level of the ciphertext) and corresponding optimal execution unit design. Based on the observation, we propose FHE-CGRA, a coarse-grained re-configurable architecture (CGRA) acceleration framework with an MLIR-based compiler toolchain for end-to-end homomorphic applications. The experiment shows that FHE-CGRA achieves up-to 8.15× speedup against a conventional CGRA baseline for accelerating the inference of FHE-encrypted convolution neural network (FHE-CNN) models, and up-to 16.48× power efficiency w.r.t. the state-of-the-art FPGA-based FHE-CNN accelerator design.",
      "paperUrl": "https://doi.org/10.1145/3649329.3656536",
      "sourceUrl": "",
      "tags": [
        "Performance",
        "Infrastructure",
        "ML",
        "MLIR"
      ],
      "keywords": [
        "Performance",
        "Infrastructure",
        "ML",
        "MLIR",
        "Fhe CGRA",
        "Fully Homomorphic Encryption",
        "Fhe Cnn",
        "Hardware"
      ],
      "matchedAuthors": [
        "Cheng Tan"
      ]
    },
    {
      "id": "openalex-w4394798706",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "ESFuzzer: An Efficient Way to Fuzz WebAssembly Interpreter",
      "authors": [
        {
          "name": "Jideng Han",
          "affiliation": "Harbin Institute of Technology"
        },
        {
          "name": "Zhaoxin Zhang",
          "affiliation": "Harbin Institute of Technology"
        },
        {
          "name": "Yuejin Du",
          "affiliation": "Qihoo 360 (China)"
        },
        {
          "name": "Wei Wang",
          "affiliation": "Harbin Institute of Technology"
        },
        {
          "name": "Xiuyuan Chen",
          "affiliation": ""
        }
      ],
      "year": "2024",
      "publication": "Electronics",
      "venue": "Electronics | Vol. 13 (Issue 8)",
      "type": "research-paper",
      "abstract": "WebAssembly code is designed to run in a sandboxed environment, such as a web browser, providing a high level of security and isolation from the underlying operating system and hardware. This enables the execution of untrusted code in a web browser without compromising the security and integrity of the user’s system. This paper discusses the challenges associated with using fuzzing tools to identify vulnerabilities or bugs in WebAssembly interpreters. Our approach, known as ESFuzzer, introduces an efficient method for fuzzing WebAssembly interpreters using an Equivalent-Statement concept and the Stack Repair Algorithm. The samples generated by our approach successfully passed code validation. In addition, we developed effective mutation strategies to enhance the efficacy of our approach. ESFuzzer has demonstrated its ability to generate code that achieves 100% WebAssembly validation testing and achieves code coverage that is more than twice that of libFuzzer. Furthermore, the 24-h experiment results show that ESFuzzer performs ten times more efficiently than libFuzzer.",
      "paperUrl": "https://www.mdpi.com/2079-9292/13/8/1498/pdf?version=1713169799",
      "sourceUrl": "https://doi.org/10.3390/electronics13081498",
      "tags": [
        "Security",
        "Testing"
      ],
      "keywords": [
        "Security",
        "Testing",
        "Fuzzing",
        "Esfuzzer",
        "Web Browser",
        "Webassembly Interpreters",
        "Fuzz Webassembly Interpreter"
      ],
      "matchedAuthors": [
        "Wei Wang"
      ]
    },
    {
      "id": "openalex-w4405765777",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Do we still need canaries in the coal mine? Measuring shadow stack effectiveness in countering stack smashing",
      "authors": [
        {
          "name": "Hugo Depuydt",
          "affiliation": ""
        },
        {
          "name": "Merve Gülmez",
          "affiliation": ""
        },
        {
          "name": "Thomas Nyman",
          "affiliation": ""
        },
        {
          "name": "Jan Tobias Mühlberg",
          "affiliation": ""
        }
      ],
      "year": "2024",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Stack canaries and shadow stacks are widely deployed mitigations to memory-safety vulnerabilities. While stack canaries are introduced by the compiler and rely on sentry values placed between variables and control data, shadow stack implementations protect return addresses explicitly and rely on hardware features available in modern processor designs for efficiency. In this paper we hypothesize that stack canaries and shadow stacks provide similar levels of protections against sequential stack-based overflows. Based on the Juliet test suite, we evaluate whether 64-bit x86 (x86-64) systems benefit from enabling stack canaries in addition to the x86-64 shadow stack enforcement. We observe divergence in overflow detection rates between the GCC and Clang compilers and across optimization levels, which we attribute to differences in stack layouts generated by the compilers. We also find that x86-64 shadow stack implementations are more effective and outperform stack canaries when combined with a stack-protector-like stack layout. We implement and evaluate an enhancement to the Clang x86-64 shadow stack instrumentation that improves the shadow stack detection accuracy based on this observation.",
      "paperUrl": "https://arxiv.org/pdf/2412.16343",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2412.16343",
      "tags": [
        "Clang",
        "Optimizations"
      ],
      "keywords": [
        "Clang",
        "Optimizations",
        "Shadow Stacks",
        "Stack Canaries",
        "Countering Stack Smashing",
        "Measuring Shadow Stack",
        "Shadow Stack Effectiveness",
        "Still Need Canaries"
      ],
      "matchedAuthors": [
        "Jan Tobias Mühlberg",
        "Merve Gülmez",
        "Thomas Nyman"
      ]
    },
    {
      "id": "openalex-w4405270109",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Detecting Compiler Error Recovery Defects via Program Mutation Exploration",
      "authors": [
        {
          "name": "Yixuan Tang",
          "affiliation": "Nanjing University of Aeronautics and Astronautics"
        },
        {
          "name": "Jingxuan Zhang",
          "affiliation": "Nanjing University of Aeronautics and Astronautics"
        },
        {
          "name": "Xiaochen Li",
          "affiliation": "Dalian University of Technology"
        },
        {
          "name": "Zhiqiu Huang",
          "affiliation": "Nanjing University of Aeronautics and Astronautics"
        },
        {
          "name": "He Jiang",
          "affiliation": "Dalian University of Technology"
        }
      ],
      "year": "2024",
      "publication": "IEEE Transactions on Software Engineering",
      "venue": "IEEE Transactions on Software Engineering | Vol. 51 (Issue 2)",
      "type": "research-paper",
      "abstract": "Compiler error recovery diagnostics facilitates software development as it provides the possible causes and suggestions on potential programming errors. However, due to compiler bugs, error recovery diagnostics could be erroneous, spurious, missing, or even crashing for mature production compilers like GCC and Clang. Compiler testing is one of the most widely used ways of ensuring its quality. However, existing compiler diagnostics testing approaches (e.g., DIPROM) only consider the typically syntactically valid test programs as inputs, which are unlikely to trigger compiler error recovery defects. Therefore, in this paper, we propose the first mutation based approach for Compiler Error Recovery diagnostics Testing, called CERTest. Specifically, CERTest first explores the mutation space for a given seed program, and leverages a series of <i>mutation configurations</i> (which are referred as a series of mutators applying for a seed) to iteratively mutate the structures of the seed, so as to generate error-sensitive program variants for triggering compiler error recovery mechanisms. To effectively construct error-sensitive structures, CERTest then applies a novel furthest-first based selection approach to select a set of representative mutation configurations to generate program variants in each iteration. With the generated program variants, CERTest finally leverages differential testing to detect error recovery defects in different compilers. The experiments on GCC and Clang demonstrate that CERTest outperforms five state-of-the-art approaches (i.e., DIPROM, <small>Ccoft</small>, <small>Clang-fuzzer</small>, AFL++, and HiCOND) by up to 13.10%<inline-formula><tex-math notation=\"LaTeX\">$\\sim$</tex-math></inline-formula>221.61% on average in the term of bug-finding capability, and CERTest detects 9 new error recovery defects, 5 of which have been confirmed or fixed by developers.",
      "paperUrl": "https://doi.org/10.1109/tse.2024.3510912",
      "sourceUrl": "",
      "tags": [
        "Clang",
        "Testing"
      ],
      "keywords": [
        "Clang",
        "Testing",
        "Fuzzing",
        "Differential Testing",
        "Compiler Error Recovery",
        "Error Recovery Defects",
        "Certest",
        "Error Recovery Diagnostics",
        "Mutation Configurations",
        "Program Variants",
        "Diagnostics Testing",
        "Error Sensitive",
        "Inline Formula",
        "Tex Math"
      ],
      "matchedAuthors": [
        "He Jiang",
        "Jingxuan Zhang",
        "Xiaochen Li",
        "Yixuan Tang",
        "Zhiqiu Huang"
      ]
    },
    {
      "id": "openalex-w4400222461",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Dataflow-Based Optimization for Quantum Intermediate Representation Programs",
      "authors": [
        {
          "name": "Junjie Luo",
          "affiliation": ""
        },
        {
          "name": "Haoyu Zhang",
          "affiliation": ""
        },
        {
          "name": "Jianjun Zhao",
          "affiliation": ""
        }
      ],
      "year": "2024",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "This paper proposes QDFO, a dataflow-based optimization approach to Microsoft QIR. QDFO consists of two main functions: one is to preprocess the QIR code so that the LLVM optimizer can capture more optimization opportunities, and the other is to optimize the QIR code so that duplicate loading and constructing of qubits and qubit arrays can be avoided. We evaluated our work on the IBM Challenge Dataset, the results show that our method effectively reduces redundant operations in the QIR code. We also completed a preliminary implementation of QDFO and conducted a case study on the real-world code. Our observational study indicates that the LLVM optimizer can further optimize the QIR code preprocessed by our algorithm. Both the experiments and the case study demonstrate the effectiveness of our approach.",
      "paperUrl": "https://arxiv.org/pdf/2406.19592",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2406.19592",
      "tags": [
        "Optimizations",
        "IR"
      ],
      "keywords": [
        "Optimizations",
        "IR",
        "LLVM",
        "Intermediate Representation",
        "LLVM Optimizer",
        "Intermediate Representation Programs",
        "Quantum Intermediate Representation"
      ],
      "matchedAuthors": [
        "Haoyu Zhang",
        "Jianjun Zhao",
        "Junjie Luo"
      ]
    },
    {
      "id": "openalex-w4404306407",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Crux, a Precise Verifier for Rust and Other Languages",
      "authors": [
        {
          "name": "Stuart Pernsteiner",
          "affiliation": ""
        },
        {
          "name": "Iavor S. Diatchki",
          "affiliation": ""
        },
        {
          "name": "Robert Dockins",
          "affiliation": ""
        },
        {
          "name": "Mike Dodds",
          "affiliation": ""
        },
        {
          "name": "Joe Hendrix",
          "affiliation": ""
        },
        {
          "name": "Tristan Ravich",
          "affiliation": ""
        },
        {
          "name": "Patrick Redmond",
          "affiliation": ""
        },
        {
          "name": "Ryan P. Scott",
          "affiliation": ""
        },
        {
          "name": "Aaron Tomb",
          "affiliation": ""
        }
      ],
      "year": "2024",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "We present Crux, a cross-language verification tool for Rust and C/LLVM. Crux targets bounded, intricate pieces of code that are difficult for humans to get right: for example, cryptographic modules and serializer / deserializer pairs. Crux builds on the same framework as the mature SAW-Cryptol toolchain, but Crux provides an interface where proofs are phrased as symbolic unit tests. Crux is designed for use in production environments, and has already seen use in industry. In this paper, we focus on Crux-MIR, our verification tool for Rust. Crux-MIR provides a bit-precise model of safe and unsafe Rust which can be used to check both inline properties about Rust code, and extensional equality to executable specifications written in Cryptol or in the hacspec dialect of Rust. Notably, Crux-MIR supports compositional reasoning, which is necessary to scale to even moderately complex proofs. We demonstrate Crux-MIR by verifying the Ring library implementations of SHA1 and SHA2 against pre-existing functional specifications. Crux is available at https://crux.galois.com.",
      "paperUrl": "https://arxiv.org/pdf/2410.18280",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2410.18280",
      "tags": [
        "Infrastructure",
        "Rust"
      ],
      "keywords": [
        "Infrastructure",
        "Rust",
        "LLVM",
        "Crux Mir",
        "Verification",
        "Precise Verifier"
      ],
      "matchedAuthors": [
        "Aaron Tomb",
        "Iavor S. Diatchki",
        "Joe Hendrix",
        "Mike Dodds",
        "Robert Dockins",
        "Ryan P. Scott"
      ]
    },
    {
      "id": "openalex-w4391124792",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Cppless: Single-Source and High-Performance Serverless Programming in C++",
      "authors": [
        {
          "name": "Lukas Möller",
          "affiliation": "ETH Zurich"
        },
        {
          "name": "Marcin Copik",
          "affiliation": "ETH Zurich"
        },
        {
          "name": "Alexandru Calotoiu",
          "affiliation": "ETH Zurich"
        },
        {
          "name": "Torsten Hoefler",
          "affiliation": "ETH Zurich"
        }
      ],
      "year": "2024",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "The rise of serverless computing introduced a new class of scalable, elastic and widely available parallel workers in the cloud. Many systems and applications benefit from offloading computations and parallel tasks to dynamically allocated resources. However, the developers of C++ applications find it difficult to integrate functions due to complex deployment, lack of compatibility between client and cloud environments, and loosely typed input and output data. To enable single-source and efficient serverless acceleration in C++, we introduce Cppless, an end-to-end framework for implementing remote functions which handles the creation, deployment, and invocation of serverless functions. Cppless is built on top of LLVM and requires only two compiler extensions to automatically extract C++ function objects and deploy them to the cloud. We demonstrate that offloading parallel computations, such as from a C++ application to serverless workers, can provide up to 59x speedup with minimal cost increase while requiring only minor code modifications.",
      "paperUrl": "https://arxiv.org/pdf/2401.10834",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2401.10834",
      "tags": [
        "Performance",
        "GPU"
      ],
      "keywords": [
        "Performance",
        "GPU",
        "LLVM",
        "Offloading",
        "Performance Serverless Programming",
        "Cppless Single"
      ],
      "matchedAuthors": [
        "Alexandru Calotoiu",
        "Lukas Möller",
        "Marcin Copik",
        "Torsten Hoefler"
      ]
    },
    {
      "id": "openalex-w4396913091",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Concolic Testing of JavaScript using Sparkplug",
      "authors": [
        {
          "name": "Zhe Li",
          "affiliation": ""
        },
        {
          "name": "Fei Xie",
          "affiliation": ""
        }
      ],
      "year": "2024",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "JavaScript is prevalent in web and server apps, handling sensitive data. JS testing methods lag behind other languages. Insitu concolic testing for JS is effective but slow and complex. Our method enhances tracing with V8 Sparkplug baseline compiler and remill libraries for assembly to LLVM IR conversion. Evaluation on 160 Node.js libraries reveals comparable coverage and bug detection in significantly less time than the in-situ method.",
      "paperUrl": "https://arxiv.org/pdf/2405.06832",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2405.06832",
      "tags": [
        "IR",
        "Testing",
        "Libraries"
      ],
      "keywords": [
        "IR",
        "Testing",
        "Libraries",
        "LLVM",
        "Intermediate Representation",
        "Concolic Testing"
      ],
      "matchedAuthors": [
        "Fei Xie",
        "Zhe Li"
      ]
    },
    {
      "id": "openalex-w4398230062",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Compiler support for semi-manual AoS-to-SoA conversions with data views",
      "authors": [
        {
          "name": "Pawel K. Radtke",
          "affiliation": ""
        },
        {
          "name": "Tobias Weinzierl",
          "affiliation": ""
        }
      ],
      "year": "2024",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "The C programming language and its cousins such as C++ stipulate the static storage of sets of structured data: Developers have to commit to one, invariant data model -- typically a structure-of-arrays (SoA) or an array-of-structs (AoS) -- unless they manually rearrange, i.e.~convert it throughout the computation. Whether AoS or SoA is favourable depends on the execution context and algorithm step. We propose a language extension based upon C++ attributes through which developers can guide the compiler what memory arrangements are to be used. The compiler can then automatically convert (parts of) the data into the format of choice prior to a calculation and convert results back afterwards. As all conversions are merely annotations, it is straightforward for the developer to experiment with different storage formats and to pick subsets of data that are subject to memory rearrangements. Our work implements the annotations within Clang and demonstrates their potential impact through a smoothed particle hydrodynamics (SPH) code.",
      "paperUrl": "https://arxiv.org/pdf/2405.12507",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2405.12507",
      "tags": [
        "Clang",
        "Programming Languages"
      ],
      "keywords": [
        "Clang",
        "Programming Languages",
        "Convert",
        "Memory",
        "Semi Manual Aos",
        "Soa Conversions"
      ],
      "matchedAuthors": [
        "Pawel K. Radtke",
        "Tobias Weinzierl"
      ]
    },
    {
      "id": "openalex-w4403223049",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Compiler Support for Sparse Tensor Convolutions",
      "authors": [
        {
          "name": "Peiming Liu",
          "affiliation": "Google (United States)"
        },
        {
          "name": "Alexander J Root",
          "affiliation": "Stanford University"
        },
        {
          "name": "Anlun Xu",
          "affiliation": "Google (United States)"
        },
        {
          "name": "Yinying Li",
          "affiliation": "Google (United States)"
        },
        {
          "name": "Fredrik Kjølstad",
          "affiliation": "Stanford University"
        },
        {
          "name": "Aart J. C. Bik",
          "affiliation": "Google (United States)"
        }
      ],
      "year": "2024",
      "publication": "Proceedings of the ACM on Programming Languages",
      "venue": "Proceedings of the ACM on Programming Languages | Vol. 8 (Issue OOPSLA2)",
      "type": "research-paper",
      "abstract": "This paper extends prior work on sparse tensor algebra compilers to generate asymptotically efficient code for tensor expressions with affine subscript expressions. Our technique enables compiler support for a wide range of sparse computations, including sparse convolutions and pooling that are widely used in ML and graphics applications. We propose an approach that gradually rewrites compound subscript expressions to simple subscript expressions with loops that exploit the sparsity pattern of the input sparse tensors. As a result, the time complexity of the generated kernels is bounded by the number of stored elements and not by the shape of the tensors. Our approach seamlessly integrates into existing frameworks and is compatible with recent advances in compilers for sparse computations, including the flexibility to efficiently handle arbitrary combinations of different sparse tensor formats. The implementation of our algorithm is open source and upstreamed to the MLIR sparse compiler. Experimental results show that our method achieves 19.5x speedup when compared with the state-of-the-art compiler-based method at 99.9% sparsity. The generated sparse kernels start to outperform dense convolution implementations at about 80% sparsity",
      "paperUrl": "https://doi.org/10.1145/3689721",
      "sourceUrl": "",
      "tags": [
        "Programming Languages",
        "MLIR"
      ],
      "keywords": [
        "Programming Languages",
        "MLIR",
        "Sparse Tensor Convolutions",
        "Subscript Expressions",
        "Sparsity",
        "Sparse Computations",
        "Kernels"
      ],
      "matchedAuthors": [
        "Aart J. C. Bik",
        "Alexander J Root",
        "Fredrik Kjølstad",
        "Pei-Ming Liu"
      ]
    },
    {
      "id": "openalex-w4403795805",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Comparing Unidirectional, Bidirectional, and Word2vec Models for Discovering Vulnerabilities in Compiled Lifted Code",
      "authors": [
        {
          "name": "Gary A. McCully",
          "affiliation": ""
        },
        {
          "name": "John D. Hastings",
          "affiliation": ""
        },
        {
          "name": "Shengjie Xu",
          "affiliation": ""
        },
        {
          "name": "Adam Fortier",
          "affiliation": ""
        }
      ],
      "year": "2024",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Ransomware and other forms of malware cause significant financial and operational damage to organizations by exploiting long-standing and often difficult-to-detect software vulnerabilities. To detect vulnerabilities such as buffer overflows in compiled code, this research investigates the application of unidirectional transformer-based embeddings, specifically GPT-2. Using a dataset of LLVM functions, we trained a GPT-2 model to generate embeddings, which were subsequently used to build LSTM neural networks to differentiate between vulnerable and non-vulnerable code. Our study reveals that embeddings from the GPT-2 model significantly outperform those from bidirectional models of BERT and RoBERTa, achieving an accuracy of 92.5% and an F1-score of 89.7%. LSTM neural networks were developed with both frozen and unfrozen embedding model layers. The model with the highest performance was achieved when the embedding layers were unfrozen. Further, the research finds that, in exploring the impact of different optimizers within this domain, the SGD optimizer demonstrates superior performance over Adam. Overall, these findings reveal important insights into the potential of unidirectional transformer-based approaches in enhancing cybersecurity defenses.",
      "paperUrl": "https://arxiv.org/pdf/2409.17513",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2409.17513",
      "tags": [
        "Performance",
        "ML"
      ],
      "keywords": [
        "Performance",
        "ML",
        "LLVM",
        "Lstm Neural Networks",
        "Unidirectional Transformer",
        "Discovering Vulnerabilities",
        "Embeddings",
        "Comparing Unidirectional Bidirectional",
        "Compiled Lifted"
      ],
      "matchedAuthors": [
        "Adam Fortier",
        "Gary A. McCully",
        "John D. Hastings",
        "Shengjie Xu"
      ]
    },
    {
      "id": "openalex-w4392120987",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "CesASMe and Staticdeps: static detection of memory-carried dependencies for code analyzers",
      "authors": [
        {
          "name": "Théophile Bastian",
          "affiliation": ""
        },
        {
          "name": "Hugo Pompougnac",
          "affiliation": ""
        },
        {
          "name": "Alban Dutilleul",
          "affiliation": ""
        },
        {
          "name": "Fabrice Rastello",
          "affiliation": ""
        }
      ],
      "year": "2024",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "A variety of code analyzers, such as IACA, uiCA, llvm-mca or Ithemal, strive to statically predict the throughput of a computation kernel. Each analyzer is based on its own simplified CPU model reasoning at the scale of a basic block. Facing this diversity, evaluating their strengths and weaknesses is important to guide both their usage and their enhancement. We present CesASMe, a fully-tooled solution to evaluate code analyzers on C-level benchmarks composed of a benchmark derivation procedure that feeds an evaluation harness. We conclude that memory-carried data dependencies are a major source of imprecision for these tools. We tackle this issue with staticdeps, a static analyzer extracting memory-carried data dependencies, including across loop iterations, from an assembly basic block. We integrate its output to uiCA, a state-of-the-art code analyzer, to evaluate staticdeps' impact on a code analyzer's precision through CesASMe.",
      "paperUrl": "https://arxiv.org/pdf/2402.14567",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2402.14567",
      "tags": [
        "Static Analysis"
      ],
      "keywords": [
        "Static Analysis",
        "LLVM",
        "Memory Carried",
        "Analyzers",
        "Cesasme",
        "Memory Carried Dependencies",
        "Staticdeps",
        "Basic Block"
      ],
      "matchedAuthors": [
        "Alban Dutilleul",
        "Fabrice Rastello",
        "Hugo Pompougnac",
        "Théophile Bastian"
      ]
    },
    {
      "id": "openalex-w4404306909",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Binary Code Similarity Detection via Graph Contrastive Learning on Intermediate Representations",
      "authors": [
        {
          "name": "Xiuwei Shang",
          "affiliation": ""
        },
        {
          "name": "Li Hu",
          "affiliation": ""
        },
        {
          "name": "Shaoyin Cheng",
          "affiliation": ""
        },
        {
          "name": "Guoqiang Chen",
          "affiliation": ""
        },
        {
          "name": "Benlong Wu",
          "affiliation": ""
        },
        {
          "name": "Weiming Zhang",
          "affiliation": ""
        },
        {
          "name": "Nenghai Yu",
          "affiliation": ""
        }
      ],
      "year": "2024",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Binary Code Similarity Detection (BCSD) plays a crucial role in numerous fields, including vulnerability detection, malware analysis, and code reuse identification. As IoT devices proliferate and rapidly evolve, their highly heterogeneous hardware architectures and complex compilation settings, coupled with the demand for large-scale function retrieval in practical applications, put forward higher requirements for BCSD methods. In this paper, we propose IRBinDiff, which mitigates compilation differences by leveraging LLVM-IR with higher-level semantic abstraction, and integrates a pre-trained language model with a graph neural network to capture both semantic and structural information from different perspectives. By introducing momentum contrastive learning, it effectively enhances retrieval capabilities in large-scale candidate function sets, distinguishing between subtle function similarities and differences. Our extensive experiments, conducted under varied compilation settings, demonstrate that IRBinDiff outperforms other leading BCSD methods in both One-to-one comparison and One-to-many search scenarios.",
      "paperUrl": "https://arxiv.org/pdf/2410.18561",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2410.18561",
      "tags": [
        "IR",
        "ML"
      ],
      "keywords": [
        "IR",
        "ML",
        "LLVM",
        "Intermediate Representation",
        "Similarity Detection",
        "Contrastive Learning",
        "Compilation Settings",
        "Binary",
        "Graph Contrastive Learning",
        "Intermediate Representations"
      ],
      "matchedAuthors": [
        "Nenghai Yu",
        "Shaoyin Cheng",
        "Weiming Zhang",
        "Xiuwei Shang"
      ]
    },
    {
      "id": "openalex-w4403322063",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Beyond the Phase Ordering Problem: Finding the Globally Optimal Code w.r.t. Optimization Phases",
      "authors": [
        {
          "name": "Yu Wang",
          "affiliation": ""
        },
        {
          "name": "Hongyu Chen",
          "affiliation": ""
        },
        {
          "name": "Ke Wang",
          "affiliation": ""
        }
      ],
      "year": "2024",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "In this paper, we propose a new concept called \\textit{semantically equivalence} \\wrt \\textit{optimization phases} \\textit{(\\sep)}, which defines the set of programs a compiler considers semantically equivalent to the input using a set of optimization phases. We show both theoretically and empirically that solving the phase ordering problem does not necessarily result in the most efficient code among all programs that a compiler deems semantically equivalent to the input, hereinafter referred to as the global optimal code \\wrt optimization phases. To find the global optimal code \\wrt optimization phases, we present a conceptual framework, leveraging the reverse of existing optimization phases. In theory, we prove that the framework is capable of finding the global optimal code for any program. We realize this framework into a technique, called \\textit{iterative bi-directional optimization (\\tool)}, which performs both the normal and reverse optimizations to increase and decrease the efficiency of the generated code, respectively. We evaluate \\tool on C/C++ files randomly extracted from highly mature and influential programs (\\eg, Linux kernel, OpenSSL, Z3). Results show that \\tool frequently generates more efficient code -- measured by either code size or runtime performance -- than exhaustive search, which is the solution to the phase ordering problem. We also find by simply incorporating \\tool's reverse optimization phases, the effectiveness of the optimization of state-of-the-art compilers (\\eg, GCC/LLVM) can be significantly improved.",
      "paperUrl": "https://arxiv.org/pdf/2410.03120",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2410.03120",
      "tags": [
        "Performance",
        "Optimizations"
      ],
      "keywords": [
        "Performance",
        "Optimizations",
        "LLVM",
        "Wrt Optimization Phases",
        "Phase Ordering",
        "Globally Optimal",
        "Called Textit",
        "Reverse",
        "Semantically Equivalent"
      ],
      "matchedAuthors": [
        "Hongyu Chen",
        "Ke Wang",
        "Yu Wang"
      ]
    },
    {
      "id": "openalex-w4390961958",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Assessing the Effectiveness of Binary-Level CFI Techniques",
      "authors": [
        {
          "name": "Ruturaj K. Vaidya",
          "affiliation": ""
        },
        {
          "name": "Prasad A. Kulkarni",
          "affiliation": ""
        }
      ],
      "year": "2024",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Memory corruption is an important class of vulnerability that can be leveraged to craft control flow hijacking attacks. Control Flow Integrity (CFI) provides protection against such attacks. Application of type-based CFI policies requires information regarding the number and type of function arguments. Binary-level type recovery is inherently speculative, which motivates the need for an evaluation framework to assess the effectiveness of binary-level CFI techniques compared with their source-level counterparts, where such type information is fully and accurately accessible. In this work, we develop a novel, generalized and extensible framework to assess how the program analysis information we get from state-of-the-art binary analysis tools affects the efficacy of type-based CFI techniques. We introduce new and insightful metrics to quantitatively compare source independent CFI policies with their ground truth source aware counterparts. We leverage our framework to evaluate binary-level CFI policies implemented using program analysis information extracted from the IDA Pro binary analyzer and compared with the ground truth information obtained from the LLVM compiler, and present our observations.",
      "paperUrl": "https://arxiv.org/pdf/2401.07148",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2401.07148",
      "tags": [],
      "keywords": [
        "LLVM",
        "CFI Policies",
        "Binary",
        "Control Flow",
        "Ground Truth"
      ],
      "matchedAuthors": [
        "Prasad A. Kulkarni",
        "Ruturaj K. Vaidya"
      ]
    },
    {
      "id": "openalex-w4392405744",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Armor: Protecting Software Against Hardware Tracing Techniques",
      "authors": [
        {
          "name": "Tai Yue",
          "affiliation": "National University of Defense Technology"
        },
        {
          "name": "Fengwei Zhang",
          "affiliation": "Southern University of Science and Technology"
        },
        {
          "name": "Zhenyu Ning",
          "affiliation": "Hunan University"
        },
        {
          "name": "Pengfei Wang",
          "affiliation": "National University of Defense Technology"
        },
        {
          "name": "Xu Zhou",
          "affiliation": "National University of Defense Technology"
        },
        {
          "name": "Kai Lu",
          "affiliation": "National University of Defense Technology"
        },
        {
          "name": "Lei Zhou",
          "affiliation": "National University of Defense Technology"
        }
      ],
      "year": "2024",
      "publication": "IEEE Transactions on Information Forensics and Security",
      "venue": "IEEE Transactions on Information Forensics and Security | Vol. 19",
      "type": "research-paper",
      "abstract": "Many modern processors have embedded hardware tracing techniques (e.g., Intel Processor Trace or ARM CoreSight).While these techniques are widely used due to their transparency and low overhead, they also bring serious security threats.Attackers can utilize hardware tracing to trace the trusted applications from a non-secure application.Existing protection techniques fail to effectively protect the runtime information when hardware tracing is employed.To counter these threats, in this paper, we propose a novel direction called anti-hardware tracing.Our key idea is to exploit the limitations of hardware tracing: trace buffer overflow can cause trace data loss.We build a model to analyse the overflow and outline three principles for efficient triggering overflows and achieving anti-hardware tracing: numerous branches in the program, high-speed execution of the program, and the high-water mark of the trace buffer.We develop a framework called Armor on ARM Juno R2 to realize our approach.Armor protects software against the trace unit Embedded Trace Macrocell (ETM) in CoreSight by instrumenting protection and loop functions.The protection function detects runtime environments, efficiently fills the trace buffer, and employs various protection strategies like PID (process identifier) replacement and PIE+STRIP+ASLR.Meanwhile, the loop function triggers overflows efficiently based on context-based calculations and anti-ETM loop.Our evaluation demonstrates that the overhead of Armor is 77.31% lower than that of OLLVM [1] on SPEC2006.Armor effectively hides 54.51% of basic blocks across 16 real-world applications, triggering 113× more overflows.Moreover, we showcase two practical applications of Armor.Firstly, we conduct a cryptographic and cross-world attack on GnuPG 1.4.13RSA private keys using ETM, which can steal entire keys from a program in the Secure world with a single run.Armor successfully reduces leaked bits by 84.5%.Secondly, Armor impedes hardware-assisted fuzzing by reducing throughput by 89.71% and branch coverage by 47.99%.",
      "paperUrl": "https://ieeexplore.ieee.org/ielx7/10206/4358835/10458672.pdf",
      "sourceUrl": "https://doi.org/10.1109/tifs.2024.3372816",
      "tags": [
        "Security",
        "Embedded",
        "Testing"
      ],
      "keywords": [
        "Security",
        "Embedded",
        "Testing",
        "Fuzzing",
        "Anti Hardware Tracing",
        "Trace Buffer",
        "Protection",
        "Overflows",
        "Armor Protecting",
        "Against Hardware Tracing"
      ],
      "matchedAuthors": [
        "Fengwei Zhang"
      ]
    },
    {
      "id": "openalex-w4399554046",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "An extension of C++ with memory-centric specifications for HPC to reduce memory footprints and streamline MPI development",
      "authors": [
        {
          "name": "Pawel K. Radtke",
          "affiliation": ""
        },
        {
          "name": "Cristian Barrera-Hinojosa",
          "affiliation": ""
        },
        {
          "name": "Mladen Ivković",
          "affiliation": ""
        },
        {
          "name": "Tobias Weinzierl",
          "affiliation": ""
        }
      ],
      "year": "2024",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "C++ leans towards a memory-inefficient storage of structs: The compiler inserts padding bits, while it is not able to exploit knowledge about the range of integers, enums or bitsets. Furthermore, the language provides no support for arbitrary floating-point precisions. We propose a language extension based upon attributes through which developers can guide the compiler what memory arrangements would be beneficial: Can multiple booleans or integers with limited range be squeezed into one bit field, do floating-point numbers hold fewer significant bits than in the IEEE standard, and is a programmer willing to trade attribute ordering guarantees for a more compact object representation? The extension offers the opportunity to fall back to normal alignment and native C++ floating point representations via plain C++ assignments, no dependencies upon external libraries are introduced, and the resulting code remains (syntactically) standard C++. As MPI remains the de-facto standard for distributed memory calculations in C++, we furthermore propose additional attributes which streamline the MPI datatype modelling in combination with our memory optimisation extensions. Our work implements the language annotations within LLVM and demonstrates their potential impact through smoothed particle hydrodynamics benchmarks. They uncover the potential gains in terms of performance and development productivity.",
      "paperUrl": "https://arxiv.org/pdf/2406.06095",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2406.06095",
      "tags": [
        "Performance",
        "Libraries"
      ],
      "keywords": [
        "Performance",
        "Libraries",
        "LLVM",
        "Memory Centric Specifications",
        "Floating Point",
        "Extension",
        "Streamline MPI",
        "Standard",
        "Reduce Memory Footprints"
      ],
      "matchedAuthors": [
        "Pawel K. Radtke",
        "Tobias Weinzierl"
      ]
    },
    {
      "id": "openalex-w4413278533",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "An MLIR-Based Compiler for Hardware Acceleration with Recursion Support: (PhD Forum Paper)",
      "authors": [
        {
          "name": "Jiangnan Li",
          "affiliation": "Fudan University"
        },
        {
          "name": "Zhengyi Zhang",
          "affiliation": "Fudan University"
        },
        {
          "name": "Xuegong Zhou",
          "affiliation": "Fudan University"
        },
        {
          "name": "Lingli Wang",
          "affiliation": "Fudan University"
        }
      ],
      "year": "2024",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "Generating custom hardware accelerators within a high-level programming framework is a complex task. However, compiling and generating accelerators for kernel programs that use recursion is often unsupported, necessitating manual refactoring to ensure compatibility with high-level synthesis (HLS) tools. The single-level abstraction in existing HLS frameworks limits recursive application transformations, hindering efficient acceleration. In this paper, we present an automated restructuring technique for recursive applications, built on multi-level intermediate representation (MLIR), aimed at generating high-quality hardware accelerators through HLS. We automatically detect recursive calls and analyze recursive data structures to generate loops, state machines, and stacks for simulating recursion, thus enabling an end-to-end compilation process. Experimental results show that, compared to a domain-specific language (DSL) compiler supporting recursion, our approach outperforms methods requiring manual modification of recursion into DSL representations in over 55% of the benchmark cases, achieving an average resource reduction of 51.3 %. Furthermore, compared to HeteroRefactor, we support more benchmarks and provide a synthesizable architecture.",
      "paperUrl": "https://doi.org/10.1109/icfpt64416.2024.11113451",
      "sourceUrl": "",
      "tags": [
        "IR",
        "MLIR"
      ],
      "keywords": [
        "IR",
        "MLIR",
        "Intermediate Representation",
        "Recursion",
        "Recursive",
        "Hardware Acceleration",
        "Hardware Accelerators",
        "HLS",
        "DSL"
      ],
      "matchedAuthors": [
        "Jiangnan Li",
        "Lingli Wang"
      ]
    },
    {
      "id": "openalex-w4401568680",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "An Agile Deploying Approach for Large-Scale Workloads on CGRA-CPU Architecture",
      "authors": [
        {
          "name": "Jiahang Lou",
          "affiliation": "Fudan University"
        },
        {
          "name": "Xuchen Gao",
          "affiliation": "Fudan University"
        },
        {
          "name": "Yiqing Mao",
          "affiliation": "Fudan University"
        },
        {
          "name": "Yunhui Qiu",
          "affiliation": "Fudan University"
        },
        {
          "name": "Yihan Hu",
          "affiliation": "Fudan University"
        },
        {
          "name": "Wenbo Yin",
          "affiliation": "Fudan University"
        },
        {
          "name": "Lingli Wang",
          "affiliation": "Fudan University"
        }
      ],
      "year": "2024",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "Adopting specialized accelerators such as Coarse-Grained Reconfigurable Architectures (CGRAs) alongside CPUs to enhance performance within specific domains is an astute choice. However, the integration of heterogeneous architectures introduces complex challenges for compiler design. Simultaneously, the ever-expanding scale of workloads imposes substantial burdens on deployment. To address above challenges, this paper introduces CGRV-OPT, a user-friendly multi-level compiler designed to deploy large-scale workloads to CGRA and RISC-V CPU architecture. Built upon the MLIR framework, CGRV-OPT serves as a pivotal bridge, facilitating the seamless conversion of high-level workload descriptions into low-level intermediate representations (IRs) for different architectures. A salient feature of our approach is the automation of a comprehensive suite of optimizations and transformations, which speed up each kernel computing within the intricate SoC. Additionally, we have seamlessly integrated an automated software-hardware partitioning mechanism, guided by our multi-level optimizations, resulting in a remarkable 2.14 × speed up over large-scale workloads. The CGRV-OPT framework significantly alleviates the challenges faced by software developers, including those with limited expertise in hardware architectures.",
      "paperUrl": "https://doi.org/10.23919/date58400.2024.10546646",
      "sourceUrl": "",
      "tags": [
        "Performance",
        "Optimizations",
        "IR",
        "MLIR"
      ],
      "keywords": [
        "Performance",
        "Optimizations",
        "IR",
        "MLIR",
        "Intermediate Representation",
        "Scale Workloads",
        "Cgrv Opt",
        "CPU Architecture",
        "Challenges",
        "CGRA CPU Architecture",
        "Hardware",
        "Agile Deploying"
      ],
      "matchedAuthors": [
        "Lingli Wang",
        "Wenbo Yin",
        "Xuchen Gao",
        "Yunhui Qiu"
      ]
    },
    {
      "id": "openalex-w4399464945",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "A Systematic Translation Validation Framework for MLIR-Based Compilers",
      "authors": [
        {
          "name": "Yanzhao Wang",
          "affiliation": "Portland State University"
        },
        {
          "name": "Fei Xie",
          "affiliation": "Portland State University"
        },
        {
          "name": "Zhenkun Yang",
          "affiliation": "Intel (United States)"
        },
        {
          "name": "Pasquale Cocchini",
          "affiliation": "Intel (United States)"
        },
        {
          "name": "Jin Yang",
          "affiliation": "Intel (United States)"
        }
      ],
      "year": "2024",
      "publication": "International Journal of Software Engineering and Knowledge Engineering",
      "venue": "International Journal of Software Engineering and Knowledge Engineering",
      "type": "research-paper",
      "abstract": "This paper introduces an innovative translation validation framework designed for MLIR-based compilers, which has garnered considerable prominence in fields such as machine learning, high-performance computing and hardware design. Despite rigorous testing, compilers based on MLIR might still induce incorrect results and undefined behaviors, necessitating verification work. Our framework first takes a pair of MLIR programs as inputs and check their function signature’s compatibility before encoding them into SMT expressions. Then it uses the Z3 SMT solver to check whether the target program refines the source program. Our framework transcends the dialect limitations of past solutions, thereby providing validation support to a wider range of MLIR-based compilers. We demonstrate its effectiveness through evaluations on prominent open-source MLIR-based compilers, where we identified bugs and undefined behaviors. We further demonstrate the capability of this framework by validating two practical deep-learning accelerator designs.",
      "paperUrl": "http://dx.doi.org/10.1142/s021819402450030x",
      "sourceUrl": "https://doi.org/10.1142/s021819402450030x",
      "tags": [
        "Performance",
        "Testing",
        "ML",
        "MLIR"
      ],
      "keywords": [
        "Performance",
        "Testing",
        "ML",
        "MLIR",
        "Validation",
        "Undefined Behaviors"
      ],
      "matchedAuthors": [
        "Fei Xie",
        "Yanzhao Wang",
        "Zhenkun Yang"
      ]
    },
    {
      "id": "openalex-w4394973007",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "A Study of Undefined Behavior Across Foreign Function Boundaries in Rust Libraries",
      "authors": [
        {
          "name": "Ian McCormack",
          "affiliation": ""
        },
        {
          "name": "Joshua Sunshine",
          "affiliation": ""
        },
        {
          "name": "Jonathan Aldrich",
          "affiliation": ""
        }
      ],
      "year": "2024",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Developers rely on the static safety guarantees of the Rust programming language to write secure and performant applications. However, Rust is frequently used to interoperate with other languages which allow design patterns that conflict with Rust's evolving aliasing models. Miri is currently the only dynamic analysis tool that can validate applications against these models, but it does not support foreign functions, indicating that there may be a critical correctness gap across the Rust ecosystem. We conducted a large-scale evaluation of Rust libraries that call foreign functions to determine whether Miri's dynamic analyses remain useful in this context. We used Miri and an LLVM interpreter to jointly execute applications that call foreign functions, where we found 47 instances of undefined or undesired behavior in 37 libraries. Three bugs were found in libraries that had more than 10,000 daily downloads on average during our observation period, and one was found in a library maintained by the Rust Project. Many of these bugs were violations of Rust's aliasing models, but the latest Tree Borrows model was significantly more permissive than the earlier Stacked Borrows model. The Rust community must invest in new, production-ready tooling for multi-language applications to ensure that developers can detect these errors.",
      "paperUrl": "https://arxiv.org/pdf/2404.11671",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2404.11671",
      "tags": [
        "Programming Languages",
        "Dynamic Analysis",
        "Libraries",
        "Rust"
      ],
      "keywords": [
        "Programming Languages",
        "Dynamic Analysis",
        "Libraries",
        "Rust",
        "LLVM",
        "Call Foreign",
        "Rust Libraries",
        "Undefined Behavior"
      ],
      "matchedAuthors": [
        "Ian McCormack",
        "Jonathan Aldrich",
        "Joshua Sunshine"
      ]
    },
    {
      "id": "openalex-w4408794219",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "A Method for Efficient Heterogeneous Parallel Compilation: A Cryptography Case Study",
      "authors": [
        {
          "name": "Zhiyuan Tan",
          "affiliation": "University of Chinese Academy of Sciences"
        },
        {
          "name": "Liutong Han",
          "affiliation": "Institute of Software"
        },
        {
          "name": "Mingjie Xing",
          "affiliation": "Institute of Software"
        },
        {
          "name": "Yanjun Wu",
          "affiliation": "Chinese Academy of Sciences"
        }
      ],
      "year": "2024",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "In the era of diminishing returns from Moore’s Law, heterogeneous computing systems have emerged as a vital approach to enhance computational efficiency. This paper introduces a novel MLIR-based dialect, named hyper, designed to optimize data management and parallel computation across diverse hardware architectures. The hyper dialect abstracts the complexities of heterogeneous computing by providing a unified compilation framework that efficiently schedules tasks and manages data communication. To demonstrate its capabilities, we present HETOCompiler, a cryptography-focused compiler prototype that implements multiple hash algorithms and enables their execution on heterogeneous systems. The proposed approach achieves performance improvements over existing programming models for heterogeneous computing (OpenCL), offering an average speedup of 1.93 x, 1.18 x, and 1.12 x for SHA-1, MD5, and SM3 algorithms, respectively. Our findings highlight the potential of the hyper dialect in harnessing the full computational power of heterogeneous devices, advancing the field of compiler design for heterogeneous systems.",
      "paperUrl": "https://doi.org/10.1109/swc62898.2024.00084",
      "sourceUrl": "",
      "tags": [
        "Performance",
        "OpenCL",
        "MLIR"
      ],
      "keywords": [
        "Performance",
        "OpenCL",
        "MLIR",
        "Heterogeneous Computing",
        "Hyper Dialect",
        "Heterogeneous Parallel Compilation"
      ],
      "matchedAuthors": [
        "Mingjie Xing",
        "Yanjun Wu"
      ]
    },
    {
      "id": "openalex-w4395065809",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "A Cross-Platform Execution Engine for the Quantum Intermediate Representation",
      "authors": [
        {
          "name": "Elaine Wong",
          "affiliation": ""
        },
        {
          "name": "Vicente Leyton Ortega",
          "affiliation": ""
        },
        {
          "name": "Daniel Claudino",
          "affiliation": ""
        },
        {
          "name": "S. R. Johnson",
          "affiliation": ""
        },
        {
          "name": "Sharmin Afrose",
          "affiliation": ""
        },
        {
          "name": "Meenambika Gowrishankar",
          "affiliation": ""
        },
        {
          "name": "Anthony M. Cabrera",
          "affiliation": ""
        },
        {
          "name": "Travis S. Humble",
          "affiliation": ""
        },
        {
          "name": "Humble, Travis S.",
          "affiliation": ""
        }
      ],
      "year": "2024",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Hybrid languages like the quantum intermediate representation (QIR) are essential for programming systems that mix quantum and conventional computing models, while execution of these programs is often deferred to a system-specific implementation. Here, we develop the QIR Execution Engine (QIR-EE) for parsing, interpreting, and executing QIR across multiple hardware platforms. QIR-EE uses LLVM to execute hybrid instructions specifying quantum programs and, by design, presents extension points that support customized runtime and hardware environments. We demonstrate an implementation that uses the XACC quantum hardware-accelerator library to dispatch prototypical quantum programs on different commercial quantum platforms and numerical simulators, and we validate execution of QIR-EE on IonQ, Quantinuum, and IBM hardware. Our results highlight the efficiency of hybrid executable architectures for handling mixed instructions, managing mixed data, and integrating with quantum computing frameworks to realize cross-platform execution.",
      "paperUrl": "https://arxiv.org/pdf/2404.14299",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2404.14299",
      "tags": [
        "IR",
        "Quantum Computing"
      ],
      "keywords": [
        "IR",
        "Quantum Computing",
        "LLVM",
        "Intermediate Representation",
        "Quantum Compilation",
        "Quantum Intermediate Representation",
        "Hardware",
        "Cross Platform Execution",
        "Platform Execution Engine",
        "Hybrid",
        "Quantum Programs"
      ],
      "matchedAuthors": [
        "Anthony M. Cabrera",
        "Daniel Claudino",
        "Elaine Wong",
        "Meenambika Gowrishankar",
        "S. R. Johnson",
        "Sharmin Afrose",
        "Travis S. Humble",
        "Vicente Leyton Ortega"
      ]
    },
    {
      "id": "openalex-w4400516953",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "A Calculus for Unreachable Code",
      "authors": [
        {
          "name": "Peter Zhong",
          "affiliation": ""
        },
        {
          "name": "Shu-Hung You",
          "affiliation": ""
        },
        {
          "name": "Simone Campanoni",
          "affiliation": ""
        },
        {
          "name": "Robert Bruce Findler",
          "affiliation": ""
        },
        {
          "name": "Matthew Flatt",
          "affiliation": ""
        },
        {
          "name": "Christos Dimoulas",
          "affiliation": ""
        }
      ],
      "year": "2024",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "In Racket, the LLVM IR, Rust, and other modern languages, programmers and static analyses can hint, with special annotations, that certain parts of a program are unreachable. Same as other assumptions about undefined behavior; the compiler assumes these hints are correct and transforms the program aggressively. While compile-time transformations due to undefined behavior often perplex compiler writers and developers, we show that the essence of transformations due to unreachable code can be distilled in a surprisingly small set of simple formal rules. Specifically, following the well-established tradition of understanding linguistic phenomena through calculi, we introduce the first calculus for unreachable. Its term-rewriting rules that take advantage of unreachable fall into two groups. The first group allows the compiler to delete any code downstream of unreachable, and any effect-free code upstream of unreachable. The second group consists of rules that eliminate conditional expressions when one of their branches is unreachable. We show the correctness of the rules with a novel logical relation, and we examine how they correspond to transformations due to unreachable in Racket and LLVM.",
      "paperUrl": "https://arxiv.org/pdf/2407.04917",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2407.04917",
      "tags": [
        "IR",
        "Rust"
      ],
      "keywords": [
        "IR",
        "Rust",
        "LLVM",
        "Intermediate Representation",
        "Unreachable",
        "Transformations Due",
        "Undefined Behavior"
      ],
      "matchedAuthors": [
        "Simone Campanoni"
      ]
    },
    {
      "id": "openalex-w4385473805",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "nelli: a lightweight frontend for MLIR",
      "authors": [
        {
          "name": "Maksim Levental",
          "affiliation": ""
        },
        {
          "name": "Alok Kamatar",
          "affiliation": ""
        },
        {
          "name": "Ryan Chard",
          "affiliation": ""
        },
        {
          "name": "Nicolas Vasilache",
          "affiliation": ""
        },
        {
          "name": "Kyle Chard",
          "affiliation": ""
        }
      ],
      "year": "2023",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Multi-Level Intermediate Representation (MLIR) is a novel compiler infrastructure that aims to provide modular and extensible components to facilitate building domain specific compilers. However, since MLIR models programs at an intermediate level of abstraction, and most extant frontends are at a very high level of abstraction, the semantics and mechanics of the fundamental transformations available in MLIR are difficult to investigate and employ in and of themselves. To address these challenges, we have developed \\texttt{nelli}, a lightweight, Python-embedded, domain-specific, language for generating MLIR code. \\texttt{nelli} leverages existing MLIR infrastructure to develop Pythonic syntax and semantics for various MLIR features. We describe \\texttt{nelli}'s design goals, discuss key details of our implementation, and demonstrate how \\texttt{nelli} enables easily defining and lowering compute kernels to diverse hardware platforms.",
      "paperUrl": "https://arxiv.org/pdf/2307.16080",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2307.16080",
      "tags": [
        "Frontend",
        "IR",
        "Embedded",
        "Infrastructure",
        "MLIR"
      ],
      "keywords": [
        "Frontend",
        "IR",
        "Embedded",
        "Infrastructure",
        "MLIR",
        "Intermediate Representation",
        "Texttt Nelli",
        "Domain Specific",
        "Semantics",
        "Lightweight Frontend"
      ],
      "matchedAuthors": [
        "Kyle Chard",
        "Nicolas Vasilache"
      ]
    },
    {
      "id": "openalex-w4390436893",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Unifying Static and Dynamic Intermediate Languages for Accelerator Generators",
      "authors": [
        {
          "name": "Caleb Kim",
          "affiliation": ""
        },
        {
          "name": "P. Y. Li",
          "affiliation": ""
        },
        {
          "name": "Anshuman Mohan",
          "affiliation": ""
        },
        {
          "name": "Andrew Butt",
          "affiliation": ""
        },
        {
          "name": "Adrian Sampson",
          "affiliation": ""
        },
        {
          "name": "Rachit Nigam",
          "affiliation": ""
        }
      ],
      "year": "2023",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Compilers for accelerator design languages (ADLs) translate high-level languages into application-specific hardware. ADL compilers rely on a hardware control interface to compose hardware units. There are two choices: static control, which relies on cycle-level timing; or dynamic control, which uses explicit signalling to avoid depending on timing details. Static control is efficient but brittle; dynamic control incurs hardware costs to support compositional reasoning. Piezo is an ADL compiler that unifies static and dynamic control in a single intermediate language (IL). Its key insight is that the IL's static fragment is a refinement of its dynamic fragment: static code admits a subset of the run-time behaviors of the dynamic equivalent. Piezo can optimize code by combining facts from static and dynamic submodules, and it opportunistically converts code from dynamic to static control styles. We implement Piezo as an extension to an existing dynamic ADL compiler, Calyx. We use Piezo to implement an MLIR frontend, a systolic array generator, and a packet-scheduling hardware generator to demonstrate its optimizations and the static-dynamic interactions it enables.",
      "paperUrl": "https://arxiv.org/pdf/2312.16300",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2312.16300",
      "tags": [
        "Frontend",
        "Optimizations",
        "MLIR"
      ],
      "keywords": [
        "Frontend",
        "Optimizations",
        "MLIR",
        "Control",
        "Hardware",
        "Adl Compiler",
        "Accelerator Generators",
        "Intermediate Languages"
      ],
      "matchedAuthors": [
        "Adrian Sampson"
      ]
    },
    {
      "id": "openalex-w4318685721",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Towards On-Chip Learning for Low Latency Reasoning with End-to-End Synthesis",
      "authors": [
        {
          "name": "Vito Giovanni Castellana",
          "affiliation": "Pacific Northwest National Laboratory"
        },
        {
          "name": "Nícolas Bohm Agostini",
          "affiliation": "Pacific Northwest National Laboratory"
        },
        {
          "name": "Ankur Limaye",
          "affiliation": "Pacific Northwest National Laboratory"
        },
        {
          "name": "Vinay Amatya",
          "affiliation": "Pacific Northwest National Laboratory"
        },
        {
          "name": "Marco Minutoli",
          "affiliation": "Pacific Northwest National Laboratory"
        },
        {
          "name": "Joseph Manzano",
          "affiliation": "Pacific Northwest National Laboratory"
        },
        {
          "name": "Antonino Tumeo",
          "affiliation": "Pacific Northwest National Laboratory"
        },
        {
          "name": "Serena Curzel",
          "affiliation": "Politecnico di Milano"
        },
        {
          "name": "Michele Fiorito",
          "affiliation": "Politecnico di Milano"
        },
        {
          "name": "Fabrizio Ferrandi",
          "affiliation": "Politecnico di Milano"
        }
      ],
      "year": "2023",
      "publication": "Proceedings of the 28th Asia and South Pacific Design Automation Conference",
      "venue": "Proceedings of the 28th Asia and South Pacific Design Automation Conference",
      "type": "research-paper",
      "abstract": "The Software Defined Architectures (SODA) Synthesizer is an open-source compiler-based tool able to automatically generate domain-specialized systems targeting Application-Specific Integrated Circuits (ASICs) or Field Programmable Gate Arrays (FPGAs) starting from high-level programming. SODA is composed of a frontend, SODA-OPT, which leverages the multilevel intermediate representation (MLIR) framework to interface with productive programming tools (e.g., machine learning frameworks), identify kernels suitable for acceleration, and perform high-level optimizations, and of a state-of-the-art high-level synthesis backend, Bambu from the PandA framework, to generate custom accelerators. One specific application of the SODA Synthesizer is the generation of accelerators to enable ultra-low latency inference and control on autonomous systems for scientific discovery (e.g., electron microscopes, sensors in particle accelerators, etc.). This paper provides an overview of the flow in the context of the generation of accelerators for edge processing to be integrated in transmission electron microscopy (TEM) devices, focusing on use cases from precision material synthesis. We show the tool in action with an example of design space exploration for inference on reconfigurable devices with a conventional deep neural network model (LeNet). Finally, we discuss the research directions and opportunities enabled by SODA in the area of autonomous control for scientific experimental workflows.",
      "paperUrl": "https://re.public.polimi.it/bitstream/11311/1229391/1/ASPDAC23.pdf",
      "sourceUrl": "https://doi.org/10.1145/3566097.3568360",
      "tags": [
        "Backend",
        "Frontend",
        "Optimizations",
        "IR",
        "ML",
        "MLIR"
      ],
      "keywords": [
        "Backend",
        "Frontend",
        "Optimizations",
        "IR",
        "ML",
        "MLIR",
        "Intermediate Representation",
        "Accelerators",
        "Synthesis",
        "Soda Synthesizer",
        "Inference",
        "Chip Learning",
        "Latency Reasoning"
      ],
      "matchedAuthors": [
        "Ankur Limaye",
        "Antonino Tumeo",
        "Fabrizio Ferrandi",
        "Joseph Manzano",
        "Marco Minutoli",
        "Michele Fiorito",
        "Nícolas Bohm Agostini",
        "Serena Curzel",
        "Vinay Amatya",
        "Vito Giovanni Castellana"
      ]
    },
    {
      "id": "openalex-w4389792040",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Test case prioritization and mutation testing",
      "authors": [
        {
          "name": "Yves Le Traon",
          "affiliation": "University of Luxembourg"
        },
        {
          "name": "Tao Xie",
          "affiliation": "Peking University"
        }
      ],
      "year": "2023",
      "publication": "Software Testing Verification and Reliability",
      "venue": "Software Testing Verification and Reliability | Vol. 34 (Issue 1)",
      "type": "research-paper",
      "abstract": "Test case prioritization and mutation testingIn this issue, we are pleased to present two papers on test case prioritization and mutation testing, respectively.The first paper, 'Semantic-aware two-phase test case prioritization for continuous integration' by Yingling Li, Ziao Wang, Junjie Wang, Jie Chen, Rui Mou, and Guibing Li, presents the SatTCP framework to conduct precise prioritization with low time overhead, in order to improve the cost effectiveness of typical continuous integration (CI) testing with frequent code submissions.In SatTCP, coarse-grained filtering based on information retrieval (IR) techniques roughly sorts test cases and selects a certain number of tests for the subsequent prioritization; then fine-grained prioritization based on pretrained Siamese network conducts precise prioritization of initially ranked test sets.The evaluation results show that SatTCP outperforms all the baselines under comparison, and achieves the lowest test costs.(Recommended by Yves Le Traon).The second paper, 'Mutation testing optimisations using the Clang front-end' by Sten Vercammen, Serge Demeyer, Markus Borg, Niklas Pettersson, and Görel Hedin, presents an investigation to which extent the Clang front-end and its state-of-the-art program analysis facilities allow to implement existing strategies for mutation optimization within the C language family.The authors develop a proof-of-concept tool used to collect detailed measurements for each mutation phase.The authors conduct evaluation of the proof-of-concept tool on four open-source C++ libraries and one industrial component.The evaluation results show that the 'Generate Mutants' and 'Detect (Un)Reachable Mutants' steps are for all practical purposes negligible; the 'Compile Mutants' step takes a significant amount of time and the compilation of the invalid and unreachable mutants is considerable; the 'Execute Mutants' step is the other dominant factor.(Recommended by Mike Papadakis).We hope that these papers will inspire further research in related directions.",
      "paperUrl": "http://dx.doi.org/10.1002/stvr.1871",
      "sourceUrl": "https://doi.org/10.1002/stvr.1871",
      "tags": [
        "Clang",
        "Optimizations",
        "IR",
        "Testing",
        "Libraries"
      ],
      "keywords": [
        "Clang",
        "Optimizations",
        "IR",
        "Testing",
        "Libraries",
        "Mutation Testing",
        "Precise Prioritization",
        "Mutants Step",
        "Sattcp",
        "Clang Front",
        "Continuous Integration"
      ],
      "matchedAuthors": [
        "Tao Xie",
        "Yves Le Traon"
      ]
    },
    {
      "id": "openalex-w4390187524",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Scope-based Compiler Differential Testing",
      "authors": [
        {
          "name": "Rong Qu",
          "affiliation": "Institute of Software"
        },
        {
          "name": "Jiangang Huang",
          "affiliation": "Chinese Academy of Sciences"
        },
        {
          "name": "Long Zhang",
          "affiliation": "Chinese Academy of Sciences"
        },
        {
          "name": "Tianlu Qiao",
          "affiliation": "Beijing University of Posts and Telecommunications"
        },
        {
          "name": "Jian Zhang",
          "affiliation": "Chinese Academy of Sciences"
        }
      ],
      "year": "2023",
      "publication": "",
      "venue": "Vol. 10",
      "type": "research-paper",
      "abstract": "Compilers are among the most critical components in the software development. Obviously, their correctness is very important, yet they are among the most complex software systems. The traditional grammar-based compiler random testing measures have two shortcomings. Firstly, the technique generating test programs for one programming language is difficult to migrate to another. The second one is that traditional grammar-based technique haven't optimized the relation of identifier definition and use yet, causing the undefined identifiers problems or the low quality of the generated test programs. To address these problems, we propose a scope-based compiler testing method ScopeGen in this paper. To generate runnable and diverse test programs, ScopeGen supports two types of identifier strategies based on the scope information, one is scope distance based and the other is global optimization based. These identifier strategies guide the definition and use of identifiers and balance the distribution of identifiers in different scopes. Benefiting from the public grammar dataset Grammar-v4, ScopeGen can be easily migrated to various programming languages. We implement a program generator and generate grammatically correct and runnable test programs for C, Java and Python. Next, we conduct differential testing to identify various bugs in compilers by comparing the output of different compilers. The experimental evaluation of 9 compilers (gcc, clang, icc, icx, Ark, Javac, CPython, Pypy and Codon) shows that ScopeGen outperforms the two state-of-the-art methods (i.e., Csmith and YARPGen) improving more than 69% in inconsistency finding ability. By running ScopeGen we have reported 114 bugs for 4 compilers, 84 of which were confirmed.",
      "paperUrl": "http://dx.doi.org/10.1109/qrs60937.2023.00043",
      "sourceUrl": "https://doi.org/10.1109/qrs60937.2023.00043",
      "tags": [
        "Clang",
        "Optimizations",
        "Programming Languages",
        "Testing"
      ],
      "keywords": [
        "Clang",
        "Optimizations",
        "Programming Languages",
        "Testing",
        "Differential Testing",
        "Scopegen",
        "Traditional Grammar",
        "Compiler Differential Testing",
        "Identifier Strategies"
      ],
      "matchedAuthors": [
        "Jian Zhang"
      ]
    },
    {
      "id": "openalex-w4381328365",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "SPARTA: Spatial Acceleration for Efficient and Scalable Horizontal Diffusion Weather Stencil Computation",
      "authors": [
        {
          "name": "Gagandeep Singh",
          "affiliation": "ETH Zurich"
        },
        {
          "name": "Alireza Khodamoradi",
          "affiliation": ""
        },
        {
          "name": "Kristof Denolf",
          "affiliation": ""
        },
        {
          "name": "Jack Lo",
          "affiliation": "Advanced Micro Devices (United States)"
        },
        {
          "name": "Juan Gómez-Luna",
          "affiliation": "ETH Zurich"
        },
        {
          "name": "Joseph Melber",
          "affiliation": ""
        },
        {
          "name": "Andra Bisca",
          "affiliation": ""
        },
        {
          "name": "Henk Corporaal",
          "affiliation": "Eindhoven University of Technology"
        },
        {
          "name": "Onur Mutlu",
          "affiliation": "ETH Zurich"
        }
      ],
      "year": "2023",
      "publication": "TU/e Research Portal",
      "venue": "TU/e Research Portal",
      "type": "research-paper",
      "abstract": "Fast and accurate climate simulations and weather predictions are critical for understanding and preparing for the impact of climate change. Real-world climate and weather simulations involve the use of complex compound stencil kernels, which are composed of a combination of different stencils. Horizontal diffusion is one such important compound stencil found in many climate and weather prediction models. Its computation involves a large amount of data access and manipulation that leads to two main issues on current computing systems. First, such compound stencils have high memory bandwidth demands as they require large amounts of data access. Second, compound stencils have complex data access patterns and poor data locality, as the memory access pattern is typically irregular with low arithmetic intensity. As a result, state-of-the-art CPU and GPU implementations suffer from limited performance and high energy consumption. Recent works propose using FPGAs as an alternative to traditional CPU and GPU-based systems to accelerate weather stencil kernels. However, we observe that stencil computation cannot leverage the bit-level flexibility available on an FPGA because of its complex memory access patterns, leading to high hardware resource utilization and low peak performance.We introduce SPARTA, a novel spatial accelerator for horizontal diffusion weather stencil computation. We exploit the two-dimensional spatial architecture to efficiently accelerate the horizontal diffusion stencil by designing the first scaled-out spatial accelerator using the MLIR (Multi-Level Intermediate Representation) compiler framework. We evaluate SPARTA on a real cutting-edge AMD-Xilinx Versal AI Engine (AIE) spatial architecture. Our real-system evaluation results demonstrate that SPARTA outperforms state-of-the-art CPU, GPU, and FPGA implementations by 17.1×, 1.2×, and 2.1×, respectively. Compared to the most energy-efficient design on an HBM-based FPGA, SPARTA provides 2.43× higher energy efficiency. Our results reveal that balancing workload across the available processing resources is crucial in achieving high performance on spatial architectures. We also implement and evaluate five elementary stencils that are commonly used as benchmarks for stencil computation research. We freely open-source all our implementations to aid future research in stencil computation and spatial computing systems at https://github.com/CMU-SAFARI/SPARTA.",
      "paperUrl": "https://doi.org/10.1145/3577193.3593719",
      "sourceUrl": "",
      "tags": [
        "Performance",
        "GPU",
        "IR",
        "AI",
        "MLIR"
      ],
      "keywords": [
        "Performance",
        "GPU",
        "IR",
        "AI",
        "MLIR",
        "Intermediate Representation",
        "Weather Stencil Computation",
        "Spatial",
        "Diffusion Weather Stencil",
        "Horizontal Diffusion Weather",
        "Sparta",
        "Access",
        "Climate",
        "Compound"
      ],
      "matchedAuthors": [
        "Andra Bisca",
        "Gagandeep Singh",
        "Henk Corporaal",
        "Jack Lo",
        "Joseph Melber",
        "Onur Mutlu"
      ]
    },
    {
      "id": "openalex-w4315588442",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "SFP: Providing System Call Flow Protection against Software and Fault Attacks",
      "authors": [
        {
          "name": "Robert Schilling",
          "affiliation": ""
        },
        {
          "name": "Pascal Nasahl",
          "affiliation": ""
        },
        {
          "name": "Martin Unterguggenberger",
          "affiliation": ""
        },
        {
          "name": "Stefan Mangard",
          "affiliation": ""
        }
      ],
      "year": "2023",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "With the improvements in computing technologies, edge devices in the Internet-of-Things have become more complex. The enabler technology for these complex systems are powerful application core processors with operating system support, such as Linux. While the isolation of applications through the operating system increases the security, the interface to the kernel poses a new threat. Different attack vectors, including fault attacks and memory vulnerabilities, exploit the kernel interface to escalate privileges and take over the system. In this work, we present SFP, a mechanism to protect the execution of system calls against software and fault attacks providing integrity to user-kernel transitions. SFP provides system call flow integrity by a two-step linking approach, which links the system call and its origin to the state of control-flow integrity. A second linking step within the kernel ensures that the right system call is executed in the kernel. Combining both linking steps ensures that only the correct system call is executed at the right location in the program and cannot be skipped. Furthermore, SFP provides dynamic CFI instrumentation and a new CFI checking policy at the edge of the kernel to verify the control-flow state of user programs before entering the kernel. We integrated SFP into FIPAC, a CFI protection scheme exploiting ARM pointer authentication. Our prototype is based on a custom LLVM-based toolchain with an instrumented runtime library combined with a custom Linux kernel to protect system calls. The evaluation of micro- and macrobenchmarks based on SPEC 2017 show an average runtime overhead of 1.9 % and 20.6 %, which is only an increase of 1.8 % over plain control-flow protection. This small impact on the performance shows the efficiency of SFP for protecting all system calls and providing integrity for the user-kernel transitions.",
      "paperUrl": "https://arxiv.org/pdf/2301.02915",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2301.02915",
      "tags": [
        "Security",
        "Performance",
        "Infrastructure"
      ],
      "keywords": [
        "Security",
        "Performance",
        "Infrastructure",
        "LLVM",
        "User Kernel Transitions",
        "Fault Attacks",
        "Control Flow",
        "Flow Integrity",
        "Flow Protection Against",
        "Call Flow Protection",
        "CFI",
        "Providing Integrity",
        "Sfp Providing"
      ],
      "matchedAuthors": [
        "Pascal Nasahl",
        "Robert Schilling",
        "Stefan Mangard"
      ]
    },
    {
      "id": "openalex-w4323650864",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "SCRAMBLE-CFI: Mitigating Fault-Induced Control-Flow Attacks on OpenTitan",
      "authors": [
        {
          "name": "Pascal Nasahl",
          "affiliation": ""
        },
        {
          "name": "Stefan Mangard",
          "affiliation": ""
        }
      ],
      "year": "2023",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Secure elements physically exposed to adversaries are frequently targeted by fault attacks. These attacks can be utilized to hijack the control-flow of software allowing the attacker to bypass security measures, extract sensitive data, or gain full code execution. In this paper, we systematically analyze the threat vector of fault-induced control-flow manipulations on the open-source OpenTitan secure element. Our thorough analysis reveals that current countermeasures of this chip either induce large area overheads or still cannot prevent the attacker from exploiting the identified threats. In this context, we introduce SCRAMBLE-CFI, an encryption-based control-flow integrity scheme utilizing existing hardware features of OpenTitan. SCRAMBLE-CFI confines, with minimal hardware overhead, the impact of fault-induced control-flow attacks by encrypting each function with a different encryption tweak at load-time. At runtime, code only can be successfully decrypted when the correct decryption tweak is active. We open-source our hardware changes and release our LLVM toolchain automatically protecting programs. Our analysis shows that SCRAMBLE-CFI complementarily enhances security guarantees of OpenTitan with a negligible hardware overhead of less than 3.97 % and a runtime overhead of 7.02 % for the Embench-IoT benchmarks.",
      "paperUrl": "https://arxiv.org/pdf/2303.03711",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2303.03711",
      "tags": [
        "Security",
        "Infrastructure"
      ],
      "keywords": [
        "Security",
        "Infrastructure",
        "LLVM",
        "Induced Control Flow",
        "Scramble CFI Mitigating",
        "Fault Induced Control",
        "Control Flow Attacks",
        "Opentitan",
        "Hardware",
        "Hardware Overhead",
        "CFI Mitigating Fault",
        "Mitigating Fault Induced"
      ],
      "matchedAuthors": [
        "Pascal Nasahl",
        "Stefan Mangard"
      ]
    },
    {
      "id": "openalex-w4320854292",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Revet: A Language and Compiler for Dataflow Threads",
      "authors": [
        {
          "name": "Alexander Rucker",
          "affiliation": ""
        },
        {
          "name": "Shiv Sundram",
          "affiliation": ""
        },
        {
          "name": "Coleman I. Smith",
          "affiliation": ""
        },
        {
          "name": "Matthew Vilim",
          "affiliation": ""
        },
        {
          "name": "Raghu Prabhakar",
          "affiliation": ""
        },
        {
          "name": "Fredrik Kjølstad",
          "affiliation": ""
        },
        {
          "name": "Kunle Olukotun",
          "affiliation": ""
        }
      ],
      "year": "2023",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Spatial dataflow architectures such as reconfigurable dataflow accelerators (RDA) can provide much higher performance and efficiency than CPUs and GPUs. In particular, vectorized reconfigurable dataflow accelerators (vRDA) in recent literature represent a design point that enhances the efficiency of dataflow architectures with vectorization. Today, vRDAs can be exploited using either hardcoded kernels or MapReduce languages like Spatial, which cannot vectorize data-dependent control flow. In contrast, CPUs and GPUs can be programmed using general-purpose threaded abstractions. The ideal combination would be the generality of a threaded programming model coupled with the efficient execution model of a vRDA. We introduce Revet: a programming model, compiler, and execution model that lets threaded applications run efficiently on vRDAs. The Revet programming language uses threads to support a broader range of applications than Spatial's parallel patterns, and our MLIR-based compiler lowers this language to a generic dataflow backend that operates on streaming tensors. Finally, we show that mapping threads to dataflow outperforms GPUs, the current state-of-the-art for threaded accelerators, by 3.8x.",
      "paperUrl": "https://arxiv.org/pdf/2302.06124",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2302.06124",
      "tags": [
        "Backend",
        "Performance",
        "GPU",
        "Autovectorization",
        "Programming Languages",
        "MLIR"
      ],
      "keywords": [
        "Backend",
        "Performance",
        "GPU",
        "Autovectorization",
        "Programming Languages",
        "MLIR",
        "Reconfigurable Dataflow Accelerators",
        "Dataflow Threads",
        "Spatial",
        "Dataflow Architectures"
      ],
      "matchedAuthors": [
        "Fredrik Kjølstad"
      ]
    },
    {
      "id": "openalex-w4390553472",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Rethinking How We Build Compilers: Synthesis and Neural Machine Translation",
      "authors": [
        {
          "name": "Michael O’Boyle",
          "affiliation": "University of Edinburgh"
        }
      ],
      "year": "2023",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "Moore’s Law has been the main driver behind the extraordinary success of computer systems. However, with the technology roadmap showing a decline in transistor scaling, computer systems are increasingly heterogeneous, specialised and diverse. As it stands, software will simply not fit and current compiler technology is struggling to bridge the gap. We need to fundamentally rethink the role and design of the compiler. This talk presents two novel approaches to this problem. The first uses program synthesis to lift programs to MLIR, an emerging infrastructure for building high-level compilers, that can effectively target modern hardware. The second uses neural machine translation to compiler and decompile code. which outperforms the state of the art.",
      "paperUrl": "http://dx.doi.org/10.52843/cassyni.2qx69k",
      "sourceUrl": "https://doi.org/10.52843/cassyni.2qx69k",
      "tags": [
        "Infrastructure",
        "MLIR"
      ],
      "keywords": [
        "Infrastructure",
        "MLIR",
        "Program Synthesis",
        "Neural Machine",
        "Build Compilers Synthesis"
      ],
      "matchedAuthors": [
        "Michael O’Boyle"
      ]
    },
    {
      "id": "openalex-w4361212776",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Refinement of Parallel Algorithms down to LLVM applied to practically efficient parallel sorting",
      "authors": [
        {
          "name": "Peter Lammich",
          "affiliation": "University of Twente"
        }
      ],
      "year": "2023",
      "publication": "Research Square (Research Square)",
      "venue": "Research Square (Research Square)",
      "type": "research-paper",
      "abstract": "<title>Abstract</title> We present a stepwise refinement approach to develop verified parallel algorithms, down to efficient LLVM code. The resulting algorithms' performance is competitive with their counterparts implemented in C/C++. Our approach is backwards compatible with the Isabelle Refinement Framework, such that existing sequential formalizations can easily be adapted or re-used. As case study, we verify a parallel quicksort algorithm that is competitive to unverified state-of-the-art algorithms.",
      "paperUrl": "https://www.researchsquare.com/article/rs-2733052/latest.pdf",
      "sourceUrl": "https://doi.org/10.21203/rs.3.rs-2733052/v1",
      "tags": [
        "Performance"
      ],
      "keywords": [
        "Performance",
        "LLVM",
        "Refinement",
        "LLVM Applied",
        "Parallel Sorting"
      ],
      "matchedAuthors": [
        "Peter Lammich"
      ]
    },
    {
      "id": "openalex-w4384154398",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Pattern-Based Peephole Optimizations with Java JIT Tests",
      "authors": [
        {
          "name": "Zhiqiang Zang",
          "affiliation": "The University of Texas at Austin"
        },
        {
          "name": "Aditya Thimmaiah",
          "affiliation": "The University of Texas at Austin"
        },
        {
          "name": "Milos Gligoric",
          "affiliation": "The University of Texas at Austin"
        }
      ],
      "year": "2023",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "We present JOG, a framework that facilitates developing Java JIT peephole\\noptimizations alongside JIT tests. JOG enables developers to write a pattern,\\nin Java itself, that specifies desired code transformations by writing code\\nbefore and after the optimization, as well as any necessary preconditions. Such\\npatterns can be written in the same way that tests of the optimization are\\nalready written in OpenJDK. JOG translates each pattern into C/C++ code that\\ncan be integrated as a JIT optimization pass. JOG also generates Java tests for\\noptimizations from patterns. Furthermore, JOG can automatically detect possible\\nshadow relation between a pair of optimizations where the effect of the\\nshadowed optimization is overridden by another. Our evaluation shows that JOG\\nmakes it easier to write readable JIT optimizations alongside tests without\\ndecreasing the effectiveness of JIT optimizations. We wrote 162 patterns,\\nincluding 68 existing optimizations in OpenJDK, 92 new optimizations adapted\\nfrom LLVM, and two new optimizations that we proposed. We opened eight pull\\nrequests (PRs) for OpenJDK, including six for new optimizations, one on\\nremoving shadowed optimizations, and one for newly generated JIT tests; seven\\nPRs have already been integrated into the master branch of OpenJDK.\\n",
      "paperUrl": "https://dl.acm.org/doi/pdf/10.1145/3597926.3598038",
      "sourceUrl": "https://doi.org/10.1145/3597926.3598038",
      "tags": [
        "JIT",
        "Optimizations"
      ],
      "keywords": [
        "JIT",
        "Optimizations",
        "LLVM",
        "JIT Compilation",
        "JIT Optimizations",
        "JIT Tests",
        "Openjdk",
        "Pattern",
        "Java JIT Tests",
        "Peephole Optimizations"
      ],
      "matchedAuthors": [
        "Aditya Thimmaiah",
        "Milos Gligoric",
        "Zhiqiang Zang"
      ]
    },
    {
      "id": "openalex-w4362717258",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "PETSc/TAO Users Manual (Rev. 3.19)",
      "authors": [
        {
          "name": "Satish Balay",
          "affiliation": "Argonne National Laboratory"
        },
        {
          "name": "Shrirang Abhyankar",
          "affiliation": "Argonne National Laboratory"
        },
        {
          "name": "Mark F. Adams",
          "affiliation": "Lawrence Berkeley National Laboratory"
        },
        {
          "name": "S. Benson",
          "affiliation": "Argonne National Laboratory"
        },
        {
          "name": "Jed Brown",
          "affiliation": "University of Colorado Boulder"
        },
        {
          "name": "Peter Brune",
          "affiliation": "Argonne National Laboratory"
        },
        {
          "name": "K. Buschelman",
          "affiliation": "Office of Scientific and Technical Information"
        },
        {
          "name": "E. Constantinescu",
          "affiliation": "Argonne National Laboratory"
        },
        {
          "name": "Lisandro Dalcín",
          "affiliation": "King Abdullah University of Science and Technology"
        },
        {
          "name": "Alp Dener",
          "affiliation": "Argonne National Laboratory"
        },
        {
          "name": "V. Eijkhout",
          "affiliation": "The University of Texas at Austin"
        },
        {
          "name": "J. Faibussowitsch",
          "affiliation": "University of Illinois Urbana-Champaign"
        },
        {
          "name": "William Gropp",
          "affiliation": "University of Illinois Urbana-Champaign"
        },
        {
          "name": "V. Hapla",
          "affiliation": "ETH Zurich"
        },
        {
          "name": "T. Isaac",
          "affiliation": "Georgia Institute of Technology"
        },
        {
          "name": "P. Jolivet",
          "affiliation": "Sorbonne Université"
        },
        {
          "name": "Dmitry Karpeev",
          "affiliation": "Argonne National Laboratory"
        },
        {
          "name": "D. Kaushik",
          "affiliation": "Argonne National Laboratory"
        },
        {
          "name": "Matthew G. Knepley",
          "affiliation": "Argonne National Laboratory"
        },
        {
          "name": "Fande Kong",
          "affiliation": "Idaho National Laboratory"
        },
        {
          "name": "S. Kruger",
          "affiliation": "Tech-X Corporation (United States)"
        },
        {
          "name": "Dave A. May",
          "affiliation": "University of Oxford"
        },
        {
          "name": "Lois Curfman McInnes",
          "affiliation": "Argonne National Laboratory"
        },
        {
          "name": "Richard Mills",
          "affiliation": "Argonne National Laboratory"
        },
        {
          "name": "Lawrence Mitchell",
          "affiliation": "Nvidia (United States)"
        },
        {
          "name": "T. Munson",
          "affiliation": "Argonne National Laboratory"
        },
        {
          "name": "José E. Román",
          "affiliation": "Consejo Superior de Investigaciones Científicas"
        },
        {
          "name": "K. Rupp",
          "affiliation": "TU Wien"
        },
        {
          "name": "Patrick Sanan",
          "affiliation": "ETH Zurich"
        },
        {
          "name": "J. Sarich",
          "affiliation": "Argonne National Laboratory"
        },
        {
          "name": "Braeton Smith",
          "affiliation": "Flatiron Institute"
        },
        {
          "name": "Stefano Zampini",
          "affiliation": "King Abdullah University of Science and Technology"
        },
        {
          "name": "H. Zhang",
          "affiliation": "Illinois Institute of Technology"
        },
        {
          "name": "Jiejing Zhang",
          "affiliation": "Argonne National Laboratory"
        }
      ],
      "year": "2023",
      "publication": "OSTI OAI (U.S. Department of Energy Office of Scientific and Technical Information)",
      "venue": "OSTI OAI (U.S. Department of Energy Office of Scientific and Technical Information)",
      "type": "research-paper",
      "abstract": "This manual describes the use of the Portable, Extensible Toolkit for Scientific Computation (PETSc) and the Toolkit for Advanced Optimization (TAO) for the numerical solution of partial differential equations and related problems on high-performance computers. PETSc/TAO is a suite of data structures and routines that provide the building blocks for the implementation of large-scale application codes on parallel (and serial) computers. PETSc uses the MPI standard for all distributed memory communication. PETSc/TAO includes a large suite of parallel linear solvers, nonlinear solvers, time integrators, and opti mization that may be used in application codes written in Fortran, C, C++, and Python (via petsc4py; see Getting Started). PETSc provides many of the mechanisms needed within parallel application codes, such as parallel matrix and vector assembly routines. The library is organized hierarchically, enabling users to employ the level of abstraction that is most appropriate for a particular problem. By using techniques of object-oriented programming, PETSc provides enormous flexibility for users. PETSc is a sophisticated set of software tools; as such, for some users it initially has a much steeper learning curve than packages such as MATLAB or a simple subroutine library. In particular, for individuals without some computer science background, experience programming in C, C++, python, or Fortran and experience using a debugger such as gdb or lldb, it may require a significant amount of time to take full advantage of the features that enable efficient software use. However, the power of the PETSc design and the algorithms it incorporates may make the efficient implementation of many application codes simpler than “rolling them” yourself. For many tasks a package such as MATLAB is often the best tool; PETSc is not intended for the classes of problems for which effective MATLAB code can be written. There are several packages, built on PETSc, that may satisfy your needs without requiring directly using PETSc. We recommend reviewing these packages functionality before starting to code directly with PETSc. PETSc can be used to provide a “MPI parallel linear solver” in an otherwise sequential, or OpenMP parallel code. This approach cannot provide extremely large improvements in the application time by utilizing large numbers of MPI processes but can still improve the performance. Certainly all parts of a previously sequential code need not be parallelized but the matrix generation portion must be parallelized to expect true scalability to large numbers of MPI processes. See PCMPI for details on how to utilize the PETSc MPI linear solver server. Since PETSc is under continued development, small changes in usage and calling sequences of routines will occur. PETSc has been supported for twenty-five years; see mailing list information on our website for information on contacting support.",
      "paperUrl": "https://www.osti.gov/servlets/purl/1968587",
      "sourceUrl": "https://doi.org/10.2172/1968587",
      "tags": [
        "Performance",
        "Optimizations",
        "LLDB"
      ],
      "keywords": [
        "Performance",
        "Optimizations",
        "LLDB",
        "MPI Processes",
        "Petsc Tao Users",
        "Linear Solver",
        "Matlab",
        "Packages",
        "Provide",
        "Routines",
        "Computers Petsc",
        "Parallel Linear",
        "Tao Users Manual",
        "Users Manual Rev"
      ],
      "matchedAuthors": [
        "Lawrence Mitchell"
      ]
    },
    {
      "id": "openalex-w4385496093",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "OpenMP offloading data transfer optimization for DCUs",
      "authors": [
        {
          "name": "Hengliang Guo",
          "affiliation": "Zhengzhou University"
        },
        {
          "name": "Long Zhang",
          "affiliation": "Zhengzhou University"
        },
        {
          "name": "Yi Zhang",
          "affiliation": "Zhengzhou University"
        },
        {
          "name": "Jianan Li",
          "affiliation": "Zhengzhou University"
        },
        {
          "name": "Xiaoyue Xu",
          "affiliation": "Zhengzhou University"
        },
        {
          "name": "Lu Liu",
          "affiliation": "Zhengzhou University"
        },
        {
          "name": "Kuangsheng Cai",
          "affiliation": "Zhengzhou University"
        },
        {
          "name": "Dan Wu",
          "affiliation": "Zhengzhou University"
        },
        {
          "name": "Shuxin Yang",
          "affiliation": "Zhengzhou University"
        },
        {
          "name": "Lingbo Kong",
          "affiliation": "Zhengzhou University"
        },
        {
          "name": "Xu Gao",
          "affiliation": "Zhengzhou University"
        }
      ],
      "year": "2023",
      "publication": "The Journal of Supercomputing",
      "venue": "The Journal of Supercomputing | Vol. 80 (Issue 2)",
      "type": "research-paper",
      "abstract": "Abstract OpenMP supports the use of target offloading compile guidance instructions to invoke heterogeneous-platform accelerators to compute core code segments; however, unreasonable use of target offloading instructions can make the data transfer process time-consuming. The problem of unused array transfer and unused data segment transfer arises when the amount of data transferred from the host side to the device side exceeds the amount of data required for the core computation on the device side. For the transmission of unused arrays, the use of the transmitted arrays is guided by adding a filter to eliminate the transmission of redundant data; for the transmission of unused data segments, the use of arrays is quickly determined on the basis of the filter, and valid data are transmitted by optimizing Clang’s code generation strategy after obtaining the lengths of the data segments in core computation. Experiments are performed using the Polybench benchmark; the optimized speedup for unused array transfer reaches 7%, and the optimized speedup for unused data segment transfer reaches 10%. The experimental results show that data transfer optimization for target offloading characteristics can help improve program performance.",
      "paperUrl": "https://link.springer.com/content/pdf/10.1007/s11227-023-05422-w.pdf",
      "sourceUrl": "https://doi.org/10.1007/s11227-023-05422-w",
      "tags": [
        "Backend",
        "Performance",
        "Clang",
        "Optimizations",
        "GPU"
      ],
      "keywords": [
        "Backend",
        "Performance",
        "Clang",
        "Optimizations",
        "GPU",
        "Code Generation",
        "Offloading",
        "Unused Array Transfer",
        "Target Offloading",
        "Transfer Optimization",
        "Arrays",
        "Segments",
        "Transmission",
        "Core Computation"
      ],
      "matchedAuthors": [
        "Jianan Li",
        "Yi Zhang"
      ]
    },
    {
      "id": "openalex-w4388483154",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "MLIRSmith: Random Program Generation for Fuzzing MLIR Compiler Infrastructure",
      "authors": [
        {
          "name": "Haoyu Wang",
          "affiliation": "Tianjin University"
        },
        {
          "name": "Junjie Chen",
          "affiliation": "Tianjin University"
        },
        {
          "name": "Chuyue Xie",
          "affiliation": "Tianjin University"
        },
        {
          "name": "Shuang Liu",
          "affiliation": "Tianjin University"
        },
        {
          "name": "Zan Wang",
          "affiliation": "Tianjin University"
        },
        {
          "name": "Qingchao Shen",
          "affiliation": "Tianjin University"
        },
        {
          "name": "Yingquan Zhao",
          "affiliation": "Tianjin University"
        }
      ],
      "year": "2023",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "MLIR (Multi-Level Intermediate Representation) compiler infrastructure has gained popularity in recent years to support the construction of many compilers. Instead of designing a new IR with a single abstraction for each domain, MLIR compiler infrastructure provides systematic passes to support a wide range of functionalities for benefiting multiple domains together and introduces dialects to support different levels of abstraction in MLIR. Due to its fundamental role in compiler community, ensuring its quality is very critical. In this work, we propose MLIRSmith, the first fuzzing technique for MLIR compiler infrastructure. MLIRSmith employs a two-phase strategy to generate valid and diverse MLIR programs, which first constructs diverse program templates guided by extended MLIR syntax rules and then generates valid MLIR programs through template instantiation guided by our designed context-sensitive grammar. After applying MLIRSmith to the latest revision of MLIR compiler infrastructure, we detected 53 previously unknown bugs, among which 49/38 have been confirmed/fixed by developers. We also transform the high-level programs generated by NNSmith (a high-level program generator for deep learning compilers) to MLIR programs for indirectly fuzzing MLIR compiler infrastructure. During the same testing time, MLIRSmith largely outperforms such an indirect technique by detecting 328.57% more bugs and covering 194.67%/225.87% more lines/branches in MLIR compiler infrastructure.",
      "paperUrl": "https://doi.org/10.1109/ase56229.2023.00120",
      "sourceUrl": "",
      "tags": [
        "IR",
        "Testing",
        "Infrastructure",
        "ML",
        "MLIR"
      ],
      "keywords": [
        "IR",
        "Testing",
        "Infrastructure",
        "ML",
        "MLIR",
        "Intermediate Representation",
        "Fuzzing",
        "MLIR Compiler Infrastructure",
        "Mlirsmith Random Program",
        "MLIR Programs",
        "Fuzzing MLIR Compiler",
        "Random Program Generation"
      ],
      "matchedAuthors": [
        "Haoyu Wang",
        "Junjie Chen",
        "Shuang Liu"
      ]
    },
    {
      "id": "openalex-w4387559420",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Leveraging LLVM's ScalarEvolution for Symbolic Data Cache Analysis",
      "authors": [
        {
          "name": "Valentin Touzeau",
          "affiliation": ""
        },
        {
          "name": "Jan Reineke",
          "affiliation": ""
        }
      ],
      "year": "2023",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "While instruction cache analysis is essentially a solved problem, data cache analysis is more challenging. In contrast to instruction fetches, the data accesses generated by a memory instruction may vary with the program's inputs and across dynamic occurrences of the same instruction in loops. We observe that the plain control-flow graph (CFG) abstraction employed in classical cache analyses is inadequate to capture the dynamic behavior of memory instructions. On top of plain CFGs, accurate analysis of the underlying program's cache behavior is impossible. Thus, our first contribution is the definition of a more expressive program abstraction coined symbolic control-flow graphs, which can be obtained from LLVM's ScalarEvolution analysis. To exploit this richer abstraction, our main contribution is the development of symbolic data cache analysis, a smooth generalization of classical LRU must analysis from plain to symbolic control-flow graphs. The experimental evaluation demonstrates that symbolic data cache analysis consistently outperforms classical LRU must analysis both in terms of accuracy and analysis runtime.",
      "paperUrl": "https://arxiv.org/pdf/2310.04809",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2310.04809",
      "tags": [],
      "keywords": [
        "LLVM",
        "Control Flow Graph",
        "Symbolic Control Flow",
        "Control Flow Graphs",
        "Classical Lru Must",
        "Abstraction",
        "Leveraging LLVM",
        "Memory"
      ],
      "matchedAuthors": [
        "Jan Reineke"
      ]
    },
    {
      "id": "openalex-w4384261883",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Latent Space Perspicacity and Interpretation Enhancement (LS-PIE) Framework",
      "authors": [
        {
          "name": "Jesse Stevens",
          "affiliation": ""
        },
        {
          "name": "Daniël N. Wilke",
          "affiliation": ""
        },
        {
          "name": "Itumeleng B. Setshedi",
          "affiliation": ""
        }
      ],
      "year": "2023",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Linear latent variable models such as principal component analysis (PCA), independent component analysis (ICA), canonical correlation analysis (CCA), and factor analysis (FA) identify latent directions (or loadings) either ordered or unordered. The data is then projected onto the latent directions to obtain their projected representations (or scores). For example, PCA solvers usually rank the principal directions by explaining the most to least variance, while ICA solvers usually return independent directions unordered and often with single sources spread across multiple directions as multiple sub-sources, which is of severe detriment to their usability and interpretability. This paper proposes a general framework to enhance latent space representations for improving the interpretability of linear latent spaces. Although the concepts in this paper are language agnostic, the framework is written in Python. This framework automates the clustering and ranking of latent vectors to enhance the latent information per latent vector, as well as, the interpretation of latent vectors. Several innovative enhancements are incorporated including latent ranking (LR), latent scaling (LS), latent clustering (LC), and latent condensing (LCON). For a specified linear latent variable model, LR ranks latent directions according to a specified metric, LS scales latent directions according to a specified metric, LC automatically clusters latent directions into a specified number of clusters, while, LCON automatically determines an appropriate number of clusters into which to condense the latent directions for a given metric. Additional functionality of the framework includes single-channel and multi-channel data sources, data preprocessing strategies such as Hankelisation to seamlessly expand the applicability of linear latent variable models (LLVMs) to a wider variety of data. The effectiveness of LR, LS, and LCON are showcased on two crafted foundational problems with two applied latent variable models, namely, PCA and ICA.",
      "paperUrl": "https://arxiv.org/pdf/2307.05620",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2307.05620",
      "tags": [],
      "keywords": [
        "Latent Variable",
        "Latent Directions According",
        "Linear Latent Variable",
        "Latent Space Perspicacity",
        "Clusters",
        "Specified Metric",
        "Sources",
        "Latent Vectors",
        "Solvers Usually",
        "Interpretation Enhancement"
      ],
      "matchedAuthors": [
        "Daniël N. Wilke",
        "Jesse Stevens"
      ]
    },
    {
      "id": "openalex-w4385301329",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "LIBAFL LIBFUZZER: LIBFUZZER on Top of LIBAFL",
      "authors": [
        {
          "name": "Addison Crump",
          "affiliation": "Helmholtz Center for Information Security"
        },
        {
          "name": "Andrea Fioraldi",
          "affiliation": "EURECOM"
        },
        {
          "name": "Dominik Maier",
          "affiliation": "Google (United States)"
        },
        {
          "name": "Dongjia Zhang",
          "affiliation": "The University of Tokyo"
        }
      ],
      "year": "2023",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "General-purpose fuzzing has come into the public eye, with many researchers developing new fuzzers to improve on the state of the art. LIBAFL, developed by the group which originally made AFL++, offers researchers the ability to develop fuzzers at a component level, allowing researchers to simply develop their own components rather than modifying an existing fuzzer. This allows for more straightforward comparisons of fuzzers, allowing researchers to experiment with the removal and addition of individual components, without compromising on the flexibility of fuzzer development. To demonstrate this flexibility and offer alternative frontends to the community, we developed two fuzzers: LIBAFL_LIBFUZZER and AFLRUSTRUST, the former of which is discussed here as a drop-in replacement for LIBFUZZER and the latter in a sister report as a drop-in replacement for AFL++. We find that LIBAFL_LIBFUZZER performed very well on the coverage benchmarks while struggling with the bug-based benchmarks conducted in the SBFT fuzzing competition, and discover and analyse which fuzzer features and bugs led to this underperformance.",
      "paperUrl": "https://doi.org/10.1109/sbft59156.2023.00021",
      "sourceUrl": "",
      "tags": [
        "Testing"
      ],
      "keywords": [
        "Testing",
        "Fuzzing",
        "Libafl",
        "Libafl Libfuzzer",
        "Fuzzers",
        "Allowing Researchers"
      ],
      "matchedAuthors": [
        "Addison Crump"
      ]
    },
    {
      "id": "openalex-w4318620778",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Khaos: The Impact of Inter-procedural Code Obfuscation on Binary Diffing Techniques",
      "authors": [
        {
          "name": "Peihua Zhang",
          "affiliation": ""
        },
        {
          "name": "Chenggang Wu",
          "affiliation": ""
        },
        {
          "name": "Mingfan Peng",
          "affiliation": ""
        },
        {
          "name": "Kai Zeng",
          "affiliation": ""
        },
        {
          "name": "Ding Yu",
          "affiliation": ""
        },
        {
          "name": "Yuanming Lai",
          "affiliation": ""
        },
        {
          "name": "Yan Kang",
          "affiliation": ""
        },
        {
          "name": "Wei Wang",
          "affiliation": ""
        },
        {
          "name": "Zhe Wang",
          "affiliation": ""
        }
      ],
      "year": "2023",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Software obfuscation techniques can prevent binary diffing techniques from locating vulnerable code by obfuscating the third-party code, to achieve the purpose of protecting embedded device software. With the rapid development of binary diffing techniques, they can achieve more and more accurate function matching and identification by extracting the features within the function. This makes existing software obfuscation techniques, which mainly focus on the intra-procedural code obfuscation, no longer effective. In this paper, we propose a new inter-procedural code obfuscation mechanism Khaos, which moves the code across functions to obfuscate the function by using compilation optimizations. Two obfuscation primitives are proposed to separate and aggregate the function, which are called fission and fusion respectively. A prototype of Khaos is implemented based on the LLVM compiler and evaluated on a large number of real-world programs including SPEC CPU 2006 &amp; 2017, CoreUtils, JavaScript engines, etc. Experimental results show that Khaos outperforms existing code obfuscations and can significantly reduce the accuracy rates of five state-of-the-art binary diffing techniques (less than 19%) with lower runtime overhead (less than 7%).",
      "paperUrl": "https://arxiv.org/pdf/2301.11586",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2301.11586",
      "tags": [
        "Optimizations",
        "Embedded"
      ],
      "keywords": [
        "Optimizations",
        "Embedded",
        "LLVM",
        "Obfuscation",
        "Binary Diffing",
        "Inter Procedural"
      ],
      "matchedAuthors": [
        "Wei Wang"
      ]
    },
    {
      "id": "openalex-w4383175415",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Isolating Compiler Bugs by Generating Effective Witness Programs with Large Language Models",
      "authors": [
        {
          "name": "Haoxin Tu",
          "affiliation": "Dalian University of Technology"
        },
        {
          "name": "Zhide Zhou",
          "affiliation": "Ubiquitous Energy (United States)"
        },
        {
          "name": "He Jiang",
          "affiliation": "Ubiquitous Energy (United States)"
        },
        {
          "name": "Imam Nur Bani Yusuf",
          "affiliation": "Ubiquitous Energy (United States)"
        },
        {
          "name": "Yuxian Li",
          "affiliation": "Dalian University of Technology"
        },
        {
          "name": "Lingxiao Jiang",
          "affiliation": "Ubiquitous Energy (United States)"
        }
      ],
      "year": "2023",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Compiler bugs pose a significant threat to safety-critical applications, and promptly as well as effectively isolating these bugs is crucial for assuring the quality of compilers. However, the limited availability of debugging information on reported bugs complicates the compiler bug isolation task. Existing compiler bug isolation approaches convert the problem into a test program mutation problem, but they are still limited by ineffective mutation strategies or high human effort requirements. Drawing inspiration from the recent progress of pre-trained Large Language Models (LLMs), such as ChatGPT, in code generation, we propose a new approach named LLM4CBI to utilize LLMs to generate effective test programs for compiler bug isolation. However, using LLMs directly for test program mutation may not yield the desired results due to the challenges associated with formulating precise prompts and selecting specialized prompts. To overcome the challenges, three new components are designed in LLM4CBI. First, LLM4CBI utilizes a program complexity-guided prompt production component, which leverages data and control flow analysis to identify the most valuable variables and locations in programs for mutation. Second, LLM4CBI employs a memorized prompt selection component, which adopts reinforcement learning to select specialized prompts for mutating test programs continuously. Third, a test program validation component is proposed to select specialized feedback prompts to avoid repeating the same mistakes during the mutation process. Compared with state-of-the-art approaches over 120 real bugs from GCC and LLVM, our evaluation demonstrates the advantages of LLM4CBI: It can isolate 69.70%/21.74% and 24.44%/8.92% more bugs than DiWi and RecBi within Top-1/Top-5 ranked results. We also demonstrate that the LLMs component used in LLM4CBI can be easily replaced while still achieving reasonable results.",
      "paperUrl": "https://arxiv.org/pdf/2307.00593",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2307.00593",
      "tags": [
        "Backend"
      ],
      "keywords": [
        "Backend",
        "LLVM",
        "Code Generation",
        "Llm4cbi",
        "Compiler Bug Isolation",
        "Program Mutation",
        "Component",
        "Specialized Prompts",
        "Isolating Compiler Bugs",
        "Select Specialized",
        "Witness Programs"
      ],
      "matchedAuthors": [
        "Haoxin Tu",
        "He Jiang",
        "Imam Nur Bani Yusuf",
        "Lingxiao Jiang",
        "Yuxian Li",
        "Zhide Zhou"
      ]
    },
    {
      "id": "openalex-w4391623924",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "HIR: An MLIR-based Intermediate Representation for Hardware Accelerator Description",
      "authors": [
        {
          "name": "Kingshuk Majumder",
          "affiliation": "Indian Institute of Science Bangalore"
        },
        {
          "name": "Uday Bondhugula",
          "affiliation": "Indian Institute of Science Bangalore"
        }
      ],
      "year": "2023",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "The emergence of machine learning, image and audio processing on edge devices has motivated research towards power-efficient custom hardware accelerators. Though FPGAs are an ideal target for custom accelerators, the difficulty of hardware design and the lack of vendor agnostic, standardized hardware compilation infrastructure has hindered their adoption.",
      "paperUrl": "https://dl.acm.org/doi/pdf/10.1145/3623278.3624767",
      "sourceUrl": "https://doi.org/10.1145/3623278.3624767",
      "tags": [
        "IR",
        "Infrastructure",
        "ML",
        "MLIR"
      ],
      "keywords": [
        "IR",
        "Infrastructure",
        "ML",
        "MLIR",
        "Intermediate Representation",
        "Hardware Accelerator Description"
      ],
      "matchedAuthors": [
        "Uday Bondhugula"
      ]
    },
    {
      "id": "openalex-w4221150161",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "GPU Accelerated Automatic Differentiation With Clad",
      "authors": [
        {
          "name": "Ioana Ifrim",
          "affiliation": "Princeton University"
        },
        {
          "name": "Vassil M. Vassilev",
          "affiliation": "Princeton University"
        },
        {
          "name": "D. J. Lange",
          "affiliation": "Princeton University"
        }
      ],
      "year": "2023",
      "publication": "Journal of Physics Conference Series",
      "venue": "Journal of Physics Conference Series | Vol. 2438 (Issue 1)",
      "type": "research-paper",
      "abstract": "Abstract Automatic Differentiation (AD) is instrumental for science and industry. It is a tool to evaluate the derivative of a function specified through a computer program. The range of AD application domain spans from Machine Learning to Robotics to High Energy Physics. Computing gradients with the help of AD is guaranteed to be more precise than the numerical alternative and have a low, constant factor more arithmetical operations compared to the original function. Moreover, AD applications to domain problems typically are computationally bound. They are often limited by the computational requirements of high-dimensional parameters and thus can benefit from parallel implementations on graphics processing units (GPUs). Clad aims to enable differential analysis for C/C++ and CUDA and is a compiler-assisted AD tool available both as a compiler extension and in ROOT. Moreover, Clad works as a plugin extending the Clang compiler; as a plugin extending the interactive interpreter Cling; and as a Jupyter kernel extension based on xeus-cling. We demonstrate the advantages of parallel gradient computations on GPUs with Clad. We explain how to bring forth a new layer of optimization and a proportional speed up by extending Clad to support CUDA. The gradients of well-behaved C++ functions can be automatically executed on a GPU. The library can be easily integrated into existing frameworks or used interactively. Furthermore, we demonstrate the achieved application performance improvements, including (≈10x) in ROOT histogram fitting and corresponding performance gains from offloading to GPUs.",
      "paperUrl": "https://iopscience.iop.org/article/10.1088/1742-6596/2438/1/012043/pdf",
      "sourceUrl": "https://doi.org/10.1088/1742-6596/2438/1/012043",
      "tags": [
        "Performance",
        "Clang",
        "Optimizations",
        "GPU",
        "CUDA",
        "ML"
      ],
      "keywords": [
        "Performance",
        "Clang",
        "Optimizations",
        "GPU",
        "CUDA",
        "ML",
        "Offloading",
        "Plugin Extending",
        "GPU Accelerated",
        "Accelerated Automatic Differentiation"
      ],
      "matchedAuthors": [
        "D. J. Lange"
      ]
    },
    {
      "id": "openalex-w4385750097",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Fuzz4All: Universal Fuzzing with Large Language Models",
      "authors": [
        {
          "name": "Chunqiu Steven Xia",
          "affiliation": ""
        },
        {
          "name": "Matteo Paltenghi",
          "affiliation": ""
        },
        {
          "name": "Jia Le Tian",
          "affiliation": ""
        },
        {
          "name": "Michael Pradel",
          "affiliation": ""
        },
        {
          "name": "Lingming Zhang",
          "affiliation": ""
        }
      ],
      "year": "2023",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Fuzzing has achieved tremendous success in discovering bugs and vulnerabilities in various software systems. Systems under test (SUTs) that take in programming or formal language as inputs, e.g., compilers, runtime engines, constraint solvers, and software libraries with accessible APIs, are especially important as they are fundamental building blocks of software development. However, existing fuzzers for such systems often target a specific language, and thus cannot be easily applied to other languages or even other versions of the same language. Moreover, the inputs generated by existing fuzzers are often limited to specific features of the input language, and thus can hardly reveal bugs related to other or new features. This paper presents Fuzz4All, the first fuzzer that is universal in the sense that it can target many different input languages and many different features of these languages. The key idea behind Fuzz4All is to leverage large language models (LLMs) as an input generation and mutation engine, which enables the approach to produce diverse and realistic inputs for any practically relevant language. To realize this potential, we present a novel autoprompting technique, which creates LLM prompts that are wellsuited for fuzzing, and a novel LLM-powered fuzzing loop, which iteratively updates the prompt to create new fuzzing inputs. We evaluate Fuzz4All on nine systems under test that take in six different languages (C, C++, Go, SMT2, Java and Python) as inputs. The evaluation shows, across all six languages, that universal fuzzing achieves higher coverage than existing, language-specific fuzzers. Furthermore, Fuzz4All has identified 98 bugs in widely used systems, such as GCC, Clang, Z3, CVC5, OpenJDK, and the Qiskit quantum computing platform, with 64 bugs already confirmed by developers as previously unknown.",
      "paperUrl": "https://arxiv.org/pdf/2308.04748",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2308.04748",
      "tags": [
        "Clang",
        "Testing",
        "Quantum Computing",
        "Libraries"
      ],
      "keywords": [
        "Clang",
        "Testing",
        "Quantum Computing",
        "Libraries",
        "Fuzzing",
        "Quantum Compilation",
        "Fuzz4all",
        "Inputs",
        "Fuzz4all Universal Fuzzing",
        "Fuzzers",
        "Specific"
      ],
      "matchedAuthors": [
        "Lingming Zhang"
      ]
    },
    {
      "id": "openalex-w4361193180",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Formalization of Quantum Intermediate Representations for Code Safety",
      "authors": [
        {
          "name": "Junjie Luo",
          "affiliation": ""
        },
        {
          "name": "Jianjun Zhao",
          "affiliation": ""
        }
      ],
      "year": "2023",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Quantum Intermediate Representation (QIR) is a Microsoft-developed, LLVM-based intermediate representation for quantum program compilers. QIR aims to provide a general solution for quantum program compilers independent of front-end languages and back-end hardware, thus avoiding duplicate development of intermediate representations and compilers. Since it is still under development, QIR is described in natural language and lacks a formal definition, leading to ambiguity in its interpretation and a lack of rigor in implementing quantum functions. In this paper, we provide formal definitions for the data types and instruction sets of QIR, aiming to provide correctness and security guarantees for operations and intermediate code conversions in QIR. To validate our design, we show some samples of unsafe QIR code where errors can be detected by our formal approach.",
      "paperUrl": "https://arxiv.org/pdf/2303.14500",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2303.14500",
      "tags": [
        "Security",
        "IR"
      ],
      "keywords": [
        "Security",
        "IR",
        "LLVM",
        "Intermediate Representation",
        "Quantum Program Compilers",
        "Intermediate Representations",
        "Quantum Intermediate Representations",
        "Formalization",
        "Provide"
      ],
      "matchedAuthors": [
        "Jianjun Zhao",
        "Junjie Luo"
      ]
    },
    {
      "id": "openalex-w4386522866",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Enhanced Memory Corruption Detection in C/C++ Programs",
      "authors": [
        {
          "name": "Ching‐Yi Lin",
          "affiliation": "National Yang Ming Chiao Tung University"
        },
        {
          "name": "Wuu Yang",
          "affiliation": "National Yang Ming Chiao Tung University"
        }
      ],
      "year": "2023",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "Out-of-bound memory accesses, which often occur in programs written in unsafe languages such as C or C++, cause severe troubles. Though there are many useful tools aiming at this problem, we report a new tool, called mcds, for detecting spatial and temporal memory corruptions in x86-64 ELF binary. Mcds allocates each memory object to a separate virtual page. The rest is left blank. Due to a facility in the memory management library, we can set up memory protection so that accessing the “blank” part of a virtual page causes a hardware trap. Because it is a hardware trap, there is little run-time overhead. In order to save memory space, we may squeeze several virtual pages into a single physical page. Our first experimental result is that mcds can find all the bugs in the Firefox 78 package, the Chrome package and the PHP7.0 package that are recorded on the CVE Details website. Furthermore, mcds can detect three classes of memory corruptions that are beyond the capability of the current AddressSanitizer (Asan). Then we compare the time for compilation and fuzzing tests. The fuzzing test is done with AFL++ fuzzer on Ubuntu 22.04 LTS with Intel i5-9600K chip. According to our experimental results, mcds shows approximately 6x speedup in fuzzing tests against AddressSanitizer. There is not significant difference between compiling the source with AddressSanitizer or with mcds, though both of them result in 2x slowdown compared with compilation without a sanitizer.",
      "paperUrl": "https://doi.org/10.1145/3605731.3605903",
      "sourceUrl": "",
      "tags": [
        "Testing"
      ],
      "keywords": [
        "Testing",
        "Fuzzing",
        "Sanitizers",
        "Memory Corruptions",
        "Addresssanitizer",
        "Fuzzing Tests",
        "Package",
        "Virtual Page",
        "Hardware Trap",
        "Compilation",
        "Enhanced Memory Corruption",
        "Memory Corruption Detection"
      ],
      "matchedAuthors": [
        "Wuu Yang"
      ]
    },
    {
      "id": "openalex-w4390091805",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Discovering Malicious Signatures in Software from Structural Interactions",
      "authors": [
        {
          "name": "Chenzhong Yin",
          "affiliation": ""
        },
        {
          "name": "Hantang Zhang",
          "affiliation": ""
        },
        {
          "name": "Mingxi Cheng",
          "affiliation": ""
        },
        {
          "name": "Xiongye Xiao",
          "affiliation": ""
        },
        {
          "name": "Xinghe Chen",
          "affiliation": ""
        },
        {
          "name": "Xin Ren",
          "affiliation": ""
        },
        {
          "name": "Paul Bogdan",
          "affiliation": ""
        }
      ],
      "year": "2023",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Malware represents a significant security concern in today's digital landscape, as it can destroy or disable operating systems, steal sensitive user information, and occupy valuable disk space. However, current malware detection methods, such as static-based and dynamic-based approaches, struggle to identify newly developed (``zero-day\") malware and are limited by customized virtual machine (VM) environments. To overcome these limitations, we propose a novel malware detection approach that leverages deep learning, mathematical techniques, and network science. Our approach focuses on static and dynamic analysis and utilizes the Low-Level Virtual Machine (LLVM) to profile applications within a complex network. The generated network topologies are input into the GraphSAGE architecture to efficiently distinguish between benign and malicious software applications, with the operation names denoted as node features. Importantly, the GraphSAGE models analyze the network's topological geometry to make predictions, enabling them to detect state-of-the-art malware and prevent potential damage during execution in a VM. To evaluate our approach, we conduct a study on a dataset comprising source code from 24,376 applications, specifically written in C/C++, sourced directly from widely-recognized malware and various types of benign software. The results show a high detection performance with an Area Under the Receiver Operating Characteristic Curve (AUROC) of 99.85%. Our approach marks a substantial improvement in malware detection, providing a notably more accurate and efficient solution when compared to current state-of-the-art malware detection methods.",
      "paperUrl": "https://arxiv.org/pdf/2312.12667",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2312.12667",
      "tags": [
        "Security",
        "Performance",
        "Dynamic Analysis",
        "ML"
      ],
      "keywords": [
        "Security",
        "Performance",
        "Dynamic Analysis",
        "ML",
        "LLVM",
        "Malware Detection",
        "Network",
        "Art Malware",
        "Virtual Machine",
        "Discovering Malicious Signatures",
        "Structural Interactions"
      ],
      "matchedAuthors": [
        "Chenzhong Yin",
        "Hantang Zhang",
        "Mingxi Cheng",
        "Paul Bogdan",
        "Xin Ren",
        "Xinghe Chen",
        "Xiongye Xiao"
      ]
    },
    {
      "id": "openalex-w4393907451",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Detecting Potentially Clobbered Variables due to the Use of Nonlocal Jumps Functions",
      "authors": [
        {
          "name": "Nikita Yurievich Shugaley",
          "affiliation": "Institute for System Programming"
        },
        {
          "name": "Vladislav Ivanishin",
          "affiliation": ""
        },
        {
          "name": "A. Monakov",
          "affiliation": ""
        }
      ],
      "year": "2023",
      "publication": "Proceedings of the Institute for System Programming of RAS",
      "venue": "Proceedings of the Institute for System Programming of RAS | Vol. 35 (Issue 6)",
      "type": "research-paper",
      "abstract": "The reason of undefined behavior is source code written in violation of the C language standard. Undefined behavior leads to vulnerabilities in software. One of the common sources of undefined behavior is an incorrect use of functions for nonlocal jumps (in particular setjmp and longjmp). This paper considers the means of detecting this type of undefined behavior which are implemented in the major modern compilers (GCC, Clang, MSVC). We conclude that these means either have significant disadvantages or are absent in some compilers. This paper presents the implementation of a new method of compiler warning of the considered undefined behavior. The described method is accurate enough for practical application on real projects. We consider the advantages of the proposed solution over similar existing ones.",
      "paperUrl": "https://ispranproceedings.elpub.ru/jour/article/download/1736/1574",
      "sourceUrl": "https://doi.org/10.15514/ispras-2023-35(6)-7",
      "tags": [
        "Clang"
      ],
      "keywords": [
        "Clang",
        "Undefined Behavior",
        "Nonlocal Jumps",
        "Clobbered Variables Due",
        "Detecting Potentially Clobbered",
        "Potentially Clobbered Variables"
      ],
      "matchedAuthors": [
        "A. Monakov",
        "Vladislav Ivanishin"
      ]
    },
    {
      "id": "openalex-w4379536150",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "CryptOpt: Verified Compilation with Randomized Program Search for Cryptographic Primitives",
      "authors": [
        {
          "name": "Joel Kuepper",
          "affiliation": "University of Adelaide"
        },
        {
          "name": "Andres Erbsen",
          "affiliation": "Massachusetts Institute of Technology"
        },
        {
          "name": "Jason Gross",
          "affiliation": "Massachusetts Institute of Technology"
        },
        {
          "name": "Owen Conoly",
          "affiliation": "Massachusetts Institute of Technology"
        },
        {
          "name": "Chuyue Sun",
          "affiliation": "Stanford University"
        },
        {
          "name": "Samuel Tian",
          "affiliation": "Massachusetts Institute of Technology"
        },
        {
          "name": "David Wu",
          "affiliation": "University of Adelaide"
        },
        {
          "name": "Adam Chlipala",
          "affiliation": "Massachusetts Institute of Technology"
        },
        {
          "name": "Chitchanok Chuengsatiansup",
          "affiliation": "University of Melbourne"
        },
        {
          "name": "Daniel Genkin",
          "affiliation": "Georgia Institute of Technology"
        },
        {
          "name": "Markus Wagner",
          "affiliation": "Monash University"
        },
        {
          "name": "Yuval Yarom",
          "affiliation": "Ruhr University Bochum"
        }
      ],
      "year": "2023",
      "publication": "Proceedings of the ACM on Programming Languages",
      "venue": "Proceedings of the ACM on Programming Languages | Vol. 7 (Issue PLDI)",
      "type": "research-paper",
      "abstract": "Most software domains rely on compilers to translate high-level code to multiple different machine languages, with performance not too much worse than what developers would have the patience to write directly in assembly language. However, cryptography has been an exception, where many performance-critical routines have been written directly in assembly (sometimes through metaprogramming layers). Some past work has shown how to do formal verification of that assembly, and other work has shown how to generate C code automatically along with formal proof, but with consequent performance penalties vs. the best- known assembly. We present CryptOpt, the first compilation pipeline that specializes high-level cryptographic functional programs into assembly code significantly faster than what GCC or Clang produce, with mechanized proof (in Coq) whose final theorem statement mentions little beyond the input functional program and the operational semantics of x86-64 assembly. On the optimization side, we apply randomized search through the space of assembly programs, with repeated automatic benchmarking on target CPUs. On the formal-verification side, we connect to the Fiat Cryptography framework (which translates functional programs into C-like IR code) and extend it with a new formally verified program-equivalence checker, incorporating a modest subset of known features of SMT solvers and symbolic-execution engines. The overall prototype is quite practical, e.g. producing new fastest-known implementations of finite-field arithmetic for both Curve25519 (part of the TLS standard) and the Bitcoin elliptic curve secp256k1 for the Intel 12𝑡ℎ and 13𝑡ℎ generations.",
      "paperUrl": "https://dl.acm.org/doi/pdf/10.1145/3591272",
      "sourceUrl": "https://doi.org/10.1145/3591272",
      "tags": [
        "Performance",
        "Clang",
        "Optimizations",
        "IR",
        "Programming Languages"
      ],
      "keywords": [
        "Performance",
        "Clang",
        "Optimizations",
        "IR",
        "Programming Languages",
        "Formal Verification",
        "Functional Programs",
        "Cryptopt Verified Compilation",
        "Randomized Program Search",
        "Cryptographic Primitives"
      ],
      "matchedAuthors": [
        "Yuval Yarom"
      ]
    },
    {
      "id": "openalex-w4384163474",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "CrabSandwich: Fuzzing Rust with Rust (Registered Report)",
      "authors": [
        {
          "name": "Addison Crump",
          "affiliation": "Helmholtz Center for Information Security"
        },
        {
          "name": "Dongjia Zhang",
          "affiliation": "EURECOM"
        },
        {
          "name": "Syeda Mahnur Asif",
          "affiliation": "Helmholtz Center for Information Security"
        },
        {
          "name": "Dominik Maier",
          "affiliation": "Technische Universität Berlin"
        },
        {
          "name": "Andrea Fioraldi",
          "affiliation": "EURECOM"
        },
        {
          "name": "Thorsten Holz",
          "affiliation": "Helmholtz Center for Information Security"
        },
        {
          "name": "Davide Balzarotti",
          "affiliation": "EURECOM"
        }
      ],
      "year": "2023",
      "publication": "Figshare",
      "venue": "Figshare",
      "type": "research-paper",
      "abstract": "The rust programming language is one of the fastest-growing programming languages, thanks to its unique blend of high performance execution and memory safety. Still, programs implemented in rust can contain critical bugs. Apart from logic bugs and crashes, code in unsafe blocks can still trigger memory corruptions. To find these, the community uses traditional fuzzers like libfuzzer or aflpp, in combination with rust-specific macros. Of course, the fuzzers themselves are still written in memory-unsafe languages. In this paper, we explore the possibility of replacing the input generators with rust, while staying compatible to existing harnesses. Based on the rust fuzzer library libafl, we develop ourtool, a drop-in replacement for the C++ component of cargo-fuzz. We evaluate our tool, written in rust, against the original fuzzer libfuzzer. We show that we are not only able to successfully fuzz all three targets we tested with ourtool, but outperform cargo-fuzz in bug coverage. During our preliminary evaluation, we already manage to uncover new bugs in the pdf crate that could not be found by cargo-fuzz, proving the real-world applicability of our approach, and giving us high hopes for the planned follow-up evaluations.",
      "paperUrl": "https://figshare.com/articles/conference_contribution/CrabSandwich_Fuzzing_Rust_with_Rust_Registered_Report_/25534195",
      "sourceUrl": "https://doi.org/10.1145/3605157.3605176",
      "tags": [
        "Security",
        "Performance",
        "Programming Languages",
        "Testing",
        "Rust"
      ],
      "keywords": [
        "Security",
        "Performance",
        "Programming Languages",
        "Testing",
        "Rust",
        "Fuzzing",
        "Memory Safety",
        "Cargo Fuzz",
        "Crabsandwich Fuzzing Rust",
        "Rust Registered Report"
      ],
      "matchedAuthors": [
        "Addison Crump"
      ]
    },
    {
      "id": "openalex-w4367628301",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Compiler Auto-tuning through Multiple Phase Learning",
      "authors": [
        {
          "name": "Mingxuan Zhu",
          "affiliation": ""
        },
        {
          "name": "Dan Hao",
          "affiliation": ""
        },
        {
          "name": "Junjie Chen",
          "affiliation": ""
        }
      ],
      "year": "2023",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Widely used compilers like GCC and LLVM usually have hundreds of optimizations controlled by optimization flags, which are enabled or disabled during compilation to improve runtime performance (e.g., small execution time) of the compiler program. Due to the large number of optimization flags and their combination, it is difficult for compiler users to manually tune compiler optimization flags. In the literature, a number of auto-tuning techniques have been proposed, which tune optimization flags for a compiled program by comparing its actual runtime performance with different optimization flag combination. Due to the huge search space and heavy actual runtime cost, these techniques suffer from the widely-recognized efficiency problem. To reduce the heavy runtime cost, in this paper we propose a lightweight learning approach which uses a small number of actual runtime performance data to predict the runtime performance of a compiled program with various optimization flag combination. Furthermore, to reduce the search space, we design a novel particle swarm algorithm which tunes compiler optimization flags with the prediction model. To evaluate the performance of the proposed approach CompTuner, we conduct an extensive experimental study on two popular C compilers GCC and LLVM with two widely used benchmarks cBench and PolyBench. The experimental results show that CompTuner significantly outperforms the five compared techniques, including the state-of-art technique BOCA.",
      "paperUrl": "https://arxiv.org/pdf/2304.14908",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2304.14908",
      "tags": [
        "Performance",
        "Optimizations"
      ],
      "keywords": [
        "Performance",
        "Optimizations",
        "LLVM",
        "Compiler Optimization Flags",
        "Runtime Performance",
        "Actual Runtime Performance",
        "Optimization Flag Combination",
        "Compiler Auto Tuning",
        "Compiled Program",
        "Runtime Cost",
        "Search Space",
        "GCC",
        "Phase Learning"
      ],
      "matchedAuthors": [
        "Dan Hao",
        "Junjie Chen",
        "Mingxuan Zhu"
      ]
    },
    {
      "id": "openalex-w4317840213",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Building the LLVM and GCC Translation Systems, with Amake",
      "authors": [
        {
          "name": "Jim Buffenbarger",
          "affiliation": "Boise State University"
        }
      ],
      "year": "2023",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "This paper describes the author’s exploratory experience of porting the build systems of two large software distributions, the LLVM and GCC programming-language translation systems, to the Amake build tool. Amake is an enhanced derivative of the very popular GNU Make. Amake adds automatic language-independent dependency analysis and site-wide heterogeneous target caching. Amake also supports GNU Make’s parallel-build capabilities. This experience included (mostly) expected changes to both of these build systems, but somewhat surprising changes to Amake’s design and implementation. A description of the former changes is hoped to encourage developers to migrate their build systems to Amake. The latter changes showcase Amake’s most recently added features.",
      "paperUrl": "https://www.authorea.com/doi/pdf/10.22541/au.167458200.08021106",
      "sourceUrl": "https://doi.org/10.22541/au.167458200.08021106/v1",
      "tags": [],
      "keywords": [
        "LLVM",
        "Changes",
        "Gnu Make",
        "GCC"
      ],
      "matchedAuthors": [
        "Jim Buffenbarger"
      ]
    },
    {
      "id": "openalex-w4388214756",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Building a Reusable and Extensible Automatic Compiler Infrastructure for Reconfigurable Devices",
      "authors": [
        {
          "name": "Zhenya Zang",
          "affiliation": "Codeplay (United Kingdom)"
        },
        {
          "name": "Uwe Dolinsky",
          "affiliation": "Software (Spain)"
        },
        {
          "name": "Pietro Ghiglio",
          "affiliation": "Codeplay (United Kingdom)"
        },
        {
          "name": "Stefano Cherubin",
          "affiliation": "Edinburgh Napier University"
        },
        {
          "name": "Mehdi Goli",
          "affiliation": "Software (Spain)"
        },
        {
          "name": "Shufan Yang",
          "affiliation": "Edinburgh Napier University"
        }
      ],
      "year": "2023",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Multi-Level Intermediate Representation (MLIR) is gaining increasing attention in reconfigurable hardware communities due to its capability to represent various abstract levels for software compilers. This project aims to be the first to provide an end-to-end framework that leverages open-source, cross-platform compilation technology to generate MLIR from SYCL. Additionally, it aims to explore a lowering pipeline that converts MLIR to RTL using open-source hardware intermediate representation (IR) and compilers. Furthermore, it aims to couple the generated hardware module with the host CPU using vendor-specific crossbars. Our preliminary results demonstrated the feasibility of lowering customized MLIR to RTL, thus paving the way for an end-to-end compilation.",
      "paperUrl": "https://arxiv.org/pdf/2401.10249",
      "sourceUrl": "https://doi.org/10.1109/fpl60245.2023.00062",
      "tags": [
        "IR",
        "Infrastructure",
        "MLIR"
      ],
      "keywords": [
        "IR",
        "Infrastructure",
        "MLIR",
        "Intermediate Representation",
        "Hardware",
        "Compilation",
        "RTL",
        "Extensible Automatic Compiler",
        "Compiler Infrastructure",
        "Reconfigurable Devices"
      ],
      "matchedAuthors": [
        "Mehdi Goli",
        "Pietro Ghiglio",
        "Stefano Cherubin",
        "Uwe Dolinsky"
      ]
    },
    {
      "id": "openalex-w4386875305",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Btor2MLIR: A Format and Toolchain for Hardware Verification",
      "authors": [
        {
          "name": "Joseph Tafese",
          "affiliation": ""
        },
        {
          "name": "Isabel Garcia-Contreras",
          "affiliation": ""
        },
        {
          "name": "Arie Gurfinkel",
          "affiliation": ""
        }
      ],
      "year": "2023",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Formats for representing and manipulating verification problems are extremely important for supporting the ecosystem of tools, developers, and practitioners. A good format allows representing many different types of problems, has a strong toolchain for manipulating and translating problems, and can grow with the community. In the world of hardware verification, and, specifically, the Hardware Model Checking Competition (HWMCC), the Btor2 format has emerged as the dominating format. It is supported by Btor2Tools, verification tools, and Verilog design tools like Yosys. In this paper, we present an alternative format and toolchain, called Btor2MLIR, based on the recent MLIR framework. The advantage of Btor2MLIR is in reusing existing components from a mature compiler infrastructure, including parsers, text and binary formats, converters to a variety of intermediate representations, and executable semantics of LLVM. We hope that the format and our tooling will lead to rapid prototyping of verification and related tools for hardware verification.",
      "paperUrl": "https://arxiv.org/pdf/2309.09100",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2309.09100",
      "tags": [
        "IR",
        "Infrastructure",
        "MLIR"
      ],
      "keywords": [
        "IR",
        "Infrastructure",
        "MLIR",
        "LLVM",
        "Intermediate Representation",
        "Model Checking",
        "Format",
        "Hardware Verification",
        "Btor2mlir",
        "Toolchain"
      ],
      "matchedAuthors": [
        "Arie Gurfinkel",
        "Isabel Garcia-Contreras",
        "Joseph Tafese"
      ]
    },
    {
      "id": "openalex-w4321496220",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Bridging Control-Centric and Data-Centric Optimization",
      "authors": [
        {
          "name": "Tal Ben‐Nun",
          "affiliation": "ETH Zurich"
        },
        {
          "name": "Berke Ates",
          "affiliation": "ETH Zurich"
        },
        {
          "name": "Alexandru Calotoiu",
          "affiliation": "ETH Zurich"
        },
        {
          "name": "Torsten Hoefler",
          "affiliation": "ETH Zurich"
        }
      ],
      "year": "2023",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "With the rise of specialized hardware and new programming languages, code\\noptimization has shifted its focus towards promoting data locality. Most\\nproduction-grade compilers adopt a control-centric mindset - instruction-driven\\noptimization augmented with scalar-based dataflow - whereas other approaches\\nprovide domain-specific and general purpose data movement minimization, which\\ncan miss important control-flow optimizations. As the two representations are\\nnot commutable, users must choose one over the other. In this paper, we explore\\nhow both control- and data-centric approaches can work in tandem via the\\nMulti-Level Intermediate Representation (MLIR) framework. Through a combination\\nof an MLIR dialect and specialized passes, we recover parametric, symbolic\\ndataflow that can be optimized within the DaCe framework. We combine the two\\nviews into a single pipeline, called DCIR, showing that it is strictly more\\npowerful than either view. On several benchmarks and a real-world application\\nin C, we show that our proposed pipeline consistently outperforms MLIR and\\nautomatically uncovers new optimization opportunities with no additional\\neffort.\\n",
      "paperUrl": "https://arxiv.org/pdf/2306.00366",
      "sourceUrl": "https://doi.org/10.1145/3579990.3580018",
      "tags": [
        "Optimizations",
        "IR",
        "Programming Languages",
        "MLIR"
      ],
      "keywords": [
        "Optimizations",
        "IR",
        "Programming Languages",
        "MLIR",
        "Intermediate Representation",
        "Control",
        "Bridging Control Centric",
        "Noptimization",
        "Centric Optimization"
      ],
      "matchedAuthors": [
        "Alexandru Calotoiu",
        "Berke Ates",
        "Tal Ben‐Nun",
        "Torsten Hoefler"
      ]
    },
    {
      "id": "openalex-w4389912041",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Beyond Over-Protection: A Targeted Approach to Spectre Mitigation and Performance Optimization",
      "authors": [
        {
          "name": "Tiziano Marinaro",
          "affiliation": "Helmholtz Center for Information Security"
        },
        {
          "name": "Pablo Buiras",
          "affiliation": ""
        },
        {
          "name": "Andreas Lindner",
          "affiliation": ""
        },
        {
          "name": "Roberto Guanciale",
          "affiliation": ""
        },
        {
          "name": "Hamed Nemati",
          "affiliation": ""
        }
      ],
      "year": "2023",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Since the advent of Spectre attacks, researchers and practitioners have developed a range of hardware and software measures to counter transient execution attacks. A prime example of such mitigation is speculative load hardening in LLVM, which protects against leaks by tracking the speculation state and masking values during misspeculation. LLVM relies on static analysis to harden programs using slh that often results in over-protection, which incurs performance overhead. We extended an existing side-channel model validation framework, Scam-V, to check the vulnerability of programs to Spectre-PHT attacks and optimize the protection of programs using the slh approach. We illustrate the efficacy of Scam-V by first demonstrating that it can automatically identify Spectre vulnerabilities in real programs, e.g., fragments of crypto-libraries. We then develop an optimization mechanism that validates the necessity of slh hardening w.r.t. the target platform. Our experiments showed that hardening introduced by LLVM in most cases could be significantly improved when the underlying microarchitecture properties are considered.",
      "paperUrl": "https://arxiv.org/pdf/2312.09770",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2312.09770",
      "tags": [
        "Performance",
        "Optimizations",
        "Static Analysis",
        "Libraries"
      ],
      "keywords": [
        "Performance",
        "Optimizations",
        "Static Analysis",
        "Libraries",
        "LLVM",
        "Spectre Mitigation",
        "Protection",
        "Attacks",
        "Performance Optimization"
      ],
      "matchedAuthors": [
        "Andreas Lindner",
        "Hamed Nemati",
        "Pablo Buiras",
        "Roberto Guanciale",
        "Tiziano Marinaro"
      ]
    },
    {
      "id": "openalex-w4383699822",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Beetle: A Feature-Based Approach to Reduce Staleness in Profile Data",
      "authors": [
        {
          "name": "Fernando Magno Quintão Pereira",
          "affiliation": "Universidade Federal de Minas Gerais"
        },
        {
          "name": "Angélica Aparecida Moreira",
          "affiliation": "Universidade Federal de Minas Gerais"
        },
        {
          "name": "Guilherme Ottoni",
          "affiliation": "BC Platforms (Finland)"
        }
      ],
      "year": "2023",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "Profiling is one of the most effective enablers of compiler optimizations. Reports of speedups of 20-30% on top of highly optimized codes are common in the industry. Despite these gains, profiling is rarely used during development — rather, it is used during the generation of production-ready executables. Collecting profile information takes time, and reusing it across different versions of the same software leads to poor results, particularly for binary-level optimizations: small changes to the code might invalidate large portions of otherwise good data. This paper proposes a methodology to mitigate this problem. When mapping profile information from one program to a newer version of it, we use branch features, instead of addresses or hash of instructions, as anchor points between programs. Branch features have been used for decades as a way to predict the outcome of branches: they are characteristics of the branch, such as direction and opcode. By choosing good feature sets, it is possible to minimize collisions between branches, so that different branches seldom share the same features. We have modified the BOLT binary optimizer to use branch features to map profile information across programs. By optimizing three new versions of four large executables — Clang, GCC, MySQL, and PostgreSQL — we show that the new approach to reuse profile data yields speedups of about 8.00% over Clang -O3. In contrast, BOLT’s default mapping, which uses relative addresses as anchor points, yields speedups of 6.06%. Previous work based on hashing of basic blocks yields speedups of 5.02%.",
      "paperUrl": "https://www.authorea.com/doi/pdf/10.22541/au.168898868.83064146",
      "sourceUrl": "https://doi.org/10.22541/au.168898868.83064146/v1",
      "tags": [
        "Clang",
        "Optimizations"
      ],
      "keywords": [
        "Clang",
        "Optimizations",
        "Profile",
        "Yields Speedups",
        "Branches",
        "Anchor Points",
        "Use Branch",
        "Binary",
        "Reduce Staleness"
      ],
      "matchedAuthors": [
        "Fernando Magno Quintão Pereira",
        "Guilherme Ottoni"
      ]
    },
    {
      "id": "openalex-w4386554637",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Automatic multi-dimensional pipelining for high-level synthesis of dataflow accelerators",
      "authors": [
        {
          "name": "Kingshuk Majumder",
          "affiliation": ""
        },
        {
          "name": "Uday Bondhugula",
          "affiliation": ""
        }
      ],
      "year": "2023",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "In recent years, there has been a surging demand for edge computing of image processing and machine learning workloads. This has reignited interest in the development of custom hardware accelerators that can deliver enhanced performance and improved energy efficiency. These workloads frequently demonstrate affine memory accesses and constant loop bounds. In this paper, we introduce an ILP-based automatic scheduler for high-level synthesis, with a specific emphasis on aggressive pipelining to enhance parallelism. In this study, we propose a unified Integer Linear Programming (ILP) formulation that can identify pipelining opportunities along multiple loop and scalar dimensions. Our multi-dimensional pipelining technique encompasses both inner loop pipelining and dataflow optimizations of Vitis HLS, while also being capable of handling more general memory access patterns compared to the dataflow optimization in Vitis HLS. Furthermore, our approach enables the generation of statically scheduled circuits, leading to improved resource efficiency. We have integrated our scheduler into a high-level synthesis compiler framework (HIR) based on MLIR and conducted performance evaluations. Our findings reveal that our scheduler, in comparison to Vitis HLS, can achieve more aggressive pipelining across multiple producer-consumer loop nests, resulting in reduced overall execution latency. The producer-consumer pipelined execution facilitated by our scheduler yields an average performance improvement of 2.42X across a set of representative benchmarks when compared to only loop pipelining. Furthermore, we achieved an average performance improvement of 1.30X over Vitis HLS with dataflow optimizations.",
      "paperUrl": "https://arxiv.org/pdf/2309.03203",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2309.03203",
      "tags": [
        "Performance",
        "Optimizations",
        "ML",
        "MLIR"
      ],
      "keywords": [
        "Performance",
        "Optimizations",
        "ML",
        "MLIR",
        "Vitis HLS",
        "Dataflow Optimizations",
        "Average Performance Improvement",
        "Scheduler",
        "Multi Dimensional Pipelining",
        "Synthesis",
        "Aggressive Pipelining",
        "Loop Pipelining",
        "Producer Consumer",
        "Memory"
      ],
      "matchedAuthors": [
        "Uday Bondhugula"
      ]
    },
    {
      "id": "openalex-w4320891761",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "AutoScaleDSE: A Scalable Design Space Exploration Engine for High-Level Synthesis",
      "authors": [
        {
          "name": "Hyegang Jun",
          "affiliation": "University of Illinois Urbana-Champaign"
        },
        {
          "name": "Hanchen Ye",
          "affiliation": "University of Illinois Urbana-Champaign"
        },
        {
          "name": "Hyunmin Jeong",
          "affiliation": "University of Illinois Urbana-Champaign"
        },
        {
          "name": "Deming Chen",
          "affiliation": "University of Illinois Urbana-Champaign"
        }
      ],
      "year": "2023",
      "publication": "ACM Transactions on Reconfigurable Technology and Systems",
      "venue": "ACM Transactions on Reconfigurable Technology and Systems | Vol. 16 (Issue 3)",
      "type": "research-paper",
      "abstract": "High-Level Synthesis (HLS) has enabled users to rapidly develop designs targeted for FPGAs from the behavioral description of the design. However, to synthesize an optimal design capable of taking better advantage of the target FPGA, a considerable amount of effort is needed to transform the initial behavioral description into a form that can capture the desired level of parallelism. Thus, a design space exploration (DSE) engine capable of optimizing large complex designs is needed to achieve this goal. We present a new DSE engine capable of considering code transformation, compiler directives (pragmas), and the compatibility of these optimizations. To accomplish this, we initially express the structure of the input code as a graph to guide the exploration process. To appropriately transform the code, we take advantage of ScaleHLS based on the multi-level compiler infrastructure (MLIR). Finally, we identify problems that limit the scalability of existing DSEs, which we name the “design space merging problem.” We address this issue by employing a Random Forest classifier that can successfully decrease the number of invalid design points without invoking the HLS compiler as a validation tool. We evaluated our DSE engine against the ScaleHLS DSE, outperforming it by a maximum of 59×. We additionally demonstrate the scalability of our design by applying our DSE to large-scale HLS designs, achieving a maximum speedup of 12× for the benchmarks in the MachSuite and Rodinia set.",
      "paperUrl": "https://doi.org/10.1145/3572959",
      "sourceUrl": "",
      "tags": [
        "Optimizations",
        "Infrastructure",
        "MLIR"
      ],
      "keywords": [
        "Optimizations",
        "Infrastructure",
        "MLIR",
        "Dse Engine Capable",
        "Space Exploration Engine",
        "Designs",
        "HLS",
        "Behavioral Description",
        "Synthesis"
      ],
      "matchedAuthors": [
        "Deming Chen",
        "Hanchen Ye",
        "Hyunmin Jeong"
      ]
    },
    {
      "id": "openalex-w4387801634",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Advances in compilation for quantum hardware -- A demonstration of magic state distillation and repeat-until-success protocols",
      "authors": [
        {
          "name": "Natalie C. Brown",
          "affiliation": ""
        },
        {
          "name": "John Peter Campora",
          "affiliation": ""
        },
        {
          "name": "Cassandra Granade",
          "affiliation": ""
        },
        {
          "name": "Bettina Heim",
          "affiliation": ""
        },
        {
          "name": "Stefan Wernli",
          "affiliation": ""
        },
        {
          "name": "Ciarán Ryan-Anderson",
          "affiliation": ""
        },
        {
          "name": "Dominic Lucchetti",
          "affiliation": ""
        },
        {
          "name": "Adam Paetznick",
          "affiliation": ""
        },
        {
          "name": "Martin Roetteler",
          "affiliation": ""
        },
        {
          "name": "Krysta M. Svore",
          "affiliation": ""
        },
        {
          "name": "Alex Chernoguzov",
          "affiliation": ""
        }
      ],
      "year": "2023",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Fault-tolerant protocols enable large and precise quantum algorithms. Many such protocols rely on a feed-forward processing of data, enabled by a hybrid of quantum and classical logic. Representing the control structure of such programs can be a challenge. Here we explore two such fault-tolerant subroutines and analyze the performance of the subroutines using Quantum Intermediate Representation (QIR) as their underlying intermediate representation. First, we look at QIR's ability to leverage the LLVM compiler toolchain to unroll the quantum iteration logic required to perform magic state distillation on the $[[5,1,3]]$ quantum error-correcting code as originally introduced by Bravyi and Kitaev [Phys. Rev. A 71, 022316 (2005)]. This allows us to not only realize the first implementation of a real-time magic state distillation protocol on quantum hardware, but also demonstrate QIR's ability to optimize complex program structures without degrading machine performance. Next, we investigate a different fault-tolerant protocol that was first introduced by Paetznick and Svore [arXiv:1311.1074 (2013)], that reduces the amount of non-Clifford gates needed for a particular algorithm. We look at four different implementations of this two-stage repeat-until-success algorithm to analyze the performance changes as the results of programming choices. We find the QIR offers a viable representation for a compiled high-level program that performs nearly as well as a hand-optimized version written directly in quantum assembly. Both of these results demonstrate QIR's ability to accurately and efficiently expand the complexity of fault-tolerant protocols that can be realized today on quantum hardware.",
      "paperUrl": "https://arxiv.org/pdf/2310.12106",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2310.12106",
      "tags": [
        "Performance",
        "IR",
        "Infrastructure"
      ],
      "keywords": [
        "Performance",
        "IR",
        "Infrastructure",
        "LLVM",
        "Intermediate Representation",
        "Quantum Hardware",
        "Fault Tolerant",
        "Magic State Distillation",
        "Fault Tolerant Protocols",
        "Repeat Until Success",
        "Ability",
        "Demonstrate Qir",
        "Until Success Protocols",
        "Compilation"
      ],
      "matchedAuthors": [
        "Martin Roetteler"
      ]
    },
    {
      "id": "openalex-w4386282770",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Accelerating Halide framework by automatic Affine scheduling using the stochastic optimization algorithm on MLIR",
      "authors": [
        {
          "name": "Xiangyu Wang",
          "affiliation": "National Taiwan University"
        },
        {
          "name": "Jian-Yu Shen",
          "affiliation": "National Taiwan University"
        },
        {
          "name": "Shih-Wei Liao",
          "affiliation": "National Taiwan University"
        }
      ],
      "year": "2023",
      "publication": "Research Square (Research Square)",
      "venue": "Research Square (Research Square)",
      "type": "research-paper",
      "abstract": "Abstract The increasing usage of computer vision algorithms in camera-centric devices has led to a growing need for optimizing these algorithms to improve their performance on resource-constrained platforms. Halide is a language specific to image processing algorithms that separates the algorithm's scheduling from its implementation, resulting in high performance. This thesis proposes an approach to improve the performance of Halide computer vision algorithms using stochastic algorithms such as simulated annealing to optimize scheduling, which enables exploring the global optimum of affine scheduling in constrained time. To convert the Halide program to MLIR, we use novel compile flows, namely the Halide to MLIR (HTM) converter. The efficacy of the approach will be evaluated on different platforms, such as x86, ARM, and RISC-V. The study demonstrates the potential of MLIR's transformation and optimization capabilities on Affine dialects and highlights the need for tuning infrastructure to fully leverage MLIR's optimization capabilities.",
      "paperUrl": "https://www.researchsquare.com/article/rs-3274775/latest.pdf",
      "sourceUrl": "https://doi.org/10.21203/rs.3.rs-3274775/v1",
      "tags": [
        "Performance",
        "Optimizations",
        "Infrastructure",
        "MLIR"
      ],
      "keywords": [
        "Performance",
        "Optimizations",
        "Infrastructure",
        "MLIR",
        "Accelerating Halide",
        "Affine Scheduling",
        "Optimization Capabilities",
        "Computer Vision",
        "Stochastic Optimization"
      ],
      "matchedAuthors": [
        "Jian-Yu Shen",
        "Shih-Wei Liao"
      ]
    },
    {
      "id": "openalex-w4385770868",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "A static analysis approach for modern iterator development",
      "authors": [
        {
          "name": "Dániel Kolozsvári",
          "affiliation": "Eötvös Loránd University"
        },
        {
          "name": "Norbert Pataki",
          "affiliation": "University of Veterinary Medicine"
        }
      ],
      "year": "2023",
      "publication": "Az Eszterházy Károly Tanárképző Főiskola tudományos közleményei. Tanulmányok a matematikai tudományok köréből/Az Eszterházy Károly Főiskola tudományos közleményei. Tanulmányok a matematikai tudományok köréből/Annales mathematicae et informaticae",
      "venue": "Az Eszterházy Károly Tanárképző Főiskola tudományos közleményei. Tanulmányok a matematikai tudományok köréből/Az Eszterházy Károly Főiskola tudományos közleményei. Tanulmányok a matematikai tudományok köréből/Annales mathematicae et informaticae | Vol. Accepted manuscript",
      "type": "research-paper",
      "abstract": "Programming languages evolve in the long term, new standards are specified in which new constructs appear, old elements may become deprecated.Standard library of programming languages also changes time by time.The standard of the C++ programming language defines the elements of the C++ Standard Template Library (STL) that provides containers, algorithms, and iterators.According to the STL's generic programming approach, these sets can be extended in a convenient way.The std::iterator class template had been in the C++ since beginning and has been deprecated in the C++17 standard.This class template's purpose was to specify the traits of an iterator.Typically, it was a base class of many standard and nonstandard iterator class to provide the necessary traits.However, the usage of iterator is straightforward and fits into the object-oriented programming paradigm.Many non-standard containers offer custom iterators because of the STL compatibility.Using this base class does not cause any weird effect, therefore usage of iterator can be found in code legacy.In this paper, we present a static analysis approach to assist the development of iterator classes in a modern way in which the iterator class template is not taken advantage of.We utilize the Clang compiler infrastructure to look for how the deprecated iterator classes can be found in legacy code and present an approach how to modernize them.",
      "paperUrl": "http://publikacio.uni-eszterhazy.hu/7703/1/AMI_online_1387.pdf",
      "sourceUrl": "https://doi.org/10.33039/ami.2023.08.006",
      "tags": [
        "Clang",
        "Static Analysis",
        "Programming Languages",
        "Infrastructure"
      ],
      "keywords": [
        "Clang",
        "Static Analysis",
        "Programming Languages",
        "Infrastructure",
        "Iterator Classes",
        "Standard",
        "Iterator Class Template",
        "Base Class"
      ],
      "matchedAuthors": [
        "Norbert Pataki"
      ]
    },
    {
      "id": "openalex-w4388964727",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "A Survey on Multimodal Large Language Models for Autonomous Driving",
      "authors": [
        {
          "name": "Can Cui",
          "affiliation": ""
        },
        {
          "name": "Yunsheng Ma",
          "affiliation": ""
        },
        {
          "name": "Xu Cao",
          "affiliation": ""
        },
        {
          "name": "Wenqian Ye",
          "affiliation": ""
        },
        {
          "name": "Yang Zhou",
          "affiliation": ""
        },
        {
          "name": "Kaizhao Liang",
          "affiliation": ""
        },
        {
          "name": "Jintai Chen",
          "affiliation": ""
        },
        {
          "name": "Juanwu Lu",
          "affiliation": ""
        },
        {
          "name": "Zichong Yang",
          "affiliation": ""
        },
        {
          "name": "Kuei-Da Liao",
          "affiliation": ""
        },
        {
          "name": "Tianren Gao",
          "affiliation": ""
        },
        {
          "name": "Erlong Li",
          "affiliation": ""
        },
        {
          "name": "Tang Kun",
          "affiliation": ""
        },
        {
          "name": "Zhipeng Cao",
          "affiliation": ""
        },
        {
          "name": "Tong Zhou",
          "affiliation": ""
        },
        {
          "name": "Ao Liu",
          "affiliation": ""
        },
        {
          "name": "Xinrui Yan",
          "affiliation": ""
        },
        {
          "name": "Shuqi Mei",
          "affiliation": ""
        },
        {
          "name": "Jianguo Cao",
          "affiliation": ""
        },
        {
          "name": "Ziran Wang",
          "affiliation": ""
        },
        {
          "name": "Chao Zheng",
          "affiliation": ""
        }
      ],
      "year": "2023",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "With the emergence of Large Language Models (LLMs) and Vision Foundation Models (VFMs), multimodal AI systems benefiting from large models have the potential to equally perceive the real world, make decisions, and control tools as humans. In recent months, LLMs have shown widespread attention in autonomous driving and map systems. Despite its immense potential, there is still a lack of a comprehensive understanding of key challenges, opportunities, and future endeavors to apply in LLM driving systems. In this paper, we present a systematic investigation in this field. We first introduce the background of Multimodal Large Language Models (MLLMs), the multimodal models development using LLMs, and the history of autonomous driving. Then, we overview existing MLLM tools for driving, transportation, and map systems together with existing datasets and benchmarks. Moreover, we summarized the works in The 1st WACV Workshop on Large Language and Vision Models for Autonomous Driving (LLVM-AD), which is the first workshop of its kind regarding LLMs in autonomous driving. To further promote the development of this field, we also discuss several important problems regarding using MLLMs in autonomous driving systems that need to be solved by both academia and industry.",
      "paperUrl": "https://arxiv.org/pdf/2311.12320",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2311.12320",
      "tags": [
        "AI"
      ],
      "keywords": [
        "AI",
        "LLVM",
        "Autonomous Driving",
        "Multimodal"
      ],
      "matchedAuthors": [
        "Ao Liu",
        "Can Cui",
        "Chao Zheng",
        "Erlong Li",
        "Jianguo Cao",
        "Jintai Chen",
        "Juanwu Lu",
        "Kaizhao Liang",
        "Kuei-Da Liao",
        "Shuqi Mei",
        "Tang Kun",
        "Tianren Gao",
        "Tong Zhou",
        "Wenqian Ye",
        "Xinrui Yan",
        "Xu Cao",
        "Yang Zhou",
        "Yunsheng Ma",
        "Zhipeng Cao",
        "Zichong Yang",
        "Ziran Wang"
      ]
    },
    {
      "id": "openalex-w4380679912",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "A Survey of Modern Compiler Fuzzing",
      "authors": [
        {
          "name": "Haoyang Ma",
          "affiliation": ""
        }
      ],
      "year": "2023",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Most software that runs on computers undergoes processing by compilers. Since compilers constitute the fundamental infrastructure of software development, their correctness is paramount. Over the years, researchers have invested in analyzing, understanding, and characterizing the bug features over mainstream compilers. These studies have demonstrated that compilers correctness requires greater research attention, and they also pave the way for compiler fuzzing. To improve compilers correctness, researchers have proposed numerous compiler fuzzing techniques. These techniques were initially developed for testing traditional compilers such as GCC/LLVM and have since been generalized to test various newly developed, domain-specific compilers, such as graphics shader compilers and deep learning (DL) compilers. In this survey, we provide a comprehensive summary of the research efforts for understanding and addressing compilers defects. Specifically, this survey mainly covers two aspects. First, it covers researchers investigation and expertise on compilers bugs, such as their symptoms and root causes. The compiler bug studies cover GCC/LLVM, JVM compilers, and DL compilers. In addition, it covers researchers efforts in designing fuzzing techniques, including constructing test programs and designing test oracles. Besides discussing the existing work, this survey outlines several open challenges and highlights research opportunities.",
      "paperUrl": "https://arxiv.org/pdf/2306.06884",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2306.06884",
      "tags": [
        "Testing",
        "Infrastructure",
        "ML"
      ],
      "keywords": [
        "Testing",
        "Infrastructure",
        "ML",
        "LLVM",
        "Fuzzing",
        "Compiler Fuzzing",
        "Survey",
        "Researchers",
        "Compilers Correctness",
        "Covers Researchers",
        "GCC LLVM"
      ],
      "matchedAuthors": [
        "Haoyang Ma"
      ]
    },
    {
      "id": "openalex-w4396234760",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "A Memory Object Sensitive Detecting Method for Use-After-Free Vulnerabilities",
      "authors": [
        {
          "name": "Runhao Li",
          "affiliation": "National University of Defense Technology"
        },
        {
          "name": "Xiaolei Wang",
          "affiliation": "National University of Defense Technology"
        },
        {
          "name": "Bin Zhang",
          "affiliation": "National University of Defense Technology"
        },
        {
          "name": "Chaojing Tang",
          "affiliation": "National University of Defense Technology"
        }
      ],
      "year": "2023",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "The Use-After-Free vulnerability has drawn significant concern recently due to its widespread occurrence and harmful impact on applications, and detecting Use-After-Free and Double Free bugs is a critical challenge in software security. Current detection methods such as AddressSanitizer fail to detect Use-After-Free bugs caused by memory object reoccupation. In this paper, we propose a memory object sensitive detecting method for Use-After-Free vulnerabilities to handle the reoccupation problem. We firstly track the lifetime of memory object through runtime library, and then we construct a novel shadow memory to retain essential diagnosing data. To detect bugs, we label the pointer to the memory object and track the propagation process. Based on that, we implement a tool MOSan. Our experiments on CWE benchmark shows that MOSan could detect all Use-After-Free and Double Free bugs without any false negative, significantly surpassing the effectiveness of Asan.",
      "paperUrl": "https://doi.org/10.1109/aihcir61661.2023.00096",
      "sourceUrl": "",
      "tags": [
        "Security",
        "Testing"
      ],
      "keywords": [
        "Security",
        "Testing",
        "Sanitizers",
        "Memory Object Sensitive",
        "Double Free Bugs",
        "Object Sensitive Detecting",
        "Free Vulnerabilities"
      ],
      "matchedAuthors": [
        "Bin Zhang",
        "Chaojing Tang",
        "Xiaolei Wang"
      ]
    },
    {
      "id": "openalex-w4382049349",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "A LLVM JIT Prototype for Running an Energy-Saving Hardware-Aware Mapping Algorithm on C/C++ Applications that use Pthreads",
      "authors": [
        {
          "name": "Iulia Știrb",
          "affiliation": "Babeș-Bolyai University"
        },
        {
          "name": "Gilbert-Rainer Gillich",
          "affiliation": "Babeș-Bolyai University"
        }
      ],
      "year": "2023",
      "publication": "Preprints.org",
      "venue": "Preprints.org",
      "type": "research-paper",
      "abstract": "Low-Level Virtual Machine (LLVM) compiler infrastructure is a useful tool for building Just-in-time (JIT) compilers, besides its reliable front-end represented by clang compiler and its elaborated middle-end containing different optimizations that improve the runtime performance. This paper addresses specifically the part of building a JIT compiler using LLVM with the scope of getting the hardware architecture details of the underlying machine such as the number of cores and the number of logical cores per processing unit and providing them to NUMA-BTLP static thread classification algorithm and to NUMA-BTDM static thread mapping algorithm. Afterwards, the hardware-aware algorithms are run by the JIT compiler within an optimization pass. JIT compiler in this paper is designed to run on a parallel C/C++ application (which creates threads using Pthreads), before the first time the application is executed on a machine. To do that, the JIT compiler takes the native code of the application, gets the corresponding LLVM IR (Intermediate Representation) for the native code and executes the hardware-aware thread classification and the thread mapping algorithms on the IR. The NUMA-Balanced Task and Loop Parallelism (NUMA-BTLP) and NUMA-Balanced Thread and Data Mapping (NUMA-BTDM) are expected to optimize the energy consumption up to 15%, on NUMA systems.",
      "paperUrl": "https://www.preprints.org/manuscript/202306.1834/v1/download",
      "sourceUrl": "https://doi.org/10.20944/preprints202306.1834.v1",
      "tags": [
        "JIT",
        "Performance",
        "Clang",
        "Optimizations",
        "IR",
        "Infrastructure"
      ],
      "keywords": [
        "JIT",
        "Performance",
        "Clang",
        "Optimizations",
        "IR",
        "Infrastructure",
        "LLVM",
        "JIT Compilation",
        "Intermediate Representation",
        "JIT Compiler",
        "Thread Classification",
        "Hardware Aware Mapping",
        "LLVM JIT Prototype",
        "Numa Balanced"
      ],
      "matchedAuthors": [
        "Gilbert-Rainer Gillich",
        "Iulia Știrb"
      ]
    },
    {
      "id": "openalex-w4282970171",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "uiCA",
      "authors": [
        {
          "name": "Andreas Abel",
          "affiliation": "Saarland University"
        },
        {
          "name": "Jan Reineke",
          "affiliation": "Saarland University"
        }
      ],
      "year": "2022",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Performance models that statically predict the steady-state throughput of\\nbasic blocks on particular microarchitectures, such as IACA, Ithemal, llvm-mca,\\nOSACA, or CQA, can guide optimizing compilers and aid manual software\\noptimization. However, their utility heavily depends on the accuracy of their\\npredictions. The average error of existing models compared to measurements on\\nthe actual hardware has been shown to lie between 9% and 36%. But how good is\\nthis? To answer this question, we propose an extremely simple analytical\\nthroughput model that may serve as a baseline. Surprisingly, this model is\\nalready competitive with the state of the art, indicating that there is\\nsignificant potential for improvement.\\n To explore this potential, we develop a simulation-based throughput\\npredictor. To this end, we propose a detailed parametric pipeline model that\\nsupports all Intel Core microarchitecture generations released between 2011 and\\n2021. We evaluate our predictor on an improved version of the BHive benchmark\\nsuite and show that its predictions are usually within 1% of measurement\\nresults, improving upon prior models by roughly an order of magnitude. The\\nexperimental evaluation also demonstrates that several microarchitectural\\ndetails considered to be rather insignificant in previous work, are in fact\\nessential for accurate prediction.\\n Our throughput predictor is available as open source at\\nhttps://github.com/andreas-abel/uiCA.\\n",
      "paperUrl": "https://dl.acm.org/doi/pdf/10.1145/3524059.3532396",
      "sourceUrl": "https://doi.org/10.1145/3524059.3532396",
      "tags": [
        "Performance"
      ],
      "keywords": [
        "Performance",
        "LLVM",
        "Throughput"
      ],
      "matchedAuthors": [
        "Andreas Abel",
        "Jan Reineke"
      ]
    },
    {
      "id": "openalex-w4309396470",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Where Did My Variable Go? Poking Holes in Incomplete Debug Information",
      "authors": [
        {
          "name": "Cristian Assaiante",
          "affiliation": ""
        },
        {
          "name": "Daniele Cono D’Elia",
          "affiliation": ""
        },
        {
          "name": "Giuseppe Antonio Di Luna",
          "affiliation": ""
        },
        {
          "name": "Leonardo Querzoni",
          "affiliation": ""
        }
      ],
      "year": "2022",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "The availability of debug information for optimized executables can largely ease crucial tasks such as crash analysis. Source-level debuggers use this information to display program state in terms of source code, allowing users to reason on it even when optimizations alter program structure extensively. A few recent endeavors have proposed effective methodologies for identifying incorrect instances of debug information, which can mislead users by presenting them with an inconsistent program state. In this work, we identify and study a related important problem: the completeness of debug information. Unlike correctness issues for which an unoptimized executable can serve as reference, we find there is no analogous oracle to deem when the cause behind an unreported part of program state is an unavoidable effect of optimization or a compiler implementation defect. In this scenario, we argue that empirically derived conjectures on the expected availability of debug information can serve as an effective means to expose classes of these defects. We propose three conjectures involving variable values and study how often synthetic programs compiled with different configurations of the popular gcc and LLVM compilers deviate from them. We then discuss techniques to pinpoint the optimizations behind such violations and minimize bug reports accordingly. Our experiments revealed, among others, 24 bugs already confirmed by the developers of the gcc-gdb and clang-lldb ecosystems.",
      "paperUrl": "https://arxiv.org/pdf/2211.09568",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2211.09568",
      "tags": [
        "Clang",
        "Optimizations",
        "LLDB",
        "Debug Information"
      ],
      "keywords": [
        "Clang",
        "Optimizations",
        "LLDB",
        "Debug Information",
        "LLVM",
        "Program State",
        "GCC",
        "Incomplete Debug",
        "Poking Holes"
      ],
      "matchedAuthors": [
        "Cristian Assaiante",
        "Daniele Cono D’Elia",
        "Giuseppe Antonio Di Luna",
        "Leonardo Querzoni"
      ]
    },
    {
      "id": "openalex-w4310283529",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Unified Language Frontend for Physic-Informed AI/ML",
      "authors": [
        {
          "name": "Brian Kelley",
          "affiliation": "Sandia National Laboratories California"
        },
        {
          "name": "Sivasankaran Rajamanickam",
          "affiliation": "Sandia National Laboratories California"
        }
      ],
      "year": "2022",
      "publication": "OSTI OAI (U.S. Department of Energy Office of Scientific and Technical Information)",
      "venue": "OSTI OAI (U.S. Department of Energy Office of Scientific and Technical Information)",
      "type": "research-paper",
      "abstract": "Artificial intelligence and machine learning (AI/ML) are becoming important tools for scientific modeling and simulation as in several other fields such as image analysis and natural language processing. ML techniques can leverage the computing power available in modern systems and reduce the human effort needed to configure experiments, interpret and visualize results, draw conclusions from huge quantities of raw data, and build surrogates for physics based models. Domain scientists in fields like fluid dynamics, microelectronics and chemistry can automate many of their most difficult and repetitive tasks or improve the design times by use of the faster ML-surrogates. However, modern ML and traditional scientific highperformance computing (HPC) tend to use completely different software ecosystems. While ML frameworks like PyTorch and TensorFlow provide Python APIs, most HPC applications and libraries are written in C++. Direct interoperability between the two languages is possible but is tedious and error-prone. In this work, we show that a compiler-based approach can bridge the gap between ML frameworks and scientific software with less developer effort and better efficiency. We use the MLIR (multi-level intermediate representation) ecosystem to compile a pre-trained convolutional neural network (CNN) in PyTorch to freestanding C++ source code in the Kokkos programming model. Kokkos is a programming model widely used in HPC to write portable, shared-memory parallel code that can natively target a variety of CPU and GPU architectures. Our compiler-generated source code can be directly integrated into any Kokkosbased application with no dependencies on Python or cross-language interfaces.",
      "paperUrl": "https://www.osti.gov/servlets/purl/1888879",
      "sourceUrl": "https://doi.org/10.2172/1888879",
      "tags": [
        "Frontend",
        "GPU",
        "IR",
        "AI",
        "ML",
        "Libraries",
        "MLIR"
      ],
      "keywords": [
        "Frontend",
        "GPU",
        "IR",
        "AI",
        "ML",
        "Libraries",
        "MLIR",
        "Intermediate Representation",
        "ML Frameworks",
        "HPC",
        "Scientific",
        "Unified Language Frontend",
        "Physic Informed"
      ],
      "matchedAuthors": [
        "Sivasankaran Rajamanickam"
      ]
    },
    {
      "id": "openalex-w4296932886",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "UPIR: Toward the Design of Unified Parallel Intermediate Representation for Parallel Programming Models",
      "authors": [
        {
          "name": "Anjia Wang",
          "affiliation": ""
        },
        {
          "name": "Xinyao Yi",
          "affiliation": ""
        },
        {
          "name": "Yonghong Yan",
          "affiliation": ""
        }
      ],
      "year": "2022",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "The complexity of heterogeneous computing architectures, as well as the demand for productive and portable parallel application development, have driven the evolution of parallel programming models to become more comprehensive and complex than before. Enhancing the conventional compilation technologies and software infrastructure to be parallelism-aware has become one of the main goals of recent compiler development. In this paper, we propose the design of unified parallel intermediate representation (UPIR) for multiple parallel programming models and for enabling unified compiler transformation for the models. UPIR specifies three commonly used parallelism patterns (SPMD, data and task parallelism), data attributes and explicit data movement and memory management, and synchronization operations used in parallel programming. We demonstrate UPIR via a prototype implementation in the ROSE compiler for unifying IR for both OpenMP and OpenACC and in both C/C++ and Fortran, for unifying the transformation that lowers both OpenMP and OpenACC code to LLVM runtime, and for exporting UPIR to LLVM MLIR dialect.",
      "paperUrl": "https://arxiv.org/pdf/2209.10643",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2209.10643",
      "tags": [
        "IR",
        "Infrastructure",
        "MLIR"
      ],
      "keywords": [
        "IR",
        "Infrastructure",
        "MLIR",
        "LLVM",
        "Intermediate Representation",
        "Parallel Computing",
        "Heterogeneous Computing",
        "Parallel Programming",
        "Parallel Intermediate Representation",
        "Unified Parallel Intermediate",
        "Parallelism",
        "OpenMP"
      ],
      "matchedAuthors": [
        "Anjia Wang",
        "Xinyao Yi",
        "Yonghong Yan"
      ]
    },
    {
      "id": "openalex-w4308085182",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Treebeard: An Optimizing Compiler for Decision Tree Based ML Inference",
      "authors": [
        {
          "name": "Ashwin Prasad",
          "affiliation": "Texas Instruments (India)"
        },
        {
          "name": "Sampath Rajendra",
          "affiliation": "Microsoft Research (India)"
        },
        {
          "name": "Kaushik Sunder Rajan",
          "affiliation": "Microsoft Research (India)"
        },
        {
          "name": "R. Govindarajan",
          "affiliation": "Indian Institute of Science Bangalore"
        },
        {
          "name": "Uday Bondhugula",
          "affiliation": "Indian Institute of Science Bangalore"
        }
      ],
      "year": "2022",
      "publication": "",
      "venue": "Vol. abs/1811.09886",
      "type": "research-paper",
      "abstract": "Decision tree ensembles are among the most commonly used machine learning models. These models are used in a wide range of applications and are deployed at scale. Decision tree ensemble inference is usually performed with libraries such as XGBoost, LightGBM, and Sklearn. These libraries incorporate a fixed set of optimizations for the hardware targets they support. However, maintaining these optimizations is prohibitively expensive with the evolution of hardware. Further, they do not specialize the inference code to the model being used, leaving significant performance on the table. This paper presents TREEBEARD, an optimizing compiler that progressively lowers the inference computation to optimized CPU code through multiple intermediate abstractions. By applying model-specific optimizations at the higher levels, tree walk optimizations at the middle level, and machine-specific optimizations lower down, TREEBEARD can specialize inference code for each model on each supported CPU target. TREEBEARD combines several novel optimizations at various abstraction levels to mitigate architectural bottlenecks and enable SIMD vectorization of tree walks. We implement TREEBEARD using the MLIR compiler infrastructure and demonstrate its utility by evaluating it on a diverse set of benchmarks. TREEBEARD is significantly faster than state-of-the-art systems, XGBoost, Treelite and Hummingbird, by 2.6×, 4.7× and 5.4× respectively in a single-core execution setting, and by 2.3×, 2.7× and 14× respectively in multi-core settings.",
      "paperUrl": "https://doi.org/10.1109/micro56248.2022.00043",
      "sourceUrl": "",
      "tags": [
        "Performance",
        "Optimizations",
        "Autovectorization",
        "Infrastructure",
        "ML",
        "Libraries",
        "MLIR"
      ],
      "keywords": [
        "Performance",
        "Optimizations",
        "Autovectorization",
        "Infrastructure",
        "ML",
        "Libraries",
        "MLIR",
        "SIMD",
        "Treebeard",
        "Specific Optimizations",
        "ML Inference",
        "Decision Tree",
        "Optimizing Compiler",
        "CPU"
      ],
      "matchedAuthors": [
        "Uday Bondhugula"
      ]
    },
    {
      "id": "openalex-w4221165501",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "The unexplored treasure trove of phabricator code reviews",
      "authors": [
        {
          "name": "Gunnar Kudrjavets",
          "affiliation": "University of Groningen"
        },
        {
          "name": "Nachiappan Nagappan",
          "affiliation": "Microsoft Research (United Kingdom)"
        },
        {
          "name": "Ayushi Rastogi",
          "affiliation": "University of Groningen"
        }
      ],
      "year": "2022",
      "publication": "University of Groningen research database (University of Groningen / Centre for Information Technology)",
      "venue": "University of Groningen research database (University of Groningen / Centre for Information Technology)",
      "type": "research-paper",
      "abstract": "Phabricator is a modern code collaboration tool used by popular projects like FreeBSD and Mozilla. However, unlike the other well-known code review environments, such as Gerrit or GitHub, there is no readily accessible public code review dataset for Phabricator. This paper describes our experience mining code reviews from five different projects that use Phabricator (Blender, FreeBSD, KDE, LLVM, and Mozilla). We discuss the challenges associated with the data retrieval process and our solutions, resulting in a dataset with details regarding 317,476 Phabricator code reviews. Our dataset is available in both JSON and MySQL database dump formats. The dataset enables analyses of the history of code reviews at a more granular level than other platforms. In addition, given that the projects we mined are publicly accessible via the Conduit API, our dataset can be used as a foundation to fetch additional details and insights.",
      "paperUrl": "https://dl.acm.org/doi/pdf/10.1145/3524842.3528005",
      "sourceUrl": "https://doi.org/10.1145/3524842.3528005",
      "tags": [],
      "keywords": [
        "LLVM",
        "Phabricator",
        "Dataset",
        "Reviews",
        "Projects",
        "Unexplored Treasure Trove"
      ],
      "matchedAuthors": [
        "Ayushi Rastogi",
        "Gunnar Kudrjavets",
        "Nachiappan Nagappan"
      ]
    },
    {
      "id": "openalex-w4226256967",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "The Unexplored Treasure Trove of Phabricator Code Review",
      "authors": [
        {
          "name": "Gunnar Kudrjavets",
          "affiliation": "University of Groningen"
        },
        {
          "name": "Nachiappan Nagappan",
          "affiliation": "Microsoft Research (United Kingdom)"
        },
        {
          "name": "Ayushi Rastogi",
          "affiliation": "University of Groningen"
        }
      ],
      "year": "2022",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Phabricator is a modern code collaboration tool used by popular projects like FreeBSD and Mozilla. However, unlike the other well-known code review environments, such as Gerrit or GitHub, there is no readily accessible public code review dataset for Phabricator. This paper describes our experience mining code reviews from five different projects that use Phabricator (Blender, FreeBSD, KDE, LLVM, and Mozilla). We discuss the challenges associated with the data retrieval process and our solutions, resulting in a dataset with details regarding 317,476 Phabricator code reviews. Our dataset is available in both JSON and MySQL database dump formats. The dataset enables analyses of the history of code reviews at a more granular level than other platforms. In addition, given that the projects we mined are publicly accessible via the Conduit API, our dataset can be used as a foundation to fetch additional details and insights.",
      "paperUrl": "https://doi.org/10.48550/arxiv.2203.07473",
      "sourceUrl": "",
      "tags": [],
      "keywords": [
        "LLVM",
        "Phabricator",
        "Dataset",
        "Reviews",
        "Projects",
        "Unexplored Treasure Trove"
      ],
      "matchedAuthors": [
        "Ayushi Rastogi",
        "Gunnar Kudrjavets",
        "Nachiappan Nagappan"
      ]
    },
    {
      "id": "openalex-w4293024964",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "The SODA approach",
      "authors": [
        {
          "name": "Nícolas Bohm Agostini",
          "affiliation": "Pacific Northwest National Laboratory"
        },
        {
          "name": "Serena Curzel",
          "affiliation": "Pacific Northwest National Laboratory"
        },
        {
          "name": "Ankur Limaye",
          "affiliation": "Pacific Northwest National Laboratory"
        },
        {
          "name": "Vinay Amatya",
          "affiliation": "Pacific Northwest National Laboratory"
        },
        {
          "name": "Marco Minutoli",
          "affiliation": "Pacific Northwest National Laboratory"
        },
        {
          "name": "Vito Giovanni Castellana",
          "affiliation": "Pacific Northwest National Laboratory"
        },
        {
          "name": "Joseph Manzano",
          "affiliation": "Pacific Northwest National Laboratory"
        },
        {
          "name": "Antonino Tumeo",
          "affiliation": "Pacific Northwest National Laboratory"
        },
        {
          "name": "Fabrizio Ferrandi",
          "affiliation": "Politecnico di Milano"
        }
      ],
      "year": "2022",
      "publication": "Proceedings of the 59th ACM/IEEE Design Automation Conference",
      "venue": "Proceedings of the 59th ACM/IEEE Design Automation Conference",
      "type": "research-paper",
      "abstract": "Novel \"converged\" applications combine phases of scientific simulation with data analysis and machine learning. Each computational phase can benefit from specialized accelerators. However, algorithms evolve so quickly that mapping them on existing accelerators is suboptimal or even impossible. This paper presents the SODA (Software Defined Accelerators) framework, a modular, multi-level, open-source, no-human-in-the-loop, hardware synthesizer that enables end-to-end generation of specialized accelerators. SODA is composed of SODA-Opt, a high-level frontend developed in MLIR that interfaces with domain-specific programming frameworks and allows performing system level design, and Bambu, a state-of-the-art high-level synthesis engine that can target different device technologies. The framework implements design space exploration as compiler optimization passes. We show how the modular, yet tight, integration of the high-level optimizer and lower-level HLS tools enables the generation of accelerators optimized for the computational patterns of converged applications. We then discuss some of the research opportunities that such a framework allows, including system-level design, profile driven optimization, and supporting new optimization metrics.",
      "paperUrl": "http://hdl.handle.net/11311/1220191",
      "sourceUrl": "https://doi.org/10.1145/3489517.3530628",
      "tags": [
        "Frontend",
        "Optimizations",
        "ML",
        "MLIR"
      ],
      "keywords": [
        "Frontend",
        "Optimizations",
        "ML",
        "MLIR",
        "Specialized Accelerators"
      ],
      "matchedAuthors": [
        "Ankur Limaye",
        "Antonino Tumeo",
        "Fabrizio Ferrandi",
        "Joseph Manzano",
        "Marco Minutoli",
        "Nícolas Bohm Agostini",
        "Serena Curzel",
        "Vinay Amatya",
        "Vito Giovanni Castellana"
      ]
    },
    {
      "id": "openalex-w4311251058",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Taskgraph: A Low Contention OpenMP Tasking Framework",
      "authors": [
        {
          "name": "Chenle Yu",
          "affiliation": ""
        },
        {
          "name": "Sara Royuela",
          "affiliation": ""
        },
        {
          "name": "Eduardo Quiñones",
          "affiliation": ""
        }
      ],
      "year": "2022",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "OpenMP is the de-facto standard for shared memory systems in High-Performance Computing (HPC). It includes a task-based model that offers a high-level of abstraction to effectively exploit highly dynamic structured and unstructured parallelism in an easy and flexible way. Unfortunately, the run-time overheads introduced to manage tasks are (very) high in most common OpenMP frameworks (e.g., GCC, LLVM), which defeats the potential benefits of the tasking model, and makes it suitable for coarse-grained tasks only. This paper presents taskgraph, a framework that uses a task dependency graph (TDG) to represent a region of code implemented with OpenMP tasks in order to reduce the run-time overheads associated with the management of tasks, i.e., contention and parallel orchestration, including task creation and synchronization. The TDG avoids the overheads related to the resolution of task dependencies and greatly reduces those deriving from the accesses to shared resources. Moreover, the taskgraph framework introduces in OpenMP the record-and-replay execution model that accelerates the taskgraph region from its second execution. Overall, the multiple optimizations presented in this paper allow exploiting fine-grained OpenMP tasks to cope with the trend in current applications pointing to leverage massive on-node parallelism, fine-grained and dynamic scheduling paradigms. The framework is implemented on LLVM 15.0. Results show that the taskgraph implementation outperforms the vanilla OpenMP system in terms of performance and scalability, for all structured and unstructured parallelism, and considering coarse and fine grained tasks. Furthermore, the proposed framework considerably reduces the performance gap between the task and the thread models of OpenMP.",
      "paperUrl": "https://arxiv.org/pdf/2212.04771",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2212.04771",
      "tags": [
        "Performance",
        "Optimizations"
      ],
      "keywords": [
        "Performance",
        "Optimizations",
        "LLVM",
        "OpenMP Tasks",
        "Taskgraph",
        "Fine Grained",
        "Overheads",
        "Unstructured Parallelism",
        "Grained Tasks",
        "Contention OpenMP Tasking"
      ],
      "matchedAuthors": [
        "Chenle Yu",
        "Eduardo Quiñones",
        "Sara Royuela"
      ]
    },
    {
      "id": "openalex-w4307535028",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "TPU-MLIR: A Compiler For TPU Using MLIR",
      "authors": [
        {
          "name": "Pengchao Hu",
          "affiliation": ""
        },
        {
          "name": "Man Lu",
          "affiliation": ""
        },
        {
          "name": "Lei Wang",
          "affiliation": ""
        },
        {
          "name": "Guoyue Jiang",
          "affiliation": ""
        }
      ],
      "year": "2022",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Multi-level intermediate representations (MLIR) show great promise for reducing the cost of building domain-specific compilers by providing a reusable and extensible compiler infrastructure. This work presents TPU-MLIR, an end-to-end compiler based on MLIR that deploys pre-trained neural network (NN) models to a custom ASIC called a Tensor Processing Unit (TPU). TPU-MLIR defines two new dialects to implement its functionality: 1. a Tensor operation (TOP) dialect that encodes the deep learning graph semantics and independent of the deep learning framework and 2. a TPU kernel dialect to provide a standard kernel computation on TPU. A NN model is translated to the TOP dialect and then lowered to the TPU dialect for different TPUs according to the chip's configuration. We demonstrate how to use the MLIR pass pipeline to organize and perform optimization on TPU to generate machine code. The paper also presents a verification procedure to ensure the correctness of each transform stage.",
      "paperUrl": "https://arxiv.org/pdf/2210.15016",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2210.15016",
      "tags": [
        "Optimizations",
        "IR",
        "Infrastructure",
        "ML",
        "MLIR"
      ],
      "keywords": [
        "Optimizations",
        "IR",
        "Infrastructure",
        "ML",
        "MLIR",
        "Intermediate Representation",
        "Tpu MLIR",
        "Top Dialect",
        "Deep Learning",
        "Kernel"
      ],
      "matchedAuthors": [
        "Lei Wang"
      ]
    },
    {
      "id": "openalex-w4223470253",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Spinsim: a GPU optimized python package for simulating spin-half and spin-one quantum systems",
      "authors": [
        {
          "name": "Alex Tritt",
          "affiliation": ""
        },
        {
          "name": "Joshua Morris",
          "affiliation": ""
        },
        {
          "name": "Joel Hochstetter",
          "affiliation": ""
        },
        {
          "name": "R. P. Anderson",
          "affiliation": ""
        },
        {
          "name": "James Saunderson",
          "affiliation": ""
        },
        {
          "name": "L. D. Turner",
          "affiliation": ""
        }
      ],
      "year": "2022",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "The Spinsim python package simulates spin-half and spin-one quantum mechanical systems following a time dependent Shroedinger equation. It makes use of numba.cuda, which is an LLVM (Low Level Virtual Machine) compiler for Nvidia Cuda compatible systems using GPU parallelization. Along with other optimizations, this allows for speed improvements from 3 to 4 orders of magnitude while staying just as accurate, compared to industry standard packages. It is available for installation on PyPI, and the source code is available on github. The initial use-case for the Spinsim will be to simulate quantum sensing-based ultracold atom experiments for the Monash University School of Physics \\&amp; Astronomy spinor Bose-Einstein condensate (spinor BEC) lab, but we anticipate it will be useful in simulating any range of spin-half or spin-one quantum systems with time dependent Hamiltonians that cannot be solved analytically. These appear in the fields of nuclear magnetic resonance (NMR), nuclear quadrupole resonance (NQR) and magnetic resonance imaging (MRI) experiments and quantum sensing, and with the spin-one systems of nitrogen vacancy centres (NVCs), ultracold atoms, and BECs.",
      "paperUrl": "https://arxiv.org/pdf/2204.05586",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2204.05586",
      "tags": [
        "Optimizations",
        "GPU",
        "CUDA"
      ],
      "keywords": [
        "Optimizations",
        "GPU",
        "CUDA",
        "LLVM",
        "Spin One Quantum",
        "Simulating Spin Half",
        "Spinsim",
        "Optimized Python Package",
        "Magnetic Resonance",
        "Quantum Sensing",
        "GPU Optimized Python"
      ],
      "matchedAuthors": [
        "Alex Tritt",
        "James Saunderson",
        "Joel Hochstetter",
        "Joshua Morris",
        "R. P. Anderson"
      ]
    },
    {
      "id": "openalex-w4309468401",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Source Matching and Rewriting for MLIR Using String-Based Automata",
      "authors": [
        {
          "name": "Vinícius Couto Espindola",
          "affiliation": "Universidade Estadual de Campinas (UNICAMP)"
        },
        {
          "name": "Luciano Zago",
          "affiliation": "Universidade Estadual de Campinas (UNICAMP)"
        },
        {
          "name": "Hervé Yviquel",
          "affiliation": "Universidade Estadual de Campinas (UNICAMP)"
        },
        {
          "name": "Guido Araújo",
          "affiliation": "Universidade Estadual de Campinas (UNICAMP)"
        }
      ],
      "year": "2022",
      "publication": "ACM Transactions on Architecture and Code Optimization",
      "venue": "ACM Transactions on Architecture and Code Optimization | Vol. 20 (Issue 2)",
      "type": "research-paper",
      "abstract": "A typical compiler flow relies on a uni-directional sequence of translation/optimization steps that lower the program abstract representation, making it hard to preserve higher-level program information across each transformation step. On the other hand, modern ISA extensions and hardware accelerators can benefit from the compiler’s ability to detect and raise program idioms to acceleration instructions or optimized library calls. Although recent works based on Multi-Level IR (MLIR) have been proposed for code raising, they rely on specialized languages, compiler recompilation, or in-depth dialect knowledge. This article presents Source Matching and Rewriting (SMR), a user-oriented source-code-based approach for MLIR idiom matching and rewriting that does not require a compiler expert’s intervention. SMR uses a two-phase automaton-based DAG-matching algorithm inspired by early work on tree-pattern matching. First, the idiom Control-Dependency Graph (CDG) is matched against the program’s CDG to rule out code fragments that do not have a control-flow structure similar to the desired idiom. Second, candidate code fragments from the previous phase have their Data-Dependency Graphs (DDGs) constructed and matched against the idiom DDG. Experimental results show that SMR can effectively match idioms from Fortran (FIR) and C (CIL) programs while raising them as BLAS calls to improve performance. Additional experiments also show performance improvements when using SMR to enable code replacement in areas like approximate computing and hardware acceleration.",
      "paperUrl": "https://dl.acm.org/doi/pdf/10.1145/3571283",
      "sourceUrl": "https://doi.org/10.1145/3571283",
      "tags": [
        "Performance",
        "Optimizations",
        "IR",
        "MLIR"
      ],
      "keywords": [
        "Performance",
        "Optimizations",
        "IR",
        "MLIR",
        "Matched Against",
        "Hardware"
      ],
      "matchedAuthors": [
        "Guido Araújo",
        "Hervé Yviquel"
      ]
    },
    {
      "id": "openalex-w4226289789",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Source Matching and Rewriting",
      "authors": [
        {
          "name": "Vinícius Milanez Couto",
          "affiliation": ""
        },
        {
          "name": "Luciano Zago",
          "affiliation": ""
        },
        {
          "name": "Hervé Yviquel",
          "affiliation": ""
        },
        {
          "name": "Guido Araújo",
          "affiliation": ""
        }
      ],
      "year": "2022",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "A typical compiler flow relies on a uni-directional sequence of translation/optimization steps that lower the program abstract representation, making it hard to preserve higher-level program information across each transformation step. On the other hand, modern ISA extensions and hardware accelerators can benefit from the compiler's ability to detect and raise program idioms to acceleration instructions or optimized library calls. Although recent works based on Multi-Level IR (MLIR) have been proposed for code raising, they rely on specialized languages, compiler recompilation, or in-depth dialect knowledge. This paper presents Source Matching and Rewriting (SMR), a user-oriented source-code-based approach for MLIR idiom matching and rewriting that does not require a compiler expert's intervention. SMR uses a two-phase automaton-based DAG-matching algorithm inspired by early work on tree-pattern matching. First, the idiom Control-Dependency Graph (CDG) is matched against the program's CDG to rule out code fragments that do not have a control-flow structure similar to the desired idiom. Second, candidate code fragments from the previous phase have their Data-Dependency Graphs (DDGs) constructed and matched against the idiom DDG. Experimental results show that SMR can effectively match idioms from Fortran (FIR) and C (CIL) programs while raising them as BLAS calls to improve performance.",
      "paperUrl": "https://arxiv.org/pdf/2202.04153",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2202.04153",
      "tags": [
        "Performance",
        "Optimizations",
        "IR",
        "MLIR"
      ],
      "keywords": [
        "Performance",
        "Optimizations",
        "IR",
        "MLIR",
        "Matched Against"
      ],
      "matchedAuthors": [
        "Guido Araújo",
        "Hervé Yviquel"
      ]
    },
    {
      "id": "openalex-w4281612087",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Software Mitigation of RISC-V Spectre Attacks",
      "authors": [
        {
          "name": "Ruxandra Bălucea",
          "affiliation": ""
        },
        {
          "name": "Paul Irofti",
          "affiliation": ""
        }
      ],
      "year": "2022",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Speculative attacks are still an active threat today that, even if initially focused on the x86 platform, reach across all modern hardware architectures. RISC-V is a newly proposed open instruction set architecture that has seen traction from both the industry and academia in recent years. In this paper we focus on the RISC-V cores where speculation is enabled and, as we show, where Spectre attacks are as effective as on x86. Even though RISC-V hardware mitigations were proposed in the past, they have not yet passed the prototype phase. Instead, we propose low-overhead software mitigations for Spectre-BTI, inspired from those used on the x86 architecture, and for Spectre-RSB, to our knowledge the first such mitigation to be proposed. We show that these mitigations work in practice and that they can be integrated in the LLVM toolchain. For transparency and reproducibility, all our programs and data are made publicly available online.",
      "paperUrl": "https://arxiv.org/pdf/2206.04507",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2206.04507",
      "tags": [
        "Infrastructure"
      ],
      "keywords": [
        "Infrastructure",
        "LLVM",
        "Spectre",
        "Spectre Attacks",
        "Mitigations",
        "Hardware"
      ],
      "matchedAuthors": [
        "Paul Irofti",
        "Ruxandra Bălucea"
      ]
    },
    {
      "id": "openalex-w4311310666",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Soft Error Assessment of CNN Inference Models Running on a RISC-V Processor",
      "authors": [
        {
          "name": "Jonas Gava",
          "affiliation": "Universidade Federal do Rio Grande do Sul"
        },
        {
          "name": "Guilherme Dorneles",
          "affiliation": "Universidade Federal do Rio Grande do Sul"
        },
        {
          "name": "Ricardo Reis",
          "affiliation": "Universidade Federal do Rio Grande do Sul"
        },
        {
          "name": "Rafael Garibotti",
          "affiliation": "Pontifícia Universidade Católica do Rio Grande do Sul"
        },
        {
          "name": "Luciano Ost",
          "affiliation": "Loughborough University"
        }
      ],
      "year": "2022",
      "publication": "2022 29th IEEE International Conference on Electronics, Circuits and Systems (ICECS)",
      "venue": "2022 29th IEEE International Conference on Electronics, Circuits and Systems (ICECS)",
      "type": "research-paper",
      "abstract": "Software engineers use different compilers and code optimisation levels (e.g., O2 and Os) to achieve the best results considering distinguish constraints (e.g., power, performance and latency). Compilers and code optimisations have specific characteristics that directly impact applications' code footprint, performance, power efficiency, and reliability. In this scenario, this paper investigates the impact of widely adopted compilers on the soft error reliability of convolutional neural network (CNN) inference models executing on a RISC-V (rv32i) processor. Fault injection campaigns consider two fault targets (registers and memory), two open-source compilers (GCC 8.1.0 and Clang 12.0.1), five code optimisation levels, and two CNN inference models with 3 and 28 layers, resulting in 680k fault injections. Results show that optimisation flags can lead to more than two orders of magnitude increase in the occurrence of critical faults. Gathered results also show that the 3-layer CNN model is more susceptible to register faults. In contrast, the 28-layer model presents a higher susceptibility to memory bit-flip incidents.",
      "paperUrl": "https://doi.org/10.1109/icecs202256217.2022.9970958",
      "sourceUrl": "",
      "tags": [
        "Performance",
        "Clang",
        "ML"
      ],
      "keywords": [
        "Performance",
        "Clang",
        "ML",
        "Cnn Inference",
        "Soft Error Assessment",
        "Optimisation Levels",
        "Memory"
      ],
      "matchedAuthors": [
        "Luciano Ost",
        "Ricardo Reis"
      ]
    },
    {
      "id": "openalex-w4393822699",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Securisation of the exececution of applications against fault injection attacks by a counter-measure integrated into the processor",
      "authors": [
        {
          "name": "Thomas Chamelot",
          "affiliation": ""
        }
      ],
      "year": "2022",
      "publication": "theses.fr (ABES)",
      "venue": "theses.fr (ABES)",
      "type": "research-paper",
      "abstract": "Embedded systems are ubiquitous in our everyday life. Those embedded systems, by their nomadic nature, are particularly sensitive to the so-called fault injection attacks. For example, an attacker might inject a physical perturbation in an integrated circuit to compromise the security features of the system. Originally used to compromise cryptographic systems, those attacks can now target any kind of system. Notably, those attacks enable to compromise the execution of a program. In this manuscript, we introduce a new security property to protect the execution of instructions in the microarchitecture: execution integrity. From this property, we describe the concept of SCI-FI, a counter-measure that ensures the protection of the whole instruction path thanks to code, control-flow and execution integrity properties. We build SCI-FI around a bit vector that we call pipeline state and that is composed of microarchitecture control signals. Two modules interact around the pipeline state to ensure the security properties. The first module computes a signature from the pipeline state to ensure code and control-flow integrity and partially execution integrity. The second module completes the execution integrity support in the microarchitecture thanks to a redundancy mechanism. We also propose a solution for indirect branches and interrupts that are required to design embedded systems. We implement two versions of SCI-FI, one built around a cryptographic primitive which provides the best security level and another lighter one built around a CRC to maximize the performances. We integrate SCI-FI into a 32 bits RISC-V processor, and we modify the LLVM compiler. We analyze the security provided by our two implementations and we show that SCI-FI, even with the lightweight implementation, is robust against state-of-the-art attacker. Finally, we evaluate the performances of our implementations through an ASIC synthesis and through the execution of the benchmark suite Embench-IoT. We show that SCI-FI has comparable performances to state-of-the-art counter-measures while ensuring a new security property: execution integrity.",
      "paperUrl": "http://www.theses.fr/2022SORUS417/document",
      "sourceUrl": "",
      "tags": [
        "Security",
        "Embedded"
      ],
      "keywords": [
        "Security",
        "Embedded",
        "LLVM",
        "Execution Integrity",
        "Fault Injection Attacks",
        "Pipeline State",
        "Counter Measure Integrated",
        "Compromise",
        "Control Flow",
        "Microarchitecture",
        "Performances",
        "Security Property",
        "One Built",
        "Against Fault Injection"
      ],
      "matchedAuthors": [
        "Thomas Chamelot"
      ]
    },
    {
      "id": "openalex-w4220973418",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "SPNC: An Open-Source MLIR-Based Compiler for Fast Sum-Product Network Inference on CPUs and GPUs",
      "authors": [
        {
          "name": "Lukáš Sommer",
          "affiliation": "Technical University of Darmstadt"
        },
        {
          "name": "Cristian Axenie",
          "affiliation": "Huawei Technologies (Germany)"
        },
        {
          "name": "Andreas Koch",
          "affiliation": "Embedded Systems (United States)"
        }
      ],
      "year": "2022",
      "publication": "",
      "venue": "Vol. 38",
      "type": "research-paper",
      "abstract": "Sum-Product Networks (SPNs) are an alternative to the widely used Neural Networks (NNs) for machine learning. SPNs can not only reason about (un)certainty by qualifying their output with a probability, they also allow fast (tractable) inference by having run-times that are just linear w.r.t. the network size.We present SPNC, the first tool flow for generating fast native code for SPN inference on both CPUs and GPUs,including the use of vectorized/SIMD execution. To this end, we add two SPN-specific dialects to the MLIR framework and discuss their lowering towards the execution targets.We evaluate our approach on two applications, for which we consider performance, scaling to very large SPNs, and compile vs execution-time trade-offs. In this manner, we achieve multiple orders of magnitude in speed-ups over existing SPN support libraries.",
      "paperUrl": "https://doi.org/10.1109/cgo53902.2022.9741277",
      "sourceUrl": "",
      "tags": [
        "Performance",
        "GPU",
        "Autovectorization",
        "ML",
        "Libraries",
        "MLIR"
      ],
      "keywords": [
        "Performance",
        "GPU",
        "Autovectorization",
        "ML",
        "Libraries",
        "MLIR",
        "SIMD",
        "Product Network Inference",
        "Fast Sum Product",
        "Sum Product Network"
      ],
      "matchedAuthors": [
        "Andreas Koch",
        "Lukáš Sommer"
      ]
    },
    {
      "id": "openalex-w4388761475",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "SODA-OPT: enabling system-level design in MLIR for HLS and beyond",
      "authors": [
        {
          "name": "Nícolas Bohm Agostini",
          "affiliation": "Northeastern University"
        }
      ],
      "year": "2022",
      "publication": "",
      "venue": "",
      "type": "thesis",
      "abstract": "System-level design frameworks commonly rely on annotated high-level language code snippets written in C/C++ to perform High-Level Synthesis (HLS). This is especially true when generating designs for specialized accelerators. However, new dataflow and machine learning frameworks use high-level programming languages and only employ C/C++ in their runtimes. This abstraction gap requires the user to translate application code to C/C++, or resort to the composition of pre-configured high-level hardware modules, resulting in a significant productivity gap. To address this gap, we propose SODA-OPT, a front-end compiler that leverages the MLIR framework to automatically partition host code from accelerator code, pre-optimizing the accelerator code to produce better HLS designs. SODA-OPT allows the user to outline and synthesize custom accelerators for a range of high-level applications. SODA-OPT applies optimizations at the appropriate level of abstraction, enabling the generation of high-quality accelerated kernels. This thesis highlights the importance and effectiveness of high-level optimizations applied before the HLS backend. We evaluate our new compilation flow by exploring automated generation of accelerators for deep neural network operators, outlined at arbitrary granularities. Our compiler interfaces to a design space exploration engine, enabling us to identify the best combination of compiler optimization passes and options, resulting in high-performance designs for the selected backend target. Experimental results with key linear algebra kernels show that high-level optimizations expose code structures that result in speedups up to 60x faster when our optimization pipeline is tuned to the target HLS backend.--Author's abstract",
      "paperUrl": "https://repository.library.northeastern.edu/files/neu:4f18p609d/fulltext.pdf",
      "sourceUrl": "https://doi.org/10.17760/d20476846",
      "tags": [
        "Backend",
        "Performance",
        "Optimizations",
        "Programming Languages",
        "ML",
        "MLIR"
      ],
      "keywords": [
        "Backend",
        "Performance",
        "Optimizations",
        "Programming Languages",
        "ML",
        "MLIR",
        "Soda Opt",
        "HLS",
        "Accelerators",
        "HLS Backend",
        "Designs",
        "Kernels"
      ],
      "matchedAuthors": [
        "Nícolas Bohm Agostini"
      ]
    },
    {
      "id": "openalex-w4312121074",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "SODA Synthesizer",
      "authors": [
        {
          "name": "Nícolas Bohm Agostini",
          "affiliation": "Pacific Northwest National Laboratory"
        },
        {
          "name": "Ankur Limaye",
          "affiliation": "Pacific Northwest National Laboratory"
        },
        {
          "name": "Marco Minutoli",
          "affiliation": "Pacific Northwest National Laboratory"
        },
        {
          "name": "Vito Giovanni Castellana",
          "affiliation": "Pacific Northwest National Laboratory"
        },
        {
          "name": "Joseph Manzano",
          "affiliation": "Pacific Northwest National Laboratory"
        },
        {
          "name": "Antonino Tumeo",
          "affiliation": "Pacific Northwest National Laboratory"
        },
        {
          "name": "Serena Curzel",
          "affiliation": "Politecnico di Milano"
        },
        {
          "name": "Fabrizio Ferrandi",
          "affiliation": "Politecnico di Milano"
        }
      ],
      "year": "2022",
      "publication": "Proceedings of the 41st IEEE/ACM International Conference on Computer-Aided Design",
      "venue": "Proceedings of the 41st IEEE/ACM International Conference on Computer-Aided Design",
      "type": "research-paper",
      "abstract": "The SODA Synthesizer is an open-source, modular, end-to-end hardware compiler framework. The SODA frontend, developed in MLIR, performs system-level design, code partitioning, and highlevel optimizations to prepare the specifications for the hardware synthesis. The backend is based on a state-of-the-art high-level synthesis tool and generates the final hardware design. The backend can interface with logic synthesis tools for field programmable gate arrays or with commercial and open-source logic synthesis tools for application-specific integrated circuits. We discuss the opportunities and challenges in integrating with commercial and open-source tools both at the frontend and backend, and highlight the role that an end-to-end compiler framework like SODA can play in an open-source hardware design ecosystem.",
      "paperUrl": "https://hdl.handle.net/11311/1229392",
      "sourceUrl": "https://doi.org/10.1145/3508352.3561101",
      "tags": [
        "Backend",
        "Frontend",
        "Optimizations",
        "MLIR"
      ],
      "keywords": [
        "Backend",
        "Frontend",
        "Optimizations",
        "MLIR",
        "Hardware",
        "Logic Synthesis",
        "Soda Synthesizer"
      ],
      "matchedAuthors": [
        "Ankur Limaye",
        "Antonino Tumeo",
        "Fabrizio Ferrandi",
        "Joseph Manzano",
        "Marco Minutoli",
        "Nícolas Bohm Agostini",
        "Serena Curzel",
        "Vito Giovanni Castellana"
      ]
    },
    {
      "id": "openalex-w4225991564",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Polytope: Practical Memory Access Control for C++ Applications",
      "authors": [
        {
          "name": "Ioannis Agadakos",
          "affiliation": ""
        },
        {
          "name": "Manuel Egele",
          "affiliation": ""
        },
        {
          "name": "William Robertson",
          "affiliation": ""
        }
      ],
      "year": "2022",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Designing and implementing secure software is inarguably more important than ever. However, despite years of research into privilege separating programs, it remains difficult to actually do so and such efforts can take years of labor-intensive engineering to reach fruition. At the same time, new intra-process isolation primitives make strong data isolation and privilege separation more attractive from a performance perspective. Yet, substituting intra-process security boundaries for time-tested process boundaries opens the door to subtle but devastating privilege leaks. In this work, we present Polytope, a language extension to C++ that aims to make efficient privilege separation accessible to a wider audience of developers. Polytope defines a policy language encoded as C++11 attributes that separate code and data into distinct program partitions. A modified Clang front-end embeds source-level policy as metadata nodes in the LLVM IR. An LLVM pass interprets embedded policy and instruments an IR with code to enforce the source-level policy using Intel MPK. A run-time support library manages partitions, protection keys, dynamic memory operations, and indirect call target privileges. An evaluation demonstrates that Polytope provides equivalent protection to prior systems with a low annotation burden and comparable performance overhead. Polytope also renders privilege leaks that contradict intended policy impossible to express.",
      "paperUrl": "https://arxiv.org/pdf/2201.08461",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2201.08461",
      "tags": [
        "Security",
        "Performance",
        "Clang",
        "IR",
        "Embedded"
      ],
      "keywords": [
        "Security",
        "Performance",
        "Clang",
        "IR",
        "Embedded",
        "LLVM",
        "Intermediate Representation",
        "Polytope Practical Memory",
        "Policy",
        "Privilege Leaks",
        "Intra Process",
        "Privilege Separation",
        "Memory Access Control"
      ],
      "matchedAuthors": [
        "William Robertson"
      ]
    },
    {
      "id": "openalex-w4221157833",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Optimizing LLVM Pass Sequences with Shackleton: A Linear Genetic Programming Framework",
      "authors": [
        {
          "name": "Hannah Peeler",
          "affiliation": ""
        },
        {
          "name": "Shuyue Stella Li",
          "affiliation": ""
        },
        {
          "name": "Andrew N. Sloss",
          "affiliation": ""
        },
        {
          "name": "Kenneth N. Reid",
          "affiliation": ""
        },
        {
          "name": "Yuan Yuan",
          "affiliation": ""
        },
        {
          "name": "Wolfgang Banzhaf",
          "affiliation": ""
        }
      ],
      "year": "2022",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "In this paper we introduce Shackleton as a generalized framework enabling the application of linear genetic programming -- a technique under the umbrella of evolutionary algorithms -- to a variety of use cases. We also explore here a novel application for this class of methods: optimizing sequences of LLVM optimization passes. The algorithm underpinning Shackleton is discussed, with an emphasis on the effects of different features unique to the framework when applied to LLVM pass sequences. Combined with analysis of different hyperparameter settings, we report the results on automatically optimizing pass sequences using Shackleton for two software applications at differing complexity levels. Finally, we reflect on the advantages and limitations of our current implementation and lay out a path for further improvements. These improvements aim to surpass hand-crafted solutions with an automatic discovery method for an optimal pass sequence.",
      "paperUrl": "https://arxiv.org/pdf/2201.13305",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2201.13305",
      "tags": [
        "Optimizations"
      ],
      "keywords": [
        "Optimizations",
        "LLVM",
        "LLVM Pass Sequences",
        "Shackleton",
        "Linear Genetic Programming",
        "Optimizing LLVM Pass"
      ],
      "matchedAuthors": [
        "Andrew N. Sloss",
        "Hannah Peeler",
        "Kenneth N. Reid",
        "Shuyue Stella Li",
        "Wolfgang Banzhaf",
        "Yuan Yuan"
      ]
    },
    {
      "id": "openalex-w4220850685",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "MLIR-based code generation for GPU tensor cores",
      "authors": [
        {
          "name": "Navdeep Katel",
          "affiliation": "Indian Institute of Science Bangalore"
        },
        {
          "name": "Vivek Khandelwal",
          "affiliation": "Indian Institute of Science Bangalore"
        },
        {
          "name": "Uday Bondhugula",
          "affiliation": "Indian Institute of Science Bangalore"
        }
      ],
      "year": "2022",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "The state-of-the-art in high-performance deep learning today is primarily driven by manually developed libraries optimized and highly tuned by expert programmers using low-level abstractions with significant effort. This effort is often repeated for similar hardware and future ones. In this work, we pursue and evaluate the more modular and reusable approach of using compiler IR infrastructure to generate libraries by encoding all the required optimizations as a sequence of transformations and customized passes on an IR. We believe that until the recent introduction of MLIR (Multi-level intermediate representation), it had been hard to represent and transform computation at various levels of abstraction within a single IR.",
      "paperUrl": "https://doi.org/10.1145/3497776.3517770",
      "sourceUrl": "",
      "tags": [
        "Backend",
        "Performance",
        "Optimizations",
        "GPU",
        "IR",
        "Infrastructure",
        "ML",
        "Libraries",
        "MLIR"
      ],
      "keywords": [
        "Backend",
        "Performance",
        "Optimizations",
        "GPU",
        "IR",
        "Infrastructure",
        "ML",
        "Libraries",
        "MLIR",
        "Intermediate Representation",
        "Code Generation",
        "GPU Tensor Cores"
      ],
      "matchedAuthors": [
        "Uday Bondhugula"
      ]
    },
    {
      "id": "openalex-w4318256778",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "MLIR Loop Optimizations for High-Level Synthesis",
      "authors": [
        {
          "name": "Serena Curzel",
          "affiliation": "Politecnico di Milano"
        },
        {
          "name": "Sofija Jovic",
          "affiliation": "Politecnico di Milano"
        },
        {
          "name": "Michele Fiorito",
          "affiliation": "Politecnico di Milano"
        },
        {
          "name": "Antonino Tumeo",
          "affiliation": "Politecnico di Milano"
        },
        {
          "name": "Fabrizio Ferrandi",
          "affiliation": "Politecnico di Milano"
        }
      ],
      "year": "2022",
      "publication": "Virtual Community of Pathological Anatomy (University of Castilla La Mancha)",
      "venue": "Virtual Community of Pathological Anatomy (University of Castilla La Mancha)",
      "type": "research-paper",
      "abstract": "High-Level Synthesis (HLS) tools automatically translate code from a general-purpose programming language (typically C or C++) into a hardware description language (HDL) such as Verilog or VHDL, significantly reducing the hardware design productivity gap. HLS benefits from the same compiler optimizations that identify instruction, memory, and data parallelism for general-purpose processors. However, they also need to consider specific needs of low-level circuit design, such as the notion of time, synchronous and asynchronous logic, and wiring delays. Because of the mismatch between hardware abstractions and general-purpose programming languages, HLS tools often require the addition of pragma directives in the input code to guide hardware generation.",
      "paperUrl": "https://dl.acm.org/doi/pdf/10.1145/3559009.3569688",
      "sourceUrl": "https://doi.org/10.1145/3559009.3569688",
      "tags": [
        "Optimizations",
        "Programming Languages",
        "MLIR"
      ],
      "keywords": [
        "Optimizations",
        "Programming Languages",
        "MLIR",
        "Hardware",
        "HLS",
        "Purpose Programming",
        "Synthesis",
        "MLIR Loop Optimizations"
      ],
      "matchedAuthors": [
        "Antonino Tumeo",
        "Fabrizio Ferrandi",
        "Michele Fiorito",
        "Serena Curzel"
      ]
    },
    {
      "id": "openalex-w4323246272",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Irbis: static taint analyzer for vulnerabilities detection in C/C++",
      "authors": [
        {
          "name": "N. V. Shimchik",
          "affiliation": ""
        },
        {
          "name": "V. N. Ignatyev",
          "affiliation": ""
        },
        {
          "name": "Andrey Belevantsev",
          "affiliation": ""
        }
      ],
      "year": "2022",
      "publication": "Proceedings of the Institute for System Programming of RAS",
      "venue": "Proceedings of the Institute for System Programming of RAS | Vol. 34 (Issue 6)",
      "type": "research-paper",
      "abstract": "Static taint analysis can be used to find various security weaknesses and vulnerabilities in programs by discovering dataflow paths from taint sources to taint sinks. In most cases the data is called ”tainted” if it was obtained from an untrusted source without proper sanitization. In this paper we present a static taint analyzer Irbis. It implements analysis based on IFDS (Interprocedural Finite Distributive Subset) dataflow problem, as well as various extensions aimed at improving accuracy and completeness of the analysis. It supports different definitions of tainted data, which enables it to find such weaknesses as out of buffer access, use of freed memory, hardcoded passwords, data leaks and discover dataflow paths between user-defined sources and sinks. All sources, sinks and propagators definitions are stored in JSON format and can be adjusted to meet the users’ needs. We compare analysis results on Juliet Test Suite for C/C++ with several other analyzers, such as Infer, Clang Static Analyzer and Svace. Irbis manages to demonstrate 100% coverage on taint-related subset of tests for implemented CWEs, while suppressing all the false positives using heuristics. We also show performance and false positive rate on real projects, with examples of real vulnerabilities, which can be detected by Irbis.",
      "paperUrl": "https://ispranproceedings.elpub.ru/jour/article/download/1590/1407",
      "sourceUrl": "https://doi.org/10.15514/ispras-2022-34(6)-4",
      "tags": [
        "Security",
        "Performance",
        "Clang",
        "Static Analysis"
      ],
      "keywords": [
        "Security",
        "Performance",
        "Clang",
        "Static Analysis",
        "Taint Analyzer",
        "Vulnerabilities Detection",
        "Dataflow Paths",
        "Sources"
      ],
      "matchedAuthors": [
        "Andrey Belevantsev",
        "N. V. Shimchik",
        "V. N. Ignatyev"
      ]
    },
    {
      "id": "openalex-w4297793675",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Energy-Efficiency Evaluation of OpenMP Loop Transformations and Runtime Constructs",
      "authors": [
        {
          "name": "Henrik Valter",
          "affiliation": ""
        },
        {
          "name": "Axel Karlsson",
          "affiliation": ""
        },
        {
          "name": "Miquel Pericàs",
          "affiliation": ""
        }
      ],
      "year": "2022",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "OpenMP is the de facto API for parallel programming in HPC applications. These programs are often computed in data centers, where energy consumption is a major issue. Whereas previous work has focused almost entirely on performance, we here analyse aspects of OpenMP from an energy consumption perspective. This analysis is accomplished by executing novel microbenchmarks and common benchmark suites on data center nodes and measuring the energy consumption. Three main aspects are analysed: directive-generated loop tiling and unrolling, parallel for loops and explicit tasking, and the policy of handling blocked threads. For loop tiling and unrolling, we find that tiling can yield significant energy savings for some, mostly unoptimised programs, while directive-generated unrolling provides very minor improvement in the best case and degenerates performance majorly in the worst case. For the second aspect, we find that parallel for loops yield better results than explicit tasking loops in cases where both can be used. This becomes more prominent with more fine-grained workloads. For the third, we find that significant energy savings can be made by not descheduling waiting threads, but instead having them spin, at the cost of a higher power consumption. We also analyse how the choice of compiler affects the above questions by compiling programs with each of ICC, Clang and GCC, and find that while neither is strictly better than the others, they can produce very different results for the same compiled programs. As a final step, we combine the findings of all results and suggest novel compiler directives as well as general recommendations on how to reduce energy consumption in OpenMP programs.",
      "paperUrl": "https://arxiv.org/pdf/2209.04317",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2209.04317",
      "tags": [
        "Performance",
        "Clang",
        "Loop transformations"
      ],
      "keywords": [
        "Performance",
        "Clang",
        "Loop transformations",
        "Loop Optimization",
        "Parallel Computing",
        "Energy Consumption",
        "OpenMP Loop Transformations",
        "Significant Energy Savings",
        "Directive Generated",
        "Explicit Tasking",
        "Loop Tiling",
        "Energy Efficiency",
        "Runtime Constructs"
      ],
      "matchedAuthors": [
        "Miquel Pericàs"
      ]
    },
    {
      "id": "openalex-w4312556184",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "End-to-End Synthesis of Dynamically Controlled Machine Learning Accelerators",
      "authors": [
        {
          "name": "Serena Curzel",
          "affiliation": "Politecnico di Milano"
        },
        {
          "name": "Nícolas Bohm Agostini",
          "affiliation": "Pacific Northwest National Laboratory"
        },
        {
          "name": "Vito Giovanni Castellana",
          "affiliation": "Pacific Northwest National Laboratory"
        },
        {
          "name": "Marco Minutoli",
          "affiliation": "Pacific Northwest National Laboratory"
        },
        {
          "name": "Ankur Limaye",
          "affiliation": "Pacific Northwest National Laboratory"
        },
        {
          "name": "Joseph Manzano",
          "affiliation": "Pacific Northwest National Laboratory"
        },
        {
          "name": "Jeff Zhang",
          "affiliation": "Harvard University Press"
        },
        {
          "name": "David Brooks",
          "affiliation": "Harvard University Press"
        },
        {
          "name": "Gu-Yeon Wei",
          "affiliation": "Harvard University Press"
        },
        {
          "name": "Fabrizio Ferrandi",
          "affiliation": "Politecnico di Milano"
        },
        {
          "name": "Antonino Tumeo",
          "affiliation": "Pacific Northwest National Laboratory"
        }
      ],
      "year": "2022",
      "publication": "IEEE Transactions on Computers",
      "venue": "IEEE Transactions on Computers",
      "type": "research-paper",
      "abstract": "Edge systems are required to autonomously make real-time decisions based on large quantities of input data under strict power, performance, area, and other constraints. Meeting these constraints is only possible by specializing systems through hardware accelerators purposefully built for machine learning and data analysis algorithms. However, data science evolves at a quick pace, and manual design of custom accelerators has high non-recurrent engineering costs: general solutions are needed to automatically and rapidly transition from the formulation of a new algorithm to the deployment of a dedicated hardware implementation. Our solution is the SOftware Defined Architectures (SODA) Synthesizer, an end-to-end, multi-level, modular, extensible compiler toolchain providing a direct path from machine learning tools to hardware. The SODA Synthesizer frontend is based on the multilevel intermediate representation (MLIR) framework; it ingests pre-trained machine learning models, identifies kernels suited for acceleration, performs high-level optimizations, and prepares them for hardware synthesis. In the backend, SODA leverages state-of-the-art high-level synthesis techniques to generate highly efficient accelerators, targeting both field programmable devices (FPGAs) and application-specific circuits (ASICs). In this paper, we describe how the SODA Synthesizer can also assemble the generated accelerators (based on the finite state machine with datapath model) in a custom system driven by a distributed controller, building a coarse-grained dataflow architecture that does not require a host processor to orchestrate parallel execution of multiple accelerators. We show the effectiveness of our approach by automatically generating ASIC accelerators for layers of popular deep neural networks (DNNs). Our high-level optimizations result in up to 74x speedup on isolated accelerators for individual DNN layers, and our dynamically scheduled architecture yields an additional 3x performance improvement when combining accelerators to handle streaming inputs.",
      "paperUrl": "https://ieeexplore.ieee.org/ielx7/12/4358213/09907051.pdf",
      "sourceUrl": "https://doi.org/10.1109/tc.2022.3211430",
      "tags": [
        "Backend",
        "Frontend",
        "Performance",
        "Optimizations",
        "IR",
        "Infrastructure",
        "ML",
        "MLIR"
      ],
      "keywords": [
        "Backend",
        "Frontend",
        "Performance",
        "Optimizations",
        "IR",
        "Infrastructure",
        "ML",
        "MLIR",
        "Intermediate Representation",
        "Machine Learning Accelerators",
        "Controlled Machine Learning",
        "Soda Synthesizer",
        "Hardware",
        "Synthesis"
      ],
      "matchedAuthors": [
        "Ankur Limaye",
        "Antonino Tumeo",
        "David Brooks",
        "Fabrizio Ferrandi",
        "Gu-Yeon Wei",
        "Joseph Manzano",
        "Marco Minutoli",
        "Nícolas Bohm Agostini",
        "Serena Curzel",
        "Vito Giovanni Castellana"
      ]
    },
    {
      "id": "openalex-w4285177210",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Detecting C++ Compiler Front-End Bugs via Grammar Mutation and Differential Testing",
      "authors": [
        {
          "name": "Haoxin Tu",
          "affiliation": "Singapore Management University"
        },
        {
          "name": "He Jiang",
          "affiliation": "Dalian University of Technology"
        },
        {
          "name": "Zhide Zhou",
          "affiliation": "Dalian University of Technology"
        },
        {
          "name": "Yixuan Tang",
          "affiliation": "Dalian University of Technology"
        },
        {
          "name": "Zhilei Ren",
          "affiliation": "Dalian University of Technology"
        },
        {
          "name": "Lei Qiao",
          "affiliation": ""
        },
        {
          "name": "Lingxiao Jiang",
          "affiliation": "Singapore Management University"
        }
      ],
      "year": "2022",
      "publication": "IEEE Transactions on Reliability",
      "venue": "IEEE Transactions on Reliability | Vol. 72 (Issue 1)",
      "type": "research-paper",
      "abstract": "C++ is a widely used programming language and the C++ front-end is a critical part of a C++ compiler. Although many techniques have been proposed to test compilers, few studies are devoted to detecting bugs in C++ compiler. In this study, we take the first step to detect bugs in C++ compiler front-ends. To do so, two main challenges need to be addressed, namely, the acquisition of test programs that are more likely to trigger bugs in compiler front-ends and the bug identification from complicated compiler outputs. In this article, we propose a novel framework named <sc xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Ccoft</small> to detect bugs in C++ compiler front-ends. To address the first challenge, <sc xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Ccoft</small> implements a practical program generator. The generator first transforms C++ grammars into a flexible structured format and then utilizes an equal-chance selection (ECS) strategy to conduct structure-aware grammar mutation to generate diverse C++ programs. Next, <sc xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Ccoft</small> employs a set of differential testing strategies to identify various kinds of bugs in C++ compiler front-ends by comparing complex outputs emitted by C++ compilers, thus tackling the second challenge. Empirical evaluation results over two mainstream compilers (i.e., GCC and Clang) show that <sc xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Ccoft</small> greatly improves two state-of-the-art approaches (i.e., Dharma and Grammarinator) by 135% and 111% in terms of the numbers of detected bugs, respectively. By running <sc xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Ccoft</small> for three months, we have successfully reported 136 bugs for two C++ compilers, of which 78 (57 confirmed, assigned, or fixed) for GCC and 58 (10 confirmed or fixed) for Clang.",
      "paperUrl": "https://doi.org/10.1109/tr.2022.3171220",
      "sourceUrl": "",
      "tags": [
        "Clang",
        "Programming Languages",
        "Testing"
      ],
      "keywords": [
        "Clang",
        "Programming Languages",
        "Testing",
        "Differential Testing",
        "Compiler Front Ends",
        "Grammar Mutation",
        "Detect Bugs",
        "GCC"
      ],
      "matchedAuthors": [
        "Haoxin Tu",
        "He Jiang",
        "Lei Qiao",
        "Lingxiao Jiang",
        "Yixuan Tang",
        "Zhide Zhou",
        "Zhilei Ren"
      ]
    },
    {
      "id": "openalex-w4312936523",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Designing an open framework for query optimization and compilation",
      "authors": [
        {
          "name": "Michael Jungmair",
          "affiliation": "Technical University of Munich"
        },
        {
          "name": "André Kohn",
          "affiliation": "Technical University of Munich"
        },
        {
          "name": "Jana Giceva",
          "affiliation": "Technical University of Munich"
        }
      ],
      "year": "2022",
      "publication": "Proceedings of the VLDB Endowment",
      "venue": "Proceedings of the VLDB Endowment | Vol. 15 (Issue 11)",
      "type": "research-paper",
      "abstract": "Since its invention, data-centric code generation has been adopted for query compilation by various database systems in academia and industry. These database systems are fast but maximize performance at the expense of developer friendliness, flexibility, and extensibility. Recent advances in the field of compiler construction identified similar issues for domain-specific compilers and introduced a solution with MLIR, a generic infrastructure for domain-specific dialects. We propose a layered query compilation stack based on MLIR with open intermediate representations that can be combined at each layer. We further propose moving query optimization into the query compiler to benefit from the existing optimization infrastructure and make cross-domain optimization viable. With LingoDB, we demonstrate that the used approach significantly decreases the implementation effort and is highly flexible and extensible. At the same time, LingoDB achieves high performance and low compilation latencies.",
      "paperUrl": "https://doi.org/10.14778/3551793.3551801",
      "sourceUrl": "",
      "tags": [
        "Backend",
        "Performance",
        "Optimizations",
        "IR",
        "Infrastructure",
        "MLIR"
      ],
      "keywords": [
        "Backend",
        "Performance",
        "Optimizations",
        "IR",
        "Infrastructure",
        "MLIR",
        "Intermediate Representation",
        "Code Generation",
        "Query Compilation",
        "Query Optimization",
        "Domain Specific"
      ],
      "matchedAuthors": [
        "André Kohn"
      ]
    },
    {
      "id": "openalex-w4310746147",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Deep-Learning-based Vulnerability Detection in Binary Executables",
      "authors": [
        {
          "name": "Andreas Schaad",
          "affiliation": ""
        },
        {
          "name": "Dominik Binder",
          "affiliation": ""
        }
      ],
      "year": "2022",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "The identification of vulnerabilities is an important element in the software development life cycle to ensure the security of software. While vulnerability identification based on the source code is a well studied field, the identification of vulnerabilities on basis of a binary executable without the corresponding source code is more challenging. Recent research [1] has shown, how such detection can be achieved by deep learning methods. However, that particular approach is limited to the identification of only 4 types of vulnerabilities. Subsequently, we analyze to what extent we could cover the identification of a larger variety of vulnerabilities. Therefore, a supervised deep learning approach using recurrent neural networks for the application of vulnerability detection based on binary executables is used. The underlying basis is a dataset with 50,651 samples of vulnerable code in the form of a standardized LLVM Intermediate Representation. The vectorised features of a Word2Vec model are used to train different variations of three basic architectures of recurrent neural networks (GRU, LSTM, SRNN). A binary classification was established for detecting the presence of an arbitrary vulnerability, and a multi-class model was trained for the identification of the exact vulnerability, which achieved an out-of-sample accuracy of 88% and 77%, respectively. Differences in the detection of different vulnerabilities were also observed, with non-vulnerable samples being detected with a particularly high precision of over 98%. Thus, the methodology presented allows an accurate detection of 23 (compared to 4 [1]) vulnerabilities.",
      "paperUrl": "https://arxiv.org/pdf/2212.01254",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2212.01254",
      "tags": [
        "Security",
        "IR",
        "ML"
      ],
      "keywords": [
        "Security",
        "IR",
        "ML",
        "LLVM",
        "Intermediate Representation",
        "Identification",
        "Vulnerabilities",
        "Detection",
        "Vulnerability Detection",
        "Deep Learning",
        "Binary Executables",
        "Recurrent Neural Networks"
      ],
      "matchedAuthors": [
        "Andreas Schaad",
        "Dominik Binder"
      ]
    },
    {
      "id": "openalex-w4225523500",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "CryptSan: Leveraging ARM Pointer Authentication for Memory Safety in C/C++",
      "authors": [
        {
          "name": "Konrad Hohentanner",
          "affiliation": ""
        },
        {
          "name": "Philipp Zieris",
          "affiliation": ""
        },
        {
          "name": "Julian Horsch",
          "affiliation": ""
        }
      ],
      "year": "2022",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Memory safety bugs remain in the top ranks of security vulnerabilities, even after decades of research on their detection and prevention. Various mitigations have been proposed for C/C++, ranging from language dialects to instrumentation. Among these, compiler-based instrumentation is particularly promising, not requiring manual code modifications and being able to achieve precise memory safety. Unfortunately, existing compiler-based solutions compromise in many areas, including performance but also usability and memory safety guarantees. New developments in hardware can help improve performance and security of compiler-based memory safety. ARM Pointer Authentication, added in the ARMv8.3 architecture, is intended to enable hardware-assisted Control Flow Integrity (CFI). But since its operations are generic, it also enables other, more comprehensive hardware-supported runtime integrity approaches. As such, we propose CryptSan, a memory safety approach based on ARM Pointer Authentication. CryptSan uses pointer signatures to retrofit memory safety to C/C++ programs, protecting heap, stack, and globals against temporal and spatial vulnerabilities. We present a full LLVM-based prototype implementation, running on an M1 MacBook Pro, i.e., on actual ARMv8.3 hardware. Our prototype evaluation shows that the system outperforms similar approaches under real-world conditions. This, together with its interoperability with uninstrumented libraries and cryptographic protection against attacks on metadata, makes CryptSan a viable solution for retrofitting memory safety to C/C++ programs.",
      "paperUrl": "https://arxiv.org/pdf/2202.08669",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2202.08669",
      "tags": [
        "Security",
        "Performance",
        "Libraries"
      ],
      "keywords": [
        "Security",
        "Performance",
        "Libraries",
        "LLVM",
        "Memory Safety",
        "ARM Pointer Authentication",
        "Cryptsan Leveraging ARM",
        "Hardware",
        "Armv8",
        "Instrumentation",
        "Leveraging ARM Pointer"
      ],
      "matchedAuthors": [
        "Julian Horsch",
        "Philipp Zieris"
      ]
    },
    {
      "id": "openalex-w4309797313",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "CryptOpt: Verified Compilation with Randomized Program Search for Cryptographic Primitives (full version)",
      "authors": [
        {
          "name": "Joel Kuepper",
          "affiliation": ""
        },
        {
          "name": "Andres Erbsen",
          "affiliation": ""
        },
        {
          "name": "Jason N. Gross",
          "affiliation": ""
        },
        {
          "name": "Owen Conoly",
          "affiliation": ""
        },
        {
          "name": "Chuyue Sun",
          "affiliation": ""
        },
        {
          "name": "Samuel Tian",
          "affiliation": ""
        },
        {
          "name": "David Wu",
          "affiliation": ""
        },
        {
          "name": "Adam Chlipala",
          "affiliation": ""
        },
        {
          "name": "Chitchanok Chuengsatiansup",
          "affiliation": ""
        },
        {
          "name": "Daniel Genkin",
          "affiliation": ""
        },
        {
          "name": "Markus Wagner",
          "affiliation": ""
        },
        {
          "name": "Yuval Yarom",
          "affiliation": ""
        }
      ],
      "year": "2022",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Most software domains rely on compilers to translate high-level code to multiple different machine languages, with performance not too much worse than what developers would have the patience to write directly in assembly language. However, cryptography has been an exception, where many performance-critical routines have been written directly in assembly (sometimes through metaprogramming layers). Some past work has shown how to do formal verification of that assembly, and other work has shown how to generate C code automatically along with formal proof, but with consequent performance penalties vs. the best-known assembly. We present CryptOpt, the first compilation pipeline that specializes high-level cryptographic functional programs into assembly code significantly faster than what GCC or Clang produce, with mechanized proof (in Coq) whose final theorem statement mentions little beyond the input functional program and the operational semantics of x86-64 assembly. On the optimization side, we apply randomized search through the space of assembly programs, with repeated automatic benchmarking on target CPUs. On the formal-verification side, we connect to the Fiat Cryptography framework (which translates functional programs into C-like IR code) and extend it with a new formally verified program-equivalence checker, incorporating a modest subset of known features of SMT solvers and symbolic-execution engines. The overall prototype is quite practical, e.g. producing new fastest-known implementations of finite-field arithmetic for both Curve25519 (part of the TLS standard) and the Bitcoin elliptic curve secp256k1 for the Intel $12^{th}$ and $13^{th}$ generations.",
      "paperUrl": "https://arxiv.org/pdf/2211.10665",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2211.10665",
      "tags": [
        "Performance",
        "Clang",
        "Optimizations",
        "IR"
      ],
      "keywords": [
        "Performance",
        "Clang",
        "Optimizations",
        "IR",
        "Formal Verification",
        "Functional Programs",
        "Cryptopt Verified Compilation",
        "Cryptographic Primitives Full",
        "Primitives Full Version",
        "Randomized Program Search"
      ],
      "matchedAuthors": [
        "Yuval Yarom"
      ]
    },
    {
      "id": "openalex-w4226443139",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Composable and Modular Code Generation in MLIR: A Structured and Retargetable Approach to Tensor Compiler Construction",
      "authors": [
        {
          "name": "Nicolas Vasilache",
          "affiliation": "University of Cambridge"
        },
        {
          "name": "Aart J. C. Bik",
          "affiliation": "University of Edinburgh"
        },
        {
          "name": "M. Ravishankar",
          "affiliation": "University of Amsterdam"
        },
        {
          "name": "Thomas Raoux",
          "affiliation": "University of Cambridge"
        }
      ],
      "year": "2022",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Despite significant investment in software infrastructure, machine learning systems, runtimes and compilers do not compose properly. We propose a new design aiming at providing unprecedented degrees of modularity, composability and genericity. This paper discusses a structured approach to the construction of domain-specific code generators for tensor compilers, with the stated goal of improving the productivity of both compiler engineers and end-users. The approach leverages the natural structure of tensor algebra. It has been the main driver for the design of progressive lowering paths in \\MLIR. The proposed abstractions and transformations span data structures and control flow with both functional (SSA form) and imperative (side-effecting) semantics. We discuss the implications of this infrastructure on compiler construction and present preliminary experimental results.",
      "paperUrl": "https://arxiv.org/pdf/2202.03293",
      "sourceUrl": "https://doi.org/10.4230/lipics.itp.2024.9",
      "tags": [
        "Backend",
        "Infrastructure",
        "ML",
        "MLIR"
      ],
      "keywords": [
        "Backend",
        "Infrastructure",
        "ML",
        "MLIR",
        "Code Generation",
        "Static Single Assignment",
        "Compiler Construction",
        "Tensor Compiler Construction"
      ],
      "matchedAuthors": [
        "Aart J. C. Bik",
        "M. Ravishankar",
        "Nicolas Vasilache",
        "Thomas Raoux"
      ]
    },
    {
      "id": "openalex-w4223458574",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Color My World: Deterministic Tagging for Memory Safety",
      "authors": [
        {
          "name": "Hans Liljestrand",
          "affiliation": ""
        },
        {
          "name": "Carlos Chinea",
          "affiliation": ""
        },
        {
          "name": "Rémi Denis-Courmont",
          "affiliation": ""
        },
        {
          "name": "Jan-Erik Ekberg",
          "affiliation": ""
        },
        {
          "name": "N. Asokan",
          "affiliation": ""
        }
      ],
      "year": "2022",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Hardware-assisted memory protection features are increasingly being deployed in COTS processors. ARMv8.5 Memory Tagging Extensions (MTE) is a recent example, which has been used to provide probabilistic checks for memory safety. This use of MTE is not secure against the standard adversary with arbitrary read/write access to memory. Consequently MTE is used as a software development tool. In this paper we present the first design for deterministic memory protection using MTE that can resist the standard adversary, and hence is suitable for post-deployment memory safety. We describe our compiler extensions for LLVM Clang implementing static analysis and subsequent MTE instrumentation. Via a comprehensive evaluation we show that our scheme is effective.",
      "paperUrl": "https://arxiv.org/pdf/2204.03781",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2204.03781",
      "tags": [
        "Security",
        "Clang",
        "Static Analysis"
      ],
      "keywords": [
        "Security",
        "Clang",
        "Static Analysis",
        "LLVM",
        "Memory Safety",
        "Memory Protection",
        "Standard Adversary",
        "World Deterministic Tagging"
      ],
      "matchedAuthors": [
        "Hans Liljestrand",
        "Jan-Erik Ekberg",
        "N. Asokan",
        "Rémi Denis-Courmont"
      ]
    },
    {
      "id": "openalex-w4308067463",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Co-optimizing Dataflow Graphs and Actors with MLIR",
      "authors": [
        {
          "name": "Pedro Ciambra",
          "affiliation": "Universidade Estadual de Campinas (UNICAMP)"
        },
        {
          "name": "Mickacl Dardaillon",
          "affiliation": "Institut d'Électronique et des Technologies du numéRique"
        },
        {
          "name": "Maxime Pelcat",
          "affiliation": "Institut d'Électronique et des Technologies du numéRique"
        },
        {
          "name": "Hervé Yviquel",
          "affiliation": "Universidade Estadual de Campinas (UNICAMP)"
        }
      ],
      "year": "2022",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "Dataflow programming is considered a good solution for the implementation of parallel signal processing applications. However, the strict separation between kernel and coordination codes limits the variety of possible optimizations and the compatibility with state-of-the-art compiler frameworks. We present a prototype static dataflow compiler, built with the LLVM MLIR framework, that overcomes these limitations and enables a previously impossible combination of optimization strategies that leverages information from the dataflow topology. Initial results show 30% wall time improvement and 53% memory usage improvement on a video processing workload.",
      "paperUrl": "https://doi.org/10.1109/sips55645.2022.9919213",
      "sourceUrl": "",
      "tags": [
        "Optimizations",
        "MLIR"
      ],
      "keywords": [
        "Optimizations",
        "MLIR",
        "LLVM",
        "Optimizing Dataflow Graphs"
      ],
      "matchedAuthors": [
        "Hervé Yviquel"
      ]
    },
    {
      "id": "openalex-w4296131215",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Automatic Creation of High-Bandwidth Memory Architectures from Domain-Specific Languages: The Case of Computational Fluid Dynamics",
      "authors": [
        {
          "name": "Stephanie Soldavini",
          "affiliation": "Politecnico di Milano"
        },
        {
          "name": "Karl F. A. Friebel",
          "affiliation": "Technische Universität Dresden"
        },
        {
          "name": "Mattia Tibaldi",
          "affiliation": "Politecnico di Milano"
        },
        {
          "name": "Gerald Hempel",
          "affiliation": "Technische Universität Dresden"
        },
        {
          "name": "Jerónimo Castrillón",
          "affiliation": "Technische Universität Dresden"
        },
        {
          "name": "Christian Pilato",
          "affiliation": "Politecnico di Milano"
        }
      ],
      "year": "2022",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Numerical simulations can help solve complex problems. Most of these algorithms are massively parallel and thus good candidates for FPGA acceleration thanks to spatial parallelism. Modern FPGA devices can leverage high-bandwidth memory technologies, but when applications are memory-bound designers must craft advanced communication and memory architectures for efficient data movement and on-chip storage. This development process requires hardware design skills that are uncommon in domain-specific experts. In this paper, we propose an automated tool flow from a domain-specific language (DSL) for tensor expressions to generate massively-parallel accelerators on HBM-equipped FPGAs. Designers can use this flow to integrate and evaluate various compiler or hardware optimizations. We use computational fluid dynamics (CFD) as a paradigmatic example. Our flow starts from the high-level specification of tensor operations and combines an MLIR-based compiler with an in-house hardware generation flow to generate systems with parallel accelerators and a specialized memory architecture that moves data efficiently, aiming at fully exploiting the available CPU-FPGA bandwidth. We simulated applications with millions of elements, achieving up to 103 GFLOPS with one compute unit and custom precision when targeting a Xilinx Alveo U280. Our FPGA implementation is up to 25x more energy-efficient than expert-crafted Intel CPU implementations.",
      "paperUrl": "https://arxiv.org/pdf/2203.10850",
      "sourceUrl": "https://doi.org/10.1145/3563553",
      "tags": [
        "Optimizations",
        "MLIR"
      ],
      "keywords": [
        "Optimizations",
        "MLIR",
        "Memory Architectures",
        "Domain Specific Languages",
        "Computational Fluid Dynamics",
        "Bandwidth Memory Architectures",
        "Hardware",
        "Massively Parallel",
        "Parallel Accelerators",
        "CPU"
      ],
      "matchedAuthors": [
        "Christian Pilato",
        "Jerónimo Castrillón",
        "Karl F. A. Friebel",
        "Stephanie Soldavini"
      ]
    },
    {
      "id": "openalex-w4285048973",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Automated Scheduling Algorithm Selection and Chunk Parameter Calculation in OpenMP",
      "authors": [
        {
          "name": "Ali Mohammed",
          "affiliation": ""
        },
        {
          "name": "Jonas H. Müller Korndörfer",
          "affiliation": "University of Basel"
        },
        {
          "name": "Ahmed Eleliemy",
          "affiliation": "University of Basel"
        },
        {
          "name": "Florina M. Ciorba",
          "affiliation": "University of Basel"
        }
      ],
      "year": "2022",
      "publication": "IEEE Transactions on Parallel and Distributed Systems",
      "venue": "IEEE Transactions on Parallel and Distributed Systems | Vol. 33 (Issue 12)",
      "type": "research-paper",
      "abstract": "Increasing node and cores-per-node counts in supercomputers render scheduling and load balancing critical for exploiting parallelism. OpenMP applications can achieve high performance via careful selection of scheduling kind and chunk parameters on a per-loop, per-application, and per-system basis from a portfolio of advanced scheduling algorithms (Korndörfer et al. , 2022). This selection approach is time-consuming, challenging, and may need to change during execution. We propose Auto4OMP , a novel approach for automated load balancing of OpenMP applications. With Auto4OMP, we introduce three scheduling algorithm selection methods and an expert-defined chunk parameter for OpenMP's schedule clause's kind and chunk , respectively. Auto4OMP extends the OpenMP schedule(auto) and chunk parameter implementation in LLVM's OpenMP runtime library to automatically select a scheduling algorithm and calculate a chunk parameter during execution. Loop characteristics are inferred in Auto4OMP from the loop execution over the application's time-steps. The experiments performed in this work show that Auto4OMP improves applications performance by up to 11 % compared to LLVM's schedule(auto) implementation and outperforms manual selection. Auto4OMP improves MPI+OpenMP applications performance by explicitly minimizing thread- and implicitly reducing process-load imbalance.",
      "paperUrl": "https://ieeexplore.ieee.org/ielx7/71/9790018/09825675.pdf",
      "sourceUrl": "https://doi.org/10.1109/tpds.2022.3189270",
      "tags": [
        "Performance"
      ],
      "keywords": [
        "Performance",
        "LLVM",
        "OpenMP",
        "Chunk Parameter Calculation",
        "Auto4omp Improves",
        "Selection",
        "Schedule Auto",
        "Load Balancing",
        "Automated Scheduling"
      ],
      "matchedAuthors": [
        "Ahmed Eleliemy",
        "Ali Mohammed",
        "Florina M. Ciorba",
        "Jonas H. Müller Korndörfer"
      ]
    },
    {
      "id": "openalex-w4225821315",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "An LLVM-based C++ Compiler Toolchain for Variational Hybrid Quantum-Classical Algorithms and Quantum Accelerators",
      "authors": [
        {
          "name": "Pradnya Khalate",
          "affiliation": ""
        },
        {
          "name": "Xin-Chuan Wu",
          "affiliation": ""
        },
        {
          "name": "Shavindra Premaratne",
          "affiliation": ""
        },
        {
          "name": "Justin Hogaboam",
          "affiliation": ""
        },
        {
          "name": "Adam Holmes",
          "affiliation": ""
        },
        {
          "name": "Albert Schmitz",
          "affiliation": ""
        },
        {
          "name": "Gian Giacomo Guerreschi",
          "affiliation": ""
        },
        {
          "name": "Xiang Zou",
          "affiliation": ""
        },
        {
          "name": "A. Y. Matsuura",
          "affiliation": ""
        }
      ],
      "year": "2022",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Variational algorithms are a representative class of quantum computing workloads that combine quantum and classical computing. This paper presents an LLVM-based C++ compiler toolchain to efficiently execute variational hybrid quantum-classical algorithms on a computational system in which the quantum device acts as an accelerator. We introduce a set of extensions to the C++ language for programming these algorithms. We define a novel Executable and Linking Format (ELF) for Quantum and create a quantum device compiler component in the LLVM framework to compile the quantum part of the C++ source and reuse the host compiler in the LLVM framework to compile the classical computing part of the C++ source. A variational algorithm runs a quantum circuit repeatedly, each time with different gate parameters. We add to the quantum runtime the capability to execute dynamically a quantum circuit with different parameters. Thus, programmers can call quantum routines the same way as classical routines. With these capabilities, a variational hybrid quantum-classical algorithm can be specified in a single-source code and only needs to be compiled once for all iterations. The single compilation significantly reduces the execution latency of variational algorithms. We evaluate the framework's performance by running quantum circuits that prepare Thermofield Double (TFD) states, a quantum-classical variational algorithm.",
      "paperUrl": "https://arxiv.org/pdf/2202.11142",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2202.11142",
      "tags": [
        "Performance",
        "Infrastructure",
        "Quantum Computing"
      ],
      "keywords": [
        "Performance",
        "Infrastructure",
        "Quantum Computing",
        "LLVM",
        "Quantum Compilation",
        "Quantum Circuit",
        "Hybrid Quantum Classical",
        "Variational Hybrid Quantum",
        "Compiler Toolchain",
        "Classical Computing",
        "Quantum Device",
        "Quantum Accelerators"
      ],
      "matchedAuthors": [
        "Shavindra Premaratne",
        "Xin-Chuan Wu"
      ]
    },
    {
      "id": "openalex-w4307993381",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Adaptive Query Compilation in Graph Databases",
      "authors": [
        {
          "name": "Alexander Baumstark",
          "affiliation": "Technische Universität Ilmenau"
        },
        {
          "name": "Muhammad Attahir Jibril",
          "affiliation": "Technische Universität Ilmenau"
        },
        {
          "name": "Kai-Uwe Sattler",
          "affiliation": "Technische Universität Ilmenau"
        }
      ],
      "year": "2022",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "<title>Abstract</title> Compiling database queries into compact and efficient machine code has proven to be a great technique to improve query performance and to exploit characteristics of modern hardware. Particularly for graph database queries, which often execute the same instructions for processing, this technique can lead to an improvement. Furthermore, compilation frameworks like LLVM provide powerful optimization techniques and support different backends. However, the time for generating and optimizing machine code becomes an issue for short-running queries or queries which could produce early results quickly.In this work, we present an adaptive approach integrating graph query interpretation and compilation. While query compilation and code generation are running in the background, the query execution starts using the interpreter. As soon as the code generation is finished, the execution switches to the compiled code. Our evaluation shows that autonomously switching execution modes helps to hide compilation times and additionally the additional latencies of the underlying storage.",
      "paperUrl": "https://www.researchsquare.com/article/rs-2223228/latest.pdf",
      "sourceUrl": "https://doi.org/10.21203/rs.3.rs-2223228/v1",
      "tags": [
        "Backend",
        "Performance",
        "Optimizations"
      ],
      "keywords": [
        "Backend",
        "Performance",
        "Optimizations",
        "LLVM",
        "Code Generation",
        "Adaptive Query Compilation",
        "Database Queries",
        "Graph Databases"
      ],
      "matchedAuthors": [
        "Alexander Baumstark",
        "Kai-Uwe Sattler",
        "Muhammad Attahir Jibril"
      ]
    },
    {
      "id": "openalex-w4292000848",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Accelerating Task-based Iterative Applications",
      "authors": [
        {
          "name": "David Álvarez",
          "affiliation": ""
        },
        {
          "name": "Vicenç Beltrán",
          "affiliation": ""
        }
      ],
      "year": "2022",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Task-based programming models have risen in popularity as an alternative to traditional fork-join parallelism. They are better suited to write applications with irregular parallelism that can present load imbalance. However, these programming models suffer from overheads related to task creation, scheduling and dependency management, limiting performance and scalability when tasks become too small. At the same time, many HPC applications implement iterative methods or multi-step simulations that create the same directed acyclic graphs of tasks on each iteration. By giving application programmers a way to express that a specific loop is creating the same task pattern on each iteration, we can create a single task DAG once and transform it into a cyclic graph. This cyclic graph is then reused for successive iterations, minimizing task creation and dependency management overhead. This paper presents the taskiter, a new construct we propose for the OmpSs-2 and OpenMP programming models, allowing the use of directed cyclic task graphs (DCTG) to minimize runtime overheads. Moreover, we present a simple immediate successor locality-aware heuristic that minimizes task scheduling overhead by bypassing the runtime task scheduler. We evaluate the implementation of the taskiter and the immediate successor heuristic in 8 iterative benchmarks. Using small task granularities, we obtain an average speedup of 3.7x over the reference OmpSs-2 implementation and an average of 5x and 7.46x speedup over the LLVM and GCC OpenMP runtimes, respectively.",
      "paperUrl": "https://arxiv.org/pdf/2208.06332",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2208.06332",
      "tags": [
        "Performance"
      ],
      "keywords": [
        "Performance",
        "LLVM",
        "Iterative",
        "Cyclic Graph",
        "Dependency Management",
        "Immediate Successor",
        "Task Creation",
        "Graphs",
        "OpenMP",
        "Parallelism",
        "Accelerating Task"
      ],
      "matchedAuthors": [
        "David Álvarez",
        "Vicenç Beltrán"
      ]
    },
    {
      "id": "openalex-w4294691697",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "AIWareK: Compiling PyTorch Model for AI Processor Using MLIR Framework",
      "authors": [
        {
          "name": "Hyunjeong Kwon",
          "affiliation": "Electronics and Telecommunications Research Institute"
        },
        {
          "name": "Tae Hyun Kim",
          "affiliation": "Electronics and Telecommunications Research Institute"
        },
        {
          "name": "Chun‐Gi Lyuh",
          "affiliation": "Electronics and Telecommunications Research Institute"
        },
        {
          "name": "Jinkyu Kim",
          "affiliation": "Electronics and Telecommunications Research Institute"
        },
        {
          "name": "Jinho Han",
          "affiliation": "Electronics and Telecommunications Research Institute"
        },
        {
          "name": "Young-Su Kwon",
          "affiliation": "Electronics and Telecommunications Research Institute"
        }
      ],
      "year": "2022",
      "publication": "2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS)",
      "venue": "2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS)",
      "type": "research-paper",
      "abstract": "Deep learning compiler becomes necessary with the active research on AI hardware. This work compiles PyTorch models into target hardware codes using MLIR framework. The compiler first constructs a graph from the PyTorch model using TorchScript tracing. To construct the graph, our domain-specific parser generates an abstract syntax tree using tokens generated from the lexer. Then, the graph IR (GIR) is built and lowered into the kernel IR (KIR) and the processor IR (PIR) in MLIR framework. PIR becomes the input of the backed compiler that generates target machine codes. Experimental result shows that AIWareK compiled ResNet18 in 7.67 seconds, yielding 1.16e-03 mean absolute error.",
      "paperUrl": "https://doi.org/10.1109/aicas54282.2022.9869913",
      "sourceUrl": "",
      "tags": [
        "IR",
        "AI",
        "ML",
        "MLIR"
      ],
      "keywords": [
        "IR",
        "AI",
        "ML",
        "MLIR",
        "Aiwarek Compiling Pytorch",
        "Graph",
        "Hardware"
      ],
      "matchedAuthors": [
        "Hyunjeong Kwon",
        "Jinho Han",
        "Young-Su Kwon"
      ]
    },
    {
      "id": "openalex-w3213257855",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "gnss-sdr/gnss-sdr: GNSS-SDR v0.0.15",
      "authors": [
        {
          "name": "Carles Fernández–Prades",
          "affiliation": "Centre Tecnologic de Telecomunicacions de Catalunya"
        },
        {
          "name": "Javier Arribas",
          "affiliation": "Cancer Targeted Technology (United States)"
        },
        {
          "name": "Damian Miralles",
          "affiliation": "Samsung (South Korea)"
        },
        {
          "name": "mmajoral",
          "affiliation": ""
        },
        {
          "name": "Luis Esteve",
          "affiliation": "Epsilon Systems (United States)"
        },
        {
          "name": "odrisci",
          "affiliation": ""
        },
        {
          "name": "jwmelto",
          "affiliation": ""
        },
        {
          "name": "Álvaro Cebrián Juan",
          "affiliation": ""
        }
      ],
      "year": "2021",
      "publication": "Zenodo (CERN European Organization for Nuclear Research)",
      "venue": "Zenodo (CERN European Organization for Nuclear Research)",
      "type": "research-paper",
      "abstract": "This is a maintenance and bug fix release, with the addition of some minor features. Most relevant changes with respect to the former release are listed below: Improvements in Availability: Added the reading of reduced clock and ephemeris data (CED) in the Galileo E1B INAV message introduced in Galileo OS SIS ICD Issue 2.0. If the reduced CED is available before the full ephemeris set, it is used for PVT computation until the full set has not yet been received. This can contribute to shortening the Time-To-First-Fix. Still experimental. Added the exploitation of the FEC2 Erasure Correction in the Galileo E1B INAV message introduced in Galileo OS SIS ICD Issue 2.0. This can contribute to shortening the Time-To-First-Fix. Since the added computational cost could break some real-time configurations, this feature is disabled by default. Itcan be activated from the configuration file by adding <code>TelemetryDecoder_1B.enable_reed_solomon=true</code>. Reduction of the TTFF in GPS L1 and Galileo E1 by improving the frame synchronization mechanism. Improvements in Maintainability: The Contributor License Agreement (CLA) signing for new contributors has been replaced by a Developer's Certificate of Origin (DCO),which implies that contributed commits in a pull request need to be signed as a manifestation that contributors have the right to submit their work under the open source license indicated in the contributed file(s) (instead of asking them to sign the CLA document). Improved handling of changes in GNU Radio 3.9 FFT API. Improved handling of the filesystem library. Added an abstract class <code>SignalSourceInterface</code> and a common base class <code>SignalSourceBase</code>, which allow removing a lot of duplicated code in Signal Source blocks, and further abstract file-based interfaces behind them. Do not apply clang-tidy fixes to protobuf-generated headers. Refactored private implementation of flow graph connection and disconnection for improved source code readability. Added a base class for GNSS ephemeris, saving some duplicated code and providing a common nomenclature for ephemeris' parameters. New generated XML files make use of the new parameters' names. Update GSL implementation to 0.38.1. See https://github.com/gsl-lite/gsl-lite/releases/tag/v0.38.1 Update references to the latest GPS ICDs (IS-GPS-200M, IS-GPS-800H, IS-GPS-705H) published in May, 2021. Improvements in Portability: Avoid collision of the <code>cpu_features</code> library when installing the <code>volk_gnsssdr</code> library on its own, and VOLK has already installed its version. Added a new building option <code>ENABLE_OWN_CPUFEATURES</code>, defaulting to <code>ON</code> when building <code>gnss-sdr</code> but defaulting to <code>OFF</code> when building a stand-alone version of <code>volk_gnsssdr</code>. When this building option is set to <code>ON</code>, it forces the building of the local version of the <code>cpu_features</code> library, regardless of whether it is already installed or not. CMake's <code>&lt;policy_max&gt;</code> version bumped to 3.21. The minimum CMake version is 2.8.12. Fix building when using the Xcode generator, Xcode &gt;= 12 and CMake &gt;= 3.19. Fix building of FPGA blocks when linking against GNU Radio &gt;= 3.9 and/or Boost &gt;= 1.74. Fix linking of the <code>&lt;filesystem&gt;</code> library when using GCC 8.x and GNU Radio &gt;= 3.8. If the Matio library is not found, now it is configured and built by CMake instead of using autotools. Added support for Apple M1 AArch64 architecture processor and for FreeBSD on x86, improved AMD microarchitecture detection. CMake now selects the C++23 standard if the environment allows for it. Improved detection of Gnuplot and <code>gnss_sim</code> when cross-compiling. NEON kernel implementations of the <code>volk_gnsssdr</code> library are now enabled in aarch64 architectures. Improvements in Reliability Bug fix in the Galileo E1/E5 telemetry decoder that produced incorrect timing information if a satellite is lost and then readquired. Check satellites' health status. If a satellite is marked as not healthy in its navigation message, the corresponding observables are not used for navigation. Improvements in Usability: Added a new <code>Fifo_Signal_Source</code> implementation that allows using a Unix FIFO as a signal source, thus allowing to multiplex signal streams outside of <code>gnss-sdr</code>, letting another program hold access to the receiver, or allowing signal sources that are not supported by <code>gnss-sdr</code> but can dump the signal to a FIFO. Avoid segmentation faults in the flow graph connection and/or starting due to some common inconsistencies in the configuration file. Provide hints to the user in case of failed flow graph connection due to inconsistencies in the configuration file. Fix segmentation fault if the RINEX output was disabled. Added a feature that optionally enables the remote monitoring of GPS and Galileo ephemeris using UDP and Protocol Buffers. Now building the software passing the <code>-DENABLE_FPGA=ON</code> to CMake does not make the receiver unusable when running on non-FPGA-enabled platforms. On FPGA-enabled platforms, now it is possible to run non-FPGA-enabled configurations. Fix bug that made the Monitor block to always set to 0 the <code>carrier_phase_rads</code> parameter value. The <code>Labsat_Signal_Source</code> implementation of the <code>SignalSource</code> block now can read files in the LabSat 3 Wideband format (<code>.LS3W</code>). When using this format, this source block can provide multiple RF chain outputs. Replace <code>Receiver.sources_count</code> configuration parameter name by <code>GNSS-SDR.num_sources</code>. The former parameter name is still read to ensure backward compatibility with configuration files using that nomenclature. Fix bug in searching for gr-iio when CMake was re-run several times with different settings for the <code>-DENABLE_FMCOMMS2</code> or <code>-DENABLE_PLUTOSDR</code> building options. Fix building when using UHD &gt;= v4.0.0.0. Fix building for <code>-DENABLE_FMCOMMS2=ON</code> and/or <code>-DENABLE_PLUTOSDR=ON</code> when the built-in gr-iio module introduced in GNU Radio 3.10 is found. This in-tree GNU Radio module takes precedence over the gr-iio package provided at https://github.com/analogdevicesinc/gr-iio. If the GNU Radio module is found, the other one is ignored. File <code>changelog.md</code> renamed to the more usual <code>CHANGELOG.md</code> uppercase name. New global configuration parameter <code>GNSS-SDR.observable_interval_ms</code>, set by default to 20 [ms], allows to control the internal rate at which computed observables sets are processed (50 observables sets per second by default). Fix bug in the <code>Monitor.decimation_factor</code> parameter, which was not working properly for other values than 1. See the definitions of concepts and metrics at https://gnss-sdr.org/design-forces/",
      "paperUrl": "https://zenodo.org/record/5242839",
      "sourceUrl": "https://doi.org/10.5281/zenodo.5242839",
      "tags": [
        "Clang"
      ],
      "keywords": [
        "Clang",
        "Gnss Sdr",
        "Gnu Radio",
        "Galileo",
        "Library",
        "Signal",
        "Configuration File",
        "Fix Building",
        "Flow Graph Connection",
        "Denable",
        "Ephemeris",
        "Improvements",
        "Parameter",
        "Version"
      ],
      "matchedAuthors": [
        "Carles Fernández–Prades",
        "Damian Miralles",
        "Javier Arribas",
        "Luis Esteve",
        "mmajoral",
        "odrisci",
        "Álvaro Cebrián Juan"
      ]
    },
    {
      "id": "openalex-w3210003329",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "gnss-sdr/gnss-sdr: GNSS-SDR v0.0.14",
      "authors": [
        {
          "name": "Carles Fernández–Prades",
          "affiliation": "Centre Tecnologic de Telecomunicacions de Catalunya"
        },
        {
          "name": "Javier Arribas",
          "affiliation": "Cancer Targeted Technology (United States)"
        },
        {
          "name": "Gabriel Araújo",
          "affiliation": ""
        },
        {
          "name": "antonioramosdet",
          "affiliation": ""
        },
        {
          "name": "Damian Miralles",
          "affiliation": "University of Colorado Boulder"
        },
        {
          "name": "mmajoral",
          "affiliation": "Cancer Targeted Technology (United States)"
        },
        {
          "name": "Luis Esteve",
          "affiliation": "Epsilon Systems (United States)"
        },
        {
          "name": "odrisci",
          "affiliation": ""
        },
        {
          "name": "Piyush Gupta",
          "affiliation": ""
        },
        {
          "name": "Anthony Arnold",
          "affiliation": ""
        },
        {
          "name": "Álvaro Cebrián Juan",
          "affiliation": ""
        },
        {
          "name": "marc-sales",
          "affiliation": ""
        },
        {
          "name": "Andrés Cecilia Luque",
          "affiliation": ""
        },
        {
          "name": "SergiSeguraMunoz",
          "affiliation": ""
        },
        {
          "name": "Josh Schindehette",
          "affiliation": "Takara (United States)"
        },
        {
          "name": "marabra",
          "affiliation": ""
        },
        {
          "name": "Gerald LaMountain",
          "affiliation": "Spiral Foundation"
        },
        {
          "name": "Osqzss",
          "affiliation": ""
        },
        {
          "name": "Zosoworld",
          "affiliation": ""
        },
        {
          "name": "L Marc",
          "affiliation": ""
        },
        {
          "name": "lmne",
          "affiliation": ""
        },
        {
          "name": "Bitsulia Dmitry",
          "affiliation": ""
        },
        {
          "name": "Michael Dickens",
          "affiliation": ""
        },
        {
          "name": "Sergey",
          "affiliation": ""
        },
        {
          "name": "TurbineEngine",
          "affiliation": ""
        },
        {
          "name": "Academias It",
          "affiliation": "Instituto Nacional de Capacitación Profesional"
        },
        {
          "name": "Dawei Sun",
          "affiliation": "International University of the Caribbean"
        },
        {
          "name": "Usman Haider",
          "affiliation": ""
        }
      ],
      "year": "2021",
      "publication": "Zenodo (CERN European Organization for Nuclear Research)",
      "venue": "Zenodo (CERN European Organization for Nuclear Research)",
      "type": "research-paper",
      "abstract": "This is a maintenance and bug fix release. Most relevant changes with respect to the former release are listed below: Improvements in Availability: Fixed bug in acquisition detection when the configuration parameter <code>Acquisition_XX.threshold</code> was set but <code>Acquisition_XX.pfa</code> was not, causing false locks. Fixed anti-jamming filters: <code>Pulse_Blanking_Filter</code>, <code>Notch_Filter</code> and <code>Notch_Filter_Lite</code>. Improvements in Efficiency: Faster <code>SignalConditioner</code> block when its implementation is set to <code>Pass_Through</code>. Improvements in Interoperability: Added the Galileo E6 B/C signal structure based on E6-B/C Codes Technical Note, Issue 1, January 2019, including Acquisition and Tracking blocks. The Telemetry Decoder is still empty (only the CRC is checked, based on Galileo High Accuracy Service E6-B Signal-In-Space Message Specification v1.2, April 2020). Improvements in Maintainability: Added a common shared pointer definition <code>gnss_shared_ptr</code>, which allows to handle the <code>boost::shared_ptr</code> to <code>std::shared_ptr</code> transition in GNU Radio 3.9 API more nicely. Support new FFT and firdes blocks' API in GNU Radio 3.9. Added detection of inconsistent function prototypes in <code>volk_gnsssdr</code> library kernels at compile time. Fixed defects detected by clang-tidy check <code>bugprone-reserved-identifier</code>, and added to the checks list. This check corresponds to CERT C Coding Standard rule DCL37-C as well as its C++ counterpart, DCL51-CPP. Applied and added more clang-tidy checks related to readability: <code>readability-make-member-function-const</code> and <code>readability-qualified-auto</code>. Improvements in Portability: Fixed <code>-DENABLE_OWN_GLOG=ON</code> building option when gflags is installed and it is older than v2.1.2 (<em>e.g.</em>, in CentOS 7). Improved handling of old gflags versions, minimum version set to 2.1.2. Replaced <code>google::</code> by <code>gflags::</code> namespace when using functions of the gflags library. Replaced <code>git://</code> by <code>https://</code> as the used protocol when downloading Gflags, so it can work through firewalls requiring authentication. Fixed static linking of the matio library when downloaded and built by CMake. Improved CPU feature detection by switching to Google's cpu_features library: The <code>volk_gnsssdr</code> library had its own CPU feature detection methods, which were not totally reliable and difficult to implement across compilers and OSes. This is now handled by the <code>cpu_features</code> library, thus building upon that expertise. Since that library has higher dependency version requirements than GNSS-SDR, the old method is still used in old development environments. No extra dependency is needed. This change is transparent to the user, since everything is managed by the CMake scripts. The <code>volk_gnsssdr</code> library can be built on Microsoft Windows and can execute SIMD instructions on that OS. Removed all instances of <code>_mm256_zeroupper()</code> in the <code>volk_gnsssdr</code> library, since they are not required and lead to miscompilation with GCC 10.2 and optimization level <code>-O3</code>. Fixed building with <code>-DENABLE_CUDA=ON</code> for blocks implemented with CUDA. Fixed linking against the ORC library if it is present in the system. Fixed a bug introduced in v0.0.13 that prevented getting Galileo-only PVT fixes in some environments. Fixed duplication of protobuf build tree if it was locally built and then installed with DESTDIR variable set. Improvements in Usability: Fixed a bug when enabling pseudorange carrier smoothing in other bands than L1. If <code>SignalConditioner.implementation=Pass_Through</code>, then all the configuration parameters for the <code>DataTypeAdapter</code>, <code>InputFilter</code> and <code>Resampler</code> blocks are ignored. This was the default behavior in GNSS-SDR v0.0.12, but it changed in v0.0.13. This change recovers the old behavior. Fixed occasional segmentation fault when exiting with <code>q</code> + <code>[Enter]</code> keys if <code>Acquisition_XX.blocking=false</code>. Fixed the termination of the receiver with <code>q</code> + <code>[Enter]</code> keys when using the <code>Osmosdr_Signal_Source</code> implementation of the <code>SignalSource</code> block. The <code>Labsat_Signal_Source</code> implementation of the <code>SignalSource</code> block now can be throttled with the new parameters <code>SignalSource.enable_throttle_control</code> and <code>SignalSource.throttle_frequency_sps</code>, thus allowing the emulation of real-time operation. Improved General Block diagram, both in content and in image resolution. The <code>Custom_UDP_Signal_Source</code> implementation now accepts <code>SignalSource.sample_type=cfloat</code>, in addition to the existing 4 and 8-bit length sample types. Fixed the <code>obsdiff</code> and <code>rinex2assist</code> utilities when installed if they were built with a locally downloaded version of GPSTk. The generated HTML documentation now makes use of the Doxygen grouping feature. Improved rendering of equations in HTML documentation generated by Doxygen. Make use of MathJax for equation rendering. Added new building option <code>ENABLE_EXTERNAL_MATHJAX</code>, set to <code>ON</code> by default. If set to <code>OFF</code>, it allows using a local installation of MathJax 2. Improved dumps in Telemetry Decoding blocks. Now they include the raw navigation message bits. If <code>TelemetryDecoder_XX.dump=true</code>, the resulting <code>.dat</code> binary file is also delivered in <code>.mat</code> format, which is readable from Matlab and Python. See the definitions of concepts and metrics at https://gnss-sdr.org/design-forces/",
      "paperUrl": "https://zenodo.org/record/4428100",
      "sourceUrl": "https://doi.org/10.5281/zenodo.4428100",
      "tags": [
        "Clang",
        "Optimizations",
        "Autovectorization",
        "CUDA"
      ],
      "keywords": [
        "Clang",
        "Optimizations",
        "Autovectorization",
        "CUDA",
        "SIMD",
        "Library",
        "Improvements",
        "Volk Gnsssdr",
        "Acquisition",
        "Blocks",
        "Gflags",
        "Signalsource",
        "Shared Ptr",
        "CPU"
      ],
      "matchedAuthors": [
        "Academias It",
        "Andrés Cecilia Luque",
        "Anthony Arnold",
        "Carles Fernández–Prades",
        "Damian Miralles",
        "Gabriel Araújo",
        "Gerald LaMountain",
        "Javier Arribas",
        "L Marc",
        "Luis Esteve",
        "Michael Dickens",
        "Osqzss",
        "Sergey",
        "Usman Haider",
        "Zosoworld",
        "antonioramosdet",
        "lmne",
        "marabra",
        "marc-sales",
        "mmajoral",
        "odrisci",
        "Álvaro Cebrián Juan"
      ]
    },
    {
      "id": "openalex-w4286965913",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "VIA: Analyzing Device Interfaces of Protected Virtual Machines",
      "authors": [
        {
          "name": "Felicitas Hetzelt",
          "affiliation": ""
        },
        {
          "name": "Martin Radev",
          "affiliation": ""
        },
        {
          "name": "Robert Buhren",
          "affiliation": ""
        },
        {
          "name": "Mathias Morbitzer",
          "affiliation": ""
        },
        {
          "name": "Jean‐Pierre Seifert",
          "affiliation": ""
        }
      ],
      "year": "2021",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Both AMD and Intel have presented technologies for confidential computing in cloud environments. The proposed solutions - AMD SEV (-ES, -SNP) and Intel TDX - protect Virtual Machines (VMs) against attacks from higher privileged layers through memory encryption and integrity protection. This model of computation draws a new trust boundary between virtual devices and the VM, which in so far lacks thorough examination. In this paper, we therefore present an analysis of the virtual device interface and discuss several attack vectors against a protected VM. Further, we develop and evaluate VIA, an automated analysis tool to detect cases of improper sanitization of input recieved via the virtual device interface. VIA improves upon existing approaches for the automated analysis of device interfaces in the following aspects: (i) support for virtualization relevant buses, (ii) efficient Direct Memory Access (DMA) support and (iii) performance. VIA builds upon the Linux Kernel Library and clang's libfuzzer to fuzz the communication between the driver and the device via MMIO, PIO, and DMA. An evaluation of VIA shows that it performs 570 executions per second on average and improves performance compared to existing approaches by an average factor of 2706. Using VIA, we analyzed 22 drivers in Linux 5.10.0-rc6, thereby uncovering 50 bugs and initiating multiple patches to the virtual device driver interface of Linux. To prove our findings criticality under the threat model of AMD SEV and Intel TDX, we showcase three exemplary attacks based on the bugs found. The attacks enable a malicious hypervisor to corrupt the memory and gain code execution in protected VMs with SEV-ES and are theoretically applicable to SEV-SNP and TDX.",
      "paperUrl": "https://arxiv.org/pdf/2109.10660",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2109.10660",
      "tags": [
        "Performance",
        "Clang",
        "Testing"
      ],
      "keywords": [
        "Performance",
        "Clang",
        "Testing",
        "Fuzzing",
        "Analyzing Device Interfaces",
        "Virtual Device Interface",
        "Protected Virtual Machines",
        "Attacks",
        "Memory",
        "Amd Sev",
        "Intel Tdx"
      ],
      "matchedAuthors": [
        "Felicitas Hetzelt"
      ]
    },
    {
      "id": "openalex-w3206733312",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "VESPA: static profiling for binary optimization",
      "authors": [
        {
          "name": "Angélica Aparecida Moreira",
          "affiliation": "Universidade Federal de Minas Gerais"
        },
        {
          "name": "Guilherme Ottoni",
          "affiliation": "Meta (United States)"
        },
        {
          "name": "Fernando Magno Quintão Pereira",
          "affiliation": "Universidade Federal de Minas Gerais"
        }
      ],
      "year": "2021",
      "publication": "Proceedings of the ACM on Programming Languages",
      "venue": "Proceedings of the ACM on Programming Languages | Vol. 5 (Issue OOPSLA)",
      "type": "research-paper",
      "abstract": "Over the past few years, there has been a surge in the popularity of binary optimizers such as BOLT, Propeller, Janus and HALO. These tools use dynamic profiling information to make optimization decisions. Although effective, gathering runtime data presents developers with inconveniences such as unrepresentative inputs, the need to accommodate software modifications, and longer build times. In this paper, we revisit the static profiling technique proposed by Calder et al. in the late 90’s, and investigate its application to drive binary optimizations, in the context of the BOLT binary optimizer, as a replacement for dynamic profiling. A few core modifications to Calder et al.’s original proposal, consisting of new program features and a new regression model, are sufficient to enable some of the gains obtained through runtime profiling. An evaluation of BOLT powered by our static profiler on four large benchmarks (clang, GCC, MySQL and PostgreSQL) yields binaries that are 5.47 % faster than the executables produced by clang -O3.",
      "paperUrl": "https://dl.acm.org/doi/pdf/10.1145/3485521",
      "sourceUrl": "https://doi.org/10.1145/3485521",
      "tags": [
        "Clang",
        "Optimizations",
        "Programming Languages"
      ],
      "keywords": [
        "Clang",
        "Optimizations",
        "Programming Languages",
        "Binary",
        "Binary Optimization"
      ],
      "matchedAuthors": [
        "Fernando Magno Quintão Pereira",
        "Guilherme Ottoni"
      ]
    },
    {
      "id": "openalex-w3138340026",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Using MLIR Framework for Codesign of ML Architectures Algorithms and Simulation Tools",
      "authors": [
        {
          "name": "Cannada Lewis",
          "affiliation": "Sandia National Laboratories California"
        },
        {
          "name": "Clayton Hughes",
          "affiliation": "Sandia National Laboratories California"
        },
        {
          "name": "Simon David Hammond",
          "affiliation": "Sandia National Laboratories California"
        },
        {
          "name": "Sivasankaran Rajamanickam",
          "affiliation": "Sandia National Laboratories California"
        }
      ],
      "year": "2021",
      "publication": "OSTI OAI (U.S. Department of Energy Office of Scientific and Technical Information)",
      "venue": "OSTI OAI (U.S. Department of Energy Office of Scientific and Technical Information)",
      "type": "research-paper",
      "abstract": "MLIR (Multi-Level Intermediate Representation), is an extensible compiler framework that supports high-level data structures and operation constructs. These higher-level code representations are particularly applicable to the artificial intelligence and machine learning (AI/ML) domain, allowing developers to more easily support upcoming heterogeneous AI/ML accelerators and develop flexible domain specific compilers/frameworks with higher-level intermediate representations (IRs) and advanced compiler optimizations. The result of using MLIR within the LLVM compiler framework is expected to yield significant improvement in the quality of generated machine code, which in turn will result in improved performance and hardware efficiency",
      "paperUrl": "https://www.osti.gov/biblio/1764336",
      "sourceUrl": "https://doi.org/10.2172/1764336",
      "tags": [
        "Performance",
        "Optimizations",
        "IR",
        "AI",
        "ML",
        "MLIR"
      ],
      "keywords": [
        "Performance",
        "Optimizations",
        "IR",
        "AI",
        "ML",
        "MLIR",
        "LLVM",
        "Intermediate Representation",
        "ML Architectures"
      ],
      "matchedAuthors": [
        "Cannada Lewis",
        "Sivasankaran Rajamanickam"
      ]
    },
    {
      "id": "openalex-w3162301386",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Unleashing Coveraged-Based Fuzzing Through Comprehensive, Efficient, and Faithful Exploitable-Bug Exposing",
      "authors": [
        {
          "name": "Bowen Wang",
          "affiliation": "University of Minnesota"
        },
        {
          "name": "Kangjie Lu",
          "affiliation": "University of Minnesota"
        },
        {
          "name": "Qiushi Wu",
          "affiliation": "University of Minnesota"
        },
        {
          "name": "Aditya Pakki",
          "affiliation": "University of Minnesota"
        }
      ],
      "year": "2021",
      "publication": "IEEE Transactions on Dependable and Secure Computing",
      "venue": "IEEE Transactions on Dependable and Secure Computing | Vol. 19 (Issue 5)",
      "type": "research-paper",
      "abstract": "Fuzzing has become an essential means of finding software bugs. Bug finding through fuzzing requires two parts—exploring code paths to reach bugs and exposing bugs when they are reached. Existing fuzzing research has primarily focused on improving code coverage but not on exposing bugs. Sanitizers such as AddressSanitizer (ASAN) and MemorySanitizer (MSAN) have been the dominating tools for exposing bugs. However, sanitizer-based bug exposing has the following limitations. (1) sanitizers are not compatible with each other. (2) sanitizers incur significant runtime overhead. (3) sanitizers may generate false positives, and (4) exposed bugs may not be exploitable. To address these limitations, we propose <sc xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Expozzer</small> , a fuzzing system that can expose bugs comprehensively, efficiently, and faithfully. The intuition of <sc xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Expozzer</small> is to detect bugs through divergences in a properly diversified dual-execution environment, which does not require maintaining or checking execution metadata. We design a practical and deterministic dual-execution engine, a co-design for dual-execution and fuzzers, bug-sensitive diversification, comprehensive, and efficient divergence detection to ensure the effectiveness of <sc xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Expozzer</small> . The results of evaluations show that <sc xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Expozzer</small> can detect not only CVE-assigned vulnerabilities reliably, but also new vulnerabilities in well-tested real-world programs. <sc xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Expozzer</small> is 10 times faster than MemorySanitizer and is similar to AddressSanitizer.",
      "paperUrl": "https://doi.org/10.1109/tdsc.2021.3079857",
      "sourceUrl": "",
      "tags": [
        "Testing"
      ],
      "keywords": [
        "Testing",
        "Fuzzing",
        "Sanitizers",
        "Dual Execution",
        "Exposing Bugs",
        "Exploitable Bug Exposing",
        "Addresssanitizer",
        "Memorysanitizer",
        "Faithful Exploitable Bug",
        "Unleashing Coveraged"
      ],
      "matchedAuthors": [
        "Aditya Pakki",
        "Kangjie Lu",
        "Qiushi Wu"
      ]
    },
    {
      "id": "openalex-w3199708547",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Union: A Unified HW-SW Co-Design Ecosystem in MLIR for Evaluating Tensor Operations on Spatial Accelerators",
      "authors": [
        {
          "name": "Geonhwa Jeong",
          "affiliation": ""
        },
        {
          "name": "Gökçen Kestor",
          "affiliation": ""
        },
        {
          "name": "Prasanth Chatarasi",
          "affiliation": ""
        },
        {
          "name": "Angshuman Parashar",
          "affiliation": ""
        },
        {
          "name": "Po-An Tsai",
          "affiliation": ""
        },
        {
          "name": "Sivasankaran Rajamanickam",
          "affiliation": ""
        },
        {
          "name": "Roberto Gioiosa",
          "affiliation": ""
        },
        {
          "name": "Tushar Krishna",
          "affiliation": ""
        }
      ],
      "year": "2021",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "To meet the extreme compute demands for deep learning across commercial and scientific applications, dataflow accelerators are becoming increasingly popular. While these \"domain-specific\" accelerators are not fully programmable like CPUs and GPUs, they retain varying levels of flexibility with respect to data orchestration, i.e., dataflow and tiling optimizations to enhance efficiency. There are several challenges when designing new algorithms and mapping approaches to execute the algorithms for a target problem on new hardware. Previous works have addressed these challenges individually. To address this challenge as a whole, in this work, we present a HW-SW co-design ecosystem for spatial accelerators called Union within the popular MLIR compiler infrastructure. Our framework allows exploring different algorithms and their mappings on several accelerator cost models. Union also includes a plug-and-play library of accelerator cost models and mappers which can easily be extended. The algorithms and accelerator cost models are connected via a novel mapping abstraction that captures the map space of spatial accelerators which can be systematically pruned based on constraints from the hardware, workload, and mapper. We demonstrate the value of Union for the community with several case studies which examine offloading different tensor operations(CONV/GEMM/Tensor Contraction) on diverse accelerator architectures using different mapping schemes.",
      "paperUrl": "https://arxiv.org/pdf/2109.07419",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2109.07419",
      "tags": [
        "Optimizations",
        "GPU",
        "Infrastructure",
        "ML",
        "MLIR"
      ],
      "keywords": [
        "Optimizations",
        "GPU",
        "Infrastructure",
        "ML",
        "MLIR",
        "Offloading",
        "Spatial Accelerators",
        "Accelerator Cost",
        "Evaluating Tensor Operations",
        "Several",
        "Hardware"
      ],
      "matchedAuthors": [
        "Sivasankaran Rajamanickam"
      ]
    },
    {
      "id": "openalex-w3196156237",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Towards Automatic and Agile AI/ML Accelerator Design with End-to-End Synthesis",
      "authors": [
        {
          "name": "Jeff Zhang",
          "affiliation": "Harvard University Press"
        },
        {
          "name": "Nícolas Bohm Agostini",
          "affiliation": "Pacific Northwest National Laboratory"
        },
        {
          "name": "Shihao Song",
          "affiliation": "Pacific Northwest National Laboratory"
        },
        {
          "name": "Cheng Tan",
          "affiliation": "Pacific Northwest National Laboratory"
        },
        {
          "name": "Ankur Limaye",
          "affiliation": "Pacific Northwest National Laboratory"
        },
        {
          "name": "Vinay Amatya",
          "affiliation": "Pacific Northwest National Laboratory"
        },
        {
          "name": "Joseph Manzano",
          "affiliation": "Pacific Northwest National Laboratory"
        },
        {
          "name": "Marco Minutoli",
          "affiliation": "Pacific Northwest National Laboratory"
        },
        {
          "name": "Vito Giovanni Castellana",
          "affiliation": "Pacific Northwest National Laboratory"
        },
        {
          "name": "Antonino Tumeo",
          "affiliation": "Pacific Northwest National Laboratory"
        },
        {
          "name": "Gu-Yeon Wei",
          "affiliation": "Harvard University Press"
        },
        {
          "name": "David Brooks",
          "affiliation": "Harvard University Press"
        }
      ],
      "year": "2021",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "Domain-specific designs offer greater energy efficiency and performance gain than general-purpose processors. For this reason, modern system-on-chips have a significant portion of their silicon area with custom accelerators. However, designing hardware by hand is laborious and time-consuming, given the large design space and the performance, power, and area constraints that are not realized in the software. Moreover, domain-specific algorithms (e.g., machine learning models) are evolving quickly, challenging the accelerator design further. To address these issues, this paper presents SODA Synthesizer, an automated open-source high-level ML framework to Verilog modular compiler targeting AI/ML Application-Specific Integrated Circuits (ASICs) accelerators. SODA tightly couples the Multi-Level Intermediate Representation (MLIR) compiler infrastructure [24] and open-source HLS approaches. Thus, SODA can support various ML frameworks and algorithms and can perform optimizations that combine specialized architecture templates and conventional HLS to generate the hardware modules. In addition, SODA's closed-loop design space exploration (DSE) engine allows developers to perform end-to-end design space explorations on different metrics and technology nodes.",
      "paperUrl": "https://doi.org/10.1109/asap52443.2021.00040",
      "sourceUrl": "",
      "tags": [
        "Performance",
        "Optimizations",
        "IR",
        "AI",
        "Infrastructure",
        "ML",
        "MLIR"
      ],
      "keywords": [
        "Performance",
        "Optimizations",
        "IR",
        "AI",
        "Infrastructure",
        "ML",
        "MLIR",
        "Intermediate Representation",
        "ML Accelerator",
        "Domain Specific",
        "Hardware",
        "HLS"
      ],
      "matchedAuthors": [
        "Ankur Limaye",
        "Antonino Tumeo",
        "Cheng Tan",
        "David Brooks",
        "Gu-Yeon Wei",
        "Joseph Manzano",
        "Marco Minutoli",
        "Nícolas Bohm Agostini",
        "Vinay Amatya",
        "Vito Giovanni Castellana"
      ]
    },
    {
      "id": "openalex-w3214439093",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Same Coverage, Less Bloat: Accelerating Binary-only Fuzzing with Coverage-preserving Coverage-guided Tracing",
      "authors": [
        {
          "name": "Stefan Nagy",
          "affiliation": "Virginia Tech"
        },
        {
          "name": "Anh Nguyen‐Tuong",
          "affiliation": "University of Virginia"
        },
        {
          "name": "Jason D. Hiser",
          "affiliation": "University of Virginia"
        },
        {
          "name": "Jack W. Davidson",
          "affiliation": "University of Virginia"
        },
        {
          "name": "Matthew Hicks",
          "affiliation": "Virginia Tech"
        }
      ],
      "year": "2021",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Coverage-guided fuzzing's aggressive, high-volume testing has helped reveal\\ntens of thousands of software security flaws. While executing billions of test\\ncases mandates fast code coverage tracing, the nature of binary-only targets\\nleads to reduced tracing performance. A recent advancement in binary fuzzing\\nperformance is Coverage-guided Tracing (CGT), which brings orders-of-magnitude\\ngains in throughput by restricting the expense of coverage tracing to only when\\nnew coverage is guaranteed. Unfortunately, CGT suits only a basic block\\ncoverage granularity -- yet most fuzzers require finer-grain coverage metrics:\\nedge coverage and hit counts. It is this limitation which prohibits nearly all\\nof today's state-of-the-art fuzzers from attaining the performance benefits of\\nCGT.\\n This paper tackles the challenges of adapting CGT to fuzzing's most\\nubiquitous coverage metrics. We introduce and implement a suite of enhancements\\nthat expand CGT's introspection to fuzzing's most common code coverage metrics,\\nwhile maintaining its orders-of-magnitude speedup over conventional always-on\\ncoverage tracing. We evaluate their trade-offs with respect to fuzzing\\nperformance and effectiveness across 12 diverse real-world binaries (8 open-\\nand 4 closed-source). On average, our coverage-preserving CGT attains\\nnear-identical speed to the present block-coverage-only CGT, UnTracer; and\\noutperforms leading binary- and source-level coverage tracers QEMU, Dyninst,\\nRetroWrite, and AFL-Clang by 2-24x, finding more bugs in less time.\\n",
      "paperUrl": "https://dl.acm.org/doi/pdf/10.1145/3460120.3484787",
      "sourceUrl": "https://doi.org/10.1145/3460120.3484787",
      "tags": [
        "Security",
        "Performance",
        "Clang",
        "Testing"
      ],
      "keywords": [
        "Security",
        "Performance",
        "Clang",
        "Testing",
        "Fuzzing",
        "Coverage Guided Tracing",
        "Fuzzing Nperformance",
        "Bloat Accelerating Binary",
        "Coverage Metrics",
        "Coverage Preserving",
        "Coverage Tracing",
        "Coverage Less Bloat",
        "Less Bloat Accelerating",
        "Preserving Coverage Guided"
      ],
      "matchedAuthors": [
        "Matthew Hicks"
      ]
    },
    {
      "id": "openalex-w4225718726",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Quantum Circuit Transformations with a Multi-Level Intermediate Representation Compiler",
      "authors": [
        {
          "name": "Thien Huu Nguyen",
          "affiliation": ""
        },
        {
          "name": "Dmitry I. Lyakh",
          "affiliation": ""
        },
        {
          "name": "Raphael C. Pooser",
          "affiliation": ""
        },
        {
          "name": "Travis S. Humble",
          "affiliation": ""
        },
        {
          "name": "Timothy Proctor",
          "affiliation": ""
        },
        {
          "name": "Mohan Sarovar",
          "affiliation": ""
        }
      ],
      "year": "2021",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Quantum computing promises remarkable approaches for processing information, but new tools are needed to compile program representations into the physical instructions required by a quantum computer. Here we present a novel adaptation of the multi-level intermediate representation (MLIR) integrated into a quantum compiler that may be used for checking program execution. We first present how MLIR enables quantum circuit transformations for efficient execution on quantum computing devices and then give an example of compiler transformations based on so-called mirror circuits. We demonstrate that mirror circuits inserted during compilation may test hardware performance by assessing quantum circuit accuracy on several superconducting and ion trap hardware platforms. Our results validate MLIR as an efficient and effective method for collecting hardware-dependent diagnostics through automated transformations of quantum circuits.",
      "paperUrl": "https://arxiv.org/pdf/2112.10677",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2112.10677",
      "tags": [
        "Performance",
        "IR",
        "Quantum Computing",
        "MLIR"
      ],
      "keywords": [
        "Performance",
        "IR",
        "Quantum Computing",
        "MLIR",
        "Intermediate Representation",
        "Quantum Compilation",
        "Quantum Circuit",
        "Quantum Circuit Transformations",
        "Intermediate Representation Compiler",
        "Mirror Circuits",
        "Hardware"
      ],
      "matchedAuthors": [
        "Dmitry I. Lyakh",
        "Travis S. Humble"
      ]
    },
    {
      "id": "openalex-w3209044664",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Programming Heterogeneous Systems with General and Domain-Specific Frameworks",
      "authors": [
        {
          "name": "Lukáš Sommer",
          "affiliation": ""
        }
      ],
      "year": "2021",
      "publication": "TUbilio (Technical University of Darmstadt)",
      "venue": "TUbilio (Technical University of Darmstadt)",
      "type": "thesis",
      "abstract": "As chip manufacturing processes are getting ever closer to what is physically possible, the projections made by Moore's Law and Dennard Scaling no longer hold true, and CPU performance has been stagnating over the last decade. At the same time, the performance requirements of many important application areas, ranging from machine learning to scientific computing, are increasing at exponential rates, creating a demand that CPUs cannot satisfy anymore. In order to cater the performance hunger of these applications, computer architects have turned their attention towards heterogeneous systems. By combining CPUs with one or multiple accelerators, architects are seeking to provide the necessary performance through specialization and more efficient forms of parallelism. And while the accelerators have successfully delivered on the promised performance in many cases, programming these heterogeneous systems is becoming increasingly difficult, as developers need to take multiple devices, execution models, and data transfers into account. Over the course of this cumulative dissertation, we investigate two potential solutions to the enormous challenges of heterogeneous systems programming. General programming frameworks such as OpenMP define language constructs that reflect important fundamental computing patterns and allow developers to expose an application's parallelism to the compiler for efficient mapping to the target hardware. Domain-specific programming frameworks, on the other hand, are tailored to a single domain and provide mechanisms to capture the high-level semantics and structure of an application, which is then again mapped to the computational units of the underlying hardware in an efficient fashion. In this thesis, we discuss the merits of both approaches in detail and show implementation examples for both. For general programming frameworks, the selection of the most suitable framework for a class of applications and target platform is a crucial step. Using automotive software development as an example, we perform an implementation study to extensively compare three different frameworks. Based on the findings from this implementation study, we identify a number of key factors to assess the suitability of general programming frameworks for applications and target platforms. One popular general programming framework is OpenMP, and the target offloading capabilities added in recent versions also make it an interesting candidate for targeting FPGAs. To enable the use of OpenMP for FPGA programming, we develop the first-ever prototype for OpenMP target offloading constructs on FPGAs via High-Level Synthesis. Furthermore, we design and implement an execution model and hardware extensions for multi-threaded execution in FPGA accelerators generated through High-Level Synthesis. By combining multi-threaded execution in the generated FPGA accelerators with OpenMP target offloading as programming interface, we do not only significantly reduce idle cycles and improve performance, but also provide an easy-to-use programming interface with intuitive mechanisms for data management. In order to showcase the implementation of a domain-specific programming framework, we develop a compiler for Sum-Product Networks, a class of machine learning models. By implementing compilation flows for CPUs, GPUs and FPGAs, we are able to cover a wide range of heterogeneous system setups and achieve improvements in inference throughput of multiple orders of magnitude compared to the existing Python-based libraries. The implementation of these toolflows, which for CPU and GPU is based on the modern MLIR framework, also illustrates the role compilers play for the future of heterogeneous computing.",
      "paperUrl": "https://doi.org/10.26083/tuprints-00019772",
      "sourceUrl": "",
      "tags": [
        "Performance",
        "GPU",
        "ML",
        "Libraries",
        "MLIR"
      ],
      "keywords": [
        "Performance",
        "GPU",
        "ML",
        "Libraries",
        "MLIR",
        "Offloading",
        "Heterogeneous Computing",
        "Programming Frameworks",
        "Target Offloading",
        "OpenMP Target Offloading",
        "Domain Specific Programming",
        "Fpga Accelerators",
        "Multi Threaded Execution",
        "Hardware"
      ],
      "matchedAuthors": [
        "Lukáš Sommer"
      ]
    },
    {
      "id": "openalex-w3173462777",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Predictive data locality optimization for higher-order tensor computations",
      "authors": [
        {
          "name": "Tharindu R. Patabandi",
          "affiliation": "University of Utah"
        },
        {
          "name": "Anand Venkat",
          "affiliation": "Intel (United States)"
        },
        {
          "name": "Abhishek Kulkarni",
          "affiliation": "Intel (United States)"
        },
        {
          "name": "Pushkar Ratnalikar",
          "affiliation": "Intel (United States)"
        },
        {
          "name": "Mary Hall",
          "affiliation": "University of Utah"
        },
        {
          "name": "Justin Gottschlich",
          "affiliation": "Intel (United States)"
        }
      ],
      "year": "2021",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "Automating locality optimization is still an open problem for compiler writers. Compiler-based approaches, guided by analytical cost models have achieved some success in matching high performance libraries on a restricted set of computations such as general matrix multiply (GEMM). On the other hand, library-based approaches may present some open scalability concerns. Recent developments in convolutional neural networks has seen an explosion of models, each with differing combinations of parameters. Manually tuning each of these configurations can take many development months. Further, these operations are called multiple times during machine learning training, which necessitates highly optimized implementations. 2D convolutional operators are unique in that they consist of 7-deep loop nests with different loops carrying reuse for different tensors, making the problem of identifying an optimal loop ordering hard. We devise a machine learning-based compiler which learns a regression model, correlating performance with the loop order. We integrate this model with other traditional compiler analysis for transformations such as loop unrolling and vectorization, relying on the MultiLevel Intermediate Representation (MLIR) compiler framework. We achieve an average speedup of 1.67x and 1.41x against oneDNN for 2D convolution forward and weight update kernels respectively. We are also at 0.88x and 0.96x the performance of oneDNN's best performing implementation which applies additional data layout transformations.",
      "paperUrl": "https://doi.org/10.1145/3460945.3464955",
      "sourceUrl": "",
      "tags": [
        "Performance",
        "Optimizations",
        "IR",
        "Loop transformations",
        "Autovectorization",
        "ML",
        "Libraries",
        "MLIR"
      ],
      "keywords": [
        "Performance",
        "Optimizations",
        "IR",
        "Loop transformations",
        "Autovectorization",
        "ML",
        "Libraries",
        "MLIR",
        "Intermediate Representation",
        "Loop Optimization",
        "Locality Optimization",
        "Machine Learning",
        "Higher Order Tensor",
        "Order Tensor Computations"
      ],
      "matchedAuthors": [
        "Mary Hall",
        "Pushkar Ratnalikar"
      ]
    },
    {
      "id": "openalex-w4226474400",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "PERCIVAL: Open-Source Posit RISC-V Core with Quire Capability",
      "authors": [
        {
          "name": "David Mallasén",
          "affiliation": ""
        },
        {
          "name": "Raúl Murillo",
          "affiliation": ""
        },
        {
          "name": "Alberto A. Del Barrio",
          "affiliation": ""
        },
        {
          "name": "Guillermo Botella",
          "affiliation": ""
        },
        {
          "name": "Luís Piñuel",
          "affiliation": ""
        },
        {
          "name": "Manuel Prieto",
          "affiliation": ""
        }
      ],
      "year": "2021",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "The posit representation for real numbers is an alternative to the ubiquitous IEEE 754 floating-point standard. In this work, we present PERCIVAL, an application-level posit capable RISC-V core based on CVA6 that can execute all posit instructions, including the quire fused operations. This solves the obstacle encountered by previous works, which only included partial posit support or which had to emulate posits in software, thus limiting the scope or the scalability of their applications. In addition, Xposit, a RISC-V extension for posit instructions is incorporated into LLVM. Therefore, PERCIVAL is the first work that integrates the complete posit instruction set in hardware. These elements allow for the native execution of posit instructions as well as the standard floating-point ones, further permitting the comparison of these representations. FPGA and ASIC synthesis show the hardware cost of implementing 32-bit posits and highlight the significant overhead of including a quire accumulator. However, results comparing posits and IEEE floats show that the quire enables a more accurate execution of dot products. In general matrix multiplications, the accuracy error is reduced up to 4 orders of magnitude when compared with single-precision floats. Furthermore, performance comparisons show that these accuracy improvements do not hinder their execution, as posits run as fast as single-precision floats and exhibit better timing than double-precision floats, thus potentially providing an alternative representation.",
      "paperUrl": "https://arxiv.org/pdf/2111.15286",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2111.15286",
      "tags": [
        "Performance"
      ],
      "keywords": [
        "Performance",
        "LLVM",
        "Posit Instructions",
        "Single Precision Floats",
        "Posits",
        "Percival Open",
        "Floating Point",
        "Hardware",
        "Quire Capability"
      ],
      "matchedAuthors": [
        "Alberto A. Del Barrio",
        "David Mallasén",
        "Guillermo Botella",
        "Luís Piñuel",
        "Manuel Prieto",
        "Raúl Murillo"
      ]
    },
    {
      "id": "openalex-w3138384652",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Leveraging Models to Reduce Test Cases in Software Repositories",
      "authors": [
        {
          "name": "Golnaz Gharachorlu",
          "affiliation": "Simon Fraser University"
        },
        {
          "name": "William N. Sumner",
          "affiliation": "Simon Fraser University"
        }
      ],
      "year": "2021",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Given a failing test case, test case reduction yields a smaller test case that reproduces the failure. This process can be time consuming due to repeated trial and error with smaller test cases. Current techniques speed up reduction by only exploring syntactically valid candidates, but they still spend significant effort on semantically invalid candidates. In this paper, we propose a model-guided approach to speed up test case reduction. The approach trains a model of semantic properties driven by syntactic test case properties. By using this model, we can skip testing even syntactically valid test case candidates that are unlikely to succeed. We evaluate this model-guided reduction on a suite of 14 large fuzzer-generated C test cases from the bug repositories of two well-known C compilers, GCC and Clang. Our results show that with an average precision of 77%, we can decrease the number of removal trials by 14% to 61%. We observe a 30% geomean improvement in reduction time over the state of the art technique while preserving similar reduction power.",
      "paperUrl": "https://arxiv.org/pdf/2103.11534",
      "sourceUrl": "https://doi.org/10.1109/msr52588.2021.00035",
      "tags": [
        "Clang",
        "Testing"
      ],
      "keywords": [
        "Clang",
        "Testing",
        "Fuzzing",
        "Reduction",
        "Candidates",
        "Syntactically Valid"
      ],
      "matchedAuthors": [
        "William N. Sumner"
      ]
    },
    {
      "id": "openalex-w4287327750",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Interface Compliance of Inline Assembly: Automatically Check, Patch and\\n Refine",
      "authors": [
        {
          "name": "Frédéric Recoules",
          "affiliation": ""
        },
        {
          "name": "Sébastien Bardin",
          "affiliation": ""
        },
        {
          "name": "Richard Bonichon",
          "affiliation": ""
        },
        {
          "name": "Matthieu Lemerre",
          "affiliation": ""
        },
        {
          "name": "Laurent Mounier",
          "affiliation": ""
        },
        {
          "name": "Marie-Laure Potet",
          "affiliation": ""
        }
      ],
      "year": "2021",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Inline assembly is still a common practice in low-level C programming,\\ntypically for efficiency reasons or for accessing specific hardware resources.\\nSuch embedded assembly codes in the GNU syntax (supported by major compilers\\nsuch as GCC, Clang and ICC) have an interface specifying how the assembly codes\\ninteract with the C environment. For simplicity reasons, the compiler treats\\nGNU inline assembly codes as blackboxes and relies only on their interface to\\ncorrectly glue them into the compiled C code. Therefore, the adequacy between\\nthe assembly chunk and its interface (named compliance) is of primary\\nimportance, as such compliance issues can lead to subtle and hard-to-find bugs.\\nWe propose RUSTInA, the first automated technique for formally checking inline\\nassembly compliance, with the extra ability to propose (proven) patches and\\n(optimization) refinements in certain cases. RUSTInA is based on an original\\nformalization of the inline assembly compliance problem together with novel\\ndedicated algorithms. Our prototype has been evaluated on 202 Debian packages\\nwith inline assembly (2656 chunks), finding 2183 issues in 85 packages -- 986\\nsignificant issues in 54 packages (including major projects such as ffmpeg or\\nALSA), and proposing patches for 92% of them. Currently, 38 patches have\\nalready been accepted (solving 156 significant issues), with positive feedback\\nfrom development teams.\\n",
      "paperUrl": "https://arxiv.org/pdf/2102.07485",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2102.07485",
      "tags": [
        "Clang",
        "Optimizations",
        "Embedded"
      ],
      "keywords": [
        "Clang",
        "Optimizations",
        "Embedded",
        "Inline Assembly Automatically",
        "Compliance",
        "Interface Compliance",
        "Assembly Codes",
        "Packages",
        "Patches",
        "Assembly Automatically Check",
        "Automatically Check Patch"
      ],
      "matchedAuthors": [
        "Richard Bonichon",
        "Sébastien Bardin"
      ]
    },
    {
      "id": "openalex-w3130405861",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Interface Compliance of Inline Assembly: Automatically Check, Patch and Refine",
      "authors": [
        {
          "name": "Frédéric Recoules",
          "affiliation": "Laboratoire d'Intégration des Systèmes et des Technologies"
        },
        {
          "name": "Sébastien Bardin",
          "affiliation": "Commissariat à l'Énergie Atomique et aux Énergies Alternatives"
        },
        {
          "name": "Richard Bonichon",
          "affiliation": ""
        },
        {
          "name": "Matthieu Lemerre",
          "affiliation": "Université Paris-Saclay"
        },
        {
          "name": "Laurent Mounier",
          "affiliation": "Université Grenoble Alpes"
        },
        {
          "name": "Marie-Laure Potet",
          "affiliation": "Université Grenoble Alpes"
        }
      ],
      "year": "2021",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Inline assembly is still a common practice in low-level C programming, typically for efficiency reasons or for accessing specific hardware resources. Such embedded assembly codes in the GNU syntax (supported by major compilers such as GCC, Clang and ICC) have an interface specifying how the assembly codes interact with the C environment. For simplicity reasons, the compiler treats GNU inline assembly codes as blackboxes and relies only on their interface to correctly glue them into the compiled C code. Therefore, the adequacy between the assembly chunk and its interface (named compliance) is of primary importance, as such compliance issues can lead to subtle and hard-to-find bugs. We propose RUSTInA, the first automated technique for formally checking inline assembly compliance, with the extra ability to propose (proven) patches and (optimization) refinements in certain cases. RUSTInA is based on an original formalization of the inline assembly compliance problem together with novel dedicated algorithms. Our prototype has been evaluated on 202 Debian packages with inline assembly (2656 chunks), finding 2183 issues in 85 packages -- 986 significant issues in 54 packages (including major projects such as ffmpeg or ALSA), and proposing patches for 92% of them. Currently, 38 patches have already been accepted (solving 156 significant issues), with positive feedback from development teams.",
      "paperUrl": "https://arxiv.org/pdf/2102.07485",
      "sourceUrl": "https://doi.org/10.1109/icse43902.2021.00113",
      "tags": [
        "Clang",
        "Optimizations",
        "Embedded"
      ],
      "keywords": [
        "Clang",
        "Optimizations",
        "Embedded",
        "Inline Assembly Automatically",
        "Inline Assembly Compliance",
        "Interface Compliance",
        "Assembly Codes",
        "Packages",
        "Patches",
        "Assembly Automatically Check",
        "Automatically Check Patch"
      ],
      "matchedAuthors": [
        "Richard Bonichon",
        "Sébastien Bardin"
      ]
    },
    {
      "id": "openalex-w4200620451",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Input-Output Example-Guided Data Deobfuscation on Binary",
      "authors": [
        {
          "name": "Yujie Zhao",
          "affiliation": "Shaanxi Normal University"
        },
        {
          "name": "Zhanyong Tang",
          "affiliation": "Northwest University"
        },
        {
          "name": "Guixin Ye",
          "affiliation": "Northwest University"
        },
        {
          "name": "Xiaoqing Gong",
          "affiliation": "Northwest University"
        },
        {
          "name": "Dingyi Fang",
          "affiliation": "Northwest University"
        }
      ],
      "year": "2021",
      "publication": "Security and Communication Networks",
      "venue": "Security and Communication Networks | Vol. 2021",
      "type": "research-paper",
      "abstract": "Data obfuscation is usually used by malicious software to avoid detection and reverse analysis. When analyzing the malware, such obfuscations have to be removed to restore the program into an easier understandable form (deobfuscation). The deobfuscation based on program synthesis provides a good solution for treating the target program as a black box. Thus, deobfuscation becomes a problem of finding the shortest instruction sequence to synthesize a program with the same input-output behavior as the target program. Existing work has two limitations: assuming that obfuscated code snippets in the target program are known and using a stochastic search algorithm resulting in low efficiency. In this paper, we propose fine-grained obfuscation detection for locating obfuscated code snippets by machine learning. Besides, we also combine the program synthesis and a heuristic search algorithm of Nested Monte Carlo Search. We have applied a prototype implementation of our ideas to data obfuscation in different tools, including OLLVM and Tigress. Our experimental results suggest that this approach is highly effective in locating and deobfuscating the binaries with data obfuscation, with an accuracy of at least 90.34%. Compared with the state-of-the-art deobfuscation technique, our approach’s efficiency has increased by 75%, with the success rate increasing by 5%.",
      "paperUrl": "https://downloads.hindawi.com/journals/scn/2021/4646048.pdf",
      "sourceUrl": "https://doi.org/10.1155/2021/4646048",
      "tags": [
        "Security",
        "ML"
      ],
      "keywords": [
        "Security",
        "ML",
        "Program Synthesis",
        "Deobfuscation",
        "Target Program",
        "Input Output",
        "Search"
      ],
      "matchedAuthors": [
        "Dingyi Fang",
        "Guixin Ye",
        "Yujie Zhao",
        "Zhanyong Tang"
      ]
    },
    {
      "id": "openalex-w3197494260",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "High Performance GPU Code Generation for Matrix-Matrix Multiplication using MLIR: Some Early Results",
      "authors": [
        {
          "name": "Navdeep Katel",
          "affiliation": ""
        },
        {
          "name": "Vivek Khandelwal",
          "affiliation": ""
        },
        {
          "name": "Uday Bondhugula",
          "affiliation": ""
        }
      ],
      "year": "2021",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "This report presents some early results on code generation targeting tensor cores on NVIDIA GPUs using the MLIR compiler infrastructure. The state-of-the-art in high-performance deep learning today is primarily driven by manually optimized highly tuned libraries. The approach to develop such libraries is often not modular or reusable to the same extent that compiler infrastructure like LLVM is. Manual optimization typically does not use a standard intermediate representation (IR), although the optimizations performed can be encoded as a sequence of transformation steps and customized passes on an IR. Hand tuning may also miss exploration of design points only reachable easily by automatic code generation. We believe that until the recent introduction of MLIR (Multi-level intermediate representation), IR infrastructure was not geared to tackle the problem of automatic generation of domain-specific libraries in an effective manner. In particular, it was hard to represent and transform compute abstractions at high, middle, and low levels using a single IR. With suitable abstractions in MLIR, we build an experimental lowering pipeline that is able to automatically generate code for matrix-matrix multiplication on NVIDIA GPUs targeting its tensor cores. On a set of problem sizes we evaluated, initial performance results show that we are able to attain performance that is 95-119% and 80-160% of CuBLAS for FP32 and FP16 accumulate respectively on NVIDIA's Ampere microarchitecture-based Geforce 3090 RTX. We believe that these results could be used as motivation for further research and development on automatic code and library generation using IR infrastructure for similar specialized accelerators.",
      "paperUrl": "https://arxiv.org/pdf/2108.13191",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2108.13191",
      "tags": [
        "Backend",
        "Performance",
        "Optimizations",
        "GPU",
        "IR",
        "Infrastructure",
        "ML",
        "Libraries",
        "MLIR"
      ],
      "keywords": [
        "Backend",
        "Performance",
        "Optimizations",
        "GPU",
        "IR",
        "Infrastructure",
        "ML",
        "Libraries",
        "MLIR",
        "LLVM",
        "Intermediate Representation",
        "Code Generation",
        "Performance GPU",
        "Compiler Infrastructure"
      ],
      "matchedAuthors": [
        "Uday Bondhugula"
      ]
    },
    {
      "id": "openalex-w3134877013",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "HIR: An MLIR-based Intermediate Representation for Hardware Accelerator Description",
      "authors": [
        {
          "name": "Kingshuk Majumder",
          "affiliation": "Indian Institute of Science Bangalore"
        },
        {
          "name": "Uday Bondhugula",
          "affiliation": "Indian Institute of Science Bangalore"
        }
      ],
      "year": "2021",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "The emergence of machine learning, image and audio processing on edge devices has motivated research towards power efficient custom hardware accelerators. Though FPGAs are an ideal target for energy efficient custom accelerators, the difficulty of hardware design and the lack of vendor agnostic, standardized hardware compilation infrastructure has hindered their adoption. This paper introduces HIR, an MLIR-based intermediate representation (IR) to describe hardware accelerator designs. HIR combines high level language features, such as loops and multi-dimensional tensors, with programmer defined explicit scheduling, to provide a high-level IR suitable for DSL compiler pipelines without compromising control over the micro-architecture of the accelerator. HIR's explicit schedules allow it to express fine-grained, synchronization-free parallelism and optimizations such as retiming and pipelining. Built as a dialect in MLIR, it draws from best IR practices learnt from communities like those of LLVM. While offering rich optimization opportunities and a high level abstraction, HIR enables sharing of optimizations, utilities and passes with software compiler infrastructure. Our implementation shows that the code generation time of the HIR code generator is on average 1112x lower than that of Xilinx Vivado HLS on a range of kernels without a compromise on the quality of the generated hardware. We believe that these are significant steps forward in the design of IRs for hardware synthesis and in equipping domain-specific languages with a productive and performing compilation path to custom hardware acceleration.",
      "paperUrl": "https://arxiv.org/pdf/2103.00194",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2103.00194",
      "tags": [
        "Backend",
        "Optimizations",
        "IR",
        "Infrastructure",
        "ML",
        "MLIR"
      ],
      "keywords": [
        "Backend",
        "Optimizations",
        "IR",
        "Infrastructure",
        "ML",
        "MLIR",
        "LLVM",
        "Intermediate Representation",
        "Code Generation",
        "Hardware",
        "Hardware Accelerator Description",
        "Custom Hardware",
        "Compilation"
      ],
      "matchedAuthors": [
        "Uday Bondhugula"
      ]
    },
    {
      "id": "openalex-w4297792550",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "HDR-Fuzz: Detecting Buffer Overruns using AddressSanitizer\\n Instrumentation and Fuzzing",
      "authors": [
        {
          "name": "Raveendra Kumar Medicherla",
          "affiliation": ""
        },
        {
          "name": "Malathy Nagalakshmi",
          "affiliation": ""
        },
        {
          "name": "Tanya Sharma",
          "affiliation": ""
        },
        {
          "name": "Raghavan Komondoor",
          "affiliation": ""
        }
      ],
      "year": "2021",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Buffer-overruns are a prevalent vulnerability in software libraries and\\napplications. Fuzz testing is one of the effective techniques to detect\\nvulnerabilities in general. Greybox fuzzers such as AFL automatically generate\\na sequence of test inputs for a given program using a fitness-guided search\\nprocess. A recently proposed approach in the literature introduced a\\nbuffer-overrun specific fitness metric called \"headroom\", which tracks how\\nclose each generated test input comes to exposing the vulnerabilities. That\\napproach showed good initial promise, but is somewhat imprecise and expensive\\ndue to its reliance on conservative points-to analysis. Inspired by the\\napproach above, in this paper we propose a new ground-up approach for detecting\\nbuffer-overrun vulnerabilities. This approach uses an extended version of ASAN\\n(Address Sanitizer) that runs in parallel with the fuzzer, and reports back to\\nthe fuzzer test inputs that happen to come closer to exposing buffer-overrun\\nvulnerabilities. The ASAN-style instrumentation is precise as it has no\\ndependence on points-to analysis. We describe in this paper our approach, as\\nwell as an implementation and evaluation of the approach.\\n",
      "paperUrl": "https://arxiv.org/pdf/2104.10466",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2104.10466",
      "tags": [
        "Testing",
        "Libraries"
      ],
      "keywords": [
        "Testing",
        "Libraries",
        "Fuzzing",
        "Sanitizers",
        "Detecting Buffer Overruns",
        "Nbuffer Overrun",
        "Instrumentation",
        "Fuzz Detecting Buffer",
        "Hdr Fuzz Detecting",
        "Addresssanitizer"
      ],
      "matchedAuthors": [
        "Raveendra Kumar Medicherla"
      ]
    },
    {
      "id": "openalex-w3154327225",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "HDR-Fuzz: Detecting Buffer Overruns using AddressSanitizer Instrumentation and Fuzzing",
      "authors": [
        {
          "name": "Raveendra Kumar Medicherla",
          "affiliation": ""
        },
        {
          "name": "Malathy Nagalakshmi",
          "affiliation": ""
        },
        {
          "name": "Tanya Sharma",
          "affiliation": ""
        },
        {
          "name": "Raghavan Komondoor",
          "affiliation": ""
        }
      ],
      "year": "2021",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Buffer-overruns are a prevalent vulnerability in software libraries and applications. Fuzz testing is one of the effective techniques to detect vulnerabilities in general. Greybox fuzzers such as AFL automatically generate a sequence of test inputs for a given program using a fitness-guided search process. A recently proposed approach in the literature introduced a buffer-overrun specific fitness metric called \"headroom\", which tracks how close each generated test input comes to exposing the vulnerabilities. That approach showed good initial promise, but is somewhat imprecise and expensive due to its reliance on conservative points-to analysis. Inspired by the approach above, in this paper we propose a new ground-up approach for detecting buffer-overrun vulnerabilities. This approach uses an extended version of ASAN (Address Sanitizer) that runs in parallel with the fuzzer, and reports back to the fuzzer test inputs that happen to come closer to exposing buffer-overrun vulnerabilities. The ASAN-style instrumentation is precise as it has no dependence on points-to analysis. We describe in this paper our approach, as well as an implementation and evaluation of the approach.",
      "paperUrl": "https://arxiv.org/pdf/2104.10466.pdf",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2104.10466",
      "tags": [
        "Testing",
        "Libraries"
      ],
      "keywords": [
        "Testing",
        "Libraries",
        "Fuzzing",
        "Sanitizers",
        "Buffer Overruns",
        "Buffer Overrun Vulnerabilities",
        "Detecting Buffer Overruns",
        "Addresssanitizer Instrumentation",
        "Fuzz Detecting Buffer",
        "Hdr Fuzz Detecting"
      ],
      "matchedAuthors": [
        "Raveendra Kumar Medicherla"
      ]
    },
    {
      "id": "openalex-w4247013288",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "For a Few Dollars More -- Verified Fine-Grained Algorithm Analysis Down to LLVM",
      "authors": [
        {
          "name": "Peter Lammich",
          "affiliation": ""
        },
        {
          "name": "Maximilian P. L. Haslbeck",
          "affiliation": ""
        }
      ],
      "year": "2021",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "We present a framework to verify both, functional correctness and (amortized) worst-case complexity of practically efficient algorithms.We implemented a stepwise refinement approach, using the novel concept of resource currencies to naturally structure the resource analysis along the refinement chain, and allow a fine-grained analysis of operation counts.Our framework targets the LLVM intermediate representation.We extend its semantics from earlier work with a cost model.As case studies, we verify the amortized constant time push operation on dynamic arrays and the O (n log n) introsort algorithm, and refine them down to efficient LLVM implementations.Our sorting algorithm performs on par with the state-of-the-art implementation found in the GNU C++ Library, and provably satisfies the complexity required by the C++ standard.",
      "paperUrl": "https://doi.org/10.26226/morressier.604907f41a80aac83ca25d21",
      "sourceUrl": "",
      "tags": [
        "IR"
      ],
      "keywords": [
        "IR",
        "LLVM",
        "Intermediate Representation",
        "Verified Fine Grained"
      ],
      "matchedAuthors": [
        "Maximilian P. L. Haslbeck",
        "Peter Lammich"
      ]
    },
    {
      "id": "openalex-w4287194641",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "FIPAC: Thwarting Fault- and Software-Induced Control-Flow Attacks with ARM Pointer Authentication",
      "authors": [
        {
          "name": "Robert Schilling",
          "affiliation": ""
        },
        {
          "name": "Pascal Nasahl",
          "affiliation": ""
        },
        {
          "name": "Stefan Mangard",
          "affiliation": ""
        }
      ],
      "year": "2021",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "With the improvements of computing technology, more and more applications embed powerful ARM processors into their devices. These systems can be attacked by redirecting the control-flow of a program to bypass critical pieces of code such as privilege checks or signature verifications. Control-flow hijacks can be performed using classical software vulnerabilities, physical fault attacks, or software-induced fault attacks. To cope with this threat and to protect the control-flow, dedicated countermeasures are needed. To counteract control-flow hijacks, control-flow integrity~(CFI) aims to be a generic solution. However, software-based CFI typically either protects against software or fault attacks, but not against both. While hardware-assisted CFI can mitigate both types of attacks, they require extensive hardware modifications. As hardware changes are unrealistic for existing ARM architectures, a wide range of systems remains unprotected and vulnerable to control-flow attacks. In this work, we present FIPAC, an efficient software-based CFI scheme protecting the execution at basic block granularity of ARM-based devices against software and fault attacks. FIPAC exploits ARM pointer authentication of ARMv8.6-A to implement a cryptographically signed control-flow graph. We cryptographically link the correct sequence of executed basic blocks to enforce CFI at this granularity. We use an LLVM-based toolchain to automatically instrument programs. The evaluation on SPEC2017 with different security policies shows a code overhead between 54-97\\% and a runtime overhead between 35-105%. While these overheads are higher than for countermeasures against software attacks, FIPAC outperforms related work protecting the control-flow against fault attacks. FIPAC is an efficient solution to provide protection against software- and fault-based CFI attacks on basic block level on modern ARM devices.",
      "paperUrl": "https://arxiv.org/pdf/2104.14993",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2104.14993",
      "tags": [
        "Security",
        "Infrastructure"
      ],
      "keywords": [
        "Security",
        "Infrastructure",
        "LLVM",
        "Control Flow Attacks",
        "Fault Attacks",
        "ARM Pointer Authentication",
        "Against",
        "CFI",
        "Fault Attacks Fipac",
        "Control Flow Hijacks",
        "Devices",
        "Hardware",
        "Basic Block",
        "Fipac Thwarting Fault"
      ],
      "matchedAuthors": [
        "Pascal Nasahl",
        "Robert Schilling",
        "Stefan Mangard"
      ]
    },
    {
      "id": "openalex-w4297800088",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Enabling Retargetable Optimizing Compilers for Quantum Accelerators via\\n a Multi-Level Intermediate Representation",
      "authors": [
        {
          "name": "Thien Huu Nguyen",
          "affiliation": ""
        },
        {
          "name": "Alexander McCaskey",
          "affiliation": ""
        }
      ],
      "year": "2021",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "We present a multi-level quantum-classical intermediate representation (IR)\\nthat enables an optimizing, retargetable, ahead-of-time compiler for available\\nquantum programming languages. To demonstrate our architecture, we leverage our\\nproposed IR to enable a compiler for version 3 of the OpenQASM quantum language\\nspecification. We support the entire gate-based OpenQASM 3 language and provide\\ncustom extensions for common quantum programming patterns and improved syntax.\\nOur work builds upon the Multi-level Intermediate Representation (MLIR)\\nframework and leverages its unique progressive lowering capabilities to map\\nquantum language expressions to the LLVM machine-level IR. We provide both\\nquantum and classical optimizations via the MLIR pattern rewriting sub-system\\nand standard LLVM optimization passes, and demonstrate the programmability,\\ncompilation, and execution of our approach via standard benchmarks and test\\ncases. In comparison to other standalone language and compiler efforts\\navailable today, our work results in compile times that are 1000x faster than\\nstandard Pythonic approaches, and 5-10x faster than comparative standalone\\nquantum language compilers. Our compiler provides quantum resource\\noptimizations via standard programming patterns that result in a 10x reduction\\nin entangling operations, a common source of program noise. Ultimately, we see\\nthis work as a vehicle for rapid quantum compiler prototyping enabling language\\nintegration, optimizations, and interoperability with classical compilation\\napproaches.\\n",
      "paperUrl": "https://arxiv.org/pdf/2109.00506",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2109.00506",
      "tags": [
        "Optimizations",
        "IR",
        "Programming Languages",
        "Quantum Computing",
        "MLIR"
      ],
      "keywords": [
        "Optimizations",
        "IR",
        "Programming Languages",
        "Quantum Computing",
        "MLIR",
        "LLVM",
        "Intermediate Representation",
        "Quantum Compilation",
        "Nquantum Language",
        "Classical",
        "Standard",
        "Programming Patterns",
        "Retargetable Optimizing Compilers",
        "Quantum Accelerators"
      ],
      "matchedAuthors": [
        "Alexander McCaskey"
      ]
    },
    {
      "id": "openalex-w3197036673",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Enabling Retargetable Optimizing Compilers for Quantum Accelerators via a Multi-Level Intermediate Representation",
      "authors": [
        {
          "name": "Thien Nguyen",
          "affiliation": "Oak Ridge National Laboratory"
        },
        {
          "name": "Alexander McCaskey",
          "affiliation": "Oak Ridge National Laboratory"
        }
      ],
      "year": "2021",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "We present a multi-level quantum-classical intermediate representation (IR) that enables an optimizing, retargetable, ahead-of-time compiler for available quantum programming languages. To demonstrate our architecture, we leverage our proposed IR to enable a compiler for version 3 of the OpenQASM quantum language specification. We support the entire gate-based OpenQASM 3 language and provide custom extensions for common quantum programming patterns and improved syntax. Our work builds upon the Multi-level Intermediate Representation (MLIR) framework and leverages its unique progressive lowering capabilities to map quantum language expressions to the LLVM machine-level IR. We provide both quantum and classical optimizations via the MLIR pattern rewriting sub-system and standard LLVM optimization passes, and demonstrate the programmability, compilation, and execution of our approach via standard benchmarks and test cases. In comparison to other standalone language and compiler efforts available today, our work results in compile times that are 1000x faster than standard Pythonic approaches, and 5-10x faster than comparative standalone quantum language compilers. Our compiler provides quantum resource optimizations via standard programming patterns that result in a 10x reduction in entangling operations, a common source of program noise. Ultimately, we see this work as a vehicle for rapid quantum compiler prototyping enabling language integration, optimizations, and interoperability with classical compilation approaches.",
      "paperUrl": "https://arxiv.org/pdf/2109.00506.pdf",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2109.00506",
      "tags": [
        "Optimizations",
        "IR",
        "Programming Languages",
        "Quantum Computing",
        "MLIR"
      ],
      "keywords": [
        "Optimizations",
        "IR",
        "Programming Languages",
        "Quantum Computing",
        "MLIR",
        "LLVM",
        "Intermediate Representation",
        "Quantum Compilation",
        "Quantum Language",
        "Standard",
        "Classical",
        "Programming Patterns",
        "Quantum Programming",
        "Retargetable Optimizing Compilers"
      ],
      "matchedAuthors": [
        "Alexander McCaskey",
        "Thien Nguyen"
      ]
    },
    {
      "id": "openalex-w4286891090",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Distill: Domain-Specific Compilation for Cognitive Models",
      "authors": [
        {
          "name": "Ján Veselý",
          "affiliation": ""
        },
        {
          "name": "Raghavendra Pradyumna Pothukuchi",
          "affiliation": ""
        },
        {
          "name": "Ketaki Joshi",
          "affiliation": ""
        },
        {
          "name": "Samyak Gupta",
          "affiliation": ""
        },
        {
          "name": "Jonathan Cohen",
          "affiliation": ""
        },
        {
          "name": "Abhishek Bhattacharjee",
          "affiliation": ""
        }
      ],
      "year": "2021",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "This paper discusses our proposal and implementation of Distill, a domain-specific compilation tool based on LLVM to accelerate cognitive models. Cognitive models explain the process of cognitive function and offer a path to human-like artificial intelligence. However, cognitive modeling is laborious, requiring composition of many types of computational tasks, and suffers from poor performance as it relies on high-level languages like Python. In order to continue enjoying the flexibility of Python while achieving high performance, Distill uses domain-specific knowledge to compile Python-based cognitive models into LLVM IR, carefully stripping away features like dynamic typing and memory management that add overheads to the actual model. As we show, this permits significantly faster model execution. We also show that the code so generated enables using classical compiler data flow analysis passes to reveal properties about data flow in cognitive models that are useful to cognitive scientists. Distill is publicly available, is being used by researchers in cognitive science, and has led to patches that are currently being evaluated for integration into mainline LLVM.",
      "paperUrl": "https://arxiv.org/pdf/2110.15425",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2110.15425",
      "tags": [
        "Performance",
        "Static Analysis",
        "IR",
        "AI"
      ],
      "keywords": [
        "Performance",
        "Static Analysis",
        "IR",
        "AI",
        "LLVM",
        "Intermediate Representation",
        "Dataflow Analysis",
        "Cognitive",
        "Domain Specific Compilation",
        "Distill Domain Specific",
        "Python"
      ],
      "matchedAuthors": [
        "Abhishek Bhattacharjee",
        "Ján Veselý",
        "Ketaki Joshi",
        "Raghavendra Pradyumna Pothukuchi",
        "Samyak Gupta"
      ]
    },
    {
      "id": "openalex-w3205281171",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Detecting Compiler Warning Defects Via Diversity-Guided Program Mutation",
      "authors": [
        {
          "name": "Yixuan Tang",
          "affiliation": "Dalian University of Technology"
        },
        {
          "name": "He Jiang",
          "affiliation": "Dalian University of Technology"
        },
        {
          "name": "Zhide Zhou",
          "affiliation": "Dalian University of Technology"
        },
        {
          "name": "Xiaochen Li",
          "affiliation": "University of Luxembourg"
        },
        {
          "name": "Zhilei Ren",
          "affiliation": "Dalian University of Technology"
        },
        {
          "name": "Weiqiang Kong",
          "affiliation": "Dalian University of Technology"
        }
      ],
      "year": "2021",
      "publication": "IEEE Transactions on Software Engineering",
      "venue": "IEEE Transactions on Software Engineering | Vol. 48 (Issue 11)",
      "type": "research-paper",
      "abstract": "Compiler diagnostic warnings help developers identify potential programming mistakes during program compilation. However, these warnings could be erroneous due to the defects of compiler warning diagnostics. Although the existing technique (i.e., Epiphron) can automatically generate test programs for compiler warning defect detection, the effectiveness of Epiphron on defect-finding is still limited, due to the limitation for generating warning-sensitive test program structures. Therefore, in this paper, we propose a DIversity-guided PROgram Mutation approach, called DIPROM, to construct diverse warning-sensitive programs for effective compiler warning defect detection. Given a seed test program, DIPROM first removes its dead code to reduce false positive warning defects. Then, the abstract syntax tree (AST) of the test program is constructed; DIPROM iteratively mutates the structures of the AST to generate warning-sensitive program variants. To effectively construct diverse warning-sensitive structures, DIPROM applies a novel diversity-guided strategy to generate program variants in each iteration. With the generated program variants, differential testing is conducted to detect warning defects in different compilers. In the experiments, we evaluate DIPROM with two popular C compilers (i.e., GCC and Clang). Experimental results show that DIPROM significantly outperforms three state-of-the-art approaches (i.e., HiCOND, Epiphron, and Hermes) by up to 18.93% <inline-formula><tex-math notation=\"LaTeX\">$\\sim$</tex-math></inline-formula> 76.74% in terms of the bug-finding capability on average. Meanwhile, DIPROM is efficient, which spends less time on finding the same average number of warning defects. We at last applied DIPROM to the latest development versions of GCC and Clang. After two months' running, we reported 8 new warning defects; 5 of them have been confirmed/fixed by developers.",
      "paperUrl": "https://doi.org/10.1109/tse.2021.3119186",
      "sourceUrl": "",
      "tags": [
        "Clang",
        "Testing"
      ],
      "keywords": [
        "Clang",
        "Testing",
        "Differential Testing",
        "Diprom",
        "Warning Defects",
        "Compiler Warning Defect",
        "Diverse Warning Sensitive",
        "Diversity Guided Program",
        "Program Variants",
        "Guided Program Mutation",
        "Construct Diverse Warning",
        "Warning Defect Detection",
        "Epiphron",
        "Generate"
      ],
      "matchedAuthors": [
        "He Jiang",
        "Weiqiang Kong",
        "Xiaochen Li",
        "Yixuan Tang",
        "Zhide Zhou",
        "Zhilei Ren"
      ]
    },
    {
      "id": "openalex-w3135606491",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "DISC: A Dynamic Shape Compiler for Machine Learning Workloads",
      "authors": [
        {
          "name": "Kai Zhu",
          "affiliation": "Alibaba Group (United States)"
        },
        {
          "name": "Wenyi Zhao",
          "affiliation": "Alibaba Group (United States)"
        },
        {
          "name": "Zhen Zheng",
          "affiliation": "Alibaba Group (United States)"
        },
        {
          "name": "Tianyou Guo",
          "affiliation": "Alibaba Group (United States)"
        },
        {
          "name": "Pengzhan Zhao",
          "affiliation": "Alibaba Group (United States)"
        },
        {
          "name": "Junjie Bai",
          "affiliation": "Alibaba Group (United States)"
        },
        {
          "name": "Jun Yang",
          "affiliation": "Alibaba Group (United States)"
        },
        {
          "name": "Xiaoyong Liu",
          "affiliation": "Alibaba Group (United States)"
        },
        {
          "name": "Lansong Diao",
          "affiliation": "Alibaba Group (United States)"
        },
        {
          "name": "Wei Lin",
          "affiliation": "Alibaba Group (United States)"
        },
        {
          "name": "Lin, Wei",
          "affiliation": ""
        }
      ],
      "year": "2021",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Many recent machine learning models show dynamic shape characteristics. However, existing AI compiler optimization systems suffer a lot from problems brought by dynamic shape models, including compilation overhead, memory usage, optimization pipeline and deployment complexity. This paper provides a compiler system to natively support optimization for dynamic shape workloads, named DISC. DISC enriches a set of IR to form a fully dynamic shape representation. It generates the runtime flow at compile time to support processing dynamic shape based logic, which avoids the interpretation overhead at runtime and enlarges the opportunity of host-device co-optimization. It addresses the kernel fusion problem of dynamic shapes with shape propagation and constraints collecting methods. This is the first work to demonstrate how to build an end-to-end dynamic shape compiler based on MLIR infrastructure. Experiments show that DISC achieves up to 3.3x speedup than TensorFlow/PyTorch, and 1.8x than Nimble.",
      "paperUrl": "https://arxiv.org/pdf/2103.05288",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2103.05288",
      "tags": [
        "Optimizations",
        "IR",
        "AI",
        "Infrastructure",
        "ML",
        "MLIR"
      ],
      "keywords": [
        "Optimizations",
        "IR",
        "AI",
        "Infrastructure",
        "ML",
        "MLIR",
        "Machine Learning Workloads",
        "Shape Compiler"
      ],
      "matchedAuthors": [
        "Jun Yang",
        "Wei Lin"
      ]
    },
    {
      "id": "openalex-w3161395920",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "DISC",
      "authors": [
        {
          "name": "Kai Zhu",
          "affiliation": "Alibaba Group (United States)"
        },
        {
          "name": "Wenyi Zhao",
          "affiliation": "Alibaba Group (United States)"
        },
        {
          "name": "Zhen Zheng",
          "affiliation": "Alibaba Group (United States)"
        },
        {
          "name": "Tianyou Guo",
          "affiliation": "Alibaba Group (United States)"
        },
        {
          "name": "Peijun Zhao",
          "affiliation": "Alibaba Group (United States)"
        },
        {
          "name": "Junjie Bai",
          "affiliation": "Alibaba Group (United States)"
        },
        {
          "name": "Jun Yang",
          "affiliation": "Alibaba Group (United States)"
        },
        {
          "name": "Xiaoyang Liu",
          "affiliation": "Alibaba Group (United States)"
        },
        {
          "name": "Lansong Diao",
          "affiliation": "Alibaba Group (United States)"
        },
        {
          "name": "Wei Lin",
          "affiliation": "Alibaba Group (United States)"
        }
      ],
      "year": "2021",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "Many recent machine learning models show dynamic shape characteristics. However, existing AI compiler optimization systems suffer a lot from problems brought by dynamic shape models, including compilation overhead, memory usage, optimization pipeline and deployment complexity. This paper provides a compiler system to natively support optimization for dynamic shape workloads, named DISC. DISC enriches a set of IR to form a fully dynamic shape representation. It generates the runtime flow at compile time to support processing dynamic shape based logic, which avoids the interpretation overhead at runtime and enlarges the opportunity of host-device co-optimization. It addresses the kernel fusion problem of dynamic shapes with shape propagation and constraints collecting methods. This is the first work to demonstrate how to build an end-to-end dynamic shape compiler based on MLIR infrastructure. Experiments show that DISC achieves up to 3.3× speedup than TensorFlow/PyTorch, and 1.8× than Nimble.",
      "paperUrl": "https://doi.org/10.1145/3437984.3458838",
      "sourceUrl": "",
      "tags": [
        "Optimizations",
        "IR",
        "AI",
        "Infrastructure",
        "ML",
        "MLIR"
      ],
      "keywords": [
        "Optimizations",
        "IR",
        "AI",
        "Infrastructure",
        "ML",
        "MLIR"
      ],
      "matchedAuthors": [
        "Jun Yang",
        "Wei Lin"
      ]
    },
    {
      "id": "openalex-w4200028141",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Comprehension of Thread Scheduling for the C++ Programming Language",
      "authors": [
        {
          "name": "Attila Gyen",
          "affiliation": "Eötvös Loránd University"
        },
        {
          "name": "Norbert Pataki",
          "affiliation": "Eötvös Loránd University"
        }
      ],
      "year": "2021",
      "publication": "",
      "venue": "Vol. 25",
      "type": "research-paper",
      "abstract": "Writing parallel programs – whether it is a multithreaded or multi-processed – can often be a daunting task. Developers need to pay close attention to a lot of things related with threads and processes. It is possible that one of these things will be ignored against their will. If this happens the program easily can go into a faulty state. In many cases, this means all that is left is to terminate the program manually. There may also be cases where a poorly written parallel program, despite the calculations run on multiple cores or on multiple computers such as social network servers for example, the program itself proves to be slower than its sequential counterpart. This paper investigates to find out whether there is an \"actual\" parallelism between threads or processes or where there are cases when one of them has to wait for the others to finish their execution. This getting to the point that the program could have been solved with a much simpler sequential program. We propose an approach and its implementation that results in the comprehension of thread schedule. We deal with C++ threads therefore we do not mind the different hardware elements, the language constructs provide abstraction over CPUs and operating systems. This approach is based on static analysis and its implementation takes advantage of the Clang compiler infrastructure.",
      "paperUrl": "https://doi.org/10.1109/icodse53690.2021.9648489",
      "sourceUrl": "",
      "tags": [
        "Clang",
        "Static Analysis",
        "Programming Languages",
        "Infrastructure"
      ],
      "keywords": [
        "Clang",
        "Static Analysis",
        "Programming Languages",
        "Infrastructure",
        "Thread Scheduling"
      ],
      "matchedAuthors": [
        "Norbert Pataki"
      ]
    },
    {
      "id": "openalex-w4394029580",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Compilation and optimizations for variable precision floating-Point arithmetic : from language and libraries to code generation",
      "authors": [
        {
          "name": "Tiago Trevisan Jost",
          "affiliation": ""
        }
      ],
      "year": "2021",
      "publication": "theses.fr (ABES)",
      "venue": "theses.fr (ABES)",
      "type": "research-paper",
      "abstract": "Floating-Point (FP) units in processors are generally limited to supporting a subset of formats deﬁned by the IEEE 754 standard, along with a few target-speciﬁc ones (X86 with an 80-bit FP format, and PowerPC performing 128-bit FP arithmetic). As a result, high-eﬃciency languages and optimizing compilers for high-performance computing are also limited by the FP types supported by these units. However, the pursuit of eﬃciency and stability on applications has led researchers to investigate a ﬁner control of exponent and fraction bits for ﬁnding the right balance between accurate results and execution time and/or energy consumed. For example, numerical computations often involve iterative solvers where the residual error is a function of the input data, or where dynamically adaptive precision can accelerate convergence. Numerical analysts have to resort to explicit conversions and multi-versioning, resulting in code bloat and making the intent of the program even less clear. Little attention in languages and compilers has been given to formats that disrupt the traditional FP arithmetics with runtime capabilities and allow the exploration of multiple conﬁgurations, a paradigm recently referred to as variable precision computing. This thesis proposes to overcome the limiting language and compiler support for traditional FP formats with novel FP arithmetic with runtime capabilities, showing the intersection between compiler technology and variable precision arithmetic. We present an extension of the C type system that can represent generic FP operations and formats, supporting both static precision and dynamically variable precision. We design and implement a compilation ﬂow bridging the abstraction gap between this type system and low-level FP instructions or software libraries. The eﬀectiveness of our solution is demonstrated through an LLVM-based implementation, leveraging aggressive optimizations in LLVM including the Polly loop nest optimizer. We provide support for two backend code generators: one for the ISA of a variable precision FP arithmetic coprocessor, and one for the MPFR multi-precision ﬂoating-point library. We demonstrate the productivity beneﬁts of our intuitive programming model and its ability to leverage an existing compiler framework. Experiments on two high-performance benchmark suites yield strong speedups for both our software and hardware targets. We also show interesting insights on the use of variable precision computing in linear algebra kernels.",
      "paperUrl": "http://www.theses.fr/2021GRALM020/document",
      "sourceUrl": "",
      "tags": [
        "Backend",
        "Performance",
        "Optimizations",
        "Polly",
        "Libraries"
      ],
      "keywords": [
        "Backend",
        "Performance",
        "Optimizations",
        "Polly",
        "Libraries",
        "LLVM",
        "Code Generation",
        "Variable Precision Computing",
        "Arithmetic",
        "Formats",
        "Floating Point Arithmetic",
        "Runtime Capabilities",
        "Compilation",
        "Precision Floating Point"
      ],
      "matchedAuthors": [
        "Tiago Trevisan Jost"
      ]
    },
    {
      "id": "openalex-w3208257120",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Cognac: Domain-Specific Compilation for Cognitive Models",
      "authors": [
        {
          "name": "Ján Veselý",
          "affiliation": ""
        },
        {
          "name": "Raghavendra Pradyumna Pothukuchi",
          "affiliation": ""
        },
        {
          "name": "Ketaki Joshi",
          "affiliation": ""
        },
        {
          "name": "Samyak Gupta",
          "affiliation": ""
        },
        {
          "name": "Jonathan D. Cohen",
          "affiliation": ""
        },
        {
          "name": "Abhishek Bhattacharjee",
          "affiliation": ""
        }
      ],
      "year": "2021",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "This paper discusses our proposal and implementation of Cognac, a domain-specific compilation tool based on LLVM to accelerate cognitive models. Cognitive models explain the process of cognitive function and offer a path to human-like artificial intelligence. However, cognitive modeling is laborious, requiring composition of many types of computational tasks, and suffers from poor performance as it relies on high-level languages like Python. In order to continue enjoying the flexibility of Python while achieving high performance, Cognac uses domain-specific knowledge to compile Python-based cognitive models into LLVM IR, carefully stripping away features like dynamic typing and memory management that add overheads to the actual model. As we show, this permits significantly faster model execution. We also show that the code so generated enables using classical compiler data flow analysis passes to reveal properties about data flow in cognitive models that are useful to cognitive scientists. Cognac is publicly available, is being used by researchers in cognitive science, and has led to patches that are currently being evaluated for integration into mainline LLVM.",
      "paperUrl": "http://arxiv.org/pdf/2110.15425.pdf",
      "sourceUrl": "",
      "tags": [
        "Performance",
        "Static Analysis",
        "IR",
        "AI"
      ],
      "keywords": [
        "Performance",
        "Static Analysis",
        "IR",
        "AI",
        "LLVM",
        "Intermediate Representation",
        "Dataflow Analysis",
        "Cognitive",
        "Domain Specific Compilation",
        "Cognac Domain Specific",
        "Python"
      ],
      "matchedAuthors": [
        "Abhishek Bhattacharjee",
        "Jonathan D. Cohen",
        "Ján Veselý",
        "Ketaki Joshi",
        "Raghavendra Pradyumna Pothukuchi",
        "Samyak Gupta"
      ]
    },
    {
      "id": "openalex-w3194856199",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "CROW: Code Diversification for WebAssembly",
      "authors": [
        {
          "name": "Javier Cabrera-Arteaga",
          "affiliation": "KTH Royal Institute of Technology"
        },
        {
          "name": "Orestis Floros",
          "affiliation": "KTH Royal Institute of Technology"
        },
        {
          "name": "Oscar Vera Perez",
          "affiliation": "Centre National de la Recherche Scientifique"
        },
        {
          "name": "Benoît Baudry",
          "affiliation": "KTH Royal Institute of Technology"
        },
        {
          "name": "Martin Monperrus",
          "affiliation": "KTH Royal Institute of Technology"
        }
      ],
      "year": "2021",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "The adoption of WebAssembly increases rapidly, as it provides a fast and safe model for program execution in the browser. However, WebAssembly is not exempt from vulnerabilities that can be exploited by malicious observers. Code diversification can mitigate some of these attacks. In this paper, we present the first fully automated workflow for the diversification of WebAssembly binaries. We present CROW, an open-source tool implementing this workflow through enumerative synthesis of diverse code snippets expressed in the LLVMintermediate representation. We evaluate CROW’s capabilitieson303C programs and study its use on a real-life security-sensitive program: libsodium, a modern cryptographic library. Overall, CROW is able to generate diverse variants for239out of303 (79%)small programs. Furthermore, our experiments show that our approach and tool is able to successfully diversify off-the-shelf cryptographic software (libsodium).",
      "paperUrl": "https://doi.org/10.14722/madweb.2021.23004",
      "sourceUrl": "",
      "tags": [
        "Security"
      ],
      "keywords": [
        "Security",
        "Diversification"
      ],
      "matchedAuthors": [
        "Martin Monperrus",
        "Orestis Floros"
      ]
    },
    {
      "id": "openalex-w3163448030",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Binary level toolchain provenance identification with graph neural networks",
      "authors": [
        {
          "name": "Tristan Benoit",
          "affiliation": "Centre National de la Recherche Scientifique"
        },
        {
          "name": "Jean-Yves Marion",
          "affiliation": "Centre National de la Recherche Scientifique"
        },
        {
          "name": "Sébastien Bardin",
          "affiliation": "Commissariat à l'Énergie Atomique et aux Énergies Alternatives"
        }
      ],
      "year": "2021",
      "publication": "HAL (Le Centre pour la Communication Scientifique Directe)",
      "venue": "HAL (Le Centre pour la Communication Scientifique Directe) | Vol. 14",
      "type": "research-paper",
      "abstract": "&lt;p&gt;We consider the problem of recovering the compiling chain used to generate a given stripped binary code. We present a Graph Neural Network framework at the binary level to solve this problem, with the idea to take into account the shallow semantics provided by the binary code&#39;s structured control flow graph (CFG). We introduce a Graph Neural Network, called Site Neural Network (SNN), dedicated to this problem. To attain scalability at the binary level, feature extraction is simplified by forgetting almost everything in a CFG except transfer control instructions and performing a parametric graph reduction. Our experiments show that our method recovers the compiler family with a very high F1-Score of 0.9950 while the optimization level is recovered with a moderately high F1-Score of 0.7517. On the compiler version prediction task, the F1-Score is about 0.8167 excluding the clang family. A comparison with a previous work demonstrates the accuracy and performance of this framework.&lt;/p&gt;",
      "paperUrl": "https://hal.science/hal-03447628",
      "sourceUrl": "https://doi.org/10.1109/saner50967.2021.00021",
      "tags": [
        "Performance",
        "Clang",
        "Optimizations",
        "Infrastructure",
        "ML"
      ],
      "keywords": [
        "Performance",
        "Clang",
        "Optimizations",
        "Infrastructure",
        "ML",
        "Control Flow Graph",
        "Binary",
        "Graph Neural",
        "Graph Neural Networks",
        "CFG",
        "Toolchain Provenance Identification"
      ],
      "matchedAuthors": [
        "Sébastien Bardin"
      ]
    },
    {
      "id": "openalex-w4200038259",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Automated Generation of Integrated Digital and Spiking Neuromorphic Machine Learning Accelerators",
      "authors": [
        {
          "name": "Serena Curzel",
          "affiliation": "Politecnico di Milano"
        },
        {
          "name": "Nícolas Bohm Agostini",
          "affiliation": "Pacific Northwest National Laboratory"
        },
        {
          "name": "Shihao Song",
          "affiliation": "Pacific Northwest National Laboratory"
        },
        {
          "name": "Ismet Dagli",
          "affiliation": "Pacific Northwest National Laboratory"
        },
        {
          "name": "Ankur Limaye",
          "affiliation": "Pacific Northwest National Laboratory"
        },
        {
          "name": "Cheng Tan",
          "affiliation": "Pacific Northwest National Laboratory"
        },
        {
          "name": "Marco Minutoli",
          "affiliation": "Pacific Northwest National Laboratory"
        },
        {
          "name": "Vito Giovanni Castellana",
          "affiliation": "Pacific Northwest National Laboratory"
        },
        {
          "name": "Vinay Amatya",
          "affiliation": "Pacific Northwest National Laboratory"
        },
        {
          "name": "Joseph Manzano",
          "affiliation": "Pacific Northwest National Laboratory"
        },
        {
          "name": "Anup Das",
          "affiliation": "Drexel University"
        },
        {
          "name": "Fabrizio Ferrandi",
          "affiliation": "Politecnico di Milano"
        },
        {
          "name": "Antonino Tumeo",
          "affiliation": "Pacific Northwest National Laboratory"
        }
      ],
      "year": "2021",
      "publication": "2021 IEEE/ACM International Conference On Computer Aided Design (ICCAD)",
      "venue": "2021 IEEE/ACM International Conference On Computer Aided Design (ICCAD)",
      "type": "research-paper",
      "abstract": "The growing numbers of application areas for artificial intelligence (AI) methods have led to an explosion in availability of domain-specific accelerators, which struggle to support every new machine learning (ML) algorithm advancement, clearly highlighting the need for a tool to quickly and automatically transition from algorithm definition to hardware implementation and explore the design space along a variety of SWaP (size, weight and Power) metrics. The software defined architectures (SODA) synthesizer implements a modular compiler-based infrastructure for the end-to-end generation of machine learning accelerators, from high-level frameworks to hardware description language. Neuromorphic computing, mimicking how the brain operates, promises to perform artificial intelligence tasks at efficiencies orders-of-magnitude higher than the current conventional tensor-processing based accelerators, as demonstrated by a variety of specialized designs leveraging Spiking Neural Networks (SNNs). Nevertheless, the mapping of an artificial neural network (ANN) to solutions supporting SNNs is still a non-trivial and very device-specific task, and completely lacks the possibility to design hybrid systems that integrate conventional and spiking neural models. In this paper, we discuss the design of such an integrated generator, leveraging the SODA Synthesizer framework and its modular structure. In particular, we present a new MLIR dialect in the SODA frontend that allows expressing spiking neural network concepts (e.g., spiking sequences, transformation, and manipulation) and we discuss how to enable the mapping of spiking neurons to the related specialized hardware (which could be generated through middle-end and backend layers of the SODA Synthesizer). We then discuss the opportunities for further integration offered by the hardware compilation infrastructure, providing a path towards the generation of complex hybrid artificial intelligence systems.",
      "paperUrl": "https://ieeexplore.ieee.org/document/9643474",
      "sourceUrl": "https://doi.org/10.1109/iccad51958.2021.9643474",
      "tags": [
        "Backend",
        "Frontend",
        "AI",
        "Infrastructure",
        "ML",
        "MLIR"
      ],
      "keywords": [
        "Backend",
        "Frontend",
        "AI",
        "Infrastructure",
        "ML",
        "MLIR",
        "Neuromorphic Machine Learning",
        "Machine Learning Accelerators",
        "Artificial Intelligence",
        "Soda Synthesizer",
        "Spiking Neural",
        "Hardware",
        "Discuss",
        "Neural Network"
      ],
      "matchedAuthors": [
        "Ankur Limaye",
        "Antonino Tumeo",
        "Anup Das",
        "Cheng Tan",
        "Fabrizio Ferrandi",
        "Joseph Manzano",
        "Marco Minutoli",
        "Nícolas Bohm Agostini",
        "Serena Curzel",
        "Vinay Amatya",
        "Vito Giovanni Castellana"
      ]
    },
    {
      "id": "openalex-w3193269541",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "AUTOCHECK: A Tool For Checking Compliance With Automotive Coding Standards",
      "authors": [
        {
          "name": "Milena Vujošević Janičić",
          "affiliation": "University of Belgrade"
        },
        {
          "name": "Ognjen Plavsic",
          "affiliation": "National Library of Serbia"
        },
        {
          "name": "Mirko Brkusanin",
          "affiliation": "National Library of Serbia"
        },
        {
          "name": "Petar Jovanović",
          "affiliation": "National Library of Serbia"
        }
      ],
      "year": "2021",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "Coding standards are especially important in the automotive industry because automotive software bugs can have fatal consequences. An important standard in this context is Autosar, which proposes guidelines for coding in C++14 language. Strictly following this coding standard improves security, safety and the overall quality of software, and should be supported by tools that can automate compliance checks. In this paper we present a tool AutoCheck that can check compliance to 190 rules defined by Autosar standard for C++14 language. AutoCheck is implemented as an extension of the Clang compiler and can be easily adopted as it can be invoked through simple options that are added to Clang. AutoCheck also offers additional options for controlling the generated output in a user-friendly way. We discuss development decisions that include experimental evaluation of different interfaces for static analysis offered by Clang. We present experimental evaluation which shows that AutoCheck performs highly efficient and precise analysis.",
      "paperUrl": "https://doi.org/10.1109/zinc52049.2021.9499304",
      "sourceUrl": "",
      "tags": [
        "Security",
        "Clang",
        "Static Analysis"
      ],
      "keywords": [
        "Security",
        "Clang",
        "Static Analysis",
        "Autocheck",
        "Automotive",
        "Checking Compliance",
        "Automotive Coding Standards"
      ],
      "matchedAuthors": [
        "Milena Vujošević Janičić",
        "Petar Jovanović"
      ]
    },
    {
      "id": "openalex-w3124403947",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "A MLIR Dialect for Quantum Assembly Languages",
      "authors": [
        {
          "name": "Alexander McCaskey",
          "affiliation": "Oak Ridge National Laboratory"
        },
        {
          "name": "Thien Nguyen",
          "affiliation": "Quantum Science Center"
        }
      ],
      "year": "2021",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "We demonstrate the utility of the Multi-Level Intermediate Representation (MLIR) for quantum computing. Specifically, we extend MLIR with a new quantum dialect that enables the expression and compilation of common quantum assembly languages. The true utility of this dialect is in its ability to be lowered to the LLVM intermediate representation (IR) in a manner that is adherent to the quantum intermediate representation (QIR) specification recently proposed by Microsoft. We leverage a qcor-enabled implementation of the QIR quantum runtime API to enable a retargetable (quantum hardware agnostic) compiler workflow mapping quantum languages to hybrid quantum-classical binary executables and object code. We evaluate and demonstrate this novel compiler workflow with quantum programs written in OpenQASM 2.0. We provide concrete examples detailing the generation of MLIR from OpenQASM source files, the lowering process from MLIR to LLVM IR, and ultimately the generation of executable binaries targeting available quantum processors.",
      "paperUrl": "https://arxiv.org/pdf/2101.11365",
      "sourceUrl": "https://doi.org/10.1109/qce52317.2021.00043",
      "tags": [
        "IR",
        "Quantum Computing",
        "MLIR"
      ],
      "keywords": [
        "IR",
        "Quantum Computing",
        "MLIR",
        "LLVM",
        "Intermediate Representation",
        "Quantum Compilation",
        "Quantum Assembly Languages",
        "MLIR Dialect",
        "Compiler Workflow"
      ],
      "matchedAuthors": [
        "Alexander McCaskey",
        "Thien Nguyen"
      ]
    },
    {
      "id": "openalex-w3217763044",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "A Comprehensive and Cross-Platform Test Suite for Memory Safety -- Towards an Open Framework for Testing Processor Hardware Supported Security Extensions",
      "authors": [
        {
          "name": "Wei Song",
          "affiliation": "Institute of Information Engineering"
        },
        {
          "name": "Jiameng Ying",
          "affiliation": "Chinese Academy of Sciences"
        },
        {
          "name": "Si‐Hao Shen",
          "affiliation": "Chinese Academy of Sciences"
        },
        {
          "name": "Boya Li",
          "affiliation": "Institute of Information Engineering"
        },
        {
          "name": "Hao Ma",
          "affiliation": "Chinese Academy of Sciences"
        },
        {
          "name": "Peng Liu",
          "affiliation": "Pennsylvania State University"
        }
      ],
      "year": "2021",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Memory safety remains a critical and widely violated property in reality. Numerous defense techniques have been proposed and developed but most of them are not applied or enabled by default in production-ready environment due to their substantial running cost. The situation might change in the near future because the hardware supported defenses against these attacks are finally beginning to be adopted by commercial processors, operating systems and compilers. We then face a question as there is currently no suitable test suite to measure the memory safety extensions supported on different processors. In fact, the issue is not constrained only for memory safety but all aspect of processor security. All of the existing test suites related to processor security lack some of the key properties, such as comprehensiveness, distinguishability and portability. As an initial step, we propose an expandable test framework for measuring the processor security and open source a memory safety test suite utilizing this framework. The framework is deliberately designed to be flexible so it can be gradually extended to all types of hardware supported security extensions in processors. The initial test suite for memory safety currently contains 160 test cases covering spatial and temporal safety of memory, memory access control, pointer integrity and control-flow integrity. Each type of vulnerabilities and their related defenses have been individually evaluated by one or more test cases. The test suite has been ported to three different instruction set architectures (ISAs) and experimented on six different platforms. We have also utilized the test suite to explore the security benefits of applying different sets of compiler flags available on the latest GNU GCC and LLVM compilers.",
      "paperUrl": "https://arxiv.org/pdf/2111.14072",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2111.14072",
      "tags": [
        "Security",
        "Testing"
      ],
      "keywords": [
        "Security",
        "Testing",
        "LLVM",
        "Memory Safety",
        "Processor Security",
        "Security Extensions",
        "Testing Processor Hardware",
        "Cross Platform"
      ],
      "matchedAuthors": [
        "Peng Liu",
        "Wei Song"
      ]
    },
    {
      "id": "openalex-w3211264865",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "gnss-sdr/gnss-sdr v0.0.12",
      "authors": [
        {
          "name": "Carles Fernández–Prades",
          "affiliation": "Centre Tecnologic de Telecomunicacions de Catalunya"
        },
        {
          "name": "Javier Arribas",
          "affiliation": "Cancer Targeted Technology (United States)"
        },
        {
          "name": "Gabriel Araújo",
          "affiliation": ""
        },
        {
          "name": "antonioramosdet",
          "affiliation": ""
        },
        {
          "name": "Damian Miralles",
          "affiliation": "University of Colorado Boulder"
        },
        {
          "name": "mmajoral",
          "affiliation": ""
        },
        {
          "name": "Luis Esteve",
          "affiliation": "Epsilon Systems (United States)"
        },
        {
          "name": "odrisci",
          "affiliation": ""
        },
        {
          "name": "Anthony Arnold",
          "affiliation": ""
        },
        {
          "name": "Gerald LaMountain",
          "affiliation": "Spiral Foundation"
        },
        {
          "name": "Álvaro Cebrián Juan",
          "affiliation": ""
        },
        {
          "name": "marc-sales",
          "affiliation": ""
        },
        {
          "name": "SergiSeguraMunoz",
          "affiliation": ""
        },
        {
          "name": "Andrés Cecilia Luque",
          "affiliation": ""
        },
        {
          "name": "marabra",
          "affiliation": ""
        },
        {
          "name": "Zosoworld",
          "affiliation": ""
        },
        {
          "name": "Osqzss",
          "affiliation": ""
        },
        {
          "name": "lmne",
          "affiliation": ""
        },
        {
          "name": "L Marc",
          "affiliation": ""
        },
        {
          "name": "Usman Haider",
          "affiliation": ""
        },
        {
          "name": "Dawei Sun",
          "affiliation": "International University of the Caribbean"
        },
        {
          "name": "Academias It",
          "affiliation": "Instituto Nacional de Capacitación Profesional"
        },
        {
          "name": "Sergey",
          "affiliation": ""
        },
        {
          "name": "Michael Dickens",
          "affiliation": ""
        },
        {
          "name": "Bitsulia Dmitry",
          "affiliation": ""
        }
      ],
      "year": "2020",
      "publication": "Zenodo (CERN European Organization for Nuclear Research)",
      "venue": "Zenodo (CERN European Organization for Nuclear Research)",
      "type": "research-paper",
      "abstract": "This release has several improvements in different dimensions, addition of new features and bug fixes: Improvements in Accuracy: Improved accuracy of the C/N0 estimator. Improvements in Availability: Fixed computation of acquisition threshold when using the <code>Acquisition_XX.pfa</code> configuration parameter, including non-coherent accumulation (<code>Acquisition_XX.max_dwells</code> &gt; 1). Improvements in Efficiency: Faster implementation of the Viterbi decoder for Galileo navigation messages. The <code>-O3</code> flag is now passed to GCC in <code>Release</code> and <code>RelWithDebInfo</code> build types (instead of <code>-O2</code>), thus enabling tree vectorization. Disabled if building for Fedora or Gentoo. Improvements in Flexibility: New Tracking parameters allow the configuration of the C/N0 and lock detector smoothers, as well as the activation of the FLL in pull-in and steady state stages. Added new Tracking parameter <code>Tracking_XX.carrier_aiding</code>, allowing enabling/disabling of carrier aiding to the code tracking loop. New PVT parameter <code>PVT.enable_rx_clock_correction</code> allows to enable or disable the continuous application of the Time solution correction (clock steering) to the computation of Observables. By default is set to <code>false</code> (that is, disabled). New PVT parameter <code>PVT.max_clock_offset_ms</code>: if <code>PVT.enable_rx_clock_correction</code> is set to <code>false</code>, this parameter sets the maximum allowed local clock offset with respect to the Time solution. If the estimated offset exceeds this parameter, a clock correction is applied to the computation of Observables. Fixed L5 and E5a receiver chains when tracking the data component. Added new PVT configuration parameter <code>PVT.rinex_name</code> to specify a custom name of the generated RINEX files. A commandline flag <code>--RINEX_name</code> is also available, and overrides the configuration. Improvements in Interoperability: Fixed PVT solution in receivers processing L1 plus L2C and/or L5 signals. Fixed the initialization of the carrier phase accumulator. Carrier phase measurements are now usable to compute integer ambiguity resolution. Added carrier phase observable initialization to match the pseudorange length. Added RINEX files generation for triple-band configurations (L1 + L2C + L5 and L1 + E1 + L2C + L5 + E5a). Fixed bugs in the decoding of BeiDou navigation messages. Fixed bugs in the generation of RTCM messages. Fixed a bug in feeding Galileo channels' observations to RTKLIB, which was causing wrong date of PVT fixes in Galileo-only receivers and not considering Galileo observations in multi-constellation receivers when using signals after the GPS rollover on April 6, 2019. Improved management of devices with the AD9361 RF transceiver. Fixed bugs in FPGA off-loading. Improvements in Maintainability: Rewriting of acquisition and tracking adapters, thus avoiding a lot of code duplication. New CMake option <code>-DENABLE_ARMA_NO_DEBUG</code> defines the macro <code>ARMA_NO_DEBUG</code>, which disables all run-time checks, such as bounds checking, in the Armadillo library. This will result in faster code. This option is disabled by default during development, but automatically set to <code>ON</code> if the option <code>ENABLE_PACKAGING</code> is set to <code>ON</code>. All shadowed variables detected by passing <code>-Wshadow</code> to the compiler have been fixed (see https://rules.sonarsource.com/cpp/RSPEC-1117?search=shadow and MISRA C++:2008, 2-10-2 - Identifiers declared in an inner scope shall not hide an identifier declared in an outer scope). Apply more clang-tidy checks related to readability: <code>readability-avoid-const-params-in-decls</code>, <code>readability-braces-around-statements</code>, <code>readability-isolate-declaration</code>, <code>readability-redundant-control-flow</code>, <code>readability-uppercase-literal-suffix</code>. Fixed raised warnings. Fixed a number of defects detected by <code>cpplint.py</code>. Filters applied: <code>+build/class</code>, <code>+build/c++14</code>, <code>+build/deprecated</code>, <code>+build/explicit_make_pair</code>, <code>+build/include_what_you_use</code>, <code>+build/printf_format</code>, <code>+build/storage_class</code>, <code>+readability/constructors</code>, <code>+readability/namespace</code>, <code>+readability/newline</code>, <code>+readability/utf8</code>, <code>+runtime/casting</code>, <code>+runtime/explicit</code>, <code>+runtime/indentation_namespace</code>, <code>+runtime/init</code>, <code>+runtime/invalid_increment</code>, <code>+runtime/member_string_references</code>, <code>+runtime/memset</code>, <code>+runtime/operator</code>, <code>+runtime/printf</code>, <code>+runtime/printf_format</code>, <code>+whitespace/blank_line</code>. <code>clang-format</code> can now be applied to the whole code tree without breaking compilation. Added more check options to <code>.clang-tidy</code> file. Default Python version is now &gt;= 3.4. Python 2.7 still can be used in systems where Python 3 is not available (e.g., CentOS 7, Debian 8, Ubuntu 10.04). CMake now passes the <code>-DCMAKE_BUILD_TYPE</code> (or configuration in multi-configuration generators like Xcode) to modules built along gnss-sdr (e.g, the volk_gnsssdr library and googletest). Build types available: <code>None</code>, <code>Release</code> (by default), <code>Debug</code>, <code>RelWithDebInfo</code>, <code>MinSizeRel</code>, <code>Coverage</code>, <code>NoOptWithASM</code>, <code>O2WithASM</code>, <code>O3WithASM</code>, <code>ASAN</code>. Fix runtime errors when compiling in <code>Debug</code> mode on macOS. Updated links in comments along the source code and in CMake scripts. Update GSL implementation to 0.36.0. See https://github.com/gsl-lite/gsl-lite/releases/tag/v0.36.0 Create a CI job on GitHub to ensure that <code>clang-tidy</code> has been applied in most of the source code (some optional blocks and tests are left apart). Create a CI job on GitHub to ensure that <code>clang-format</code> has been applied. Create a CI job on GitHub to ensure that <code>cpplint</code> filters have been applied. Create a CI job on GitHub to ensure compliance with REUSE Specification (see https://reuse.software) Create a CI job on GitHub using <code>prettier</code> (https://prettier.io/) to check markdown files formatting. Create a CI job on GitHub to check the formatting of CMake scripts using <code>cmakelint</code> (see https://github.com/richq/cmake-lint). Improvements in Openness: Make software compliant with REUSE Specification – Version 3.0 (see https://reuse.software/spec/). Improvements in Portability: The CMake scripts now find dependencies in Debian's riscv64 architecture. Enable AVX2 kernels of the volk_gnsssdr library when using the Clang compiler. Fixed building in some ARM-based devices. Now Clang and ARMClang can be used for native building. Added toolchain files for building gnss-sdr and the volk_gnsssdr library in several ARM processor architectures, including those in Raspberry Pi 3 and 4. The software can now be built using Xcode (passing <code>-GXcode</code> to CMake) without previous manual installation of volk_gnsssdr. The software can now be built using Xcode (passing <code>-GXcode</code> to CMake) without gflags, glog, matio, PugiXML, Protocol Buffers or googletest previously installed. Now the volk_gnsssdr library can be built on Microsoft Windows. Now the volk_gnsssdr library makes use of C11 <code>aligned_alloc</code> where available. Improved CMake script for cross-compilation and for the detection of AVX, AVX2 and NEON (v7 and v8) instructions. Fixed warnings raised by CMake 3.17. Fixed warnings raised by <code>cmake --warn-uninitialized ..</code> Fixed the receiver's availability in systems in which the Sys V message queue mechanism is not available. Improvements in Reliability: Decoding of navigation messages no longer rely on implementation defined behavior for shifting left a signed integer. Removed usage of functions with insecure API (e.g., <code>strcpy</code>, <code>sprintf</code>). New type alias <code>volk_gnsssdr::vector</code> allows both aligned memory allocation and automatic deallocation. Fixed a memory leak in the generation of Galileo PRN codes. Added clang-tidy checks <code>clang-analyzer-security.*</code>, <code>clang-analyzer-optin.portability.UnixAPI</code> clang-tidy checks. Fixed raised warnings. Fixed <code>cpplint.py</code> <code>runtime/printf</code> and <code>runtime/explicit</code> errors. All constructors callable with one argument are marked with the keyword explicit. See MISRA C++:2008, 12-1-3 - All constructors that are callable with a single argument of fundamental type shall be declared explicit. Improvements in Repeatability: Added the option to apply carrier smoothing of code pseudoranges with new Observables parameter <code>Observables.enable_carrier_smoothing</code>. Fixed normalization of DLL discriminator in BPSK modulations when the spacing between correlators was not 0.5. Improvements in Testability: Add receiver runtime to <code>position_test</code> report. Improvements in FPGA unit tests. Add new utility tool <code>obsdiff</code> to perform single and double differences computations from observation RINEX files. Requires GPSTk and Armadillo &gt;= 9.800. Improvements in Usability: A new global parameter <code>GNSS-SDR.pre_2009_file</code> allows to process raw sample files containing GPS L1 C/A signals dated before July 14, 2009. Improved DLL-PLL binary dump MATLAB/Octave plot script. Old versions removed. Simplified RTKLIB error log. Added a Python 3 plotting script to show relative performance of generic volk_gnsssdr kernels wrt SIMD fastest versions. Added reporting of velocity in the terminal. Added reporting of user clock drift estimation, in ppm, in the Pvt_Monitor and in internal logging (<code>Debug</code> mode). Updated documentation generated by Doxygen, now the <code>pdfmanual</code",
      "paperUrl": "https://doi.org/10.5281/zenodo.3709089",
      "sourceUrl": "",
      "tags": [
        "Security",
        "Performance",
        "Clang",
        "Autovectorization",
        "Infrastructure"
      ],
      "keywords": [
        "Security",
        "Performance",
        "Clang",
        "Autovectorization",
        "Infrastructure",
        "SIMD",
        "Improvements",
        "Volk Gnsssdr Library",
        "Clang Tidy Checks",
        "Readability",
        "Parameter",
        "Carrier Phase",
        "Configuration",
        "Create"
      ],
      "matchedAuthors": [
        "Academias It",
        "Andrés Cecilia Luque",
        "Anthony Arnold",
        "Carles Fernández–Prades",
        "Damian Miralles",
        "Gabriel Araújo",
        "Gerald LaMountain",
        "Javier Arribas",
        "L Marc",
        "Luis Esteve",
        "Michael Dickens",
        "Osqzss",
        "Sergey",
        "Usman Haider",
        "Zosoworld",
        "antonioramosdet",
        "lmne",
        "marabra",
        "marc-sales",
        "mmajoral",
        "odrisci",
        "Álvaro Cebrián Juan"
      ]
    },
    {
      "id": "openalex-w3109614308",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "TracerX: Dynamic Symbolic Execution with Interpolation",
      "authors": [
        {
          "name": "Joxan Jaffar",
          "affiliation": ""
        },
        {
          "name": "Rasool Maghareh",
          "affiliation": ""
        },
        {
          "name": "Sangharatna Godboley",
          "affiliation": ""
        },
        {
          "name": "Xuan-Linh Ha",
          "affiliation": ""
        }
      ],
      "year": "2020",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Dynamic Symbolic Execution (DSE) is an important method for the testing of programs. An important system on DSE is KLEE which inputs a C/C++ program annotated with symbolic variables, compiles it into LLVM, and then emulates the execution paths of LLVM using a specified backtracking strategy. The major challenge in symbolic execution is path explosion. The method of abstraction learning has been used to address this. The key step here is the computation of an interpolant to represent the learnt abstraction. In this paper, we present a new interpolation algorithm and implement it on top of the KLEE system. The main objective is to address the path explosion problem in pursuit of code penetration: to prove that a target program point is either reachable or unreachable. That is, our focus is verification. We show that despite the overhead of computing interpolants, the pruning of the symbolic execution tree that interpolants provide often brings significant overall benefits. We then performed a comprehensive experimental evaluation against KLEE, as well as against one well-known system that is based on Static Symbolic Execution, CBMC. Our primary experiment shows code penetration success at a new level, particularly so when the target is hard to determine. A secondary experiment shows that our implementation is competitive for testing.",
      "paperUrl": "https://arxiv.org/pdf/2012.00556",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2012.00556",
      "tags": [
        "Testing",
        "Dynamic Analysis"
      ],
      "keywords": [
        "Testing",
        "Dynamic Analysis",
        "LLVM",
        "Symbolic Execution",
        "Experiment Shows",
        "Path Explosion"
      ],
      "matchedAuthors": [
        "Joxan Jaffar",
        "Rasool Maghareh",
        "Sangharatna Godboley",
        "Xuan-Linh Ha"
      ]
    },
    {
      "id": "openalex-w3016328412",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "The MosaicSim Simulator (Full Technical Report)",
      "authors": [
        {
          "name": "Opeoluwa Matthews",
          "affiliation": ""
        },
        {
          "name": "Aninda Manocha",
          "affiliation": ""
        },
        {
          "name": "Davide Giri",
          "affiliation": ""
        },
        {
          "name": "Marcelo Orenes-Vera",
          "affiliation": ""
        },
        {
          "name": "Esin Türeci",
          "affiliation": ""
        },
        {
          "name": "Tyler Sorensen",
          "affiliation": ""
        },
        {
          "name": "Tae Jun Ham",
          "affiliation": ""
        },
        {
          "name": "Juan L. Aragón",
          "affiliation": ""
        },
        {
          "name": "Luca P. Carloni",
          "affiliation": ""
        },
        {
          "name": "Margaret Martonosi",
          "affiliation": ""
        }
      ],
      "year": "2020",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "As Moore's Law has slowed and Dennard Scaling has ended, architects are increasingly turning to heterogeneous parallelism and domain-specific hardware-software co-designs. These trends present new challenges for simulation-based performance assessments that are central to early-stage architectural exploration. Simulators must be lightweight to support rich heterogeneous combinations of general purpose cores and specialized processing units. They must also support agile exploration of hardware-software co-design, i.e. changes in the programming model, compiler, ISA, and specialized hardware. To meet these challenges, we introduce MosaicSim, a lightweight, modular simulator for heterogeneous systems, offering accuracy and agility designed specifically for hardware-software co-design explorations. By integrating the LLVM toolchain, MosaicSim enables efficient modeling of instruction dependencies and flexible additions across the stack. Its modularity also allows the composition and integration of different hardware components. We first demonstrate that MosaicSim captures architectural bottlenecks in applications, and accurately models both scaling trends in a multicore setting and accelerator behavior. We then present two case-studies where MosaicSim enables straightforward design space explorations for emerging systems, i.e. data science application acceleration and heterogeneous parallel architectures.",
      "paperUrl": "https://arxiv.org/pdf/2004.07415",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2004.07415",
      "tags": [
        "Performance",
        "Infrastructure"
      ],
      "keywords": [
        "Performance",
        "Infrastructure",
        "LLVM",
        "Mosaicsim Simulator Full",
        "Hardware",
        "Heterogeneous",
        "Full Technical Report",
        "Simulator Full Technical"
      ],
      "matchedAuthors": [
        "Aninda Manocha",
        "Davide Giri",
        "Esin Türeci",
        "Juan L. Aragón",
        "Luca P. Carloni",
        "Marcelo Orenes-Vera",
        "Margaret Martonosi",
        "Opeoluwa Matthews",
        "Tae Jun Ham",
        "Tyler Sorensen"
      ]
    },
    {
      "id": "openalex-w3090815597",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Tensor Optimization for High-Level Synthesis Design Flows",
      "authors": [
        {
          "name": "Marco Siracusa",
          "affiliation": "Politecnico di Milano"
        },
        {
          "name": "Fabrizio Ferrandi",
          "affiliation": "Politecnico di Milano"
        }
      ],
      "year": "2020",
      "publication": "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems",
      "venue": "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems | Vol. 39 (Issue 11)",
      "type": "research-paper",
      "abstract": "Improving data locality of tensor data structures is a crucial optimization for maximizing the performance of Machine Learning and intensive Linear Algebra applications. While CPUs and GPUs improve data locality by means of automated caching mechanisms, FPGAs let the developer specify data structure allocation. Although this feature enables a high degree of customizability, the increasing complexity and memory footprint of modern applications prevent considering any manual approach to find an optimal allocation. For this reason, we propose a compiler optimization to automatically improve the tensor allocation of high-level software descriptions. The optimization is controlled by a flexible cost model that can be tuned by means of simple yet expressive callback functions. In this way, the user can tailor the optimization strategy with respect to the optimization goal. We tested our methodology integrating our optimization in the Bambu open-source HLS framework. In this setting, we achieved a 14% speedup on the digit recognition version proposed by the Rosetta benchmark. Moreover, we tested our optimization on the CHStone benchmark suite, achieving an average of 6% speedup. Finally, we applied our methodology on two industrial examples from the aerospace domain obtaining a 15% speedup. As a final step, we tested the versatility of our methodology inserting our optimization in the Clang software optimization flow achieving a 12% speedup on the Rosetta benchmark when running on CPU.",
      "paperUrl": "http://hdl.handle.net/11311/1148653",
      "sourceUrl": "https://doi.org/10.1109/tcad.2020.3012318",
      "tags": [
        "Performance",
        "Clang",
        "Optimizations",
        "GPU",
        "ML"
      ],
      "keywords": [
        "Performance",
        "Clang",
        "Optimizations",
        "GPU",
        "ML",
        "Speedup",
        "Tensor Optimization",
        "Allocation",
        "Methodology"
      ],
      "matchedAuthors": [
        "Fabrizio Ferrandi"
      ]
    },
    {
      "id": "openalex-w3103929536",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Task-Graph Scheduling Extensions for Efficient Synchronization and Communication",
      "authors": [
        {
          "name": "Seonmyeong Bak",
          "affiliation": "Georgia Institute of Technology"
        },
        {
          "name": "Óscar Hernández",
          "affiliation": "Oak Ridge National Laboratory"
        },
        {
          "name": "Mark Gates",
          "affiliation": ""
        },
        {
          "name": "Piotr Łuszczek",
          "affiliation": ""
        },
        {
          "name": "Vivek Sarkar",
          "affiliation": "Georgia Institute of Technology"
        }
      ],
      "year": "2020",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Task graphs have been studied for decades as a foundation for scheduling irregular parallel applications and incorporated in programming models such as OpenMP. While many high-performance parallel libraries are based on task graphs, they also have additional scheduling requirements, such as synchronization from inner levels of data parallelism and internal blocking communications. In this paper, we extend task-graph scheduling to support efficient synchronization and communication within tasks. Our scheduler avoids deadlock and oversubscription of worker threads, and refines victim selection to increase the overlap of sibling tasks. To the best of our knowledge, our approach is the first to combine gang-scheduling and work-stealing in a single runtime. Our approach has been evaluated on the SLATE highperformance linear algebra library. Relative to the LLVM OMP runtime, our runtime demonstrates performance improvements of up to 13.82%, 15.2%, and 36.94% for LU, QR, and Cholesky, respectively, evaluated across different configurations.",
      "paperUrl": "https://arxiv.org/pdf/2011.03196",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2011.03196",
      "tags": [
        "Performance",
        "Libraries"
      ],
      "keywords": [
        "Performance",
        "Libraries",
        "LLVM",
        "Task Graph Scheduling",
        "Synchronization",
        "Graph Scheduling Extensions"
      ],
      "matchedAuthors": [
        "Mark Gates",
        "Piotr Łuszczek",
        "Seonmyeong Bak",
        "Vivek Sarkar",
        "Óscar Hernández"
      ]
    },
    {
      "id": "openalex-w3064302811",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Static Neural Compiler Optimization via Deep Reinforcement Learning",
      "authors": [
        {
          "name": "Rahim Mammadli",
          "affiliation": "Technical University of Darmstadt"
        },
        {
          "name": "Ali Jannesari",
          "affiliation": "Iowa State University"
        },
        {
          "name": "Felix Wolf",
          "affiliation": "Technical University of Darmstadt"
        }
      ],
      "year": "2020",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "The phase-ordering problem of modern compilers has received a lot of attention from the research community over the years, yet remains largely unsolved. Various optimization sequences exposed to the user are manually designed by compiler developers. In designing such a sequence developers have to choose the set of optimization passes, their parameters and ordering within a sequence. Resulting sequences usually fall short of achieving optimal runtime for a given source code and may sometimes even degrade the performance when compared to unoptimized version. In this paper, we employ a deep reinforcement learning approach to the phase-ordering problem. Provided with sub-sequences constituting LLVM's O3 sequence, our agent learns to outperform the O3 sequence on the set of source codes used for training and achieves competitive performance on the validation set, gaining up to 1.32x speedup on previously-unseen programs. Notably, our approach differs from autotuning methods by not depending on one or more test runs of the program for making successful optimization decisions. It has no dependence on any dynamic feature, but only on the statically-attainable intermediate representation of the source code. We believe that the models trained using our approach can be integrated into modern compilers as neural optimization agents, at first to complement, and eventually replace the hand-crafted optimization sequences.",
      "paperUrl": "https://arxiv.org/pdf/2008.08951",
      "sourceUrl": "https://doi.org/10.1109/llvmhpchipar51896.2020.00006",
      "tags": [
        "Performance",
        "Optimizations",
        "IR"
      ],
      "keywords": [
        "Performance",
        "Optimizations",
        "IR",
        "LLVM",
        "Intermediate Representation",
        "Neural Compiler Optimization",
        "Optimization Sequences",
        "Deep Reinforcement Learning",
        "Phase Ordering"
      ],
      "matchedAuthors": [
        "Ali Jannesari",
        "Felix Wolf"
      ]
    },
    {
      "id": "openalex-w3004986831",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "SMA: Eliminate Memory Spatial Errors via Saturation Memory Access.",
      "authors": [
        {
          "name": "Dongwei Chen",
          "affiliation": ""
        },
        {
          "name": "Daliang Xu",
          "affiliation": ""
        },
        {
          "name": "Dong Tong",
          "affiliation": ""
        },
        {
          "name": "kang dae sun",
          "affiliation": ""
        },
        {
          "name": "Xuetao Guan",
          "affiliation": ""
        },
        {
          "name": "Chun Yang",
          "affiliation": ""
        },
        {
          "name": "Cheng Xu",
          "affiliation": ""
        }
      ],
      "year": "2020",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Memory spatial error, i.e., buffer overflow, has been a well-known issue in computer security for a long time and remains one of the root causes of exploitable vulnerabilities. Existing tools focus on the detection of memory spatial errors and prevent intrusion by terminating the execution of the victim program. However, such tools cannot eliminate the vulnerabilities without patching the program. Unfortunately, in the increasingly popular embedded environment, deploying patches becomes harder because of the enormous number of devices. The limited resource in the embedded environment also prevents many existing tools to be used in the real world. This paper proposes the Saturation Memory Access (SMA), a memory spatial error elimination tool that prevents out-of-bound access without terminating the execution of a program. We use the tagged pointer scheme to store the boundary metadata of a memory object in the pointer itself, and correct the address to the object boundary upon detecting out-of-bound access. This method is based on a key observation that developers generally do not rely on out-of-bounds access to implement the program logic, so the correction of the address does not interfere with the execution of a program. We have implemented the prototype of SMA on LLVM 4.0.1 with two pointer encoding schemes designed for different tradeoff decisions between performance and memory usage. Experiments show that our prototype can stop nearly all attack forms in the RIPE benchmark and incurs 64\\%-84\\% overhead on SPEC CPU2017.",
      "paperUrl": "https://arxiv.org/abs/2002.02831",
      "sourceUrl": "",
      "tags": [
        "Security",
        "Performance",
        "Embedded"
      ],
      "keywords": [
        "Security",
        "Performance",
        "Embedded",
        "LLVM",
        "Memory Spatial Errors",
        "Saturation Memory Access",
        "Pointer",
        "Bound Access",
        "Embedded Environment",
        "Eliminate Memory Spatial",
        "Sma Eliminate Memory"
      ],
      "matchedAuthors": [
        "Chun Yang",
        "Daliang Xu",
        "Dong Tong",
        "Dongwei Chen",
        "Xuetao Guan",
        "kang dae sun"
      ]
    },
    {
      "id": "openalex-w3016343721",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "S3Library: Automatically Eliminating C/C++ Buffer Overflow using Compatible Safer Libraries",
      "authors": [
        {
          "name": "kang dae sun",
          "affiliation": ""
        },
        {
          "name": "Daliang Xu",
          "affiliation": ""
        },
        {
          "name": "Dongwei Chen",
          "affiliation": ""
        },
        {
          "name": "Cheng Xu",
          "affiliation": ""
        },
        {
          "name": "Dong Tong",
          "affiliation": ""
        }
      ],
      "year": "2020",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Annex K of C11, bounds-checking interfaces, recently introduced a set of alternative functions to mitigate buffer overflows, primarily those caused by string/memory functions. However, poor compatibility limits their adoption. Failure oblivious computing can eliminate the possibility that an attacker can exploit memory errors to corrupt the address space and significantly increase the availability of systems. In this paper, we present S3Library (Saturation-Memory-Access Safer String Library), which is compatible with the standard C library in terms of function signature. Our technique automatically replaces unsafe deprecated memory/string functions with safer versions that perform bounds checking and eliminate buffer overflows via boundless memory. S3Library employs MinFat, a very compact pointer representation following the Less is More principle, to encode metadata into unused upper bits within pointers. In addition, S3Library utilizes Saturation Memory Access to eliminate illegal memory accesses into boundless padding area. Even if an out-of-bounds access is made, the fault program will not be interrupted. We implement our scheme within the LLVM framework on X86-64 and evaluate our approach on correctness, security, runtime performance and availability.",
      "paperUrl": "https://arxiv.org/pdf/2004.09062",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2004.09062",
      "tags": [
        "Security",
        "Performance",
        "C Libs",
        "Libraries"
      ],
      "keywords": [
        "Security",
        "Performance",
        "C Libs",
        "Libraries",
        "LLVM",
        "Saturation Memory Access",
        "S3library Automatically Eliminating",
        "Buffer Overflows",
        "Bounds Checking",
        "Eliminate",
        "Compatible Safer Libraries"
      ],
      "matchedAuthors": [
        "Daliang Xu",
        "Dong Tong",
        "Dongwei Chen",
        "kang dae sun"
      ]
    },
    {
      "id": "openalex-w3037242241",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Retrofitting Symbolic Holes to LLVM IR",
      "authors": [
        {
          "name": "Bruce Collie",
          "affiliation": ""
        },
        {
          "name": "Michael O’Boyle",
          "affiliation": ""
        }
      ],
      "year": "2020",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Symbolic holes are one of the fundamental building blocks of solver-aided and interactive programming. Unknown values can be soundly integrated into programs, and automated tools such as SAT solvers can be used to prove properties of programs containing them. However, supporting symbolic holes in a programming language is challenging; specifying interactions of holes with the type system and execution semantics requires careful design. This paper motivates and introduces the implementation of symbolic holes with unknown type to LLVM IR, a strongly-typed compiler intermediate language. We describe how such holes can be implemented safely by abstracting unsound and type-unsafe details behind a new primitive IR manipulation. Our implementation co-operates well with existing features such as type and dependency checking. Finally, we highlight potentially fruitful areas for investigation using our implementation.",
      "paperUrl": "https://arxiv.org/pdf/2006.05875",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2006.05875",
      "tags": [
        "IR",
        "Programming Languages"
      ],
      "keywords": [
        "IR",
        "Programming Languages",
        "LLVM",
        "Intermediate Representation",
        "Retrofitting Symbolic Holes",
        "LLVM IR"
      ],
      "matchedAuthors": [
        "Michael O’Boyle"
      ]
    },
    {
      "id": "openalex-w2995506849",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "RVSDG",
      "authors": [
        {
          "name": "Nico Reissmann",
          "affiliation": "Norwegian University of Science and Technology"
        },
        {
          "name": "Jan Christian Meyer",
          "affiliation": "Norwegian University of Science and Technology"
        },
        {
          "name": "Helge Bahmann",
          "affiliation": ""
        },
        {
          "name": "Magnus Själander",
          "affiliation": "Uppsala University"
        }
      ],
      "year": "2020",
      "publication": "ACM Transactions on Embedded Computing Systems",
      "venue": "ACM Transactions on Embedded Computing Systems | Vol. 19 (Issue 6)",
      "type": "research-paper",
      "abstract": "Intermediate Representations (IRs) are central to optimizing compilers as the way the program is represented may enhance or limit analyses and transformations. Suitable IRs focus on exposing the most relevant information and establish invariants that different compiler passes can rely on. While control-flow centric IRs appear to be a natural fit for imperative programming languages, analyses required by compilers have increasingly shifted to understand data dependencies and work at multiple abstraction layers at the same time. This is partially evidenced in recent developments such as the Multi-Level Intermediate Representation (MLIR) proposed by Google. However, rigorous use of data flow centric IRs in general purpose compilers has not been evaluated for feasibility and usability as previous works provide no practical implementations. We present the Regionalized Value State Dependence Graph (RVSDG) IR for optimizing compilers. The RVSDG is a data flow centric IR where nodes represent computations, edges represent computational dependencies, and regions capture the hierarchical structure of programs. It represents programs in demand-dependence form, implicitly supports structured control flow, and models entire programs within a single IR. We provide a complete specification of the RVSDG, construction and destruction methods, as well as exemplify its utility by presenting Dead Node and Common Node Elimination optimizations. We implemented a prototype compiler and evaluate it in terms of performance, code size, compilation time, and representational overhead. Our results indicate that the RVSDG can serve as a competitive IR in optimizing compilers while reducing complexity.",
      "paperUrl": "https://arxiv.org/pdf/1912.05036",
      "sourceUrl": "https://doi.org/10.1145/3391902",
      "tags": [
        "Performance",
        "Optimizations",
        "IR",
        "Embedded",
        "Programming Languages",
        "MLIR"
      ],
      "keywords": [
        "Performance",
        "Optimizations",
        "IR",
        "Embedded",
        "Programming Languages",
        "MLIR",
        "Intermediate Representation",
        "Flow Centric",
        "Optimizing Compilers",
        "Flow Centric Irs",
        "Control Flow"
      ],
      "matchedAuthors": [
        "Magnus Själander"
      ]
    },
    {
      "id": "openalex-w3095611276",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "On the Generation of Disassembly Ground Truth and the Evaluation of Disassemblers",
      "authors": [
        {
          "name": "Kaiyuan Li",
          "affiliation": "Carnegie Mellon University"
        },
        {
          "name": "Maverick Woo",
          "affiliation": "Carnegie Mellon University"
        },
        {
          "name": "Limin Jia",
          "affiliation": "Carnegie Mellon University"
        }
      ],
      "year": "2020",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "When a software transformation or software security task needs to analyze a given program binary, the first step is often disassembly. Since many modern disassemblers have become highly accurate on many binaries, we believe reliable disassembler benchmarking requires standardizing the set of binaries used and the disassembly ground truth about these binaries. This paper presents (i) a first version of our work-in-progress disassembly benchmark suite, which comprises $879$ binaries from diverse projects compiled with multiple compilers and optimization settings, and (ii) a novel disassembly ground truth generator leveraging the notion of \"listing files'', which has broad support by clang, gcc, icc, and msvc. In additional, it presents our evaluation of four prominent open-source disassemblers using this benchmark suite and a custom evaluation system. Our entire system and all generated data are maintained openly on GitHub to encourage community adoption.",
      "paperUrl": "https://dl.acm.org/doi/pdf/10.1145/3411502.3418429",
      "sourceUrl": "https://doi.org/10.1145/3411502.3418429",
      "tags": [
        "Security",
        "Clang",
        "Optimizations"
      ],
      "keywords": [
        "Security",
        "Clang",
        "Optimizations",
        "Disassembly Ground Truth",
        "Binaries",
        "Disassemblers"
      ],
      "matchedAuthors": [
        "Limin Jia"
      ]
    },
    {
      "id": "openalex-w2975489744",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "NeuroVectorizer: end-to-end vectorization with deep reinforcement learning",
      "authors": [
        {
          "name": "Ameer Haj-Ali",
          "affiliation": "University of California, Berkeley"
        },
        {
          "name": "Nesreen K. Ahmed",
          "affiliation": "Intel (United States)"
        },
        {
          "name": "Ted Willke",
          "affiliation": "Intel (United States)"
        },
        {
          "name": "Sophia Shao",
          "affiliation": "University of California, Berkeley"
        },
        {
          "name": "Krste Asanović",
          "affiliation": "University of California, Berkeley"
        },
        {
          "name": "Ion Stoica",
          "affiliation": "University of California, Berkeley"
        }
      ],
      "year": "2020",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "One of the key challenges arising when compilers vectorize loops for today's SIMD-compatible architectures is to decide if vectorization or interleaving is beneficial. Then, the compiler has to determine how many instructions to pack together and how many loop iterations to interleave. Compilers are designed today to use fixed-cost models that are based on heuristics to make vectorization decisions on loops. However, these models are unable to capture the data dependency, the computation graph, or the organization of instructions. Alternatively, software engineers often hand-write the vectorization factors of every loop. This, however, places a huge burden on them, since it requires prior experience and significantly increases the development time. In this work, we explore a novel approach for handling loop vectorization and propose an end-to-end solution using deep reinforcement learning (RL). We conjecture that deep RL can capture different instructions, dependencies, and data structures to enable learning a sophisticated model that can better predict the actual performance cost and determine the optimal vectorization factors. We develop an end-to-end framework, from code to vectorization, that integrates deep RL in the LLVM compiler. Our proposed framework takes benchmark codes as input and extracts the loop codes. These loop codes are then fed to a loop embedding generator that learns an embedding for these loops. Finally, the learned embeddings are used as input to a Deep RL agent, which determines the vectorization factors for all the loops. We further extend our framework to support multiple supervised learning methods. We evaluate our approaches against the currently used LLVM vectorizer and loop polyhedral optimization techniques. Our experiments show 1.29X-4.73X performance speedup compared to baseline and only 3% worse than the brute-force search on a wide range of benchmarks.",
      "paperUrl": "https://dl.acm.org/doi/pdf/10.1145/3368826.3377928",
      "sourceUrl": "https://doi.org/10.1145/3368826.3377928",
      "tags": [
        "Performance",
        "Optimizations",
        "Autovectorization"
      ],
      "keywords": [
        "Performance",
        "Optimizations",
        "Autovectorization",
        "LLVM",
        "SIMD",
        "Vectorization Factors",
        "Deep Reinforcement Learning",
        "Loop Codes"
      ],
      "matchedAuthors": [
        "Ameer Haj-Ali",
        "Ion Stoica",
        "Krste Asanović",
        "Nesreen K. Ahmed"
      ]
    },
    {
      "id": "openalex-w2891545657",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Improved Basic Block Reordering",
      "authors": [
        {
          "name": "Andy Newell",
          "affiliation": "Meta (United States)"
        },
        {
          "name": "Sergey Pupyrev",
          "affiliation": "Meta (United States)"
        }
      ],
      "year": "2020",
      "publication": "IEEE Transactions on Computers",
      "venue": "IEEE Transactions on Computers | Vol. 69 (Issue 12)",
      "type": "research-paper",
      "abstract": "Basic block reordering is an important step for profile-guided binary optimization. The state-of-the-art goal for basic block reordering is to maximize the number of fall-through branches. However, we demonstrate that such orderings may impose suboptimal performance on instruction and I-TLB caches. We propose a new algorithm that relies on a model combining the effects of fall-through and caching behavior. As details of modern processor caching is quite complex and often unknown, we show how to use machine learning in selecting parameters that best trade off different caching effects to maximize binary performance. An extensive evaluation on a variety of applications, including Facebook production workloads, the open-source compilers Clang and GCC, and SPEC CPU benchmarks, indicate that the new method outperforms existing block reordering techniques, improving the resulting performance of applications with large code size. We have open sourced the code of the new algorithm as a part of a post-link binary optimization tool, BOLT.",
      "paperUrl": "https://arxiv.org/pdf/1809.04676",
      "sourceUrl": "https://doi.org/10.1109/tc.2020.2982888",
      "tags": [
        "Performance",
        "Clang",
        "Optimizations",
        "ML"
      ],
      "keywords": [
        "Performance",
        "Clang",
        "Optimizations",
        "ML",
        "Basic Block Reordering",
        "Binary Optimization"
      ],
      "matchedAuthors": [
        "Sergey Pupyrev"
      ]
    },
    {
      "id": "openalex-w3008964021",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "High Performance Code Generation in MLIR: An Early Case Study with GEMM",
      "authors": [
        {
          "name": "Uday Bondhugula",
          "affiliation": "Indian Institute of Science Bangalore"
        }
      ],
      "year": "2020",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "This article is primarily meant to present an early case study on using MLIR, a new compiler intermediate representation infrastructure, for high-performance code generation. Aspects of MLIR covered in particular include memrefs, the affine dialect, and polyhedral utilities and pass infrastructure surrounding those. This article is also aimed at showing the role compiler infrastructure could play in generating code that is competitive with highly tuned manually developed libraries, albeit in a more modular, reusable, and automatable way.",
      "paperUrl": "https://arxiv.org/pdf/2003.00532",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2003.00532",
      "tags": [
        "Backend",
        "Performance",
        "IR",
        "Infrastructure",
        "Libraries",
        "MLIR"
      ],
      "keywords": [
        "Backend",
        "Performance",
        "IR",
        "Infrastructure",
        "Libraries",
        "MLIR",
        "Intermediate Representation",
        "Code Generation"
      ],
      "matchedAuthors": [
        "Uday Bondhugula"
      ]
    },
    {
      "id": "openalex-w3016562408",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "GEVO: GPU Code Optimization using Evolutionary Computation",
      "authors": [
        {
          "name": "Jhe-Yu Liou",
          "affiliation": ""
        },
        {
          "name": "Xiaodong Wang",
          "affiliation": ""
        },
        {
          "name": "Stephanie Forrest",
          "affiliation": ""
        },
        {
          "name": "Carole-Jean Wu",
          "affiliation": ""
        }
      ],
      "year": "2020",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "GPUs are a key enabler of the revolution in machine learning and high performance computing, functioning as de facto co-processors to accelerate large-scale computation. As the programming stack and tool support have matured, GPUs have also become accessible to programmers, who may lack detailed knowledge of the underlying architecture and fail to fully leverage the GPU's computation power. GEVO (Gpu optimization using EVOlutionary computation) is a tool for automatically discovering optimization opportunities and tuning the performance of GPU kernels in the LLVM representation. GEVO uses population-based search to find edits to GPU code compiled to LLVM-IR and improves performance on desired criteria while retaining required functionality. We demonstrate that GEVO improves the execution time of the GPU programs in the Rodinia benchmark suite and the machine learning models, SVM and ResNet18, on NVIDIA Tesla P100. For the Rodinia benchmarks, GEVO improves GPU kernel runtime performance by an average of 49.48% and by as much as 412% over the fully compiler-optimized baseline. If kernel output accuracy is relaxed to tolerate up to 1% error, GEVO can find kernel variants that outperform the baseline version by an average of 51.08%. For the machine learning workloads, GEVO achieves kernel performance improvement for SVM on the MNIST handwriting recognition (3.24X) and the a9a income prediction (2.93X) datasets with no loss of model accuracy. GEVO achieves 1.79X kernel performance improvement on image classification using ResNet18/CIFAR-10, with less than 1% model accuracy reduction.",
      "paperUrl": "https://arxiv.org/pdf/2004.08140",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2004.08140",
      "tags": [
        "Performance",
        "Optimizations",
        "GPU",
        "IR",
        "ML"
      ],
      "keywords": [
        "Performance",
        "Optimizations",
        "GPU",
        "IR",
        "ML",
        "LLVM",
        "Gevo GPU",
        "Kernel Performance Improvement",
        "Evolutionary Computation",
        "Machine Learning",
        "Accuracy",
        "Gevo Improves",
        "Gevo Achieves",
        "Resnet18"
      ],
      "matchedAuthors": [
        "Carole-Jean Wu",
        "Jhe-Yu Liou",
        "Stephanie Forrest",
        "Xiaodong Wang"
      ]
    },
    {
      "id": "openalex-w3125884626",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Enabling Reliability-Driven Optimization Selection with Gate Graph Attention Neural Network",
      "authors": [
        {
          "name": "Jiang Wu",
          "affiliation": "National University of Defense Technology"
        },
        {
          "name": "Jianjun Xu",
          "affiliation": "National University of Defense Technology"
        },
        {
          "name": "Xiankai Meng",
          "affiliation": "National University of Defense Technology"
        },
        {
          "name": "Haoyu Zhang",
          "affiliation": "National University of Defense Technology"
        },
        {
          "name": "Zhuo Zhang",
          "affiliation": "Guilin University of Electronic Technology"
        }
      ],
      "year": "2020",
      "publication": "International Journal of Software Engineering and Knowledge Engineering",
      "venue": "International Journal of Software Engineering and Knowledge Engineering | Vol. 30 (Issue 11n12)",
      "type": "research-paper",
      "abstract": "Modern compilers provide a huge number of optional compilation optimization options. It is necessary to select the appropriate compilation optimization options for different programs or applications. To mitigate this problem, machine learning is widely used as an efficient technology. How to ensure the integrity and effectiveness of program information is the key to problem mitigation. In addition, when selecting the best compilation optimization option, the optimization goals are often execution speed, code size, and CPU consumption. There is not much research on program reliability. This paper proposes a Gate Graph Attention Neural Network (GGANN)-based compilation optimization option selection model. The data flow and function-call information are integrated into the abstract syntax tree as the program graph-based features. We extend the deep neural network based on GGANN and build a learning model that learns the heuristics method for program reliability. The experiment is performed under the Clang compiler framework. Compared with the traditional machine learning method, our model improves the average accuracy by 5–11% in the optimization option selection for program reliability. At the same time, experiments show that our model has strong scalability.",
      "paperUrl": "https://doi.org/10.1142/s0218194020400240",
      "sourceUrl": "",
      "tags": [
        "Clang",
        "Optimizations",
        "ML"
      ],
      "keywords": [
        "Clang",
        "Optimizations",
        "ML",
        "Compilation Optimization",
        "Attention Neural Network",
        "Program Reliability",
        "Compilation Optimization Options",
        "Gate Graph Attention",
        "Graph Attention Neural",
        "Optimization Option Selection",
        "Machine Learning",
        "Driven Optimization Selection",
        "Reliability Driven Optimization"
      ],
      "matchedAuthors": [
        "Haoyu Zhang",
        "Jiang Wu",
        "Jianjun Xu",
        "Xiankai Meng",
        "Zhuo Zhang"
      ]
    },
    {
      "id": "openalex-w3044775852",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Dynamic Binary Lifting and Recompilation",
      "authors": [
        {
          "name": "Anil Altinay",
          "affiliation": ""
        }
      ],
      "year": "2020",
      "publication": "eScholarship (California Digital Library)",
      "venue": "eScholarship (California Digital Library)",
      "type": "research-paper",
      "abstract": "Legacy binaries that do not have source code remain a vital part of our software ecosystem. Lifting and recompilation of legacy binaries allows for a wide range of late program transformations such as security hardening, deobfuscation, and reoptimization even when the source code is unavailable. Existing binary lifting approaches are based on static binary disassembly which has several limitations. Distinguishing code from data statically, for example, is undecidable in the general case. Static disassembly must rely on heuristics and assumptions to disassemble binaries in the absence of dynamic information and high-level language semantics. Consequently, static disassembly cannot reliably handle indirect jumps, inline assembly, and obfuscated code. Lifting approaches that rely on static disassembly, therefore, often produce unsound binaries.Dynamic disassembly of binaries can circumvent the limitations of static disassembly including the ability to handle obfuscated and encrypted binary code. In this dissertation, we present BinRec, a new approach to heuristic-free binary recompilation which lifts dynamic traces of binaries to a compiler-level intermediate representation (IR); the lifted IR is lowered to a \"recovered'' binary by taking advantage of the existing compiler toolchain. Our approach allows applying rich program transformations, such as compiler-based hardening and optimization passes, on top of the recovered representation. We identify and address a number of challenges in binary lifting, including unique challenges posed by our dynamic approach.In contrast to existing frameworks, our dynamic front end can accurately disassemble and lift binaries without heuristics, and we can successfully recover all SPEC INT 2006 benchmarks including C++ applications. We evaluate our approach in four application domains: I) binary reoptimization, ii) deobfuscation (by recovering partial program semantics from virtualization-obfuscated code), iii) binary hardening (by applying existing compiler-level passes such as AddressSanitizer and SafeStack on binary code), and iv) attack surface reduction in the recovered binary (by removing unused program paths).",
      "paperUrl": "https://escholarship.org/uc/item/8pz574mn",
      "sourceUrl": "",
      "tags": [
        "Security",
        "Optimizations",
        "IR",
        "Testing",
        "Infrastructure"
      ],
      "keywords": [
        "Security",
        "Optimizations",
        "IR",
        "Testing",
        "Infrastructure",
        "Intermediate Representation",
        "Sanitizers",
        "Binary Lifting",
        "Legacy Binaries",
        "Recompilation",
        "Program Transformations",
        "Recovered Binary",
        "Deobfuscation",
        "Reoptimization"
      ],
      "matchedAuthors": [
        "Anil Altinay"
      ]
    },
    {
      "id": "openalex-w3011058170",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Devil is Virtual: Reversing Virtual Inheritance in C++ Binaries",
      "authors": [
        {
          "name": "Rukayat Ayomide Erinfolami",
          "affiliation": "Binghamton University"
        },
        {
          "name": "Aravind Prakash",
          "affiliation": "Binghamton University"
        }
      ],
      "year": "2020",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Complexities that arise from implementation of object-oriented concepts in C++ such as virtual dispatch and dynamic type casting have attracted the attention of attackers and defenders alike. Binary-level defenses are dependent on full and precise recovery of class inheritance tree of a given program. While current solutions focus on recovering single and multiple inheritances from the binary, they are oblivious to virtual inheritance. Conventional wisdom among binary-level defenses is that virtual inheritance is uncommon and/or support for single and multiple inheritances provides implicit support for virtual inheritance. In this paper, we show neither to be true. Specifically, (1) we present an efficient technique to detect virtual inheritance in C++ binaries and show through a study that virtual inheritance can be found in non-negligible number (more than 10\\% on Linux and 12.5\\% on Windows) of real-world C++ programs including Mysql and libstdc++. (2) we show that failure to handle virtual inheritance introduces both false positives and false negatives in the hierarchy tree. These false positves and negatives either introduce attack surface when the hierarchy recovered is used to enforce CFI policies, or make the hierarchy difficult to understand when it is needed for program understanding (e.g., during decompilation). (3) We present a solution to recover virtual inheritance from COTS binaries. We recover a maximum of 95\\% and 95.5\\% (GCC -O0) and a minimum of 77.5\\% and 73.8\\% (Clang -O2) of virtual and intermediate bases respectively in the virtual inheritance tree.",
      "paperUrl": "https://dl.acm.org/doi/pdf/10.1145/3372297.3417251",
      "sourceUrl": "https://doi.org/10.1145/3372297.3417251",
      "tags": [
        "Clang"
      ],
      "keywords": [
        "Clang",
        "Reversing Virtual Inheritance",
        "Binaries",
        "Binary",
        "Hierarchy",
        "Inheritance Tree",
        "Virtual Reversing"
      ],
      "matchedAuthors": [
        "Aravind Prakash"
      ]
    },
    {
      "id": "openalex-w3049473015",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Compilation Optimization Pass Selection Using Gate Graph Attention Neural Network for Reliability Improvement",
      "authors": [
        {
          "name": "Jiang Wu",
          "affiliation": "National University of Defense Technology"
        },
        {
          "name": "Jianjun Xu",
          "affiliation": "National University of Defense Technology"
        },
        {
          "name": "Xiankai Meng",
          "affiliation": "National University of Defense Technology"
        },
        {
          "name": "Haoyu Zhang",
          "affiliation": "National University of Defense Technology"
        },
        {
          "name": "Zhuo Zhang",
          "affiliation": "Guilin University of Electronic Technology"
        },
        {
          "name": "Long Li",
          "affiliation": "Guilin University of Electronic Technology"
        }
      ],
      "year": "2020",
      "publication": "IEEE Access",
      "venue": "IEEE Access | Vol. 8",
      "type": "research-paper",
      "abstract": "When dealing with different programs or applications, it is necessary to select the appropriate compilation optimization pass or subsequence for the program. Machine learning is widely used as an efficient technological means of solving this problem. However, the most important problem when using machine learning is the extraction of program features. Obtaining more semantic and syntax information and complex transitions among code segments from the source code are obviously necessary in this context, and is also an area that may have been neglected by previous work. Ensuring the integrity and effectiveness of program information is key to this problem. Moreover, when performing and improving the selection, the measurement indicators are often program performance, code size, etc.; there is limited research on program reliability in this context, which requires both the longest measurement time and the most complicated measurement methods. Accordingly, this paper establishes a combined program feature extraction model and proposes a graph-based compilation optimization pass selection model that learns heuristics for program reliability. This experiment was performed using the clang compilation framework. The alternative compilation optimization pass adopts the C language standard compilation optimization passes. Compared with traditional machine learning methods, our model improves the average accuracy by between 5% and 11% in the optimization pass selection for program reliability. Our experiments also demonstrate the strong scalability of our proposed model.",
      "paperUrl": "https://ieeexplore.ieee.org/ielx7/6287639/8948470/09167239.pdf",
      "sourceUrl": "https://doi.org/10.1109/access.2020.3016758",
      "tags": [
        "Performance",
        "Clang",
        "Optimizations",
        "ML"
      ],
      "keywords": [
        "Performance",
        "Clang",
        "Optimizations",
        "ML",
        "Compilation Optimization Pass",
        "Optimization Pass Selection",
        "Program Reliability",
        "Machine Learning",
        "Measurement",
        "Gate Graph Attention",
        "Attention Neural Network",
        "Graph Attention Neural",
        "Reliability Improvement"
      ],
      "matchedAuthors": [
        "Haoyu Zhang",
        "Jiang Wu",
        "Jianjun Xu",
        "Xiankai Meng",
        "Zhuo Zhang"
      ]
    },
    {
      "id": "openalex-w3087775079",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "CUDAsmith: A Fuzzer for CUDA Compilers",
      "authors": [
        {
          "name": "Bo Jiang",
          "affiliation": "Beihang University"
        },
        {
          "name": "Xiaoyan Wang",
          "affiliation": "Beihang University"
        },
        {
          "name": "W. K. Chan",
          "affiliation": "City University of Hong Kong"
        },
        {
          "name": "T.H. Tse",
          "affiliation": "University of Hong Kong"
        },
        {
          "name": "Na Li",
          "affiliation": ""
        },
        {
          "name": "Yongfeng Yin",
          "affiliation": "Beihang University"
        },
        {
          "name": "Zhenyu Zhang",
          "affiliation": "Chinese Academy of Sciences"
        }
      ],
      "year": "2020",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "CUDA is a parallel computing platform and programming model for the graphics processing unit (GPU) of NVIDIA. With CUDA programming, general purpose computing on GPU (GPGPU) is possible. However, the correctness of CUDA programs relies on the correctness of CUDA compilers, which is difficult to test due to its complexity. In this work, we propose CUDAsmith, a fuzzing framework for CUDA compilers. Our tool can randomly generate deterministic and valid CUDA kernel code with several different strategies. Moreover, it adopts random differential testing and EMI testing techniques to solve the test oracle problems of CUDA compiler testing. In particular, we lift live code injection to CUDA compiler testing to help generate EMI variants. Our fuzzing experiments with both the NVCC compiler and the Clang compiler for CUDA have detected thousands of failures, some of which have been confirmed by compiler developers. Finally, the cost-effectiveness of CUDAsmith is also thoroughly evaluated in our fuzzing experiment.",
      "paperUrl": "https://doi.org/10.1109/compsac48688.2020.0-156",
      "sourceUrl": "",
      "tags": [
        "Clang",
        "GPU",
        "CUDA",
        "Testing"
      ],
      "keywords": [
        "Clang",
        "GPU",
        "CUDA",
        "Testing",
        "Fuzzing",
        "Differential Testing",
        "Parallel Computing",
        "CUDA Compilers",
        "CUDA Compiler Testing",
        "Cudasmith"
      ],
      "matchedAuthors": [
        "T.H. Tse",
        "W. K. Chan"
      ]
    },
    {
      "id": "openalex-w3033691023",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Automatic Verification of LLVM Code",
      "authors": [
        {
          "name": "Axel Legay",
          "affiliation": ""
        },
        {
          "name": "Dirk Nowotka",
          "affiliation": ""
        },
        {
          "name": "Danny Bøgsted Poulsen",
          "affiliation": ""
        }
      ],
      "year": "2020",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "In this work we present our work in developing a software verification tool for llvm-code - Lodin - that incorporates both explicit-state model checking, statistical model checking and symbolic state model checking algorithms.",
      "paperUrl": "https://arxiv.org/pdf/2006.02670",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2006.02670",
      "tags": [],
      "keywords": [
        "LLVM",
        "Model Checking",
        "Verification"
      ],
      "matchedAuthors": [
        "Axel Legay",
        "Danny Bøgsted Poulsen",
        "Dirk Nowotka"
      ]
    },
    {
      "id": "openalex-w3092225291",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "A Vertex Cut based Framework for Load Balancing and Parallelism Optimization in Multi-core Systems",
      "authors": [
        {
          "name": "Guixiang Ma",
          "affiliation": ""
        },
        {
          "name": "Yao Xiao",
          "affiliation": ""
        },
        {
          "name": "Theodore L. Willke",
          "affiliation": ""
        },
        {
          "name": "Nesreen K. Ahmed",
          "affiliation": ""
        },
        {
          "name": "Shahin Nazarian",
          "affiliation": ""
        },
        {
          "name": "Paul Bogdan",
          "affiliation": ""
        }
      ],
      "year": "2020",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "High-level applications, such as machine learning, are evolving from simple models based on multilayer perceptrons for simple image recognition to much deeper and more complex neural networks for self-driving vehicle control systems.The rapid increase in the consumption of memory and computational resources by these models demands the use of multi-core parallel systems to scale the execution of the complex emerging applications that depend on them. However, parallel programs running on high-performance computers often suffer from data communication bottlenecks, limited memory bandwidth, and synchronization overhead due to irregular critical sections. In this paper, we propose a framework to reduce the data communication and improve the scalability and performance of these applications in multi-core systems. We design a vertex cut framework for partitioning LLVM IR graphs into clusters while taking into consideration the data communication and workload balance among clusters. First, we construct LLVM graphs by compiling high-level programs into LLVM IR, instrumenting code to obtain the execution order of basic blocks and the execution time for each memory operation, and analyze data dependencies in dynamic LLVM traces. Next, we formulate the problem as Weight Balanced $p$-way Vertex Cut, and propose a generic and flexible framework, wherein four different greedy algorithms are proposed for solving this problem. Lastly, we propose a memory-centric run-time mapping of the linear time complexity to map clusters generated from the vertex cut algorithms onto a multi-core platform. We conclude that our best algorithm, WB-Libra, provides performance improvements of 1.56x and 1.86x over existing state-of-the-art approaches for 8 and 1024 clusters running on a multi-core platform, respectively.",
      "paperUrl": "https://arxiv.org/pdf/2010.04414",
      "sourceUrl": "https://doi.org/10.48550/arxiv.2010.04414",
      "tags": [
        "Performance",
        "Optimizations",
        "IR",
        "ML"
      ],
      "keywords": [
        "Performance",
        "Optimizations",
        "IR",
        "ML",
        "LLVM",
        "Intermediate Representation",
        "Multi Core Platform",
        "Vertex Cut",
        "Clusters",
        "LLVM IR",
        "Memory",
        "Communication",
        "Propose",
        "Graphs"
      ],
      "matchedAuthors": [
        "Guixiang Ma",
        "Nesreen K. Ahmed",
        "Paul Bogdan",
        "Shahin Nazarian",
        "Theodore L. Willke",
        "Yao Xiao"
      ]
    },
    {
      "id": "openalex-w3115177176",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "A DSL for Resource Checking Using Finite State Automaton-Driven Symbolic Execution",
      "authors": [
        {
          "name": "Endre Fülöp",
          "affiliation": "Eötvös Loránd University"
        },
        {
          "name": "Norbert Pataki",
          "affiliation": "Eötvös Loránd University"
        }
      ],
      "year": "2020",
      "publication": "Open Computer Science",
      "venue": "Open Computer Science | Vol. 11 (Issue 1)",
      "type": "research-paper",
      "abstract": "Abstract Static analysis is an essential way to find code smells and bugs. It checks the source code without execution and no test cases are required, therefore its cost is lower than testing. Moreover, static analysis can help in software engineering comprehensively, since static analysis can be used for the validation of code conventions, for measuring software complexity and for executing code refactorings as well. Symbolic execution is a static analysis method where the variables ( e.g. input data) are interpreted with symbolic values. Clang Static Analyzer is a powerful symbolic execution engine based on the Clang compiler infrastructure that can be used with C, C++ and Objective-C. Validation of resources’ usage ( e.g. files, memory) requires finite state automata (FSA) for modeling the state of resource ( e.g. locked or acquired resource). In this paper, we argue for an approach in which automata are in-use during symbolic execution. The generic automaton can be customized for different resources. We present our domain-specific language to define automata in terms of syntactic and semantic rules. We have developed a tool for this approach which parses the automaton and generates Clang Static Analyzer checker that can be used in the symbolic execution engine. We show an example automaton in our domain-specific language and the usage of generated checker.",
      "paperUrl": "https://www.degruyter.com/document/doi/10.1515/comp-2020-0120/pdf",
      "sourceUrl": "https://doi.org/10.1515/comp-2020-0120",
      "tags": [
        "Clang",
        "Static Analysis",
        "Testing",
        "Dynamic Analysis",
        "Infrastructure"
      ],
      "keywords": [
        "Clang",
        "Static Analysis",
        "Testing",
        "Dynamic Analysis",
        "Infrastructure",
        "Symbolic Execution",
        "Symbolic Execution Engine",
        "Automaton Driven Symbolic",
        "Domain Specific Language",
        "Resource Checking",
        "Finite State Automaton",
        "Automata",
        "Driven Symbolic Execution",
        "State Automaton Driven"
      ],
      "matchedAuthors": [
        "Norbert Pataki"
      ]
    },
    {
      "id": "openalex-w3208319921",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "gnss-sdr/gnss-sdr: v0.0.11",
      "authors": [
        {
          "name": "Carles Fernández–Prades",
          "affiliation": "Centre Tecnologic de Telecomunicacions de Catalunya"
        },
        {
          "name": "Javier Arribas",
          "affiliation": "Cancer Targeted Technology (United States)"
        },
        {
          "name": "Gabriel Araújo",
          "affiliation": ""
        },
        {
          "name": "antonioramosdet",
          "affiliation": ""
        },
        {
          "name": "Damian Miralles",
          "affiliation": "University of Colorado System"
        },
        {
          "name": "Luis Esteve",
          "affiliation": "Epsilon Systems (United States)"
        },
        {
          "name": "mmajoral",
          "affiliation": ""
        },
        {
          "name": "odrisci",
          "affiliation": ""
        },
        {
          "name": "Anthony Arnold",
          "affiliation": ""
        },
        {
          "name": "Álvaro Cebrián Juan",
          "affiliation": ""
        },
        {
          "name": "marc-sales",
          "affiliation": ""
        },
        {
          "name": "Andrés Cecilia Luque",
          "affiliation": ""
        },
        {
          "name": "Gerald LaMountain",
          "affiliation": "Spiral Foundation"
        },
        {
          "name": "marabra",
          "affiliation": ""
        },
        {
          "name": "Zosoworld",
          "affiliation": ""
        },
        {
          "name": "Osqzss",
          "affiliation": ""
        },
        {
          "name": "lmne",
          "affiliation": ""
        },
        {
          "name": "L Marc",
          "affiliation": ""
        },
        {
          "name": "Usman Haider",
          "affiliation": ""
        },
        {
          "name": "sundw",
          "affiliation": ""
        },
        {
          "name": "Academias It",
          "affiliation": "Instituto Nacional de Capacitación Profesional"
        },
        {
          "name": "Sergey",
          "affiliation": ""
        },
        {
          "name": "Michael Dickens",
          "affiliation": ""
        },
        {
          "name": "Hoernchen",
          "affiliation": ""
        }
      ],
      "year": "2019",
      "publication": "Zenodo (CERN European Organization for Nuclear Research)",
      "venue": "Zenodo (CERN European Organization for Nuclear Research)",
      "type": "research-paper",
      "abstract": "This release has several improvements in different dimensions, addition of new features and bug fixes: Improvements in Accuracy Local clock correction based on PVT solution, allowing the delivery of continuous observables. Fix a bug in broadcast ionospheric parameters usage. Improvements in Availability Improved mechanism for false lock detection in the Tracking loops. Fixed bug in Galileo INAV/FNAV message decoding when PLL is locked at 180 degrees, which prevented from correct navigation message decoding in some situations. Fixed bug that caused a random deadlock in the Observables block, preventing the computation of PVT fixes. Fixed PVT computation continuity through the TOW rollover. Improved signal acquisition and tracking mechanisms in high dynamic scenarios. Improvements in Efficiency Added mechanism for assisted acquisition of signals on a secondary band when the primary has already been acquired. This allows a great reduction of the computational load in multi-frequency configurations. Tracking loops now perform bit synchronization, simplifying the decoding process in Telemetry blocks and FPGA-offloading. Improved preamble detection implementation in the decoding of navigation messages (acceleration by x1.6 on average per channel). Shortened Acquisition to Tracking transition time. Applied clang-tidy checks and fixes related to performance: performance-faster-string-find, performance-for-range-copy, performance-implicit-conversion-in-loop, performance-inefficient-algorithm, performance-inefficient-string-concatenation, performance-inefficient-vector-operation, performance-move-const-arg, performance-move-constructor-init, performance-noexcept-move-constructor, performance-type-promotion-in-math-fn, performance-unnecessary-copy-initialization, performance-unnecessary-value-param, readability-string-compare. Improvements in Flexibility: Rewritten Control Thread and GNSS flow graph for increased control of channels' status and smarter assignation of satellites in multi-band configurations. New Tracking parameters allow the configuration of PLL and DLL filters order. Added parameter to enable FLL during pull-in time. Configurable pull-in time in the Tracking loops. Improvements in Interoperability: Added the BeiDou B1I and B3I receiver chains. Fix bug in GLONASS dual frequency receiver. Added a custom UDP/IP output for PVT data streaming. Improved Monitor block with UDP/IP output for internal receiver's data streaming. Custom output formats described with .proto files, making easier to other applications reading them in a forward and backward-compatible fashion upon future format changes. New dependency: Protocol Buffers &gt;= 3.0.0 Fixes in RINEX generation: week rollover, annotations are not repeated anymore in navigation files. Parameter rinexnav_rate_ms has been removed, annotations are made as new ephemeris arrive. Fixes in RTCM messages generation: week rollover. Improvements in Maintainability: The internal communication mechanism based on gr::msg_queue has been replaced by a thread-safe, built-in asynchronous message passing system based on GNU Radio's Polymorphic Types. This change is backwards-compatible and prevents from a failure in case of a possible future deprecation or removal of the gr::msg_queue API. Deprecated boost::asio::io_service replaced by boost::asio::io_context if Boost &gt; 1.65 CMake turns all policies to ON according to the running version up to version 3.15. Usage of clang-tidy integrated into CMake scripts. New option -DENABLE_CLANG_TIDY=ON executes clang-tidy along with compilation. Requires clang compiler. Applied clang-tidy checks and fixes related to readability: readability-container-size-empty, readability-identifier-naming, readability-inconsistent-declaration-parameter-name, readability-named-parameter, readability-non-const-parameter, readability-string-compare. Improved includes selection following suggestions by include-what-you-use (see https://include-what-you-use.org/), allowing faster compiles, fewer recompiles and making refactoring easier. Massive reduction of warnings triggered by clang-tidy checks. Throughout code cleaning and formatting performed with automated tools in order to reduce future commit noise. Improvements in Portability: Added interfaces for FPGA off-loading in GPS L1 C/A, Galileo E1b/c, GPS L2C, GPS L5 and Galileo E5a receiver chains. CMake scripts now follow a modern approach (targets and properties) but still work with 2.8.12. Improvements for macOS users using Homebrew. The software builds against GNU Radio &gt;= 3.7.3, including 3.8.0. Automatically detected, no user intervention is required. The volk_gnsssdr library can now be built without requiring Boost if the compiler supports C++17 or higher. The Boost Filesystem library is not anymore a required dependency in cases where it can be replaced by std::filesystem. Automatically detected, no user intervention is required. CMake scripts automatically select among C++11, C++14, C++17 or C++20 standards, the most recent as possible, depending on compiler and dependencies versions. Drawback in portability: Protocol Buffers &gt;= 3.0.0 is a new required dependency. Improvements in Reliability Included the Guidelines Support Library. General improvement of memory management, replacement of raw pointers by containers or smart pointers. Applied clang-tidy checks and fixes related to High Integrity C++: performance-move-const-arg, modernize-use-auto, modernize-use-equals-default, modernize-use-equals-delete, modernize-use-noexcept, modernize-use-nullptr, cert-dcl21-cpp, misc-new-delete-overloads, cert-dcl58-cpp, cert-err52-cpp, cert-err60-cpp, hicpp-exception-baseclass, hicpp-explicit-conversions. Fixed a number of defects detected by Coverity Scan (version June 2019). Improvements in Usability The receiver now admits FPGA off-loading, allowing for real time operation in embedded systems at high sampling rates and high number of signals and channels per signal in multiple bands. Fixed program termination (avoiding hangs and segfaults in some platforms/configurations). The Labsat_Signal_Source now terminates the receiver's execution when the end of file(s) is reached. It now accepts LabSat 2 filenames and series of LabSat 3 files. Added configuration parameters to set the annotation rate in KML, GPX, GeoJSON and NMEA outputs, set by default to 1 s. New parameter PVT.show_local_time_zone displays time in the local time zone. Subject to the proper system configuration of the machine running the software receiver. This feature is not available in old compilers. CMake now generates a summary of required/optional dependency packages found and enabled/disabled features. This info is also stored in a file called features.log in the building directory. Improved information provided to the user in case of building configuration and runtime failures. See the definitions of concepts and metrics at https://gnss-sdr.org/design-forces/",
      "paperUrl": "https://zenodo.org/record/3359989",
      "sourceUrl": "https://doi.org/10.5281/zenodo.3359989",
      "tags": [
        "Performance",
        "Clang",
        "GPU",
        "Embedded"
      ],
      "keywords": [
        "Performance",
        "Clang",
        "GPU",
        "Embedded",
        "Offloading",
        "Performance Inefficient",
        "Improvements",
        "Clang Tidy Checks",
        "Readability",
        "Modernize Use",
        "Receiver",
        "Parameter",
        "Applied Clang Tidy",
        "Cmake Scripts"
      ],
      "matchedAuthors": [
        "Academias It",
        "Andrés Cecilia Luque",
        "Anthony Arnold",
        "Carles Fernández–Prades",
        "Damian Miralles",
        "Gabriel Araújo",
        "Gerald LaMountain",
        "Hoernchen",
        "Javier Arribas",
        "L Marc",
        "Luis Esteve",
        "Michael Dickens",
        "Osqzss",
        "Sergey",
        "Usman Haider",
        "Zosoworld",
        "antonioramosdet",
        "lmne",
        "marabra",
        "marc-sales",
        "mmajoral",
        "odrisci",
        "sundw",
        "Álvaro Cebrián Juan"
      ]
    },
    {
      "id": "openalex-w2947865796",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Towards Stateflow Model Aware Debugging with LLDB",
      "authors": [
        {
          "name": "Bewoayia Kebianyor",
          "affiliation": "Oldenburger Institut für Informatik"
        },
        {
          "name": "Philipp Ittershagen",
          "affiliation": "Oldenburger Institut für Informatik"
        },
        {
          "name": "Kim Grüttner",
          "affiliation": "Oldenburger Institut für Informatik"
        }
      ],
      "year": "2019",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "In many of today's products the embedded software is designed and tested in a model based environment. With the help of code generation techniques, a part of the model can be cross-compiled and integrated on the processor of the final product. While testing and debugging of the input model is usually well supported, debugging of the generated code for the target processor together with its run-time environment is more difficult, because traceability between the generated code and the input model is lost or has to be manually reconstructed. This paper focuses on providing traceability of automatically generated source code to model elements. Our proposed approach extends LLDB with model related debug information to become aware of the original input model. We demonstrate the correct functionality of our approach by running the model-related LLDB commands for two Stateflow models with generated source code in C and C++ respectively. The concept presented here is not limited to Stateflow models, but can be applicable to other models where source code is automatically generated with source-to-model traceability tags.",
      "paperUrl": "https://doi.org/10.1145/3300189.3300190",
      "sourceUrl": "",
      "tags": [
        "Backend",
        "Embedded",
        "LLDB",
        "Testing",
        "Debug Information"
      ],
      "keywords": [
        "Backend",
        "Embedded",
        "LLDB",
        "Testing",
        "Debug Information",
        "Code Generation",
        "Stateflow",
        "Traceability",
        "Automatically Generated",
        "Aware Debugging"
      ],
      "matchedAuthors": [
        "Kim Grüttner"
      ]
    },
    {
      "id": "openalex-w2945057371",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Towards Neural Decompilation",
      "authors": [
        {
          "name": "Omer Katz",
          "affiliation": "Technion – Israel Institute of Technology"
        },
        {
          "name": "Yuval Olshaker",
          "affiliation": "Technion – Israel Institute of Technology"
        },
        {
          "name": "Yoav Goldberg",
          "affiliation": ""
        },
        {
          "name": "Eran Yahav",
          "affiliation": "Technion – Israel Institute of Technology"
        }
      ],
      "year": "2019",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "We address the problem of automatic decompilation, converting a program in low-level representation back to a higher-level human-readable programming language. The problem of decompilation is extremely important for security researchers. Finding vulnerabilities and understanding how malware operates is much easier when done over source code. The importance of decompilation has motivated the construction of hand-crafted rule-based decompilers. Such decompilers have been designed by experts to detect specific control-flow structures and idioms in low-level code and lift them to source level. The cost of supporting additional languages or new language features in these models is very high. We present a novel approach to decompilation based on neural machine translation. The main idea is to automatically learn a decompiler from a given compiler. Given a compiler from a source language S to a target language T , our approach automatically trains a decompiler that can translate (decompile) T back to S . We used our framework to decompile both LLVM IR and x86 assembly to C code with high success rates. Using our LLVM and x86 instantiations, we were able to successfully decompile over 97% and 88% of our benchmarks respectively.",
      "paperUrl": "https://arxiv.org/pdf/1905.08325",
      "sourceUrl": "https://doi.org/10.48550/arxiv.1905.08325",
      "tags": [
        "Security",
        "IR",
        "Programming Languages"
      ],
      "keywords": [
        "Security",
        "IR",
        "Programming Languages",
        "LLVM",
        "Intermediate Representation",
        "Neural Decompilation",
        "Decompilers"
      ],
      "matchedAuthors": [
        "Eran Yahav"
      ]
    },
    {
      "id": "openalex-w2931679308",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "The Code That Never Ran: Modeling Attacks on Speculative Evaluation",
      "authors": [
        {
          "name": "Craig Disselkoen",
          "affiliation": "University of California, San Diego"
        },
        {
          "name": "Radha Jagadeesan",
          "affiliation": "DePaul University"
        },
        {
          "name": "Alan Jeffrey",
          "affiliation": ""
        },
        {
          "name": "James Riely",
          "affiliation": "DePaul University"
        }
      ],
      "year": "2019",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "This paper studies information flow caused by speculation mechanisms in hardware and software. The Spectre attack shows that there are practical information flow attacks which use an interaction of dynamic security checks, speculative evaluation and cache timing. Previous formal models of program execution are designed to capture computer architecture, rather than micro-architecture, and so do not capture attacks such as Spectre. In this paper, we propose a model based on pomsets which is designed to model speculative evaluation. The model is abstract with respect to specific micro-architectural features, such as caches and pipelines, yet is powerful enough to express known attacks such as Spectre and Prime+Abort, and verify their countermeasures. The model also allows for the prediction of new information flow attacks. We derive two such attacks, which exploit compiler optimizations, and validate these experimentally against gcc and clang.",
      "paperUrl": "https://ieeexplore.ieee.org/ielx7/8826229/8835208/08835248.pdf",
      "sourceUrl": "https://doi.org/10.1109/sp.2019.00047",
      "tags": [
        "Security",
        "Clang",
        "Optimizations"
      ],
      "keywords": [
        "Security",
        "Clang",
        "Optimizations",
        "Flow Attacks",
        "Speculative",
        "Spectre",
        "Never Ran Modeling",
        "Ran Modeling Attacks"
      ],
      "matchedAuthors": [
        "Craig Disselkoen"
      ]
    },
    {
      "id": "openalex-w2971294480",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "TapirXLA: Embedding Fork-Join Parallelism into the XLA Compiler in TensorFlow Using Tapir",
      "authors": [
        {
          "name": "Tao B. Schardl",
          "affiliation": "Massachusetts Institute of Technology"
        },
        {
          "name": "Siddharth Samsi",
          "affiliation": "MIT Lincoln Laboratory"
        }
      ],
      "year": "2019",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "This work introduces TapirXLA, a replacement for TensorFlow's XLA compiler that embeds recursive fork-join parallelism into XLA's low-level representation of code. Machine-learning applications rely on efficient parallel processing to achieve performance, and they employ a variety of technologies to improve performance, including compiler technology. But compilers in machine-learning frameworks lack a deep understanding of parallelism, causing them to lose performance by missing optimizations on parallel computation. This work studies how Tapir, a compiler intermediate representation (IR) that embeds parallelism into a mainstream compiler IR, can be incorporated into a compiler for machine learning to remedy this problem. TapirXLA modifies the XLA compiler in TensorFlow to employ the Tapir/LLVM compiler to optimize low-level parallel computation. TapirXLA encodes the parallelism within high-level TensorFlow operations using Tapir's representation of fork-join parallelism. TapirXLA also exposes to the compiler implementations of linear-algebra library routines whose parallel operations are encoded using Tapir's representation. We compared the performance of TensorFlow using TapirXLA against TensorFlow using an unmodified XLA compiler. On four neural-network benchmarks, TapirXLA speeds up the parallel running time of the network by a geometric-mean multiplicative factor of 30% to 100%, across four CPU architectures.",
      "paperUrl": "https://arxiv.org/pdf/1908.11338",
      "sourceUrl": "https://doi.org/10.1109/hpec.2019.8916312",
      "tags": [
        "Performance",
        "Optimizations",
        "IR",
        "ML"
      ],
      "keywords": [
        "Performance",
        "Optimizations",
        "IR",
        "ML",
        "LLVM",
        "Intermediate Representation",
        "Tapirxla Embedding Fork",
        "Fork Join Parallelism",
        "Tensorflow",
        "Xla Compiler",
        "Machine Learning",
        "Parallel Computation",
        "Embedding Fork Join"
      ],
      "matchedAuthors": [
        "Tao B. Schardl"
      ]
    },
    {
      "id": "openalex-w2971707596",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Synthesis of Benchmarks for the C Programming Language by Mining Software Repositories",
      "authors": [
        {
          "name": "Breno Campos Ferreira Guimarães",
          "affiliation": ""
        },
        {
          "name": "José Wesley de Souza Magalhães",
          "affiliation": ""
        },
        {
          "name": "Anderson Faustino da Silva",
          "affiliation": "Universidade Estadual de Maringá"
        },
        {
          "name": "Fernando Magno Quintão Pereira",
          "affiliation": ""
        }
      ],
      "year": "2019",
      "publication": "",
      "venue": "Vol. 10",
      "type": "research-paper",
      "abstract": "Compilers are usually distributed with a test framework. This framework supports the task of tuning optimizations and static analyses. As an example, clang has a test suite that, in March 2019, counted 259 benchmarks. Although in principle a large collection, this number is small once we consider the needs of the automatic tuning techniques that became fashionable recently. To mitigate the problems caused by such lack of benchmarks, this paper introduces a technique that allows the automatic construction of compilable programs out of open-source repositories. Our approach has made it possible to build, in less than 24 hours, a collection with over 500 thousand functions that clang can compile. In this paper, we show that such abundance of data gives us precise information about the behavior of compiler optimizations, and lets us create accurate prediction models. This collection of benchmarks is today freely available to the open-source community.",
      "paperUrl": "https://doi.org/10.1145/3355378.3355380",
      "sourceUrl": "",
      "tags": [
        "Clang",
        "Optimizations",
        "Programming Languages"
      ],
      "keywords": [
        "Clang",
        "Optimizations",
        "Programming Languages",
        "Collection"
      ],
      "matchedAuthors": [
        "Anderson Faustino da Silva",
        "Breno Campos Ferreira Guimarães",
        "Fernando Magno Quintão Pereira",
        "José Wesley de Souza Magalhães"
      ]
    },
    {
      "id": "openalex-w3036130004",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Symbolic Execution with Finite State Automata",
      "authors": [
        {
          "name": "Endre Fülöp",
          "affiliation": "Eötvös Loránd University"
        },
        {
          "name": "Norbert Pataki",
          "affiliation": "Eötvös Loránd University"
        }
      ],
      "year": "2019",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "Static analysis is an essential way to find code smells and bugs because it checks the source code without execution. Moreover, static analysis can help in software engineering comprehensively, since static analysis can be used for the validation of code style, evaluate software complexity and execute code refactorings, as well. Symbolic execution is a static analysis method where the variables are interpreted with symbolic values.Clang Static Analyzer is a powerful symbolic execution engine based on the Clang compiler infrastructure that can be used with C, C++ and Objective-C. Validation of resources' usage (e.g. files, memory) requires finite state automata (FSA) for modeling the state of resource (e.g. locked or acquired resource). In this paper, we argue for an approach in which automata are in-use during the symbolic execution. In this approach, a generic automaton is used. The generic automaton can be customized for different resources. We present our domain-specific language to define automata. Our tool parses the automaton and generates checker for the symbolic execution engine. We present some generated checkers, as well.",
      "paperUrl": "https://doi.org/10.1109/informatics47936.2019.9119287",
      "sourceUrl": "",
      "tags": [
        "Clang",
        "Static Analysis",
        "Dynamic Analysis",
        "Infrastructure"
      ],
      "keywords": [
        "Clang",
        "Static Analysis",
        "Dynamic Analysis",
        "Infrastructure",
        "Symbolic Execution",
        "Symbolic Execution Engine",
        "Finite State Automata",
        "Generic Automaton"
      ],
      "matchedAuthors": [
        "Norbert Pataki"
      ]
    },
    {
      "id": "openalex-w2954495824",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "StackVault: Protection from Untrusted Functions",
      "authors": [
        {
          "name": "Qi Zhang",
          "affiliation": "IBM Research - Thomas J. Watson Research Center"
        },
        {
          "name": "Zehra Sura",
          "affiliation": "Bloomberg (United States)"
        },
        {
          "name": "Ashish Kundu",
          "affiliation": ""
        },
        {
          "name": "Gong Su",
          "affiliation": "IBM Research - Thomas J. Watson Research Center"
        },
        {
          "name": "Arun Iyengar",
          "affiliation": "IBM Research - Thomas J. Watson Research Center"
        },
        {
          "name": "Ling Liu",
          "affiliation": "Georgia Institute of Technology"
        }
      ],
      "year": "2019",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Data exfiltration attacks have led to huge data breaches. Recently, the Equifax attack affected 147M users and a third-party library - Apache Struts - was alleged to be responsible for it. These attacks often exploit the fact that sensitive data are stored unencrypted in process memory and can be accessed by any function executing within the same process, including untrusted third-party library functions. This paper presents StackVault, a kernel-based system to prevent sensitive stack-based data from being accessed in an unauthorized manner by intra-process functions. Stack-based data includes data on stack as well as data pointed to by pointer variables on stack. StackVault consists of three components: (1) a set of programming APIs to allow users to specify which data needs to be protected, (2) a kernel module which uses unforgeable function identities to reliably carry out the sensitive data protection, and (3) an LLVM compiler extension that enables transparent placement of stack protection operations. The StackVault system automatically enforces stack protection through spatial and temporal access monitoring and control over both sensitive stack data and untrusted functions. We implemented StackVault and evaluated it using a number of popular real-world applications, including gRPC. The results show that StackVault is effective and efficient, incurring only up to 2.4% runtime overhead.",
      "paperUrl": "https://arxiv.org/pdf/1907.03710",
      "sourceUrl": "https://doi.org/10.48550/arxiv.1907.03710",
      "tags": [],
      "keywords": [
        "LLVM",
        "Stackvault Protection",
        "Stack Protection",
        "Sensitive Stack",
        "Third Party Library",
        "Process",
        "Kernel"
      ],
      "matchedAuthors": [
        "Arun Iyengar",
        "Ashish Kundu",
        "Gong Su",
        "Ling Liu",
        "Qi Zhang",
        "Zehra Sura"
      ]
    },
    {
      "id": "openalex-w2946031616",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "SpecFuzz: Bringing Spectre-type vulnerabilities to the surface",
      "authors": [
        {
          "name": "Oleksii Oleksenko",
          "affiliation": "TU Dresden"
        }
      ],
      "year": "2019",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "SpecFuzz is the first tool that enables dynamic testing for speculative execution vulnerabilities (e.g., Spectre). The key is a novel concept of speculation exposure: The program is instrumented to simulate speculative execution in software by forcefully executing the code paths that could be triggered due to mispredictions, thereby making the speculative memory accesses visible to integrity checkers (e.g., AddressSanitizer). Combined with the conventional fuzzing techniques, speculation exposure enables more precise identification of potential vulnerabilities compared to state-of-the-art static analyzers. Our prototype for detecting Spectre V1 vulnerabilities successfully identifies all known variations of Spectre V1 and decreases the mitigation overheads across the evaluated applications, reducing the amount of instrumented branches by up to 77% given a sufficient test coverage.",
      "paperUrl": "https://arxiv.org/pdf/1905.10311",
      "sourceUrl": "https://doi.org/10.48550/arxiv.1905.10311",
      "tags": [
        "Testing"
      ],
      "keywords": [
        "Testing",
        "Fuzzing",
        "Sanitizers",
        "Bringing Spectre Type",
        "Spectre Type Vulnerabilities",
        "Speculative Execution",
        "Speculation Exposure",
        "Specfuzz Bringing Spectre"
      ],
      "matchedAuthors": [
        "Oleksii Oleksenko"
      ]
    },
    {
      "id": "openalex-w2945653479",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Partial Redundancy Elimination using Lazy Code Motion",
      "authors": [
        {
          "name": "Sandeep Dasgupta",
          "affiliation": "University of Illinois Urbana-Champaign"
        },
        {
          "name": "Tanmay Gangwani",
          "affiliation": "University of Illinois Urbana-Champaign"
        }
      ],
      "year": "2019",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Partial Redundancy Elimination (PRE) is a compiler optimization that eliminates expressions that are redundant on some but not necessarily all paths through a program. In this project, we implemented a PRE optimization pass in LLVM and measured results on a variety of applications. We chose PRE because it is a powerful technique that subsumes Common Subexpression Elimination (CSE) and Loop Invariant Code Motion (LICM), and hence has the potential to greatly improve performance.",
      "paperUrl": "https://arxiv.org/pdf/1905.08178",
      "sourceUrl": "https://doi.org/10.48550/arxiv.1905.08178",
      "tags": [
        "Performance",
        "Optimizations"
      ],
      "keywords": [
        "Performance",
        "Optimizations",
        "LLVM",
        "Partial Redundancy Elimination"
      ],
      "matchedAuthors": [
        "Sandeep Dasgupta"
      ]
    },
    {
      "id": "openalex-w3008843498",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Parallel Training via Computation Graph Transformation",
      "authors": [
        {
          "name": "Fei Wang",
          "affiliation": "Purdue University West Lafayette"
        },
        {
          "name": "Guoyang Chen",
          "affiliation": "Alibaba Group (United States)"
        },
        {
          "name": "Weifeng Zhang",
          "affiliation": "Alibaba Group (United States)"
        },
        {
          "name": "Tiark Rompf",
          "affiliation": "Purdue University West Lafayette"
        }
      ],
      "year": "2019",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "Parallel training can speed up the convergence of machine learning models via splitting the workload into multiple accelerators by the wide array of possible parallel paradigms (e.g., data parallelism, model parallelism, attribute parallelism, and pipelining parallelism). However, most machine learning frameworks lack sufficient support for these flexible and sometimes complex parallel training schemes (e.g., TensorFlow does not provide convenient APIs for any paradigm other than data parallelism), and the engineering effort to support all parallelisms in all machine learning frameworks seems gigantic. In this paper, we demonstrate that most parallel training designs/paradigms can be abstracted as a computation graph transformation problem, so that they are realized via computation graph duplication, splitting, augmentation, and assignment to different accelerators, which are then connected by send/recv channels for tensor communications. Furthermore, conducting such computation graph transformations in a por table I R allows the engineering efforts of parallel training to be widely applied across machine learning frameworks. We propose an extensible parallel training search space which describes parallel training schemes in a declarative fashion. We then implement a computation graph transformation compiler that can instantiate the parallel schemes into explicit execution plans, which are readily executable on modern machine learning frameworks (such as TensorFlow). We maximize code reuse by handling parallel configurations and computation graph transformations in extended ONNX, which can be ported to machine learning frameworks by adapting their existing ONNX frontend/backend implementations. Our design reflects a few good themes in machine learning frameworks, including code reuse via powerful IR (as in MLIR) and separation of declaration and realization (as in Halide/TVM).",
      "paperUrl": "https://doi.org/10.1109/bigdata47090.2019.9006180",
      "sourceUrl": "",
      "tags": [
        "Backend",
        "Frontend",
        "IR",
        "ML",
        "MLIR"
      ],
      "keywords": [
        "Backend",
        "Frontend",
        "IR",
        "ML",
        "MLIR",
        "Machine Learning Frameworks",
        "Parallel Training Schemes",
        "Computation Graph Transformations",
        "Parallelism"
      ],
      "matchedAuthors": [
        "Tiark Rompf"
      ]
    },
    {
      "id": "openalex-w4288104003",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "NeuroVectorizer: End-to-End Vectorization with Deep Reinforcement\\n Learning",
      "authors": [
        {
          "name": "Ameer Haj-Ali",
          "affiliation": ""
        },
        {
          "name": "Nesreen K. Ahmed",
          "affiliation": ""
        },
        {
          "name": "Ted Willke",
          "affiliation": ""
        },
        {
          "name": "Sophia Shao",
          "affiliation": ""
        },
        {
          "name": "Krste Asanović",
          "affiliation": ""
        },
        {
          "name": "Ion Stoica",
          "affiliation": ""
        }
      ],
      "year": "2019",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "One of the key challenges arising when compilers vectorize loops for today's\\nSIMD-compatible architectures is to decide if vectorization or interleaving is\\nbeneficial. Then, the compiler has to determine how many instructions to pack\\ntogether and how many loop iterations to interleave. Compilers are designed\\ntoday to use fixed-cost models that are based on heuristics to make\\nvectorization decisions on loops. However, these models are unable to capture\\nthe data dependency, the computation graph, or the organization of\\ninstructions. Alternatively, software engineers often hand-write the\\nvectorization factors of every loop. This, however, places a huge burden on\\nthem, since it requires prior experience and significantly increases the\\ndevelopment time. In this work, we explore a novel approach for handling loop\\nvectorization and propose an end-to-end solution using deep reinforcement\\nlearning (RL). We conjecture that deep RL can capture different instructions,\\ndependencies, and data structures to enable learning a sophisticated model that\\ncan better predict the actual performance cost and determine the optimal\\nvectorization factors. We develop an end-to-end framework, from code to\\nvectorization, that integrates deep RL in the LLVM compiler. Our proposed\\nframework takes benchmark codes as input and extracts the loop codes. These\\nloop codes are then fed to a loop embedding generator that learns an embedding\\nfor these loops. Finally, the learned embeddings are used as input to a Deep RL\\nagent, which determines the vectorization factors for all the loops. We further\\nextend our framework to support multiple supervised learning methods. We\\nevaluate our approaches against the currently used LLVM vectorizer and loop\\npolyhedral optimization techniques. Our experiments show 1.29X-4.73X\\nperformance speedup compared to baseline and only 3% worse than the brute-force\\nsearch on a wide range of benchmarks.\\n",
      "paperUrl": "https://arxiv.org/pdf/1909.13639",
      "sourceUrl": "https://doi.org/10.48550/arxiv.1909.13639",
      "tags": [
        "Performance",
        "Optimizations",
        "Autovectorization"
      ],
      "keywords": [
        "Performance",
        "Optimizations",
        "Autovectorization",
        "LLVM",
        "Nvectorization",
        "Deep Reinforcement",
        "Nvectorization Factors"
      ],
      "matchedAuthors": [
        "Ameer Haj-Ali",
        "Ion Stoica",
        "Krste Asanović",
        "Nesreen K. Ahmed"
      ]
    },
    {
      "id": "openalex-w2983112851",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "KLARAPTOR: A Tool for Dynamically Finding Optimal Kernel Launch Parameters Targeting CUDA Programs",
      "authors": [
        {
          "name": "Alexander Brandt",
          "affiliation": ""
        },
        {
          "name": "Davood Mohajerani",
          "affiliation": ""
        },
        {
          "name": "Marc Moreno Maza",
          "affiliation": ""
        },
        {
          "name": "Jeeva Paudel",
          "affiliation": ""
        },
        {
          "name": "Linxiao Wang",
          "affiliation": ""
        }
      ],
      "year": "2019",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "In this paper we present KLARAPTOR (Kernel LAunch parameters RAtional Program estimaTOR), a new tool built on top of the LLVM Pass Framework and NVIDIA CUPTI API to dynamically determine the optimal values of kernel launch parameters of a CUDA program P. To be precise, we describe a novel technique to statically build (at the compile time of P) a so-called rational program R. Using a performance prediction model, and knowing particular data and hardware parameters of P at runtime, the program R can automatically and dynamically determine the values of launch parameters of P that will yield optimal performance. Our technique can be applied to parallel programs in general, as well as to generic performance prediction models which account for program and hardware parameters. We are particularly interested in programs targeting manycore accelerators. We have implemented and successfully tested our technique in the context of GPU kernels written in CUDA using the MWP-CWP performance prediction model.",
      "paperUrl": "https://arxiv.org/pdf/1911.02373",
      "sourceUrl": "https://doi.org/10.48550/arxiv.1911.02373",
      "tags": [
        "Performance",
        "GPU",
        "CUDA"
      ],
      "keywords": [
        "Performance",
        "GPU",
        "CUDA",
        "LLVM",
        "Kernel Launch Parameters",
        "Performance Prediction",
        "Parameters Targeting CUDA",
        "Dynamically Finding Optimal",
        "Dynamically Determine",
        "Hardware Parameters",
        "Rational Program",
        "Finding Optimal Kernel",
        "Launch Parameters Targeting",
        "Optimal Kernel Launch"
      ],
      "matchedAuthors": [
        "Jeeva Paudel",
        "Marc Moreno Maza"
      ]
    },
    {
      "id": "openalex-w2906875436",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Full-Speed Fuzzing: Reducing Fuzzing Overhead through Coverage-Guided Tracing",
      "authors": [
        {
          "name": "Stefan Nagy",
          "affiliation": "Virginia Tech"
        },
        {
          "name": "Matthew Hicks",
          "affiliation": "Virginia Tech"
        }
      ],
      "year": "2019",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Of coverage-guided fuzzing's three main components: (1) testcase generation, (2) code coverage tracing, and (3) crash triage, code coverage tracing is a dominant source of overhead. Coverage-guided fuzzers trace every testcase's code coverage through either static or dynamic binary instrumentation, or more recently, using hardware support. Unfortunately, tracing all testcases incurs significant performance penalties---even when the overwhelming majority of testcases and their coverage information are discarded because they do not increase code coverage. To eliminate needless tracing by coverage-guided fuzzers, we introduce the notion of coverage-guided tracing. Coverage-guided tracing leverages two observations: (1) only a fraction of generated testcases increase coverage, and thus require tracing; and (2) coverage-increasing testcases become less frequent over time. Coverage-guided tracing works by encoding the current frontier of code coverage in the target binary so that it self-reports when a testcase produces new coverage---without tracing. This acts as a filter for tracing; restricting the expense of tracing to only coverage-increasing testcases. Thus, coverage-guided tracing chooses to tradeoff increased coverage-increasing-testcase handling time for the ability to execute testcases initially at native speed. To show the potential of coverage-guided tracing, we create an implementation based on the static binary instrumentor Dyninst called UnTracer. We evaluate UnTracer using eight real-world binaries commonly used by the fuzzing community. Experiments show that after only an hour of fuzzing, UnTracer's average overhead is below 1%, and after 24-hours of fuzzing, UnTracer approaches 0% overhead, while tracing every testcase with popular white- and black-box-binary tracers AFL-Clang, AFL-QEMU, and AFL-Dyninst incurs overheads of 36%, 612%, and 518%, respectively.",
      "paperUrl": "https://ieeexplore.ieee.org/ielx7/8826229/8835208/08835316.pdf",
      "sourceUrl": "https://doi.org/10.1109/sp.2019.00069",
      "tags": [
        "Performance",
        "Clang",
        "Testing"
      ],
      "keywords": [
        "Performance",
        "Clang",
        "Testing",
        "Fuzzing",
        "Coverage Guided Tracing",
        "Testcases",
        "Full Speed Fuzzing",
        "Reducing Fuzzing Overhead",
        "Coverage Increasing Testcases",
        "Binary",
        "Fuzzing Untracer",
        "Coverage Guided Fuzzers",
        "Coverage Tracing",
        "Every Testcase"
      ],
      "matchedAuthors": [
        "Matthew Hicks"
      ]
    },
    {
      "id": "openalex-w2974648190",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Evaluation of Compilers Effects on OpenMP Soft Error Resiliency",
      "authors": [
        {
          "name": "Jonas Gava",
          "affiliation": "Universidade Federal do Rio Grande do Sul"
        },
        {
          "name": "Vitor Bandeira",
          "affiliation": "Universidade Federal do Rio Grande do Sul"
        },
        {
          "name": "Ricardo Reis",
          "affiliation": "Universidade Federal do Rio Grande do Sul"
        },
        {
          "name": "Luciano Ost",
          "affiliation": "Loughborough University"
        }
      ],
      "year": "2019",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "Software engineers are using different compilers and parallel programming models (e.g., Pthreads, OpenMP) to take the best performance offered by multicore systems. Both programming models and compilers have specific characteristics, which directly impact on applications code footprint, performance, power-efficiency and reliability. The occurrence of soft errors in multicore systems is a growing reliability issue in several domains (e.g., automotive, medical, avionics). In this scenario, this paper investigates the impact of widely adopted compilers on the soft error reliability of applications implemented with OpenMP library. Fault injection campaigns consider 3 open-source compilers (GNU/GCC 5.5.0, 7.3.1, Clang 6.0.1), 16 OpenMP benchmarks executing on single, dual and quad-core versions of the Arm Cortex-A72 processor. Results show that, on average, Clang is 15.85% more reliable than both versions of GCC, which demonstrate to be more sensitive to the optimisation flags when compared to Clang.",
      "paperUrl": "https://doi.org/10.1109/isvlsi.2019.00055",
      "sourceUrl": "",
      "tags": [
        "Performance",
        "Clang"
      ],
      "keywords": [
        "Performance",
        "Clang",
        "Parallel Computing",
        "OpenMP",
        "OpenMP Soft Error",
        "Reliability",
        "GCC",
        "Soft Error Resiliency",
        "Compilers Effects"
      ],
      "matchedAuthors": [
        "Luciano Ost",
        "Ricardo Reis"
      ]
    },
    {
      "id": "openalex-w2999423666",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Design Space Exploration in Heterogeneous Platforms Using OpenMP",
      "authors": [
        {
          "name": "A. Carrillo Álvarez",
          "affiliation": "Universidad de Cantabria"
        },
        {
          "name": "I. Ugarte",
          "affiliation": "Universidad de Cantabria"
        },
        {
          "name": "Víctor Fernández",
          "affiliation": "Universidad de Cantabria"
        },
        {
          "name": "Pablo Sánchez",
          "affiliation": "Universidad de Cantabria"
        }
      ],
      "year": "2019",
      "publication": "UCrea (University of Cantabria)",
      "venue": "UCrea (University of Cantabria)",
      "type": "research-paper",
      "abstract": "In the fields of high performance computing (HPC) and embedded systems, the current trend is to employ heterogeneous platforms which integrate general purpose CPUs with specialized accelerators such as GPUs and FPGAs. Programming these architectures to approach their theoretical performance limits is a complex issue. In this article, we present a design methodology targeting heterogeneous platforms which combines a novel dynamic offloading mechanism for OpenMP and a scheduling strategy for assigning tasks to accelerator devices. The current OpenMP offloading model depends on the compiler supporting each target device, with many architectures still unsupported by the most popular compilers, such as GCC and Clang. In our approach, the software and/or hardware design flows for programming the accelerators are dissociated from the host OpenMP compiler and the device-specific implementations are dynamically loaded at runtime. Moreover, the assignment of tasks to computing resources is dynamically evaluated at runtime, with the aim of maximizing performance when using the available resources. The proposed methodology has been applied to a video processing system as a test case. The results demonstrate the flexibility of the proposal by exploiting different heterogeneous platforms and design particularities of devices, leading to a significant performance improvement.",
      "paperUrl": "http://hdl.handle.net/10902/23133",
      "sourceUrl": "https://doi.org/10.1109/dcis201949030.2019.8959934",
      "tags": [
        "Performance",
        "Clang",
        "GPU",
        "Embedded"
      ],
      "keywords": [
        "Performance",
        "Clang",
        "GPU",
        "Embedded",
        "Offloading",
        "Heterogeneous Platforms",
        "OpenMP",
        "Space Exploration"
      ],
      "matchedAuthors": [
        "Pablo Sánchez"
      ]
    },
    {
      "id": "openalex-w2976412716",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Design Methodology for Energy Efficient Unmanned Aerial Vehicles",
      "authors": [
        {
          "name": "Jingyu He",
          "affiliation": ""
        },
        {
          "name": "Yao Xiao",
          "affiliation": ""
        },
        {
          "name": "Paul Bogdan",
          "affiliation": "Association for Computing Machinery"
        },
        {
          "name": "Corina Bogdan",
          "affiliation": "Association for Computing Machinery"
        },
        {
          "name": "Bogdan, Paul",
          "affiliation": ""
        }
      ],
      "year": "2019",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "In this paper, we present a load-balancing approach to analyze and partition the UAV perception and navigation intelligence (PNI) code for parallel execution, as well as assigning each parallel computational task to a processing element in an Network-on-chip (NoC) architecture such that the total communication energy is minimized and congestion is reduced. First, we construct a data dependency graph (DDG) by converting the PNI high level program into Low Level Virtual Machine (LLVM) Intermediate Representation (IR). Second, we propose a scheduling algorithm to partition the PNI application into clusters such that (1) inter-cluster communication is minimized, (2) NoC energy is reduced and (3) the workloads of different cores are balanced for maximum parallel execution. Finally, an energy-aware mapping scheme is adopted to assign clusters onto tile-based NoCs. We validate this approach with a drone self-navigation application and the experimental results show that our optimal 32-core design achieves an average 82% energy savings and 4.7x performance speedup against the state-of-art flight controller.",
      "paperUrl": "https://arxiv.org/pdf/1909.11238",
      "sourceUrl": "https://doi.org/10.48550/arxiv.1909.11238",
      "tags": [
        "Performance",
        "IR"
      ],
      "keywords": [
        "Performance",
        "IR",
        "LLVM",
        "Intermediate Representation",
        "Energy",
        "Parallel Execution",
        "Unmanned Aerial Vehicles"
      ],
      "matchedAuthors": [
        "Paul Bogdan",
        "Yao Xiao"
      ]
    },
    {
      "id": "openalex-w2944464415",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Characterizing and Detecting CUDA Program Bugs",
      "authors": [
        {
          "name": "Mingyuan Wu",
          "affiliation": ""
        },
        {
          "name": "Husheng Zhou",
          "affiliation": ""
        },
        {
          "name": "Lingming Zhang",
          "affiliation": ""
        },
        {
          "name": "Cong Liu",
          "affiliation": ""
        },
        {
          "name": "Yuqun Zhang",
          "affiliation": ""
        }
      ],
      "year": "2019",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "While CUDA has become a major parallel computing platform and programming model for general-purpose GPU computing, CUDA-induced bug patterns have not yet been well explored. In this paper, we conduct the first empirical study to reveal important categories of CUDA program bug patterns based on 319 bugs identified within 5 popular CUDA projects in GitHub. Our findings demonstrate that CUDA-specific characteristics may cause program bugs such as synchronization bugs that are rather difficult to detect. To efficiently detect such synchronization bugs, we establish the first lightweight general CUDA bug detection framework, namely Simulee, to simulate CUDA program execution by interpreting the corresponding llvm bytecode and collecting the memory-access information to automatically detect CUDA synchronization bugs. To evaluate the effectiveness and efficiency of Simulee, we conduct a set of experiments and the experimental results suggest that Simulee can detect 20 out of the 27 studied synchronization bugs and successfully detects 26 previously unknown synchronization bugs, 10 of which have been confirmed by the developers.",
      "paperUrl": "https://arxiv.org/pdf/1905.01833",
      "sourceUrl": "https://doi.org/10.48550/arxiv.1905.01833",
      "tags": [
        "GPU",
        "CUDA"
      ],
      "keywords": [
        "GPU",
        "CUDA",
        "LLVM",
        "Parallel Computing",
        "CUDA Program",
        "Synchronization Bugs",
        "Detecting CUDA Program",
        "CUDA Program Bugs",
        "Simulee",
        "Bug Patterns"
      ],
      "matchedAuthors": [
        "Cong Liu",
        "Husheng Zhou",
        "Lingming Zhang",
        "Mingyuan Wu",
        "Yuqun Zhang"
      ]
    },
    {
      "id": "openalex-w2960665846",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Automated Deobfuscation of Android Native Binary Code",
      "authors": [
        {
          "name": "Zeliang Kan",
          "affiliation": ""
        },
        {
          "name": "Haoyu Wang",
          "affiliation": ""
        },
        {
          "name": "Lei Wu",
          "affiliation": ""
        },
        {
          "name": "Yao Guo",
          "affiliation": ""
        },
        {
          "name": "Xiapu Luo",
          "affiliation": ""
        }
      ],
      "year": "2019",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "With the popularity of Android apps, different techniques have been proposed to enhance app protection. As an effective approach to prevent reverse engineering, obfuscation can be used to serve both benign and malicious purposes. In recent years, more and more sensitive logic or data have been implemented as obfuscated native code because of the limitations of Java bytecode. As a result, native code obfuscation becomes a great obstacle for security analysis to understand the complicated logic. In this paper, we propose DiANa, an automated system to facilitate the deobfuscation of native binary code in Android apps. Specifically, given a binary obfuscated by Obfuscator-LLVM (the most popular native code obfuscator), DiANa is capable of recovering the original Control Flow Graph. To the best of our knowledge, DiANa is the first system that aims to tackle the problem of Android native binary deobfuscation. We have applied DiANa in different scenarios, and the experimental results demonstrate the effectiveness of DiANa based on generic similarity comparison metrics.",
      "paperUrl": "https://arxiv.org/pdf/1907.06828",
      "sourceUrl": "https://doi.org/10.48550/arxiv.1907.06828",
      "tags": [
        "Security"
      ],
      "keywords": [
        "Security",
        "LLVM",
        "Control Flow Graph",
        "Reverse Engineering",
        "Native Binary",
        "Android Native Binary",
        "Automated Deobfuscation",
        "Android Apps"
      ],
      "matchedAuthors": [
        "Haoyu Wang",
        "Lei Wu",
        "Xiapu Luo",
        "Yao Guo",
        "Zeliang Kan"
      ]
    },
    {
      "id": "openalex-w2910717943",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Automated Customized Bug-Benchmark Generation",
      "authors": [
        {
          "name": "Vineeth Kashyap",
          "affiliation": "GrammaTech (United States)"
        },
        {
          "name": "Jason Ruchti",
          "affiliation": "GrammaTech (United States)"
        },
        {
          "name": "Łucja Kot",
          "affiliation": "GrammaTech (United States)"
        },
        {
          "name": "Emma Turetsky",
          "affiliation": "GrammaTech (United States)"
        },
        {
          "name": "Rebecca Swords",
          "affiliation": "GrammaTech (United States)"
        },
        {
          "name": "Shih An Pan",
          "affiliation": "GrammaTech (United States)"
        },
        {
          "name": "Julien Henry",
          "affiliation": "GrammaTech (United States)"
        },
        {
          "name": "David Melski",
          "affiliation": "GrammaTech (United States)"
        },
        {
          "name": "Eric Schulte",
          "affiliation": "GrammaTech (United States)"
        }
      ],
      "year": "2019",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "We introduce Bug-Injector, a system that automatically creates benchmarks for customized evaluation of static analysis tools. We share a benchmark generated using Bug-Injector and illustrate its efficacy by using it to evaluate the recall of two leading open-source static analysis tools: Clang Static Analyzer and Infer. Bug-Injector works by inserting bugs based on bug templates into real-world host programs. It runs tests on the host program to collect dynamic traces, searches the traces for a point where the state satisfies the preconditions for some bug template, then modifies the host program to inject a bug based on that template. Injected bugs are used as test cases in a static analysis tool evaluation benchmark. Every test case is accompanied by a program input that exercises the injected bug. We have identified a broad range of requirements and desiderata for bug benchmarks; our approach generates on-demand test benchmarks that meet these requirements. It also allows us to create customized benchmarks suitable for evaluating tools for a specific use case (e.g., a given codebase and set of bug types). Our experimental evaluation demonstrates the suitability of our generated benchmark for evaluating static bug-detection tools and for comparing the performance of different tools.",
      "paperUrl": "https://arxiv.org/pdf/1901.02819",
      "sourceUrl": "https://doi.org/10.1109/scam.2019.00020",
      "tags": [
        "Performance",
        "Clang",
        "Static Analysis"
      ],
      "keywords": [
        "Performance",
        "Clang",
        "Static Analysis",
        "Bug Injector",
        "Host Program",
        "Automated Customized Bug"
      ],
      "matchedAuthors": [
        "Julien Henry"
      ]
    },
    {
      "id": "openalex-w4288356921",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "An Introduction to hpxMP",
      "authors": [
        {
          "name": "Tianyi Zhang",
          "affiliation": ""
        },
        {
          "name": "Shahrzad Shirzad",
          "affiliation": ""
        },
        {
          "name": "Patrick Diehl",
          "affiliation": ""
        },
        {
          "name": "R. Tohid",
          "affiliation": ""
        },
        {
          "name": "Weile Wei",
          "affiliation": ""
        },
        {
          "name": "Hartmut Kaiser",
          "affiliation": ""
        }
      ],
      "year": "2019",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "Asynchronous Many-task (AMT) runtime systems have gained increasing acceptance in the HPC community due to the performance improvements offered by fine-grained tasking runtime systems. At the same time, C++ standardization efforts are focused on creating higher-level interfaces able to replace OpenMP or OpenACC in modern C++ codes. These higher level functions have been adopted in standards conforming runtime systems such as HPX, giving users the ability to simply utilize fork-join parallelism in their own codes. Despite innovations in runtime systems and standardization efforts users face enormous challenges porting legacy applications. Not only must users port their own codes, but often users rely on highly optimized libraries such as BLAS and LAPACK which use OpenMP for parallization. Current efforts to create smooth migration paths have struggled with these challenges, especially as the threading systems of AMT libraries often compete with the treading system of OpenMP. To overcome these issues, our team has developed hpxMP, an implementation of the OpenMP standard, which utilizes the underlying AMT system to schedule and manage tasks. This approach leverages the C++ interfaces exposed by HPX and allows users to execute their applications on an AMT system without changing their code. In this work, we compare hpxMP with Clang's OpenMP library with four linear algebra benchmarks of the Blaze C++ library. While hpxMP is often not able to reach the same performance, we demonstrate viability for providing a smooth migration for applications but have to be extended to benefit from a more general task based programming model.",
      "paperUrl": "https://dl.acm.org/doi/pdf/10.1145/3318170.3318191",
      "sourceUrl": "https://doi.org/10.1145/3318170.3318191",
      "tags": [
        "Performance",
        "Clang",
        "Libraries"
      ],
      "keywords": [
        "Performance",
        "Clang",
        "Libraries",
        "OpenMP",
        "Standardization Efforts",
        "Own Codes",
        "Smooth Migration"
      ],
      "matchedAuthors": [
        "Weile Wei"
      ]
    },
    {
      "id": "openalex-w2996435911",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "ARM Pointer Authentication based Forward-Edge and Backward-Edge Control Flow Integrity for Kernels",
      "authors": [
        {
          "name": "Yutian Yang",
          "affiliation": ""
        },
        {
          "name": "Songbo Zhu",
          "affiliation": ""
        },
        {
          "name": "Wenbo Shen",
          "affiliation": ""
        },
        {
          "name": "Yajin Zhou",
          "affiliation": ""
        },
        {
          "name": "Jiadong Sun",
          "affiliation": ""
        },
        {
          "name": "Kui Ren",
          "affiliation": "Zhejiang University"
        }
      ],
      "year": "2019",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Code reuse attacks are still big threats to software and system security. Control flow integrity is a promising technique to defend against such attacks. However, its effectiveness has been weakened due to the inaccurate control flow graph and practical strategy to trade security for performance. In recent years, CPU vendors have integrated hardware features as countermeasures. For instance, ARM Pointer Authentication (PA in short) was introduced in ARMV8-A architecture. It can efficiently generate an authentication code for an address, which is encoded in the unused bits of the address. When the address is de-referenced, the authentication code is checked to ensure its integrity. Though there exist systems that adopt PA to harden user programs, how to effectively use PA to protect OS kernels is still an open research question. In this paper, we shed lights on how to leverage PA to protect control flows, including function pointers and return addresses, of Linux kernel. Specifically, to protect function pointers, we embed authentication code into them, track their propagation and verify their values when loading from memory or branching to targets. To further defend against the pointer substitution attack, we use the function pointer address as its context, and take a clean design to propagate the address by piggybacking it into the pointer value. We have implemented a prototype system with LLVM to identify function pointers, add authentication code and verify function pointers by emitting new machine instructions. We applied this system to Linux kernel, and solved numerous practical issues, e.g., function pointer comparison and arithmetic operations. The security analysis shows that our system can protect all function pointers and return addresses in Linux kernel.",
      "paperUrl": "https://arxiv.org/pdf/1912.10666",
      "sourceUrl": "https://doi.org/10.48550/arxiv.1912.10666",
      "tags": [
        "Security",
        "Performance"
      ],
      "keywords": [
        "Security",
        "Performance",
        "LLVM",
        "Control Flow Graph",
        "ARM Pointer Authentication",
        "Pointers",
        "Return Addresses",
        "Control Flow Integrity",
        "Linux Kernel",
        "Protect",
        "Defend Against",
        "Kernels",
        "Backward Edge Control",
        "Edge Control Flow"
      ],
      "matchedAuthors": [
        "Wenbo Shen"
      ]
    },
    {
      "id": "openalex-w4299937676",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Program Generation for Small-Scale Linear Algebra Applications",
      "authors": [
        {
          "name": "Daniele G. Spampinato",
          "affiliation": "ETH Zurich"
        },
        {
          "name": "Diego Fabregat‐Traver",
          "affiliation": "RWTH Aachen University"
        },
        {
          "name": "Paolo Bientinesi",
          "affiliation": "RWTH Aachen University"
        },
        {
          "name": "Markus Püeschel",
          "affiliation": "ETH Zurich"
        }
      ],
      "year": "2018",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "We present SLinGen, a program generation system for linear algebra. The input to SLinGen is an application expressed mathematically in a linear-algebra-inspired language (LA) that we define. LA provides basic scalar/vector/matrix additions/multiplications and higher level operations including linear systems solvers, Cholesky and LU factorizations. The output of SLinGen is performance-optimized single-source C code, optionally vectorized with intrinsics. The target of SLinGen are small-scale computations on fixed-size operands, for which a straightforward implementation using optimized libraries (e.g., BLAS or LAPACK) is known to yield suboptimal performance (besides increasing code size and introducing dependencies), but which are crucial in control, signal processing, computer vision, and other domains. Internally, SLinGen uses synthesis and DSL-based techniques to optimize at a high level of abstraction. We benchmark our program generator on three prototypical applications: the Kalman filter, Gaussian process regression, and an L1-analysis convex solver, as well as basic routines including Cholesky factorization and solvers for the continuous-time Lyapunov and Sylvester equations. The results show significant speed-ups compared to straightforward C with Intel icc and clang with a polyhedral optimizer, as well as library-based and template-based implementations.",
      "paperUrl": "https://arxiv.org/pdf/1805.04775",
      "sourceUrl": "https://doi.org/10.48550/arxiv.1805.04775",
      "tags": [
        "Performance",
        "Clang",
        "Libraries"
      ],
      "keywords": [
        "Performance",
        "Clang",
        "Libraries",
        "Slingen",
        "Scale Linear Algebra",
        "Program Generation",
        "Small Scale Linear"
      ],
      "matchedAuthors": [
        "Daniele G. Spampinato",
        "Paolo Bientinesi"
      ]
    },
    {
      "id": "openalex-w2885571639",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Evaluating Support for OpenMP Offload Features",
      "authors": [
        {
          "name": "Jose Monsalve Diaz",
          "affiliation": "University of Delaware"
        },
        {
          "name": "Swaroop Pophale",
          "affiliation": "Oak Ridge National Laboratory"
        },
        {
          "name": "Kyle Friedline",
          "affiliation": "University of Delaware"
        },
        {
          "name": "Óscar Hernández",
          "affiliation": "Oak Ridge National Laboratory"
        },
        {
          "name": "David E. Bernholdt",
          "affiliation": "Oak Ridge National Laboratory"
        },
        {
          "name": "Sunita Chandrasekaran",
          "affiliation": "University of Delaware"
        }
      ],
      "year": "2018",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "The OpenMP language features have been evolving to meet the rapid development in hardware platforms. DOE applications tend to push the bleeding edge of features ratified in the OpenMP specification and tend to expose the rough edges of the features' implementations. The software harness on DOE supercomputers such as Titan and (upcoming) Summit include Cray, Clang, Flang, XL and GCC compilers. It is critical, especially for Summit, that the compilers support OpenMP offloading features. This paper focuses on evaluating support for OpenMP 4.5 target offload directives across compiler implementations on Titan and Summitdev, an early access system, which is one generation removed from Summit's architecture enabling application teams to test the systems' architecture. Our tests not only evaluate the OpenMP implementations but also expose ambiguities in the OpenMP 4.5 specification. We also evaluate compiler implementations using kernels extracted from production DOE applications. This helps in assessing the interaction of different OpenMP directives independent of other application artifacts. We are aware that the implementations are constantly evolving and are advertised as having only partial OpenMP 4.x support. We see this as a synergistic effort to help identify and correct features that are required by DOE applications and prevent deployment delays later on. Going forward, we also plan to interact with standard benchmarking bodies like SPEC/HPG to donate our tests and mini-apps/kernels for potential inclusion in the next release versions of SPEC OMP and SPEC ACCEL benchmark suites.",
      "paperUrl": "https://doi.org/10.1145/3229710.3229717",
      "sourceUrl": "",
      "tags": [
        "Clang",
        "GPU",
        "Flang"
      ],
      "keywords": [
        "Clang",
        "GPU",
        "Flang",
        "Offloading",
        "OpenMP Offload",
        "Summit",
        "Kernels"
      ],
      "matchedAuthors": [
        "David E. Bernholdt",
        "Sunita Chandrasekaran",
        "Swaroop Pophale",
        "Óscar Hernández"
      ]
    },
    {
      "id": "openalex-w2792800398",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Enhancing Memory Error Detection for Large-Scale Applications and Fuzz Testing",
      "authors": [
        {
          "name": "Wookhyun Han",
          "affiliation": "Purdue University West Lafayette"
        },
        {
          "name": "Byunggill Joe",
          "affiliation": "University of California, Riverside"
        },
        {
          "name": "Byoungyoung Lee",
          "affiliation": "Purdue University West Lafayette"
        },
        {
          "name": "Chengyu Song",
          "affiliation": "Kootenay Association for Science & Technology"
        },
        {
          "name": "Insik Shin",
          "affiliation": "Purdue University West Lafayette"
        }
      ],
      "year": "2018",
      "publication": "Seoul National University Open Repository (Seoul National University)",
      "venue": "Seoul National University Open Repository (Seoul National University)",
      "type": "research-paper",
      "abstract": "Memory errors are one of the most common vulnerabilities for the popularity of memory unsafe languages including C and C++. Once exploited, it can easily lead to system crash (i.e., denial-of-service attacks) or allow adversaries to fully compromise the victim system. This paper proposes MEDS, a practical memory error detector. MEDS significantly enhances its detection capability by approximating two ideal properties, called an infinite gap and an infinite heap. The approximated infinite gap of MEDS setups large inaccessible memory region between objects (i.e., 4 MB), and the approximated infinite heap allows MEDS to fully utilize virtual address space (i.e., 45-bits memory space). The key idea of MEDS in achieving these properties is a novel user-space memory allocation mechanism, MEDSALLOC. MEDSALLOC leverages a page aliasing mechanism, which allows MEDS to maximize the virtual memory space utilization but minimize the physical memory uses. To highlight the detection capability and practical impacts of MEDS, we evaluated and then compared to Google&amp;apos;s state-of-the-art detection tool, AddressSanitizer. MEDS showed three times better detection rates on four real-world vulnerabilities in Chrome and Firefox. More importantly, when used for a fuzz testing, MEDS was able to identify 68.3% more memory errors than AddressSanitizer for the same amount of a testing time, highlighting its practical aspects in the software testing area. In terms of performance overhead, MEDS slowed down 108% and 86% compared to native execution and AddressSanitizer, respectively, on real-world applications including Chrome, Firefox, Apache, Nginx, and OpenSSL.",
      "paperUrl": "https://doi.org/10.14722/ndss.2018.23312",
      "sourceUrl": "",
      "tags": [
        "Performance",
        "Testing"
      ],
      "keywords": [
        "Performance",
        "Testing",
        "Fuzzing",
        "Sanitizers",
        "Memory Errors",
        "Detection Capability",
        "Approximated Infinite",
        "Fuzz Testing",
        "Addresssanitizer",
        "Allows Meds",
        "Infinite Gap",
        "Infinite Heap",
        "Memory Space",
        "Real World"
      ],
      "matchedAuthors": [
        "Chengyu Song"
      ]
    },
    {
      "id": "openalex-w2896884779",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Detecting Misusages of the C++ Standard Template Library",
      "authors": [
        {
          "name": "Gábor Horväth",
          "affiliation": "Eötvös Loránd University"
        },
        {
          "name": "Attila Páter-Részeg",
          "affiliation": "Eötvös Loránd University"
        },
        {
          "name": "Norbert Pataki",
          "affiliation": "London Rebuilding Society"
        }
      ],
      "year": "2018",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "The C++ Standard Template Library (STL) is the most well-known and widely used library that is based on the generic programming paradigm.The STL takes advantage of C++ templates, so it is an extensible, effective but flexible system.Professional C++ programs cannot miss the usage of the STL because it increases quality, maintainability, understandability and efficacy of the code.However, the usage of C++ STL does not guarantee bugfree or errorfree code.Contrarily, incorrect application of the library may introduce new types of problems.Unfortunately, there is still a large number of properties are tested neither at compilation-time nor at run-time.It is not surprising that in implementation of C++ programs so many STL-related bugs may occur.It is clearly seen that the compilation validation is not enough to exclude the misuage of STL.Our paper introduces different approaches for the validation of the C++ STL's usage.We take advantage of metaprogramming techniques, static analysis based on the Clang compiler infrastructure and gdb debugging tool as well.",
      "paperUrl": "https://doi.org/10.14794/icai.10.2017.129",
      "sourceUrl": "",
      "tags": [
        "Clang",
        "Static Analysis",
        "Infrastructure"
      ],
      "keywords": [
        "Clang",
        "Static Analysis",
        "Infrastructure",
        "Standard Template Library",
        "Compilation",
        "Detecting Misusages"
      ],
      "matchedAuthors": [
        "Gábor Horváth",
        "Norbert Pataki"
      ]
    },
    {
      "id": "openalex-w3105701676",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Context-aware Failure-oblivious Computing as a Means of Preventing Buffer Overflows",
      "authors": [
        {
          "name": "Manuel Rigger",
          "affiliation": "Johannes Kepler University of Linz"
        },
        {
          "name": "Daniel Pekarek",
          "affiliation": "Johannes Kepler University of Linz"
        },
        {
          "name": "Hanspeter Mössenböck",
          "affiliation": "Johannes Kepler University of Linz"
        }
      ],
      "year": "2018",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "In languages like C, buffer overflows are widespread. A common mitigation technique is to use tools that detect them during execution and abort the program to prevent the leakage of data or the diversion of control flow. However, for server applications, it would be desirable to prevent such errors while maintaining availability of the system. To this end, we present an approach to handle buffer overflows without aborting the program. This approach involves implementing a continuation logic in library functions based on an introspection function that allows querying the size of a buffer. We demonstrate that introspection can be implemented in popular bug-finding and bug-mitigation tools such as LLVM's AddressSanitizer, SoftBound, and Intel-MPX-based bounds checking. We evaluated our approach in a case study of real-world bugs and show that for tools that explicitly track bounds data, introspection results in a low performance overhead.",
      "paperUrl": "http://arxiv.org/abs/1806.09026",
      "sourceUrl": "https://doi.org/10.48550/arxiv.1806.09026",
      "tags": [
        "Performance",
        "Testing"
      ],
      "keywords": [
        "Performance",
        "Testing",
        "LLVM",
        "Sanitizers",
        "Preventing Buffer Overflows",
        "Introspection",
        "Aware Failure Oblivious",
        "Context Aware Failure",
        "Failure Oblivious Computing"
      ],
      "matchedAuthors": [
        "Hanspeter Mössenböck",
        "Manuel Rigger"
      ]
    },
    {
      "id": "openalex-w4289753838",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Concepts and Meta-Programming Library",
      "authors": [
        {
          "name": "Adam Kunen",
          "affiliation": "Lawrence Livermore National Laboratory"
        },
        {
          "name": "William Killian",
          "affiliation": "Lawrence Livermore National Laboratory"
        },
        {
          "name": "David Beckingsale",
          "affiliation": "Lawrence Livermore National Laboratory"
        },
        {
          "name": "Tom Scogland",
          "affiliation": "Lawrence Livermore National Laboratory"
        }
      ],
      "year": "2018",
      "publication": "OSTI OAI (U.S. Department of Energy Office of Scientific and Technical Information)",
      "venue": "OSTI OAI (U.S. Department of Energy Office of Scientific and Technical Information)",
      "type": "research-paper",
      "abstract": "CAMP provides a portable optimized implementation of template meta-programming primitives. All capabilities found within are available in other open source projects, including metal and mpl among others, but no other library we know of supports all compilers required by LLNL codes. CAMP serves as an efficient facility for writing portable compile-time operations in C++ codes. It was developed as part of the RAJA project to facilitate more complex compile-time introspection and better error message delivery to users, but has since proven useful in Umpire, CHAI and other pre-release LLNL software projects and is thus being re-factored to stand alone. The CAMP library uses portable C++ template mechanisms almost exclusively, with the exception of intrinsics provided for performance by some compilers such as clang and gee. There are no private or protected interfaces and no proprietary information included in the source. Any and all future versions will limit themselves to implementing commonly available and well known primitives for compile-time manipulation of types. A new public github repository will be created to host the code independent of its current location in the raja repository, likely at github.com/llnl/camp.",
      "paperUrl": "https://www.osti.gov/biblio/1471491",
      "sourceUrl": "https://doi.org/10.11578/dc.20180919.2",
      "tags": [
        "Performance",
        "Clang"
      ],
      "keywords": [
        "Performance",
        "Clang",
        "Library",
        "Meta Programming Library",
        "Compile",
        "Portable"
      ],
      "matchedAuthors": [
        "David Beckingsale"
      ]
    },
    {
      "id": "openalex-w2908683625",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Compiler and runtime based parallelization & optimization for GPUs",
      "authors": [
        {
          "name": "Güray Özen",
          "affiliation": ""
        }
      ],
      "year": "2018",
      "publication": "Tesis Doctorals en Xarxa (Consorci de Serveis Universitaris de Catalunya)",
      "venue": "Tesis Doctorals en Xarxa (Consorci de Serveis Universitaris de Catalunya)",
      "type": "thesis",
      "abstract": "Graphics Processing Units (GPU) have been widely adopted to accelerate the execution of HPC workloads due to their vast computational throughput, ability to execute a large number of threads inside SIMD groups in parallel and their use of hardware multithreading to hide long pipelining and memory access latencies. There are two APIs commonly used for native GPU programming: CUDA, which only targets NVIDIA GPUs and OpenCL, which targets all types of GPUs as well as other accelerators. However these APIs only expose low-level hardware characteristics to the programmer. So developing applications able to exploit the dazzling performance of GPUs is not a trivial task, and becomes even harder when they have irregular data access patterns or control flows. Several approaches have been proposed to help simplify accelerator programming. Models like OpenACC and OpenMP are intended to solve the aforementioned programming challenges. They take a directive based approach which allows the users to insert non-executable directives that guide the compiler to handle the low-level complexities of the system. However they have a performance gap with native programming models as their compiler does not have comprehensive knowledge about how to transform code and what to optimize. This thesis targets directive-based programming models to enhance their capabilities for GPU programming. The thesis introduces a new dialect model, which is a combination of OpenMP and OmpSs. It also includes several extensions and the MACC infrastructure, a source-to-source compiler targeting CUDA developed on top of BSC's Mercurium compiler and able to support the new dialect model. The new model allows the use of multiple GPUs in conjunction with the vector and heavily multithreaded capabilities in multicore processors automatically. Moreover, it introduces new clauses to make use of on-chip memory efficiently. Secondly the thesis focusses on code transformation techniques and proposes the LazyNP method to support nested parallelism for irregular applications such as sparse matrix operations, graph and graphics algorithms. The method efficiently increases thread granularity for the code region where nested parallelism is desired. The compiler generates code to dynamically pack kernel invocations and to postpone their execution until a bunch of them are available. To the best of our knowledge, LazyNP code transformation was the first successful code transformation method related to nested directives for GPUs. Finally, the thesis conducts a thorough exploration of conventional loop scheduling methods on GPUs to find the advantage and disadvantages of each method. It then proposes the concept of optimized dynamic loop scheduling as an improvement to all the existing methods. The contributions of this thesis improve the programmability of GPUs. This has had an outstanding impact on the whole OpenMP and OpenACC language committee. Additionally, our work includes contributions to widely used compilers such as Mercurium, Clang and PGI, helping thousands of users to take advantage of our work.",
      "paperUrl": "http://hdl.handle.net/10803/664285",
      "sourceUrl": "https://doi.org/10.5821/dissertation-2117-125844",
      "tags": [
        "Performance",
        "Clang",
        "Optimizations",
        "GPU",
        "Autovectorization",
        "CUDA",
        "OpenCL",
        "Infrastructure"
      ],
      "keywords": [
        "Performance",
        "Clang",
        "Optimizations",
        "GPU",
        "Autovectorization",
        "CUDA",
        "OpenCL",
        "Infrastructure",
        "SIMD",
        "Thesis",
        "GPU Programming",
        "OpenMP",
        "Targets",
        "Transformation"
      ],
      "matchedAuthors": [
        "Güray Özen"
      ]
    },
    {
      "id": "openalex-w4289765729",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Compiler Phase Ordering as an Orthogonal Approach for Reducing Energy\\n Consumption",
      "authors": [
        {
          "name": "Ricardo Nobre",
          "affiliation": ""
        },
        {
          "name": "Luís Paulo Reis",
          "affiliation": ""
        },
        {
          "name": "João M. P. Cardoso",
          "affiliation": ""
        }
      ],
      "year": "2018",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Compiler writers typically focus primarily on the performance of the\\ngenerated program binaries when selecting the passes and the order in which\\nthey are applied in the standard optimization levels, such as GCC -O3. In some\\ndomains, such as embedded systems and High-Performance Computing (HPC), it\\nmight be sometimes acceptable to slowdown computations if the energy consumed\\ncan be significantly decreased. Embedded systems often rely on a battery and\\nbesides energy also have power dissipation limitations, while HPC centers have\\na growing concern with electricity and cooling costs. Relying on power policies\\nto apply frequency/voltage scaling and/or change the CPU to idle states (e.g.,\\nalternate between power levels in bursts) as the main method to reduce energy\\nleaves potential for improvement using other orthogonal approaches. In this\\nwork we evaluate the impact of compiler pass sequences specialization (also\\nknown as compiler phase ordering) as a means to reduce the energy consumed by a\\nset of programs/functions when comparing with the use of the standard compiler\\nphase orders provided by, e.g., -OX flags. We use our phase selection and\\nordering framework to explore the design space in the context of a Clang+LLVM\\ncompiler targeting a multicore ARM processor in an ODROID board and a dual x86\\ndesktop representative of a node in a Supercomputing center. Our experiments\\nwith a set of representative kernels show that there we can reduce energy\\nconsumption by up to 24% and that some of these improvements can only be\\npartially explained by improvements to execution time. The experiments show\\ncases where applications that run faster consume more energy. Additionally, we\\nmake an effort to characterize the compiler sequence exploration space in terms\\nof their impact on performance and energy.\\n",
      "paperUrl": "https://arxiv.org/pdf/1807.00638",
      "sourceUrl": "https://doi.org/10.48550/arxiv.1807.00638",
      "tags": [
        "Performance",
        "Clang",
        "Optimizations",
        "Embedded"
      ],
      "keywords": [
        "Performance",
        "Clang",
        "Optimizations",
        "Embedded",
        "LLVM",
        "Energy Consumed",
        "Compiler Phase Ordering",
        "Reduce Energy",
        "HPC",
        "Reducing Energy"
      ],
      "matchedAuthors": [
        "João M. P. Cardoso",
        "Ricardo Nobre"
      ]
    },
    {
      "id": "openalex-w2810599632",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Compiler Phase Ordering as an Orthogonal Approach for Reducing Energy Consumption",
      "authors": [
        {
          "name": "Ricardo Nobre",
          "affiliation": ""
        },
        {
          "name": "Luís Reis",
          "affiliation": ""
        },
        {
          "name": "João M. P. Cardoso",
          "affiliation": ""
        }
      ],
      "year": "2018",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Compiler writers typically focus primarily on the performance of the generated program binaries when selecting the passes and the order in which they are applied in the standard optimization levels, such as GCC -O3. In some domains, such as embedded systems and High-Performance Computing (HPC), it might be sometimes acceptable to slowdown computations if the energy consumed can be significantly decreased. Embedded systems often rely on a battery and besides energy also have power dissipation limitations, while HPC centers have a growing concern with electricity and cooling costs. Relying on power policies to apply frequency/voltage scaling and/or change the CPU to idle states (e.g., alternate between power levels in bursts) as the main method to reduce energy leaves potential for improvement using other orthogonal approaches. In this work we evaluate the impact of compiler pass sequences specialization (also known as compiler phase ordering) as a means to reduce the energy consumed by a set of programs/functions when comparing with the use of the standard compiler phase orders provided by, e.g., -OX flags. We use our phase selection and ordering framework to explore the design space in the context of a Clang+LLVM compiler targeting a multicore ARM processor in an ODROID board and a dual x86 desktop representative of a node in a Supercomputing center. Our experiments with a set of representative kernels show that there we can reduce energy consumption by up to 24% and that some of these improvements can only be partially explained by improvements to execution time. The experiments show cases where applications that run faster consume more energy. Additionally, we make an effort to characterize the compiler sequence exploration space in terms of their impact on performance and energy.",
      "paperUrl": "https://arxiv.org/pdf/1807.00638",
      "sourceUrl": "https://doi.org/10.48550/arxiv.1807.00638",
      "tags": [
        "Performance",
        "Clang",
        "Optimizations",
        "Embedded"
      ],
      "keywords": [
        "Performance",
        "Clang",
        "Optimizations",
        "Embedded",
        "LLVM",
        "Reducing Energy Consumption",
        "Compiler Phase Ordering",
        "Reduce Energy",
        "Energy Consumed",
        "HPC"
      ],
      "matchedAuthors": [
        "João M. P. Cardoso",
        "Luís Reis",
        "Ricardo Nobre"
      ]
    },
    {
      "id": "openalex-w2895622976",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Assessing the effect of data transformations on test suite compilation",
      "authors": [
        {
          "name": "Panagiotis Stratis",
          "affiliation": "University of Edinburgh"
        },
        {
          "name": "Vanya Yaneva",
          "affiliation": "University of Edinburgh"
        },
        {
          "name": "Ajitha Rajan",
          "affiliation": "University of Edinburgh"
        }
      ],
      "year": "2018",
      "publication": "Edinburgh Research Explorer (University of Edinburgh)",
      "venue": "Edinburgh Research Explorer (University of Edinburgh) | Vol. 5",
      "type": "research-paper",
      "abstract": "<b>Background.</b> The requirements and responsibilities assumed by software has increasingly rendered it to be large and complex. Testing to ensure that software meets all its requirements and is free from failures is a difficult and time-consuming task that necessitates the use of large test suites, containing many tests. Large test suites result in a corresponding increase in the size of the test code that sets up, exercises and verifies the tests. Time needed to compile and optimise the test code becomes prohibitive for large test code sizes. <b><br/></b><b>Aims.</b> In this paper we demonstrate for the first time optimisations to speedup compilation of test code. Reducing the compilation time of test code for large and complex systems will allow additional tests to be compiled and executed, while also enabling more frequent and rigorous testing. <b>Methods.</b> We propose transformations that reduce the number of instructions in the test code, which in turn reduces compilation time. Using two well known compilers, GCC and Clang, we conduct empirical evaluations using subject programs from industry standard benchmarks and an industry provided program. We evaluate compilation speedup, execution time, scalability and correctness of the proposed test code transformation. <br/><b>Results.</b> Our approach resulted in significant compilation speedups in the range of 1.3× to 69×. Execution of the test code was just as fast with our transformation when compared to the original while also preserving correctness of execution. Finally, our experiments show that the gains in compilation time allow significantly more tests to be included in a single binary, improving scalability of test code compilation.<b><br/></b><b>Conclusions.</b> The proposed transformation results in faster test code compilation for all the programs in our experiment, with more significant speedups for larger case studies and larger numbers of tests. As systems get more complex requiring frequent and extensive testing, we believe our approach provides a safe and efficient means of compiling test code.",
      "paperUrl": "https://www.research.ed.ac.uk/en/publications/5b431444-d206-4fbb-8e83-7faa133c1a5b",
      "sourceUrl": "https://doi.org/10.1145/3239235.3240499",
      "tags": [
        "Clang",
        "Testing"
      ],
      "keywords": [
        "Clang",
        "Testing",
        "Suite Compilation",
        "Complex",
        "Transformation"
      ],
      "matchedAuthors": [
        "Ajitha Rajan",
        "Panagiotis Stratis"
      ]
    },
    {
      "id": "openalex-w2809414023",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "An Initial Prototype of Tiered Constraint Solving in the Clang Static Analyzer",
      "authors": [
        {
          "name": "Ramona F. Kovacs",
          "affiliation": "Eötvös Loránd University"
        },
        {
          "name": "Gábor Horváth",
          "affiliation": "Eötvös Loránd University"
        }
      ],
      "year": "2018",
      "publication": "Studia Universitatis Babeș-Bolyai Informatica",
      "venue": "Studia Universitatis Babeș-Bolyai Informatica | Vol. 63 (Issue 2)",
      "type": "research-paper",
      "abstract": "Static analysis is a widely used method for finding bugs in large code bases. One of the most popular static analysis tools used for software written in C/C++ languages is the Clang Static Analyzer [1]. During symbolic execution [2] of the source code, the analyzer models path sensitivity by keeping track of constraints on symbolic variables. The built-in constraint manager module, while granting excellent performance, only handles constraints on certain types of integer expressions, which has a detrimental effect on the quality of the analysis, as the infeasibility of certain execution paths cannot be proved. This often leads to false positive findings, i.e. error reports issued for code parts that are actually correct. This paper records the first milestone in an effort to integrate the state-of-the-art Z3 theorem prover [3] into the Clang Static Analyzer in order to post-process bug reports. While full integration is hindered by the burden Z3 places on the duration of the analysis, the refutation of false positive reports using information collected by the default pass can improve analysis quality substantially while introducing only a moderate regression in performance. We present an initial prototype of the tiered constraint solving solution that is already capable of filtering out some bogus reports, evaluate it on real-world software projects, and explore possible improvements we plan to accomplish in our future work.",
      "paperUrl": "http://www.cs.ubbcluj.ro/~studia-i/journal/journal/article/download/30/30",
      "sourceUrl": "https://doi.org/10.24193/subbi.2018.2.06",
      "tags": [
        "Performance",
        "Clang",
        "Static Analysis",
        "Dynamic Analysis"
      ],
      "keywords": [
        "Performance",
        "Clang",
        "Static Analysis",
        "Dynamic Analysis",
        "Symbolic Execution",
        "Analyzer",
        "Reports",
        "Tiered Constraint Solving",
        "Initial Prototype",
        "False Positive"
      ],
      "matchedAuthors": [
        "Gábor Horváth"
      ]
    },
    {
      "id": "openalex-w2952139678",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Skeletal program enumeration for rigorous compiler testing",
      "authors": [
        {
          "name": "Qirun Zhang",
          "affiliation": "University of California, Davis"
        },
        {
          "name": "C. P. Sun",
          "affiliation": "University of California, Davis"
        },
        {
          "name": "Zhendong Su",
          "affiliation": "University of California, Davis"
        }
      ],
      "year": "2017",
      "publication": "ACM SIGPLAN Notices",
      "venue": "ACM SIGPLAN Notices | Vol. 52 (Issue 6)",
      "type": "research-paper",
      "abstract": "A program can be viewed as a syntactic structure P (syntactic skeleton) parameterized by a collection of identifiers V (variable names). This paper introduces the skeletal program enumeration (SPE) problem: Given a syntactic skeleton P and a set of variables V , enumerate a set of programs P exhibiting all possible variable usage patterns within P. It proposes an effective realization of SPE for systematic, rigorous compiler testing by leveraging three important observations: (1) Programs with different variable usage patterns exhibit diverse control- and data-dependence, and help exploit different compiler optimizations; (2) most real compiler bugs were revealed by small tests (i.e., small-sized P) — this “small-scope” observation opens up SPE for practical compiler validation; and (3) SPE is exhaustive w.r.t. a given syntactic skeleton and variable set, offering a level of guarantee absent from all existing compiler testing techniques. The key challenge of SPE is how to eliminate the enormous amount of equivalent programs w.r.t. α-conversion. Our main technical contribution is a novel algorithm for computing the canonical (and smallest) set of all non-α-equivalent programs. To demonstrate its practical utility, we have applied the SPE technique to test C/C++ compilers using syntactic skeletons derived from their own regression test-suites. Our evaluation results are extremely encouraging. In less than six months, our approach has led to 217 confirmed GCC/Clang bug reports, 119 of which have already been fixed, and the majority are long latent despite extensive prior testing efforts. Our SPE algorithm also provides six orders of magnitude reduction. Moreover, in three weeks, our technique has found 29 CompCert crashing bugs and 42 bugs in two Scala optimizing compilers. These results demonstrate our SPE technique’s generality and further illustrate its effectiveness.",
      "paperUrl": "https://doi.org/10.1145/3140587.3062379",
      "sourceUrl": "",
      "tags": [
        "Clang",
        "Optimizations",
        "Testing"
      ],
      "keywords": [
        "Clang",
        "Optimizations",
        "Testing",
        "Syntactic Skeleton",
        "Rigorous Compiler Testing",
        "Variable",
        "Skeletal Program Enumeration",
        "Equivalent Programs"
      ],
      "matchedAuthors": [
        "C. P. Sun",
        "Qirun Zhang",
        "Zhendong Su"
      ]
    },
    {
      "id": "openalex-w2950291962",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Comparison of Parallelisation Approaches, Languages, and Compilers for Unstructured Mesh Algorithms on GPUs",
      "authors": [
        {
          "name": "Gábor Dániel Balogh",
          "affiliation": ""
        },
        {
          "name": "István Z. Reguly",
          "affiliation": ""
        },
        {
          "name": "Gihan R. Mudalige",
          "affiliation": ""
        }
      ],
      "year": "2017",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Efficiently exploiting GPUs is increasingly essential in scientific computing, as many current and upcoming supercomputers are built using them. To facilitate this, there are a number of programming approaches, such as CUDA, OpenACC and OpenMP 4, supporting different programming languages (mainly C/C++ and Fortran). There are also several compiler suites (clang, nvcc, PGI, XL) each supporting different combinations of languages. In this study, we take a detailed look at some of the currently available options, and carry out a comprehensive analysis and comparison using computational loops and applications from the domain of unstructured mesh computations. Beyond runtimes and performance metrics (GB/s), we explore factors that influence performance such as register counts, occupancy, usage of different memory types, instruction counts, and algorithmic differences. Results of this work show how clang's CUDA compiler frequently outperform NVIDIA's nvcc, performance issues with directive-based approaches on complex kernels, and OpenMP 4 support maturing in clang and XL; currently around 10% slower than CUDA.",
      "paperUrl": "https://arxiv.org/pdf/1711.01845",
      "sourceUrl": "https://doi.org/10.48550/arxiv.1711.01845",
      "tags": [
        "Performance",
        "Clang",
        "GPU",
        "CUDA",
        "Programming Languages"
      ],
      "keywords": [
        "Performance",
        "Clang",
        "GPU",
        "CUDA",
        "Programming Languages",
        "Unstructured Mesh",
        "OpenMP",
        "Parallelisation"
      ],
      "matchedAuthors": [
        "Gihan R. Mudalige",
        "Gábor Dániel Balogh",
        "István Z. Reguly"
      ]
    },
    {
      "id": "openalex-w2773447780",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Code Generation Techniques for Raw Data Processing",
      "authors": [
        {
          "name": "Xin Zhang",
          "affiliation": ""
        }
      ],
      "year": "2017",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "The motivation of the current study was to design an algorithm that can speed up the processing of a query. The important feature is generating code dynamically for a specific query. We present the technique of code generation that is applied to query processing on a raw file. The idea was to customize a query program with a given query and generate a machine- and query-specific source code. The generated code is compiled by GCC, Clang or any other C/C++ compiler, and the compiled file is dynamically linked to the main program for further processing. Code generation reduces the cost of generalizing query processing. It also avoids the overhead of the conventional interpretation during achieve high performance. Database Management Systems (DBMSs) perform excellent jobs in many aspects of big data, such as storage, indexing, and analysis. DBMSs typically format entire data and load them into their storage layer. They increase data-to-query time, which is the cost time it takes to convert data into a specific schema and persist them in a disk. Ideally, DBMSs should adapt to the input data and extract one/some of columns, not the entire data, that is/are associated with a given query. Therefore, the query engine on a raw file can reduce the cost of conventional general operators and avoid some unnecessary procedures, such as fully scanning, tokenizing and paring the whole data. In the current study, we introduce our code-generation approach for in-situ processing of raw files, which is based on the template approach and the hype approach. The approach minimizes the data-to-query time and achieves a high performance for query processing. There are some benefits from our work: reducing branches and instructions, unrolling loops, eliminating unnecessary data type checks and optimizing the binary code with a compiler on a local machine.",
      "paperUrl": "https://arxiv.org/pdf/1712.03320",
      "sourceUrl": "https://doi.org/10.48550/arxiv.1712.03320",
      "tags": [
        "Backend",
        "Performance",
        "Clang"
      ],
      "keywords": [
        "Backend",
        "Performance",
        "Clang",
        "Code Generation",
        "Query Processing",
        "Specific",
        "Given Query",
        "Raw File"
      ],
      "matchedAuthors": [
        "Xin Zhang"
      ]
    },
    {
      "id": "openalex-w2952388295",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "AutoWIG: Automatic Generation of Python Bindings for C++ Libraries",
      "authors": [
        {
          "name": "Pierre Fernique",
          "affiliation": "Centre de Coopération Internationale en Recherche Agronomique pour le Développement"
        },
        {
          "name": "Christophe Pradal",
          "affiliation": "Centre de Coopération Internationale en Recherche Agronomique pour le Développement"
        }
      ],
      "year": "2017",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Most of Python and R scientific packages incorporate compiled scientific libraries to speed up the code and reuse legacy libraries. While several semi-automatic solutions exist to wrap these compiled libraries, the process of wrapping a large library is cumbersome and time consuming. In this paper, we introduce AutoWIG, a Python package that wraps automatically compiled libraries into high-level languages using LLVM/Clang technologies and the Mako templating engine. Our approach is automatic, extensible, and applies to complex C++ libraries, composed of thousands of classes or incorporating modern meta-programming constructs.",
      "paperUrl": "https://arxiv.org/pdf/1705.11000.pdf",
      "sourceUrl": "https://doi.org/10.48550/arxiv.1705.11000",
      "tags": [
        "Clang",
        "Libraries"
      ],
      "keywords": [
        "Clang",
        "Libraries",
        "LLVM",
        "Compiled Libraries",
        "Python Bindings",
        "Autowig Automatic Generation"
      ],
      "matchedAuthors": [
        "Christophe Pradal",
        "Pierre Fernique"
      ]
    },
    {
      "id": "openalex-w2624263823",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Architecture, Languages, Compilation and Hardware support for Emerging ManYcore systems (ALCHEMY): Preface",
      "authors": [
        {
          "name": "Johanna Sepúlveda",
          "affiliation": "Technical University of Munich"
        },
        {
          "name": "Vania Marangozova‐Martin",
          "affiliation": "Translational Innovation in Medicine and Complexity"
        },
        {
          "name": "Jerónimo Castrillón",
          "affiliation": "Technische Universität Dresden"
        }
      ],
      "year": "2017",
      "publication": "Procedia Computer Science",
      "venue": "Procedia Computer Science | Vol. 108",
      "type": "research-paper",
      "abstract": "Manycore systems are one of the key enabler technologies for most of current computational paradigms, including Internet of things, data-centers on chip and big data processing. These paradigms are characterized by tight and demanding requirements such as code portability, dynamicity, high performance, usability, predictability, reliability, low power and security. This combination of requirements has led to heterogeneous manycore systems which are extremely challenging to design and to program. As a result, a large body of research has focused on development of languages, simulation environments and analysis tools that allow to model and predict the behavior of this type of systems from early design stages. ALCHEMY 2017 presents five research works addressing the challenges of code portability, high performance, usability, security and reliability in manycore systems. These are namely: 1. \"An OpenMP backend for the Sigma-C streaming language, addresses the software portability challenge of manycore architectures. It proposes an implementation of an OpenMP backend for the SigmaC language, a cycle-static data flow abstraction to program many-core embedded platforms. Its compilation scheme allows for utilization of future manycore embedded systems such as Kalray's MPPA. 2. A multi-level optimization strategy to improve the performance of the stencil computation combines manual vectorization, space tiling and stencil composition for achieving high performance of stencil kernels on manycore systems. The evaluation with three compilers (Intel, Clang and GCC) and two target multi-core platforms (Intel Broadwell and Ivybridge) reports better results compared to the state of the art. 3. A Distributed Shared Memory Model and C++ Templated Meta-Programming Interface for the Epiphany RISC Array Processor addresses the usability challenge. It proposes techniques for data layout and parallel loop order abstraction as a parallel programming API targeting the Epiphany architecture. This results into a transparent distributed shared memory (DSM) model for Epiphany that eliminates the need to manage local data movement between cores. 4. Towards Protected MPSoC Communication for Information Protection against a Malicious NoC deals with vulnerabilities on Network-on-Chip (NoC). The authors propose a security protocol which allows the secure communication among the cores of the system, even in the presence of Trojan insertions at the NoC whose aim is to modify and steal data. 5. GPU-Accelerated Real-Time Path Planning and the Predictable Execution Model addresses the reliability challenge and tackles the important problem of ensuring reliable Worst Case Execution Time for Real-Time and Cyber Physical Systems. While considering heterogeneous (CPU/GPU), the idea is to separate memory and processor operations through Time-Division Multiplexing (TDM).",
      "paperUrl": "https://doi.org/10.1016/j.procs.2017.05.276",
      "sourceUrl": "",
      "tags": [
        "Backend",
        "Security",
        "Performance",
        "Clang",
        "Optimizations",
        "GPU",
        "Autovectorization",
        "Embedded"
      ],
      "keywords": [
        "Backend",
        "Security",
        "Performance",
        "Clang",
        "Optimizations",
        "GPU",
        "Autovectorization",
        "Embedded",
        "Parallel Computing",
        "Manycore",
        "Distributed Shared Memory",
        "Addresses",
        "Challenge",
        "Epiphany"
      ],
      "matchedAuthors": [
        "Jerónimo Castrillón"
      ]
    },
    {
      "id": "openalex-w2757437994",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Analysis of Include Dependencies in C++ Source Code",
      "authors": [
        {
          "name": "Bence Babati",
          "affiliation": "Eötvös Loránd University"
        },
        {
          "name": "Norbert Pataki",
          "affiliation": "Eötvös Loránd University"
        }
      ],
      "year": "2017",
      "publication": "Annals of Computer Science and Information Systems",
      "venue": "Annals of Computer Science and Information Systems | Vol. 13",
      "type": "research-paper",
      "abstract": "The C++ Standard Template Library (STL) is the flagship example for libraries based on the generic programming paradigm.The usage of this library is intended to minimize classical C/C++ errors, but does not warrant bug-free programs.Furthermore, many new kinds of errors may arise from the inaccurate use of the generic programming paradigm, like dereferencing invalid iterators or misunderstanding remove-like algorithms.Unfortunately, the C++ Standard does not define which standard header includes another standard headers.It is easy to write code that works perfectly on an implementation but fails to compile with another implementation of STL.These unportable codes should be result in compilation error with every STL implementation.However, in this case the compiler does not warn us that this code is erroneous.In this paper we present our tool that is based on the Clang.This tool is able to detect the missing include directives that are patched by the STL implementation's internal structure.It also reports the unnecessary include directives to avoid extra compilation time.The background of our tool is discovered and we briefly present the underlying data structures and algorithms.We analyse how these problems occur in open source libraries and programs.Which environment proves oneself to be lazy or strict?How the developers take advantage of this portability issue?",
      "paperUrl": "https://annals-csis.org/proceedings/2017/drp/pdf/358.pdf",
      "sourceUrl": "https://doi.org/10.15439/2017f358",
      "tags": [
        "Clang",
        "Libraries"
      ],
      "keywords": [
        "Clang",
        "Libraries",
        "Standard",
        "Generic Programming Paradigm",
        "Compilation"
      ],
      "matchedAuthors": [
        "Bence Babati",
        "Norbert Pataki"
      ]
    },
    {
      "id": "openalex-w2766767559",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "An LLVM Instrumentation Plug-in for Score-P",
      "authors": [
        {
          "name": "Ronny Tschüter",
          "affiliation": "TU Dresden"
        },
        {
          "name": "Johannes Ziegenbalg",
          "affiliation": "TU Dresden"
        },
        {
          "name": "Bert Wesarg",
          "affiliation": "TU Dresden"
        },
        {
          "name": "Matthias Weber",
          "affiliation": "TU Dresden"
        },
        {
          "name": "Christian Herold",
          "affiliation": "TU Dresden"
        },
        {
          "name": "Sebastian Döbel",
          "affiliation": "TU Dresden"
        },
        {
          "name": "Ronny Brendel",
          "affiliation": "Oak Ridge National Laboratory"
        }
      ],
      "year": "2017",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "Reducing application runtime, scaling parallel applications to higher numbers of processes/threads, and porting applications to new hardware architectures are tasks necessary in the software development process. Therefore, developers have to investigate and understand application runtime behavior. Tools such as monitoring infrastructures that capture performance relevant data during application execution assist in this task. The measured data forms the basis for identifying bottlenecks and optimizing the code.Monitoring infrastructures need mechanisms to record application activities in order to conduct measurements. Automatic instrumentation of the source code is the preferred method in most application scenarios. We introduce a plug-in for the LLVM infrastructure that enables automatic source code instrumentation at compile-time. In contrast to available instrumentation mechanisms in LLVM/Clang, our plug-in can selectively include/exclude individual application functions. This enables developers to fine-tune the measurement to the required level of detail while avoiding large runtime overheads due to excessive instrumentation.",
      "paperUrl": "https://arxiv.org/pdf/1712.01718",
      "sourceUrl": "https://doi.org/10.1145/3148173.3148187",
      "tags": [
        "Performance",
        "Clang",
        "Infrastructure"
      ],
      "keywords": [
        "Performance",
        "Clang",
        "Infrastructure",
        "LLVM",
        "Instrumentation",
        "LLVM Instrumentation Plug",
        "Monitoring Infrastructures"
      ],
      "matchedAuthors": [
        "Ronny Tschüter"
      ]
    },
    {
      "id": "openalex-w2775796483",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "An Instrumenting Compiler for Enforcing Confidentiality in Low-Level Code",
      "authors": [
        {
          "name": "Ajay Brahmakshatriya",
          "affiliation": ""
        },
        {
          "name": "Piyus Kedia",
          "affiliation": ""
        },
        {
          "name": "Derrick McKee",
          "affiliation": ""
        },
        {
          "name": "Pratik Bhatu",
          "affiliation": ""
        },
        {
          "name": "Deepak Garg",
          "affiliation": "Max Planck Society"
        },
        {
          "name": "Akash Lal",
          "affiliation": ""
        },
        {
          "name": "Aseem Rastogi",
          "affiliation": ""
        }
      ],
      "year": "2017",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "We present an instrumenting compiler for enforcing data confidentiality in low-level applications (e.g. those written in C) in the presence of an active adversary. In our approach, the programmer marks secret data by writing lightweight annotations on top-level definitions in the source code. The compiler then uses a static flow analysis coupled with efficient runtime instrumentation, a custom memory layout, and custom control-flow integrity checks to prevent data leaks even in the presence of low-level attacks. We have implemented our scheme as part of the LLVM compiler. We evaluate it on the SPEC micro-benchmarks for performance, and on larger, real-world applications (including OpenLDAP, which is around 300KLoC) for programmer overhead required to restructure the application when protecting the sensitive data such as passwords. We find that performance overheads introduced by our instrumentation are moderate (average 12% on SPEC), and the programmer effort to port OpenLDAP is only about 160 LoC.",
      "paperUrl": "http://hdl.handle.net/21.11116/0000-0000-AC98-3",
      "sourceUrl": "",
      "tags": [
        "Performance"
      ],
      "keywords": [
        "Performance",
        "LLVM",
        "Instrumenting Compiler",
        "Programmer",
        "Instrumentation",
        "Enforcing Confidentiality"
      ],
      "matchedAuthors": [
        "Ajay Brahmakshatriya",
        "Deepak Garg",
        "Derrick McKee",
        "Piyus Kedia",
        "Pratik Bhatu"
      ]
    },
    {
      "id": "openalex-w4306749256",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Skeletal Program Enumeration for Rigorous Compiler Testing",
      "authors": [
        {
          "name": "Qirun Zhang",
          "affiliation": ""
        },
        {
          "name": "C. P. Sun",
          "affiliation": ""
        },
        {
          "name": "Zhendong Su",
          "affiliation": ""
        }
      ],
      "year": "2016",
      "publication": "arXiv (Cornell University)",
      "venue": "arXiv (Cornell University)",
      "type": "research-paper",
      "abstract": "A program can be viewed as a syntactic structure P (syntactic skeleton) parameterized by a collection of the identifiers V (variable names). This paper introduces the skeletal program enumeration (SPE) problem: Given a fixed syntactic skeleton P and a set of variables V , enumerate a set of programs P exhibiting all possible variable usage patterns within P. It proposes an effective realization of SPE for systematic, rigorous compiler testing by leveraging three important observations: (1) Programs with different variable usage patterns exhibit diverse control- and data-dependence information, and help exploit different compiler optimizations and stress-test compilers; (2) most real compiler bugs were revealed by small tests (i.e., small-sized P) --- this \"small-scope\" observation opens up SPE for practical compiler validation; and (3) SPE is exhaustive w.r.t. a given syntactic skeleton and variable set, and thus can offer a level of guarantee that is absent from all existing compiler testing techniques. The key challenge of SPE is how to eliminate the enormous amount of equivalent programs w.r.t. $α$-conversion. Our main technical contribution is a novel algorithm for computing the canonical (and smallest) set of all non-$α$-equivalent programs. We have realized our SPE technique and evaluated it using syntactic skeletons derived from GCC's testsuite. Our evaluation results on testing GCC and Clang are extremely promising. In less than six months, our approach has led to 217 confirmed bug reports, 104 of which have already been fixed, and the majority are long latent bugs despite the extensive prior efforts of automatically testing both compilers (e.g., Csmith and EMI). The results also show that our algorithm for enumerating non-$α$-equivalent programs provides six orders of magnitude reduction, enabling processing the GCC test-suite in under a month.",
      "paperUrl": "https://arxiv.org/pdf/1610.03148",
      "sourceUrl": "https://doi.org/10.48550/arxiv.1610.03148",
      "tags": [
        "Clang",
        "Optimizations",
        "Testing"
      ],
      "keywords": [
        "Clang",
        "Optimizations",
        "Testing",
        "Syntactic Skeleton",
        "Rigorous Compiler Testing",
        "Non Equivalent Programs",
        "Variable",
        "Skeletal Program Enumeration",
        "GCC"
      ],
      "matchedAuthors": [
        "C. P. Sun",
        "Qirun Zhang",
        "Zhendong Su"
      ]
    },
    {
      "id": "openalex-w2390518826",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Finding and analyzing compiler warning defects",
      "authors": [
        {
          "name": "C. P. Sun",
          "affiliation": "University of California, Davis"
        },
        {
          "name": "Vu Le",
          "affiliation": "University of California, Davis"
        },
        {
          "name": "Zhendong Su",
          "affiliation": "University of California, Davis"
        }
      ],
      "year": "2016",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "Good compiler diagnostic warnings facilitate software development as they indicate likely programming mistakes or code smells. However, due to compiler bugs, the warnings may be erroneous, superfluous or missing, even for mature production compilers like GCC and Clang. In this paper, we (1) propose the first randomized differential testing technique to detect compiler warning defects and (2) describe our extensive evaluation in finding warning defects in widely-used C compilers.",
      "paperUrl": "https://doi.org/10.1145/2884781.2884879",
      "sourceUrl": "",
      "tags": [
        "Clang",
        "Testing"
      ],
      "keywords": [
        "Clang",
        "Testing",
        "Differential Testing",
        "Compiler Warning Defects",
        "Analyzing Compiler Warning"
      ],
      "matchedAuthors": [
        "C. P. Sun",
        "Vu Le",
        "Zhendong Su"
      ]
    },
    {
      "id": "openalex-w2346354542",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "C++ Classes and Templates for OpenCL Kernels with PATOS",
      "authors": [
        {
          "name": "Franz Richter-Gottfried",
          "affiliation": "Friedrich-Alexander-Universität Erlangen-Nürnberg"
        },
        {
          "name": "Patrick Kreutzer",
          "affiliation": "Friedrich-Alexander-Universität Erlangen-Nürnberg"
        },
        {
          "name": "Alexander Ditter",
          "affiliation": "Friedrich-Alexander-Universität Erlangen-Nürnberg"
        },
        {
          "name": "Max Schneider",
          "affiliation": "Friedrich-Alexander-Universität Erlangen-Nürnberg"
        },
        {
          "name": "Dietmar Fey",
          "affiliation": "Friedrich-Alexander-Universität Erlangen-Nürnberg"
        }
      ],
      "year": "2016",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "We present PATOS, a CLANG-based source-to-source compiler to extend the OpenCL kernel language with C++ classes and template types for classes and functions. The generated code is standard conforming OpenCL-C which is usable with unmodified OpenCL drivers. With PATOS, type-agnostic host libraries can directly use OpenCL without having to deal with manual type matching.",
      "paperUrl": "https://doi.org/10.1145/2909437.2909462",
      "sourceUrl": "",
      "tags": [
        "Clang",
        "OpenCL",
        "Libraries"
      ],
      "keywords": [
        "Clang",
        "OpenCL",
        "Libraries",
        "OpenCL Kernels",
        "Classes"
      ],
      "matchedAuthors": [
        "Dietmar Fey",
        "Franz Richter-Gottfried",
        "Patrick Kreutzer"
      ]
    },
    {
      "id": "openalex-w3029527999",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "The Oblivious Machine - or: How to Put the C into MPC.",
      "authors": [
        {
          "name": "Marcel Keller",
          "affiliation": ""
        }
      ],
      "year": "2015",
      "publication": "IACR Cryptology ePrint Archive",
      "venue": "IACR Cryptology ePrint Archive | Vol. 2015",
      "type": "research-paper",
      "abstract": "Abstract. We present an oblivious machine, a concrete notion for a multiparty random access machine (RAM) computation and a toolchain to allow the efficient execution of general programs written in a subset of C that allows RAM-model computation over the integers. The machine only leaks the list of possible instructions and the running time. Our work is based on the oblivious array for secret-sharing-based multiparty computation by Keller and Scholl (Asiacrypt ‘14). This means that we only incur a polylogarithmic overhead over the execution on a normal CPU. We describe an implementation of our construction using the Clang compiler from the LLVM project and the SPDZ protocol by Damg̊ard et al. (Crypto ‘12). The latter provides active security against a dishonest majority and works in the preprocessing model. The online phase clock rate of the resulting machine is 41 Hz for a memory size of 1024 64-bit integers and 2.2 Hz for a memory of 220 integers. Both timings have been taken for two parties in a local network. Similar work by other authors has only been the semi-honest setting. To further showcase our toolchain, we implemented and benchmarked private regular expression match-ing. Matching a string of length 1024 against a regular expression with 69270 transitions as a finite state machine takes seven hours online time, of which more than six hours are devoted to loading the reusable program.",
      "paperUrl": "http://dblp.uni-trier.de/db/journals/iacr/iacr2015.html#Keller15",
      "sourceUrl": "",
      "tags": [
        "Security",
        "Clang",
        "Infrastructure"
      ],
      "keywords": [
        "Security",
        "Clang",
        "Infrastructure",
        "LLVM",
        "Oblivious Machine",
        "Computation",
        "Integers",
        "Regular Expression",
        "Memory"
      ],
      "matchedAuthors": [
        "Marcel Keller"
      ]
    },
    {
      "id": "openalex-w4240590466",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "MemorySanitizer: Fast detector of uninitialized memory use in C&#x002B;&#x002B;",
      "authors": [
        {
          "name": "Evgeniy Stepanov",
          "affiliation": "Google (United States)"
        },
        {
          "name": "Konstantin Serebryany",
          "affiliation": "Google (United States)"
        }
      ],
      "year": "2015",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "This paper presents MemorySanitizer, a dynamic tool that detects uses of uninitialized memory in C and C++. The tool is based on compile time instrumentation and relies on bit-precise shadow memory at run-time. Shadow propagation technique is used to avoid false positive reports on copying of uninitialized memory. MemorySanitizer finds bugs at a modest cost of 2.5× in execution time and 2× in memory usage; the tool has an optional origin tracking mode that provides better reports with moderate extra overhead. The reports with origins are more detailed compared to reports from other similar tools; such reports contain names of local variables and the entire history of the uninitialized memory including intermediate stores. In this paper we share our experience in deploying the tool at a large scale and demonstrate the benefits of compile-time instrumentation over dynamic binary instrumentation.",
      "paperUrl": "https://doi.org/10.1109/cgo.2015.7054186",
      "sourceUrl": "",
      "tags": [],
      "keywords": [
        "Uninitialized Memory Use",
        "Reports",
        "Memorysanitizer Fast Detector",
        "Instrumentation"
      ],
      "matchedAuthors": [
        "Evgeniy Stepanov",
        "Konstantin Serebryany"
      ]
    },
    {
      "id": "openalex-w2243626006",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Generating declarations needed by LuaJIT compiler for binding Lua and C",
      "authors": [
        {
          "name": "Violeta Vukobrat",
          "affiliation": "RT-RK Institute for Computer Based Systems (Serbia)"
        },
        {
          "name": "Branislav Rankov",
          "affiliation": "RT-RK Institute for Computer Based Systems (Serbia)"
        },
        {
          "name": "Petar Jovanović",
          "affiliation": "RT-RK Institute for Computer Based Systems (Serbia)"
        },
        {
          "name": "Miroslav Popović",
          "affiliation": "Pokrajinski Sekretarijat za Nauku i Tehnološki Razvoj"
        }
      ],
      "year": "2015",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "This paper presents an implementation of a tool used for generating declarations required by LuaJIT compiler to bind programs written in Lua with programs written in C. The implementation is based on Clang compiler. It's purpose is to enable easier and faster development of programs written in Lua that rely on code written in C.",
      "paperUrl": "https://doi.org/10.1109/telfor.2015.7377598",
      "sourceUrl": "",
      "tags": [
        "Clang"
      ],
      "keywords": [
        "Clang",
        "Programs Written",
        "Generating Declarations Needed",
        "Luajit Compiler"
      ],
      "matchedAuthors": [
        "Petar Jovanović"
      ]
    },
    {
      "id": "openalex-w2332325362",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Concurrent object construction in modern object-oriented programming languages",
      "authors": [
        {
          "name": "Viktor Májer",
          "affiliation": ""
        },
        {
          "name": "Norbert Pataki",
          "affiliation": "Associated Compiler Experts (Netherlands)"
        }
      ],
      "year": "2015",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "Nowadays concurrency is a key issue in modern object-oriented programming languages.Billions of objects and object graphs are created at runtime, thus parallelization of object construction may result in significant speed-up in applications.The C++ programming language uses value semantics as basis of objectorientation.Objects can be used as values and C++ offers copy constructors automatically that copy all members of a class.This operation seems to be ideal for parallelization because independent sources need to be copied to independent targets: without locks, without synchronization problems.In this paper we present scenarios where parallelization seems to be valuable.These scenarios belong to object constructions which is fundamental.We present our approach and tool that makes the copy constructors concurrent.This tool is based on the Clang architecture.",
      "paperUrl": "https://doi.org/10.14794/icai.9.2014.2.293",
      "sourceUrl": "",
      "tags": [
        "Clang",
        "Programming Languages"
      ],
      "keywords": [
        "Clang",
        "Programming Languages",
        "Object Oriented Programming",
        "Oriented Programming Languages",
        "Concurrent Object Construction",
        "Parallelization",
        "Copy Constructors"
      ],
      "matchedAuthors": [
        "Norbert Pataki",
        "Viktor Májer"
      ]
    },
    {
      "id": "openalex-w2339131307",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Clang matchers for verified usage of the C++ Standard Template Library",
      "authors": [
        {
          "name": "Gábor Horváth",
          "affiliation": ""
        },
        {
          "name": "Norbert Pataki",
          "affiliation": "Eötvös Loránd University"
        }
      ],
      "year": "2015",
      "publication": "Acta Biologica Plantarum Agriensis (Eszterházy Károly University, Hungary)",
      "venue": "Acta Biologica Plantarum Agriensis (Eszterházy Károly University, Hungary)",
      "type": "research-paper",
      "abstract": "The C++ Standard Template Library (STL) is the exemplar of generic&#13;\\nlibraries. Professional C++ programs cannot miss the usage of this standard&#13;\\nlibrary because it increases quality, maintainability, understandability and&#13;\\neﬃcacy of the code. However, the usage of C++ STL does not guarantee&#13;\\nerror-free code. Contrarily, incorrect application of the library may intro-&#13;\\nduce new types of problems. Unfortunately, there is still a large number of&#13;\\nproperties are tested neither at compilation-time nor at run-time. It is not&#13;\\nsurprising that in implementation of C++ programs so many STL-related&#13;\\nbugs are occurred.&#13;\\nWe match patterns on abstract syntax trees (AST) with the help of predicates.&#13;\\nThe predicates can be combined and deﬁne an embedded language.&#13;\\nWe have developed a tool which ﬁnds the potential missuses of the STL as a&#13;\\nvalidation of our approach. The software takes advantage of the Clang ASTMatcher&#13;\\ntechnology. The tool is in-use in Ericsson. We advise new matchers&#13;\\nthat have get into the Clang code base.&#13;\\nKeywords: C++ STL, generic programming, Clang, AST, static analysis,&#13;\\ncode validation",
      "paperUrl": "http://publikacio.uni-eszterhazy.hu/2984/1/AMI_44_from99to109.pdf",
      "sourceUrl": "https://openalex.org/W2339131307",
      "tags": [
        "Clang",
        "Static Analysis",
        "Embedded"
      ],
      "keywords": [
        "Clang",
        "Static Analysis",
        "Embedded",
        "Clang Matchers",
        "Standard Template Library"
      ],
      "matchedAuthors": [
        "Gábor Horváth",
        "Norbert Pataki"
      ]
    },
    {
      "id": "openalex-w1993445765",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "A basic linear algebra compiler for embedded processors",
      "authors": [
        {
          "name": "Nikolaos Kyrtatas",
          "affiliation": "ETH Zurich"
        },
        {
          "name": "Daniele G. Spampinato",
          "affiliation": "ETH Zurich"
        },
        {
          "name": "Markus Püschel",
          "affiliation": "ETH Zurich"
        }
      ],
      "year": "2015",
      "publication": "Design, Automation, and Test in Europe",
      "venue": "Design, Automation, and Test in Europe",
      "type": "research-paper",
      "abstract": "Many applications in signal processing, control, and graphics on embedded devices require efficient linear algebra computations. On general-purpose computers, program generators have proven useful to produce such code, or important building blocks, automatically. An example is LGen, a compiler for basic linear algebra computations of fixed size. In this work, we extend LGen towards the embedded domain using as example targets Intel Atom, ARM Cortex-A8, ARM Cortex-A9, and ARM1176 (Raspberry Pi). To efficiently support these processors we introduce support for the NEON vector ISA and a methodology for domain-specific load/store optimizations. Our experimental evaluation shows that the new version of LGen produces code that performs in many cases considerably better than well-established, commercial and non-commercial libraries (Intel MKL and IPP), software generators (Eigen and ATLAS), and compilers (icc, gcc, and clang).",
      "paperUrl": "http://e-collection.library.ethz.ch/eserv/eth:8584/eth-8584-01.pdf",
      "sourceUrl": "https://doi.org/10.5555/2755753.2757058",
      "tags": [
        "Clang",
        "Optimizations",
        "Embedded",
        "Libraries"
      ],
      "keywords": [
        "Clang",
        "Optimizations",
        "Embedded",
        "Libraries",
        "Basic Linear Algebra",
        "Linear Algebra Computations",
        "ARM Cortex",
        "Linear Algebra Compiler",
        "Embedded Processors"
      ],
      "matchedAuthors": [
        "Daniele G. Spampinato"
      ]
    },
    {
      "id": "openalex-w4237159548",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Validation of memory accesses through symbolic analyses",
      "authors": [
        {
          "name": "Henrique Nazaré",
          "affiliation": "Universidade Federal de Minas Gerais"
        },
        {
          "name": "Izabela Karennina Travizani Maffra",
          "affiliation": "Universidade Federal de Minas Gerais"
        },
        {
          "name": "Willer Santos",
          "affiliation": "Universidade Federal de Minas Gerais"
        },
        {
          "name": "Leonardo Valentino Soares Barbosa",
          "affiliation": "Universidade Federal de Minas Gerais"
        },
        {
          "name": "Laure Gonnord",
          "affiliation": "Institut national de recherche en informatique et en automatique"
        },
        {
          "name": "Fernando Magno Quintão Pereira",
          "affiliation": "Universidade Federal de Minas Gerais"
        }
      ],
      "year": "2014",
      "publication": "ACM SIGPLAN Notices",
      "venue": "ACM SIGPLAN Notices | Vol. 49 (Issue 10)",
      "type": "research-paper",
      "abstract": "The C programming language does not prevent out-of-bounds memory accesses. There exist several techniques to secure C programs; however, these methods tend to slow down these programs substantially, because they populate the binary code with runtime checks. To deal with this problem, we have designed and tested two static analyses - symbolic region and range analysis - which we combine to remove the majority of these guards. In addition to the analyses themselves, we bring two other contributions. First, we describe live range splitting strategies that improve the efficiency and the precision of our analyses. Secondly, we show how to deal with integer overflows, a phenomenon that can compromise the correctness of static algorithms that validate memory accesses. We validate our claims by incorporating our findings into AddressSanitizer. We generate SPEC CINT 2006 code that is 17% faster and 9% more energy efficient than the code produced originally by this tool. Furthermore, our approach is 50% more effective than Pentagons, a state-of-the-art analysis to sanitize memory accesses.",
      "paperUrl": "https://doi.org/10.1145/2714064.2660205",
      "sourceUrl": "",
      "tags": [
        "Programming Languages",
        "Testing"
      ],
      "keywords": [
        "Programming Languages",
        "Testing",
        "Sanitizers",
        "Memory Accesses",
        "Symbolic Analyses"
      ],
      "matchedAuthors": [
        "Fernando Magno Quintão Pereira",
        "Henrique Nazaré",
        "Izabela Karennina Travizani Maffra",
        "Laure Gonnord"
      ]
    },
    {
      "id": "openalex-w2081611814",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Static Analysis Usage for Customizable Semantic Checks of C and C++ Programming Languages Constraints",
      "authors": [
        {
          "name": "V. N. Ignatyev",
          "affiliation": "Institute for System Programming"
        }
      ],
      "year": "2014",
      "publication": "",
      "venue": "Vol. 20",
      "type": "research-paper",
      "abstract": "We propose the formal model of programming language constraints, which allows specifying stylistic, syntax and contextual rules. We also give the classification of those constraints. We describe the developed program model and the set of static analysis algorithms for the analyzer subsystem that implements automatic constraints checking and describe the implementation of the proposed formalizations in the Clang open source compiler.",
      "paperUrl": "https://doi.org/10.1109/icstw.2014.59",
      "sourceUrl": "",
      "tags": [
        "Clang",
        "Static Analysis",
        "Programming Languages"
      ],
      "keywords": [
        "Clang",
        "Static Analysis",
        "Programming Languages",
        "Programming Languages Constraints",
        "Customizable Semantic Checks"
      ],
      "matchedAuthors": [
        "V. N. Ignatyev"
      ]
    },
    {
      "id": "openalex-w4300799498",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Verificação Estática de Acessos a Arranjos em C",
      "authors": [
        {
          "name": "Henrique Nazaré Santos",
          "affiliation": "San Antonio College"
        },
        {
          "name": "Fernando Magno Quintão Pereira",
          "affiliation": "San Antonio College"
        },
        {
          "name": "Leonardo B. Oliveira",
          "affiliation": "San Antonio College"
        }
      ],
      "year": "2013",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "Existem linguagens, tais como C ou C++, que permitem que arranjos sejam lidos fora de seus limites alocados. Essa característica, se por um lado aumenta o desempenho dessas linguagens, por outro permite que vírus e worms contaminem software de forma efetiva. O objetivo deste trabalho é remediar tal vulnerabilidade; contudo, sem diminuir sobremaneira a eficiência do código escrito em C ou C++. Com tal propósito, nós projetamos e testamos um conjunto de análises estáticas de programas que mostram que alguns acessos a arranjos são seguros, e aponta outros que não o são. Nossos algoritmos foram usados para estender a popular ferramenta AddressSanitizer, que protege arranjos contra ataques de estouro de buffer. Pudemos apontar que 40% dos acessos a arranjos em SPEC CPU 2006 são seguros. Tal informação permitiu-nos diminuir as responsabilidades de verificação impostas sobre AddressSanitizer, aumentando o desempenho dos programas protegidos em cerca de 10% – um feito animador, considerando-se a qualidade industrial daquela ferramenta.",
      "paperUrl": "https://sol.sbc.org.br/index.php/sbseg/article/download/19546/19374",
      "sourceUrl": "https://doi.org/10.5753/sbseg.2013.19546",
      "tags": [
        "Testing"
      ],
      "keywords": [
        "Testing",
        "Sanitizers",
        "Arranjos",
        "Acessos",
        "Addresssanitizer"
      ],
      "matchedAuthors": [
        "Fernando Magno Quintão Pereira",
        "Henrique Nazaré Santos",
        "Leonardo B. Oliveira"
      ]
    },
    {
      "id": "openalex-w2048693719",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Rendezvous: A search engine for binary code",
      "authors": [
        {
          "name": "Wei Ming Khoo",
          "affiliation": "University of Cambridge"
        },
        {
          "name": "Alan Mycroft",
          "affiliation": "University of Cambridge"
        },
        {
          "name": "Ross Anderson",
          "affiliation": "University of Cambridge"
        }
      ],
      "year": "2013",
      "publication": "",
      "venue": "",
      "type": "research-paper",
      "abstract": "The problem of matching between binaries is important for software copyright enforcement as well as for identifying disclosed vulnerabilities in software. We present a search engine prototype called Rendezvous which enables indexing and searching for code in binary form. Rendezvous identifies binary code using a statistical model comprising instruction mnemonics, control flow sub-graphs and data constants which are simple to extract from a disassembly, yet normalising with respect to different compilers and optimisations. Experiments show that Rendezvous achieves F <sub xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">2</sub> measures of 86.7% and 83.0% on the GNU C library compiled with different compiler optimisations and the GNU coreutils suite compiled with gcc and clang respectively. These two code bases together comprise more than one million lines of code. Rendezvous will bring significant changes to the way patch management and copyright enforcement is currently performed.",
      "paperUrl": "https://doi.org/10.1109/msr.2013.6624046",
      "sourceUrl": "",
      "tags": [
        "Clang",
        "C Libs"
      ],
      "keywords": [
        "Clang",
        "C Libs",
        "Rendezvous",
        "Binary",
        "Search Engine",
        "Copyright Enforcement"
      ],
      "matchedAuthors": [
        "Ross Anderson"
      ]
    },
    {
      "id": "openalex-w2400645950",
      "source": "openalex-discovery",
      "sourceName": "OpenAlex Discovery (seeded by LLVM speakers/authors)",
      "title": "Cytokeratin-positive interstitial reticulum cell tumors of lymph nodes: a case report and review of literature",
      "authors": [
        {
          "name": "Yingchun Dong",
          "affiliation": "Nanjing University"
        },
        {
          "name": "Bo Wu",
          "affiliation": "Nanjing General Hospital of Nanjing Military Command"
        },
        {
          "name": "Zhen Sheng",
          "affiliation": "Nanjing University"
        },
        {
          "name": "Jiandong Wang",
          "affiliation": "Nanjing General Hospital of Nanjing Military Command"
        },
        {
          "name": "Hang‐bo Zhou",
          "affiliation": "Nanjing General Hospital of Nanjing Military Command"
        },
        {
          "name": "Xiaojun Zhou",
          "affiliation": "Nanjing University"
        }
      ],
      "year": "2008",
      "publication": "Chinese Medical Journal",
      "venue": "Chinese Medical Journal | Vol. 121 (Issue 7)",
      "type": "research-paper",
      "abstract": "Cytokeratin-positive interstitial reticulum cells (CIRCs) are considered to represent a subset of fibroblastic reticulum cells (FBRCs) belonging to accessory dendritic cells in lymph nodes, the spleen and tonsils.1-3 The tumors arising from CIRCs are so rare that they are easily misdiagnosed as tumors originating from other accessory dendritic cells, myofibroblasts or even metastatic poor-differentiated carcinomas due to their similar histomorphologic features. We report herein one new case of a CIRC tumor (CIRCT) located in the retroperitoneum and analyze the clinicopathologic characteristics, pathogenesis, treatment and prognosis by reviewing the literature. CASE REPORT Clinical findings A 27-year-old man presented to Nanjing Jinling Hospital with complaints of intermittent pain in the left middle quadrant of the abdomen for 4 years. The symptoms occurred one or two times a year. The pain could be completely remitted when he rested or took some anti-inflammatory drugs, but later the pain became progressively worse. Computed tomography scan of the abdominal region showed a large tumor mass in the left middle quadrant with a left kidney dislocation. The patient was then admitted to our hospital. He had no fever, weight loss or other complaints. He had a discontinuous medical history of drug abuse for four years. Laboratory examinations revealed that hepatitis C virus antibody was positive and serum glutamic pyruvic transaminase was abnormal. Serum human immunodeficiency virus was not detected. Exploratory laparotomy was performed under general anesthesia and examination during the operation revealed a large tumor mass located in the retroperitoneum, measuring 12.0 cm×12.0 cm×10.0 cm with a smooth surface and solid texture. A total excision of the tumor mass together with the left kidney was performed due to adherence. The postoperative recovery was uneventful. The patient refused local radiotherapy and showed no signs of relapse 13 months after diagnosis. Pathologic findings Grossly, the oval mass measured 12.0 cm×12.0 cm×10.0 cm was grayish to tan on the cut surface and solid in texture. It had a relatively complete capsule. Hemorrhage and necrosis were not observed. The tumor mass was closely adherent to the left kidney measuring 11.0 cm×10.0 cm×7.0 cm. Microscopically, the architecture of the lymph node was subtotally effaced by the proliferation of spindle tumor cells, leaving a rim of cortex and residual or atrophic follicles in the tumor tissues. Tumor tissue was arranged in a diffusely fascicular, storiform growth pattern or irregularly (Figure 1). Scattered among the collagenous background infiltrated by abundant mature lymphocytes were spindle cells or ill-defined cells, with eosinophilic plasma, vesicular nuclei and distinct nucleoli. The mildly atypical nuclei were round to oval or even kidney-shaped (Figure 2). Nuclear mitotic count was 0-2 per 10 high-power fields. No foci of necrosis or hemorrhage were observed. Reticular fiber staining displayed abundant reticular fibers encompassing single tumor cells or small cell nests.Figure 1.: The tumor issue was arranged in a fascicular, storiform growth pattern. The neoplasm cells were scattered amongst a collagen background infiltrated by some small lymphocytes (HE, original magnification ×200).Figure 2. The spindle-shaped or ill-defined tumor cells showed mildly-atypic vesicular nuclei, prominent nucleoli and distinct nuclear membrane (HE, original magnification ×400).Figure 3. The slender cytoplasmic processes of the tumor cells were highlighted by immunohistochemical staining for cytokeratin 8/18 (Envision, original magnification ×200).Figure 4. EGFR were detected in the membrane and cytoplasma of the tumors cells (Envision, original magnification×400).Figure 5. The tumor cells were positive for SMA in comparison with vascular smooth muscle cells as the internal control (Envision, original magnification ×200).Figure 6. Desmosome-like junctions between the tumor cells were observed (Electron microscopy, Bar=200 nm).Figure 7. The tumor cell nests were surrounded by basement membrane-like material and long-spacing collagen (Electron microscopy, Bar=1 μm).Figure 8. The long-spacing collagen showed 90-110 nm cyclical transverse striation (Electron microscopy, Bar=200 nm).Immunohistochemical findings Immunohistochemical study was performed using En Vision methods on 2 μm formalin-fixed, paraffinembedded sections using a panel of monoclonal antibodies listed in Table 1. Heat-mediated antigen retrieval was run by autoclave treatment (120°C for 2 minutes in 1 mmol/L EDTA, pH 8.0). Color development was performed with 3, 3′-diaminobenzidine (DAB) (Dako, UK). Nuclei were counterstained with hematoxylin. The result of immunostaining was evaluated according to the proportion of tumor cells stained as follows: >50% (+++), 25%-50% (++), 5%-25% (+) and <5% (-). The tumor cells were positive for cytokeratin (CK) AE1/AE2 (+++), CK8/18 (+++, Figure 3), vimentin (+++), epidermal growth factor receptor (EGFR, +++, Figure 4), smooth muscle actin (SMA, ++, Figure 5), lysozyme (+) and α1-antitrypsin (+). The tumor cells were negative for clusterin, CD21+35, S-100, CD1a, CD68, desmin, anaplastic lymphoma kinase-1 (ALK-1), p53, CD3, CD20, CD34, D2-40, CK7 and CK20. The proliferative index, revealed by Ki-67 staining, was approximately 10%. Appropriate positive and negative controls were performed.Table 1: List of primary antibodies used in the case presentedIn situ hybridization findings In situ hybridization for the presence of Epstein-Barr virus (EBV)-encoded small RNA was performed following the manufacturer's instructions on formalinfixed, paraffin-embedded tissue sections using the digoxigenin-labeled oligonucleotides probe specific for the small RNA of EBV (PanPath, Netherlands). The result was negative in the present case. Ultrastructural findings The specimen initially fixed in 10% neutral formalin was subsequently refixed in 2.5% glutaraldehyde, postfixed in 1% osmium tetroxide in 0.1 mol/L phosphate buffer solution (Ph 7.4) and then routinely processed. The ultrathin 60-80 nm sections were examined under a JEM-1200EX transmission electron microscope (JEOL, Tokyo, Japan) after further contrasting with uranyl acetate and lead citrate. The tumor cells had interlaced interdigitating cytoplasmic processes and desmosomelike junctions between the cells (Figure 6). Around some cell nests were discontinuous basement membrane-like material and long-spacing collagen with 90-110 nm cyclical transverse striations (Figures 7 and 8). The tumor cells contained rich cytoplasm, intermediate filaments and dense bodies. A moderate amount of rough endoplasmic reticulum and chondriosomes were observed. Oval nuclei had shallow invaginations and affluent chromatin. The occasional apoptotic tumor cells were characterized by shrinking cells, curly nuclei, highly aggregated chromatin and dissociation from their surrounding cells. CLINICAL OVERVIEW History Accessory dendritic cells in lymph nodes consist of follicular dendritic cells (FDCs), interdigitating dendritic cells, Langerhans cells and FBRCs. FBRCs and reticular fibers together construct the framework of the interstitial reticular system of lymph nodes.2,4 FBRCs can be classified into CK-negative FBRCs and CK-positive FBRCs by immunohistochemical staining for cytokeratins. CK-positive FBRCs are also called CIRCs. In 1987, Franke and Moll first described that CIRCs were located in extrafollicular zone, paracortex and medulla and especially distributed around blood vessels in the human lymph nodes, the spleen and tonsils. They are considered to originate from mesenchymal stem cells.1,2 Three years later, for the first time, Gould et al5 reported 3 cases of CIRCTs. So far 14 cases of FBRC tumors (FBRCTs) had been found to be reported in the Englishlanguage literature including 4 cases of CK-negative FBRCTs6,7 and 10 cases of CIRCTs (including this present case).3,5,8-10 The patients, including 9 men and 5 women, ranged in ages from 13 to 73 years with a mean age of 46.6 years. The predominant sites of tumor involvement were lymph nodes in 12 cases (mediastinal, 5; submandibular, 2; retroperitoneum, 2; supraclavicular, 1; epitrochlear, 1; and cervical, 1), and extranodal sites in 2 cases (spleen, 1; and soft tissue, 1). The clinical symptoms varied according to tumor locations. The patients presenting with mediastinal or intra-abdominal lymphadenopathy often had obvious clinical evidence including cough, bloody sputum, dyspnea or abdominal discomfort. Superficial tumors were often characterized by painless, solitary augmented lymph nodes. Systemic symptoms were rarely seen. The masses were measured ranging in size from 1.5 cm to 12.0 cm in their greatest dimension. Hemorrhage and necrosis were not easily observed. The summary of clinicopathologic features of the patients with FBRCTs reported in the literature is listed in Table 2.Table 2: Summary of Clinicopathologic features of the patients with FBRCTs reported in the literaturePathogenesis Etiology of FBRCTs remained undetermined. It was speculated that the hyperplasia of FBRCs was a lesion that is highly reactive to injury or was related to autoimmune disease or immune deficiency.2 In the recurrent lesion of a CIRC sarcoma associated with Castleman's disease described by Kakiuchi et al,9 supernatant from primary cultures contained high levels of IL-6 and VEGF secreted by neoplastic cells. Immunostaining also showed strong reactivity for IL-6 and VEGF in specimen sections, revealing some associations between IL-6, VEGF and CIRC sarcoma. In addition, a karyotypic analysis of the recurrent sarcoma showed 47, XXY with some instability. Immunohistochemically, p53 overexpression was identified in the pleomorphic spindle cells of the primary lesion and metastatic tumor. In the case described by Lucioni et al,10 p53 overexpression was also higher in recurrent lesions (60%) than in the primary lesion (20%). We presume that P53 protein may participate in the malignant transformation of a CIRCT while the final mechanism warrants further investigation. FDC sarcomas, especially those located in the abdominal cavity, are related to EBV infection.11 The detection of EBV infection was preformed in 9 out of 14 cases of CIRCTs and the results were all negative, suggesting that CIRCTS bore little relation to EBV infection. Human herpes virus type 8 infection was also not detected.5,8-10 STRATEGIES Diagnosis and differential diagnosis The prerequisite of diagnosis is to be aware of the existence of an FBRCT. In the predominant locations, including mediastinum, retroperitoneum or submandibular sites, a solitary, well-defined mass and a large number of spindle cells distributed in a storiform pattern are indicative of the possibility of FBRCTs. The current pathologic diagnosis is based on histopathologic characteristics, immunostaining and electron microscopic findings. It is imperative to differentiate CIRCTs from tumors derived from other accessory dendritic cells, myofibroblasts and metastatic poorly-differentiated carcinomas. According to the International Lymphoma Study Group, six immunohistochemical markers (CD68, lysozyme, CD1a, S100, CD21, and CD35) are used to divide the tumors of histiocytes and accessory dendritic cells into four groups: histiocytic sarcoma, Langerhans cell tumor, FDC tumor/sarcoma and interdigitating dendritic cell tumor/sarcoma.12 FBRCTs are not included. CD68 and lysozyme are the specific markers for histiocytes. The negative immunostaining for CD1a, S100, and CD68 is helpful to rule out Langerhans cell tumors and interdigitating dendritic cell tumors. Although CD21 and CD35 are specific for FDCs, some FDC tumors are negative for them.13 Clusterin staining has a higher specificity and sensitivity for FDC tumors compared to CD21 and CD35.14,15 CIRCs have immunostaining for CK8/18, SMA and vimentin.1 The immunoreactivity for EGFR is observed in CIRCs as well as in FDCs,16 so EGFR expression has no significance in the differential diagnosis of the two types of tumors. Electron microscopic findings reveal that the neoplasmic cells of CIRCTs have slender cytoplasmic projections and desmosome-like junctions between the tumor cells, supporting the expression of CK in CIRCs. True desmosomes are rarely seen and Birbeck granules are absent, so FDC tumors and Langerhans cell tumors can be ruled out. Basement membrane-like material and long-spacing collagen between the tumor cells are easily identified, which is consistent with the findings of reticular fiber staining in our case. Rich intermediate filaments and dense bodies in the cytoplasm, which correspond to the expression of vimentin and SMA, reveal that the CIRCTs derive from mesenchymal tissue and have bi-directional differentiation features towards epithelioid and myoid/myofibroblastic cells. CIRCTs in lymph nodes coexpress cytokeratins, so another alternative diagnosis is the metastatic poorly differentiated carcinoma, especially lymphoepithelial carcinoma. The possibility can be eliminated since the tumor cells in poorly differentiated carcinomas often have a greater degree of cytologic atypia, more nuclear mitotic figures and epithelial characteristics under electron microscope. In addition, metastatic poorly differentiated carcinomas usually have primary sites and EBV infection is often detected in lymphoepithelial carcinomas. Another important differential diagnosis is inflammatory myofibroblastic tumors (IMTs) which are often positive for ALK-1 and desmin. Ultrastructural features of myofibroblasts differing from FBRCs included fibronexus junction, a special transmembrance structure connecting intracellular microfilaments and extracellular fibronectin.17,18 Desmosome-like junctions are not identified in myofibroblasts. However, cytokeratin may be positive in some IMTs. The difficulties in distinguishing a CIRCT from a CK-positive, but ALK-1- and desmin-negative IMT show a close relationship between the two entities. Nonaka et al17 presented some evidence that so-called IMT might be a proliferative lesion of FBRCs. The two entities might be included in the same tumor spectrum with IMTs representing the low-grade phase while FBRCTs represent the high-grade phase of the same tumor with aggressive characteristics. We speculate that some CK-positive, ALK-1-negative IMTs may be CIRCTs rather than genuine IMTs. A special marker for CIRCs is expected for the diagnosis of CIRCTs. Treatment and prognosis Twelve out of 14 cases of FBRCTs were treated by surgical excision, of which 5 cases were supplemented by adjuvant radiotherapy and 1 case by adjuvant chemotherapy. The other two underwent radiotherapy alone or chemotherapy combined with radiotherapy. There was no uniformly efficacious therapeutic regimen of radiotherapy or chemotherapy. Follow-up information was available in 11 patients, with a follow-up duration of 8 months to 12 years. One patient had local recurrence and 4 patients had metastasis to distant lymph nodes, lung and liver. In the 4 patients with metastasis, 3 patients died of disease at 8 months, 9 months, and 10 months, respectively. The remaining 6 cases were alive and well. The overall recurrence, metastasis, and mortality rates of the 11 cases were 9.1%, 36.4%, and 27.3%, respectively. The general therapy efficacy for FBRCTs showed variability. The role of chemotherapy and radiotherapy was not clearly defined and there was only a partial response or brief remission in some cases.8,10 For non-metastatic cases, surgery alone or surgery followed by adjuvant radiotherapy seemed to achieve survival longer than 12 years.5 However, there was no such efficacious treatment that could prevent the malignant process and prolong the life span for the cases with distant metastasis. In follicular dendritic cell tumors, it appeared that intraabdominal location, presence of coagulative necrosis, high mitotic count (≥5/10 HPF) and lack of adjuvant therapy were associated with an unfavorable prognosis.19 Unfortunately, in FBRCTs, we did not find any relationship of the clinical process and prognosis to histomorphological characteristics, including cell atypia, nuclear mitotic figures and necrosis. It may be due to limited case number, the correlation of clinical prognosis to clinical variables such as age, sex, tumor location, size and treatment was not significant. Only two cases indicated higher cell atypia, frequent nuclear mitotic figures and occurrence of necrosis when the two cases relapsed and underwent malignant transformation. The two patients died of distant metastasis.9,10 CLINICAL DIFFICULTIES Because of limited number of cases, CIRCTs are not well known at present. The clinical difficulties are listed as follows: (1) Difficulties in diagnosis: as mentioned above, CIRCTs had no peculiar clinical symptoms or histomorphological features, so the diagnosis mainly depended on immunohistochemistry and electron microscopy. In addition, the specimens, especially fresh specimens, need to be fixed in a timely manner and strictly processed. (2) Diversification in clinical process: the natural histories of the 14 cases of FBRCTs were variable. Some patients were cured by surgery alone. But some tumors were highly aggressive, resulting in distant metastasis or death within 1 year. So, the biological behavior was difficult to predict. (3) Lack of efficacious therapy: there had not been a feasible therapeutic regimen for those with distant metastasis. Total excision of the tumor mass was the primary therapy. When the nuclear mitotic figures and the proliferative index are increased, radiotherapy or/and chemotherapy are suggested to be given as soon as possible to try to prevent the distant metastasis and extend the life span. Although cyclophosphamide, doxorubicin, vincristine and prednisone (CHOP) and radiotherapy have been used to treat FDC sarcoma and Castleman's disease with good effect, respectively,20,21 whether they can be used on CIRCTs or not will deserved further investigation. Based on the high expression of IL-6, VEGF and EGFR in FBRCTs,9,16 the antibodies or inhibitors of the three markers may have the potential for adjuvant therapy for FBRCTs. PERSONAL OPINIONS In summary, we report a rare case of CIRCT of the lymph node. The obvious discrepancy between the ubiquity of CIRCs in lymph nodes, the spleen or tonsils, and the rarity of reported CIRCTs in the literature is difficult to explain. Misdiagnosis as other accessory dendritic cell tumors or metastatic cancers may be the main cause. Maybe not included in the classification of the tumors of histiocytes and accessory dendritic cells, CIRCTs are not usually considered in clinical pathological diagnosis. For further study of CIRCTs, we believe that CIRCTs should be included in the classification of stromal tumors of lymphatic tissue as they are normally present in lymph nodes or extranodal lymph tissues. Acknowledgments: We are grateful to JIANG Shao-jun, MA Heng-hui and LU Zhen-feng for their skillful assistance and the clinical and follow-up information.",
      "paperUrl": "https://doi.org/10.1097/00029330-200804010-00016",
      "sourceUrl": "",
      "tags": [
        "Embedded",
        "CIRCT"
      ],
      "keywords": [
        "Embedded",
        "CIRCT",
        "Tumor Cells",
        "Cell Tumors",
        "Circts",
        "Lymph Nodes",
        "Figure",
        "Clinical",
        "Fbrcts",
        "Positive",
        "Accessory Dendritic Cells",
        "Diagnosis",
        "Negative",
        "Patients"
      ],
      "matchedAuthors": [
        "Bo Wu"
      ]
    }
  ]
}
