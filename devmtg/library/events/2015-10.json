{
  "meeting": {
    "slug": "2015-10",
    "name": "2015 US LLVM Developers' Meeting",
    "date": "October 29-30, 2015",
    "location": "San Jose, CA, USA",
    "canceled": false,
    "talkCount": 25
  },
  "talks": [
    {
      "id": "2015-10-002",
      "meeting": "2015-10",
      "meetingName": "2015 US LLVM Developers' Meeting",
      "meetingLocation": "San Jose, CA, USA",
      "meetingDate": "October 29-30, 2015",
      "category": "technical-talk",
      "title": "WebAssembly: Here Be Dragons",
      "speakers": [
        {
          "name": "Jf Bastien",
          "affiliation": "",
          "github": "",
          "linkedin": "",
          "twitter": ""
        },
        {
          "name": "Dan Gohman",
          "affiliation": "",
          "github": "",
          "linkedin": "",
          "twitter": ""
        }
      ],
      "abstract": "WebAssembly: Here Be Dragons Our existing instruction selection framework, SelectionDAGISel (SDISel), has some fundamental limitations, including, but not limited to, slow compile time, basic block only scope, and monolithic approach. Over the years, we spent a lot of effort to workaround these limitations with more target hooks and more optimizations passes (e.g., CodeGenPrepare, ConstantHoisting) with their own problems (inaccurate heuristic, have to predict what the instruction selector will do, etc.) and limitations. We believe that it is time to come up with a new instruction selection framework, global-isel, that will solve these problems while offering new opportunities to improve our code generation. In this talk, we will present our plan to bring global-isel to LLVM.",
      "videoUrl": "https://youtu.be/5W7NkofUtAw",
      "videoId": "5W7NkofUtAw",
      "slidesUrl": "https://llvm.org/devmtg/2015-10/slides/BastienGohman-WebAssembly-HereBeDragons.pdf",
      "projectGithub": "",
      "tags": [
        "Backend",
        "Optimizations",
        "Performance"
      ]
    },
    {
      "id": "2015-10-003",
      "meeting": "2015-10",
      "meetingName": "2015 US LLVM Developers' Meeting",
      "meetingLocation": "San Jose, CA, USA",
      "meetingDate": "October 29-30, 2015",
      "category": "technical-talk",
      "title": "A Proposal for Global Instruction Selection",
      "speakers": [
        {
          "name": "Quentin Colombet",
          "affiliation": "",
          "github": "",
          "linkedin": "",
          "twitter": ""
        }
      ],
      "abstract": "",
      "videoUrl": "https://youtu.be/F6GGbYtae3g",
      "videoId": "F6GGbYtae3g",
      "slidesUrl": "https://llvm.org/devmtg/2015-10/slides/Colombet-GlobalInstructionSelection.pdf",
      "projectGithub": "",
      "tags": [
        "Backend"
      ]
    },
    {
      "id": "2015-10-004",
      "meeting": "2015-10",
      "meetingName": "2015 US LLVM Developers' Meeting",
      "meetingLocation": "San Jose, CA, USA",
      "meetingDate": "October 29-30, 2015",
      "category": "technical-talk",
      "title": "Input Space Splitting for OpenCL",
      "speakers": [
        {
          "name": "Johannes Doerfert",
          "affiliation": "",
          "github": "",
          "linkedin": "",
          "twitter": ""
        }
      ],
      "abstract": "Splitting for OpenCL OpenCL programs are prone to memory and control flow divergence. When implementing OpenCL for machines with explicit SIMD instructions, compilers can usually generate more efficient code if they can prove non-divergence of memory and branch instructions. To this end, they leverage a so-called divergence analysis. However, in practice divergence is often input-dependent and exhibited for some, but not all inputs. Hence, static analyses fail to prove non-divergence. To obtain good performance, developers can manually split the input space, however this is a tedious and error prone task. In this talk we present a new OpenCL to CPU compiler pipeline that addresses this problem by automatically ensuring divergence free control flow through program specialization. To this end we represent the full kernel as well as the implicit work item dimensions in the polyhedral model. For data dependent control flow and non-affine expression overapproximation is used. From the polyhedral iteration domains and memory access functions we can then derive conditions for the absence of memory as well as control divergence. Based one these conditions the input space is split in order to generate specialized kernel versions with beneficial divergence characteristics. Commonly large parts of the input exhibit regular access and control patterns and only a fixed size boundary of the input space does not. In such cases we can achieve speedups almost as high as the used vectorization with. However, also for non-diverging kernels our technique can improve the performance due to simplifications in the polyhedral model.",
      "videoUrl": "https://youtu.be/py3pUnvQ7cY",
      "videoId": "py3pUnvQ7cY",
      "slidesUrl": "https://llvm.org/devmtg/2015-10/slides/Doerfert-InputSpaceSplittingForOpenCL.pdf",
      "projectGithub": "",
      "tags": [
        "Autovectorization",
        "GPU",
        "Loop transformations",
        "OpenCL",
        "Performance",
        "Polly"
      ]
    },
    {
      "id": "2015-10-005",
      "meeting": "2015-10",
      "meetingName": "2015 US LLVM Developers' Meeting",
      "meetingLocation": "San Jose, CA, USA",
      "meetingDate": "October 29-30, 2015",
      "category": "technical-talk",
      "title": "Profile-based Indirect Call Promotion",
      "speakers": [
        {
          "name": "Ivan Baev",
          "affiliation": "",
          "github": "",
          "linkedin": "",
          "twitter": ""
        },
        {
          "name": "QuIC",
          "affiliation": "",
          "github": "",
          "linkedin": "",
          "twitter": ""
        }
      ],
      "abstract": "Indirect call promotion (ICP) is the second most profitable profile-based optimization according to a recent study. This talk will present LLVM ICP pass that iterates over all indirect call sites in the module and selectively transforms them. We will discuss how subsequent optimizations in the compiler pipeline may benefit from ICP.",
      "videoUrl": "https://youtu.be/ZeuEMLG3gVI",
      "videoId": "ZeuEMLG3gVI",
      "slidesUrl": "https://llvm.org/devmtg/2015-10/slides/Baev-IndirectCallPromotion.pdf",
      "projectGithub": "",
      "tags": [
        "Optimizations",
        "Performance"
      ]
    },
    {
      "id": "2015-10-006",
      "meeting": "2015-10",
      "meetingName": "2015 US LLVM Developers' Meeting",
      "meetingLocation": "San Jose, CA, USA",
      "meetingDate": "October 29-30, 2015",
      "category": "technical-talk",
      "title": "Beyond Sanitizers: guided fuzzing and security hardening",
      "speakers": [
        {
          "name": "Kostya Serebryany",
          "affiliation": "",
          "github": "",
          "linkedin": "",
          "twitter": ""
        }
      ],
      "abstract": "The Sanitizers (AddressSanitizer and friends) allow you to find many stability and security bugs in C++ code, but they are only as good as your tests are. In this talk we will show how to improve your test coverage with guided fuzzing (libFuzzer) and how to protect your applications in production even if some bugs are still there (Control Flow Integrity and SafeStack).",
      "videoUrl": "https://youtu.be/5K_uIda0tZU",
      "videoId": "5K_uIda0tZU",
      "slidesUrl": "https://llvm.org/devmtg/2015-10/slides/SerebryanyCollingbourne-BeyondSanitizers.pdf",
      "projectGithub": "",
      "tags": [
        "Dynamic Analysis",
        "Security"
      ]
    },
    {
      "id": "2015-10-007",
      "meeting": "2015-10",
      "meetingName": "2015 US LLVM Developers' Meeting",
      "meetingLocation": "San Jose, CA, USA",
      "meetingDate": "October 29-30, 2015",
      "category": "technical-talk",
      "title": "Automated performance-tracking of LLVM-generated code",
      "speakers": [
        {
          "name": "Kristof Beyls",
          "affiliation": "",
          "github": "",
          "linkedin": "",
          "twitter": ""
        }
      ],
      "abstract": "Ensuring that top-of-trunk consistently generates high-quality code remains harder than it should be. Continuous integration (CI) setups that track correctness of top-of-trunk work pretty well today since they automatically report correctness regressions with low false positive rate to committers. In comparison, the output generated by CI setups that track performance require far more human effort to interpret. In this talk, I’ll describe why I think effective performance tracking is hard and what problems need solving, with a focus on our real world experiences and observations. As part of the bring-up of one of the public performance tracking bots, I’ve done an in-depth analysis of its performance and noise characteristics. The insights gained from this analysis drove a number of improvements to LNT and the test-suite in the past year. I hope that sharing these insights will help others in setting up low-noise performance-tracking bots. I’ll conclude by summarizing what seem to be the most important missing pieces of CI functionality to make the performance-tracking infrastructure as effective as the correctness-tracking infrastructure.",
      "videoUrl": "https://youtu.be/9UliHoRYjZI",
      "videoId": "9UliHoRYjZI",
      "slidesUrl": "https://llvm.org/devmtg/2015-10/slides/Beyls-AutomatedPerformanceTrackingOfLlvmGeneratedCode.pdf",
      "projectGithub": "",
      "tags": [
        "Infrastructure",
        "Performance"
      ]
    },
    {
      "id": "2015-10-008",
      "meeting": "2015-10",
      "meetingName": "2015 US LLVM Developers' Meeting",
      "meetingLocation": "San Jose, CA, USA",
      "meetingDate": "October 29-30, 2015",
      "category": "technical-talk",
      "title": "A Heterogeneous Execution Engine for LLVM",
      "speakers": [
        {
          "name": "Christos Margiolas",
          "affiliation": "",
          "github": "",
          "linkedin": "",
          "twitter": ""
        }
      ],
      "abstract": "Hexe, which stands for Heterogeneous Execution Engine, is an new compiler component that integrates with the LLVM infrastructure. It targets efficient computation on heterogeneous platforms by allowing the automatic offloading of workloads on computational accelerators, such as Graphics Processing Units (GPUs) or Digital Signal Processors(DSPs). The workloads we consider for offloading are either explicitly annotated by the programmer or automatically detected by static compiler analysis and runtime checks. Our infrastructure operates at the level of LLVM intermediate representation and effectively supports multiple source languages. Hexe consists of a set of compiler passes and a runtime environment. The compiler passes perform the required code analysis and transformations to enable workload offloading. The runtime environment manages data transfers and synchronization operations, and performs dynamic workload scheduling. We consider a diverse set of heterogeneous systems ranging from mobile devices equipped with arm based multi-core CPUs, embedded GPUs and DSPs to data center nodes consisting of x86 multi-cores and high-end GPUs. Hexe has a modular design where new accelerator types and programming environments can be supported via a plugin interface. We also consider interoperability between Hexe and modern JIT technologies, such as LLVM MCJIT.",
      "videoUrl": "https://youtu.be/utpD3Kv7h88",
      "videoId": "utpD3Kv7h88",
      "slidesUrl": "https://llvm.org/devmtg/2015-10/slides/Margiolas-HeterogeneousExecutionEngineForLLVM.pdf",
      "projectGithub": "",
      "tags": [
        "Embedded",
        "GPU",
        "IR",
        "JIT"
      ]
    },
    {
      "id": "2015-10-009",
      "meeting": "2015-10",
      "meetingName": "2015 US LLVM Developers' Meeting",
      "meetingLocation": "San Jose, CA, USA",
      "meetingDate": "October 29-30, 2015",
      "category": "tutorial",
      "title": "Building, Testing and Debugging a Simple out-of-tree LLVM Pass",
      "speakers": [
        {
          "name": "Serge Guelton",
          "affiliation": "",
          "github": "",
          "linkedin": "",
          "twitter": ""
        },
        {
          "name": "Adrien Guinet",
          "affiliation": "",
          "github": "",
          "linkedin": "",
          "twitter": ""
        }
      ],
      "abstract": "",
      "videoUrl": "https://youtu.be/BnlG-owSVTk",
      "videoId": "BnlG-owSVTk",
      "slidesUrl": "https://llvm.org/devmtg/2015-10/slides/GueltonGuinet-BuildingTestingDebuggingASimpleOutOfTreePass.pdf",
      "projectGithub": "",
      "tags": [
        "Testing"
      ]
    },
    {
      "id": "2015-10-010",
      "meeting": "2015-10",
      "meetingName": "2015 US LLVM Developers' Meeting",
      "meetingLocation": "San Jose, CA, USA",
      "meetingDate": "October 29-30, 2015",
      "category": "tutorial",
      "title": "Creating an SPMD Vectorizer for OpenCL with LLVM",
      "speakers": [
        {
          "name": "Pierre-Andre Saulais",
          "affiliation": "",
          "github": "",
          "linkedin": "",
          "twitter": ""
        }
      ],
      "abstract": "",
      "videoUrl": "https://youtu.be/ePu6c4FLc9I",
      "videoId": "ePu6c4FLc9I",
      "slidesUrl": "https://llvm.org/devmtg/2015-10/slides/Saulais-CreatingSPMDVectorizerOpenCL.pdf",
      "projectGithub": "",
      "tags": [
        "Autovectorization",
        "GPU",
        "OpenCL"
      ]
    },
    {
      "id": "2015-10-011",
      "meeting": "2015-10",
      "meetingName": "2015 US LLVM Developers' Meeting",
      "meetingLocation": "San Jose, CA, USA",
      "meetingDate": "October 29-30, 2015",
      "category": "tutorial",
      "title": "Polly - Optimistic Loop Nest Optimizations with Schedule Trees",
      "speakers": [
        {
          "name": "Tobias Grosser",
          "affiliation": "",
          "github": "",
          "linkedin": "",
          "twitter": ""
        },
        {
          "name": "Johannes Doerfert",
          "affiliation": "",
          "github": "",
          "linkedin": "",
          "twitter": ""
        }
      ],
      "abstract": "",
      "videoUrl": "https://youtu.be/mIBUY20d8c8",
      "videoId": "mIBUY20d8c8",
      "slidesUrl": "https://llvm.org/devmtg/2015-10/slides/DoerfertGrosser-OptimisticAssumptionsInPolly.pdf",
      "projectGithub": "",
      "tags": [
        "Loop transformations",
        "Optimizations",
        "Polly"
      ]
    },
    {
      "id": "2015-10-012",
      "meeting": "2015-10",
      "meetingName": "2015 US LLVM Developers' Meeting",
      "meetingLocation": "San Jose, CA, USA",
      "meetingDate": "October 29-30, 2015",
      "category": "technical-talk",
      "title": "Tutorial/BoF: Living Downstream Without Drowning",
      "speakers": [
        {
          "name": "Paul Robinson",
          "affiliation": "",
          "github": "",
          "linkedin": "",
          "twitter": ""
        },
        {
          "name": "Michael Edwards",
          "affiliation": "",
          "github": "",
          "linkedin": "",
          "twitter": ""
        }
      ],
      "abstract": "",
      "videoUrl": "https://youtu.be/INCi9gOVMug",
      "videoId": "INCi9gOVMug",
      "slidesUrl": "https://llvm.org/devmtg/2015-10/slides/RobinsonEdwards-LivingDownstreamWithoutDrowning.pdf",
      "projectGithub": "",
      "tags": []
    },
    {
      "id": "2015-10-013",
      "meeting": "2015-10",
      "meetingName": "2015 US LLVM Developers' Meeting",
      "meetingLocation": "San Jose, CA, USA",
      "meetingDate": "October 29-30, 2015",
      "category": "technical-talk",
      "title": "Swift's High-Level IR: A Case Study of Complementing LLVM IR with Language-Specific Optimization",
      "speakers": [
        {
          "name": "Joseph Groff",
          "affiliation": "",
          "github": "",
          "linkedin": "",
          "twitter": ""
        },
        {
          "name": "Chris Lattner",
          "affiliation": "",
          "github": "",
          "linkedin": "",
          "twitter": ""
        }
      ],
      "abstract": "The Swift programming language is built on LLVM and uses LLVM IR and the LLVM backend for code generation, but it also contains a new high-level IR called SIL to model the semantics of the language (and perform optimizations) at a higher level. In this talk, we discuss the motivations and applications of SIL, including high-level semantic analyses and transformations such as flow-dependent diagnostics, devirtualization, specialization, reference counting optimization, and TBAA, and we compare SIL's design with that of LLVM IR.",
      "videoUrl": "https://youtu.be/Ntj8ab-5cvE",
      "videoId": "Ntj8ab-5cvE",
      "slidesUrl": "https://llvm.org/devmtg/2015-10/slides/GroffLattner-SILHighLevelIR.pdf",
      "projectGithub": "",
      "tags": [
        "Backend",
        "IR",
        "Optimizations",
        "Programming Languages"
      ]
    },
    {
      "id": "2015-10-014",
      "meeting": "2015-10",
      "meetingName": "2015 US LLVM Developers' Meeting",
      "meetingLocation": "San Jose, CA, USA",
      "meetingDate": "October 29-30, 2015",
      "category": "technical-talk",
      "title": "Typeless Pointers in LLVM IR",
      "speakers": [
        {
          "name": "David Blaikie",
          "affiliation": "",
          "github": "",
          "linkedin": "",
          "twitter": ""
        }
      ],
      "abstract": "Typeless Pointers in LLVM IR In an effort to simplify and canonicalize LLVM IR surrounding pointer expressions, the type information from pointers is being removed. Hear about the current changes, utilities for updating your test cases, as well as current open questions and future work.",
      "videoUrl": "https://youtu.be/OWgWDx_gB1I",
      "videoId": "OWgWDx_gB1I",
      "slidesUrl": "https://llvm.org/devmtg/2015-10/slides/Blaikie-OpaquePointerTypes.pdf",
      "projectGithub": "",
      "tags": [
        "IR"
      ]
    },
    {
      "id": "2015-10-015",
      "meeting": "2015-10",
      "meetingName": "2015 US LLVM Developers' Meeting",
      "meetingLocation": "San Jose, CA, USA",
      "meetingDate": "October 29-30, 2015",
      "category": "technical-talk",
      "title": "LLVM Performance Improvements and Headroom",
      "speakers": [
        {
          "name": "Gerolf Hoflehner",
          "affiliation": "",
          "github": "",
          "linkedin": "",
          "twitter": ""
        }
      ],
      "abstract": "While LLVM is known for very fast compile-time, many developers in the community also push for improving run-time performance of generated code. This talk highlights this year’s performance gains on AArch64 in key benchmarks like SPEC2006, Kernels and also the llvm test suite. While progress has been impressive more work needs to be done. Therefore we will discuss future performance headroom which involves both expanding existing and architecting new optimizations.",
      "videoUrl": "https://youtu.be/mLhDzqKdUCQ",
      "videoId": "mLhDzqKdUCQ",
      "slidesUrl": "https://llvm.org/devmtg/2015-10/slides/Gerolf-PerformanceImprovementsAndHeadroom.pdf",
      "projectGithub": "",
      "tags": [
        "Optimizations",
        "Performance",
        "Testing"
      ]
    },
    {
      "id": "2015-10-016",
      "meeting": "2015-10",
      "meetingName": "2015 US LLVM Developers' Meeting",
      "meetingLocation": "San Jose, CA, USA",
      "meetingDate": "October 29-30, 2015",
      "category": "technical-talk",
      "title": "Optimizing LLVM for GPGPU",
      "speakers": [
        {
          "name": "Jingyue Wu",
          "affiliation": "",
          "github": "",
          "linkedin": "",
          "twitter": ""
        }
      ],
      "abstract": "Optimizing LLVM for GPGPU This talk presents Google’s effort of optimizing LLVM for CUDA. When we started this effort, LLVM was well-tuned for CPUs but there had been little public work on improving its GPU performance. We developed, tuned, and augmented several general and CUDA-specific optimization passes. As a result, our LLVM-based compiler generates better code than nvcc on key end-to-end internal benchmarks and is on par with nvcc on a variety of open-source benchmarks.",
      "videoUrl": "https://youtu.be/9TlR9hNZbck",
      "videoId": "9TlR9hNZbck",
      "slidesUrl": "https://llvm.org/devmtg/2015-10/slides/Wu-OptimizingLLVMforGPGPU.pdf",
      "projectGithub": "",
      "tags": [
        "CUDA",
        "GPU",
        "Optimizations",
        "Performance"
      ]
    },
    {
      "id": "2015-10-017",
      "meeting": "2015-10",
      "meetingName": "2015 US LLVM Developers' Meeting",
      "meetingLocation": "San Jose, CA, USA",
      "meetingDate": "October 29-30, 2015",
      "category": "technical-talk",
      "title": "Exception handling in LLVM, from Itanium to MSVC",
      "speakers": [
        {
          "name": "Reid Kleckner",
          "affiliation": "",
          "github": "",
          "linkedin": "",
          "twitter": ""
        },
        {
          "name": "David Majnemer",
          "affiliation": "",
          "github": "",
          "linkedin": "",
          "twitter": ""
        }
      ],
      "abstract": "This talk covers the design and implementation of MSVC-compatible exception handling in Clang and LLVM. Unlike the Itanium C++ exception handling model, the Windows exception handling model is not designed around successive unwinding. As a result, the existing LLVM landingpad instruction is insufficient for expressing how Windows exceptions should be handled. To support Windows exceptions, we added the new token type and a family of new EH pad instructions to LLVM. This talk describes the final design of the new representation and the tradeoffs we made along the way.",
      "videoUrl": "https://youtu.be/JHfb8z-iSYk",
      "videoId": "JHfb8z-iSYk",
      "slidesUrl": "https://llvm.org/devmtg/2015-10/slides/KlecknerMajnemer-ExceptionHandling.pdf",
      "projectGithub": "",
      "tags": [
        "C++",
        "Clang"
      ]
    },
    {
      "id": "2015-10-018",
      "meeting": "2015-10",
      "meetingName": "2015 US LLVM Developers' Meeting",
      "meetingLocation": "San Jose, CA, USA",
      "meetingDate": "October 29-30, 2015",
      "category": "technical-talk",
      "title": "OpenMP GPU/Accelerator support Coming of Age in Clang",
      "speakers": [
        {
          "name": "Michael Wong",
          "affiliation": "",
          "github": "",
          "linkedin": "",
          "twitter": ""
        },
        {
          "name": "Alexey Bataev",
          "affiliation": "",
          "github": "",
          "linkedin": "",
          "twitter": ""
        }
      ],
      "abstract": "GPU/Accelerator computing will be the basis for the future of Exacale computing through the DOE's CORAL project. It is also the basis for future features for C++ Std's SG14's Games Development/Low Latency/Real Time/Graphics Study Group. However, llvm currently lacks a unified platform-neutral infrastructure for offloading to GPUs/Accelerators, which severely limits clang/llvm usage in these hugely important application domains. For the past several years, a number of contributors from AMD, Argonne National Lab., IBM, Intel, Texas Instruments, University of Houston and many others have come together to deliver OpenMP support to clang. OpenMP 3.1 is now officially in clang 3.7 and work continues to completion of OpenMP 4 aiming for clang 3.8. One of the most important features of OpenMP 4 standard is a vendor- and platform-neutral support for Accelerators. The main presenters will be the OpenMP CEO and Chair of ISO C++'s SG5/SG14 along with the main developer who has been delivering OpenMP implementation in clang (with the help of many others). This talk will describe how GPU and Accelerators will be supported in clang. It offers an overview of the OpenMP 4 syntax, and a description of the upstreaming progress in both clang and llvm through this continued collaboration, as well as the offloading interface design that will describe target independent support across many hardware targets including Nvidia, Xeon Phi, ARM, and AMD devices.",
      "videoUrl": "https://youtu.be/1S2A0VWGOws",
      "videoId": "1S2A0VWGOws",
      "slidesUrl": "https://llvm.org/devmtg/2015-10/slides/WongBataev-OpenMPGPUAcceleratorsComingOfAgeInClang.pdf",
      "projectGithub": "",
      "tags": [
        "Clang",
        "GPU",
        "Performance"
      ]
    },
    {
      "id": "2015-10-019",
      "meeting": "2015-10",
      "meetingName": "2015 US LLVM Developers' Meeting",
      "meetingLocation": "San Jose, CA, USA",
      "meetingDate": "October 29-30, 2015",
      "category": "technical-talk",
      "title": "An update on Clang-based C++ Tooling",
      "speakers": [
        {
          "name": "Daniel Jasper",
          "affiliation": "",
          "github": "",
          "linkedin": "",
          "twitter": ""
        },
        {
          "name": "Manuel Klimek",
          "affiliation": "",
          "github": "",
          "linkedin": "",
          "twitter": ""
        }
      ],
      "abstract": "An update on Clang-based C++ Tooling This talk is going to give an update of the C++ tooling we are building on top of clang. Among others, it will focus on clang-tidy, a tool to statically analyze source code to diagnose and fix typical programming errors like style violations, interface misuse, or bugs. We'll give an update on the direction this project is taking, new checks that are being integrated and challenges we are facing. In a live demo, we'll show how we can fix specific problems throughout LLVM's own codebase. We'll also show how a new check can be added in a matter of minutes and how other Clang-based tools can help with its development.",
      "videoUrl": "https://youtu.be/1S2A0VWGOws",
      "videoId": "1S2A0VWGOws",
      "slidesUrl": "https://llvm.org/devmtg/2015-10/slides/JasperKlimek-UpdateOnClangBasedTooling.pdf",
      "projectGithub": "",
      "tags": [
        "Clang"
      ]
    },
    {
      "id": "2015-10-020",
      "meeting": "2015-10",
      "meetingName": "2015 US LLVM Developers' Meeting",
      "meetingLocation": "San Jose, CA, USA",
      "meetingDate": "October 29-30, 2015",
      "category": "technical-talk",
      "title": "LLVM for a managed language: what we've learned",
      "speakers": [
        {
          "name": "Sanjoy Das",
          "affiliation": "",
          "github": "",
          "linkedin": "",
          "twitter": ""
        },
        {
          "name": "Philip Reames",
          "affiliation": "",
          "github": "",
          "linkedin": "",
          "twitter": ""
        }
      ],
      "abstract": "For a little over a year we have been working towards a production quality, state of the art LLVM based JIT compiler for Java. This talk focuses on what we've learned about LLVM's strengths and weaknesses as an optimization framework for Java-like languages. We will discuss interesting challenges in efficiently implementing Java's semantics within LLVM IR, and how we've been growing LLVM towards being a more effective compiler for managed languages.",
      "videoUrl": "https://youtu.be/3G2Rg6GBXqA",
      "videoId": "3G2Rg6GBXqA",
      "slidesUrl": "https://llvm.org/devmtg/2015-10/slides/DasReames-LLVMForAManagedLanguage.pdf",
      "projectGithub": "",
      "tags": [
        "IR",
        "JIT",
        "Optimizations"
      ]
    },
    {
      "id": "2015-10-021",
      "meeting": "2015-10",
      "meetingName": "2015 US LLVM Developers' Meeting",
      "meetingLocation": "San Jose, CA, USA",
      "meetingDate": "October 29-30, 2015",
      "category": "technical-talk",
      "title": "Throttling Automatic Vectorization: When Less Is More",
      "speakers": [
        {
          "name": "Vasileios Porpodas",
          "affiliation": "",
          "github": "",
          "linkedin": "",
          "twitter": ""
        }
      ],
      "abstract": "SIMD vectors are widely adopted in modern general purpose processors as they can boost performance and energy efficiency for certain applications. Compiler-based automatic vectorization is one approach for generating code that makes efficient use of the SIMD units, and has the benefit of avoiding hand development and platform-specific optimizations. The Superword-Level Parallelism (SLP) vectorization algorithm is the most well-known implementation of automatic vectorization when starting from straight-line scalar code, and is implemented in several major compilers. The existing SLP algorithm greedily packs scalar instructions into vectors starting from stores and traversing the data dependence graph upwards until it reaches loads or non-vectorizable instructions. Choosing whether to vectorize is a one-off decision for the whole graph that has been generated. This, however, is suboptimal because the graph may contain code that is harmful to vectorization due to the need to move data from scalar registers into vectors. The decision does not consider the potential benefits of throttling the graph by removing this harmful code. In this work we propose a solution to overcome this limitation by introducing Throttled SLP (TSLP), a novel vectorization algorithm that finds the optimal graph to vectorize, forcing vectorization to stop earlier whenever this is beneficial. Our experiments show that TSLP improves performance across a number of kernels extracted from widely-used benchmark suites, decreasing execution time compared to SLP by 9% on average and up to 14% in the best case.",
      "videoUrl": "https://youtu.be/xxtA2XPmIug",
      "videoId": "xxtA2XPmIug",
      "slidesUrl": "https://llvm.org/devmtg/2015-10/slides/Porpodas-ThrottlingAutomaticVectorization.pdf",
      "projectGithub": "",
      "tags": [
        "Autovectorization",
        "Optimizations",
        "Performance"
      ]
    },
    {
      "id": "2015-10-022",
      "meeting": "2015-10",
      "meetingName": "2015 US LLVM Developers' Meeting",
      "meetingLocation": "San Jose, CA, USA",
      "meetingDate": "October 29-30, 2015",
      "category": "technical-talk",
      "title": "LLVM back end for HHVM/PHP",
      "speakers": [
        {
          "name": "Brett Simmers",
          "affiliation": "",
          "github": "",
          "linkedin": "",
          "twitter": ""
        },
        {
          "name": "Maksim Panchenko",
          "affiliation": "",
          "github": "",
          "linkedin": "",
          "twitter": ""
        }
      ],
      "abstract": "LLVM back end for HHVM/PHP The Hip-Hop Virtual Machine (HHVM) is a JIT compiler for executing PHP programs. It is used by some of the world’s largest websites such as facebook.com and wikipedia.org, among many others. At Facebook we have frequently been asked why we don't use LLVM as a back end for HHVM. Inspired by the success of Apple’s FTL we implemented an alternative back end using LLVM. In this talk we will share what it took to hook LLVM in to HHVM from conception to running limited production traffic. We will cover changes to our internal IR and modifications we had to make to LLVM. We will discuss performance challenges we faced, peculiar bugs, and finally will discuss why we are not yet at the point of enabling the LLVM back end for production Facebook traffic.",
      "videoUrl": "https://youtu.be/VZ7A7t5LcR8",
      "videoId": "VZ7A7t5LcR8",
      "slidesUrl": "https://llvm.org/devmtg/2015-10/slides/SimmersPanchenko-LLVMBackendForHHVM.pdf",
      "projectGithub": "",
      "tags": [
        "Backend",
        "JIT",
        "Performance"
      ]
    },
    {
      "id": "2015-10-023",
      "meeting": "2015-10",
      "meetingName": "2015 US LLVM Developers' Meeting",
      "meetingLocation": "San Jose, CA, USA",
      "meetingDate": "October 29-30, 2015",
      "category": "technical-talk",
      "title": "LoopVersioning LICM",
      "speakers": [
        {
          "name": "Ashutosh Nema",
          "affiliation": "",
          "github": "",
          "linkedin": "",
          "twitter": ""
        }
      ],
      "abstract": "Loop invariant code motion is an important compiler optimization and it moves invariant instructions out of a loop without affecting the semantics of a program. For safety it ensures the alias dependencies before moving invariant out of loop. In some cases memory aliasing may make this optimization ineffective. This results in possible missed opportunities in speeding up applications. LoopVersioning LICM is a step to exploit those missed opportunities where memory aliasing may make LICM optimization ineffective.",
      "videoUrl": "https://youtu.be/VxRjJmkFsgM",
      "videoId": "VxRjJmkFsgM",
      "slidesUrl": "https://llvm.org/devmtg/2015-10/slides/Nema-LoopVersioningLICM.pdf",
      "projectGithub": "",
      "tags": [
        "Optimizations",
        "Security"
      ]
    },
    {
      "id": "2015-10-024",
      "meeting": "2015-10",
      "meetingName": "2015 US LLVM Developers' Meeting",
      "meetingLocation": "San Jose, CA, USA",
      "meetingDate": "October 29-30, 2015",
      "category": "technical-talk",
      "title": "Compiling large, real-world codebases with clang on Windows",
      "speakers": [
        {
          "name": "Hans Wennborg",
          "affiliation": "",
          "github": "",
          "linkedin": "",
          "twitter": ""
        },
        {
          "name": "Nico Weber",
          "affiliation": "",
          "github": "",
          "linkedin": "",
          "twitter": ""
        }
      ],
      "abstract": "llvm 3.7 is the first release that can build large projects such as Chromium on Windows without having to fall back to Visual Studio's compiler for a single translation unit. This talk gives an overview of the work done to get to this state: It covers language extensions clang needed to learn to parse Microsoft's headers and dark corners of the Microsoft ABI, with a focus on work done in the last year. Much of the Windows support was developed in tight collaboration between the Chromium and LLVM projects. The talk also touches on how this collaboration works and why it’s successful. Finally, the talk also gives an overview of how to get projects building with clang that build with Visual Studio.",
      "videoUrl": "https://youtu.be/rXi065XC6zY",
      "videoId": "rXi065XC6zY",
      "slidesUrl": "https://docs.google.com/presentation/d/1oxNHaVjA9Gn_rTzX6HIpJHP7nXRua_0URXxxJ3oYRq0/edit#slide=id.p",
      "projectGithub": "",
      "tags": [
        "Clang"
      ]
    },
    {
      "id": "2015-10-025",
      "meeting": "2015-10",
      "meetingName": "2015 US LLVM Developers' Meeting",
      "meetingLocation": "San Jose, CA, USA",
      "meetingDate": "October 29-30, 2015",
      "category": "technical-talk",
      "title": "Debug Info: From Metadata to Modules",
      "speakers": [
        {
          "name": "Duncan Exon Smith",
          "affiliation": "",
          "github": "",
          "linkedin": "",
          "twitter": ""
        },
        {
          "name": "Adrian Prantl",
          "affiliation": "",
          "github": "",
          "linkedin": "",
          "twitter": ""
        }
      ],
      "abstract": "Debug Info: From Metadata to Modules The efficiency of debug info in LLVM and Clang improved dramatically this year. This talk is about what it took to get here and what work remains. We'll talk about how Metadata was redesigned to make the debug info IR memory-efficient (with a human-readable assembly syntax). We'll go into the implications for other Metadata graphs, and what a more expressive Metadata future could look like. We'll also include an overview of what's left to scale debug info for LTO. We'll also talk about Clang's new module debugging feature, which reduces the size of debug info on disk, improves compile time, and makes full type information available to debuggers. We'll highlight how Clang-based debuggers like LLDB can use module debug information to enhance expression evaluation.",
      "videoUrl": "https://youtu.be/EgkZ8PTNSHQ",
      "videoId": "EgkZ8PTNSHQ",
      "slidesUrl": "https://llvm.org/devmtg/2015-10/slides/Prantl-ExonSmith-DebugInfoMetadataToModules.pdf",
      "projectGithub": "",
      "tags": [
        "Clang",
        "Debug Information",
        "LLDB",
        "LTO",
        "Performance"
      ]
    },
    {
      "id": "2015-10-026",
      "meeting": "2015-10",
      "meetingName": "2015 US LLVM Developers' Meeting",
      "meetingLocation": "San Jose, CA, USA",
      "meetingDate": "October 29-30, 2015",
      "category": "technical-talk",
      "title": "Advances in Loop Analysis Frameworks and Optimizations",
      "speakers": [
        {
          "name": "Adam Nemet",
          "affiliation": "",
          "github": "",
          "linkedin": "",
          "twitter": ""
        },
        {
          "name": "Michael Zolotukhin",
          "affiliation": "",
          "github": "",
          "linkedin": "",
          "twitter": ""
        }
      ],
      "abstract": "Have you made changes to your copy of an llvm.org project? Not planning to contribute them back to the open-source project right away? Then you are LIVING DOWNSTREAM. Have you noticed that there are actually quite a lot of changes made to the upstream projects? Clang + LLVM together see an average of 50 commits every day. This is a FLOOD. Are you seeing lots of conflicts or test failures when you merge from upstream? Spending too much time patching things back together before you can make any progress on your project? Then you are DROWNING! On a project with lots of local changes, managing the flood can be a half-time job all by itself. It's not _exactly_ unproductive time, but it's time you do not spend on your unique project and customizations. At Sony Computer Entertainment, we were drowning... but we've learned to swim with the current, and we are building a lifeboat. In this combined tech-talk/BOF session, Paul and Mike will talk about SCE's practices and plans for reducing our merge overhead, including source-patch practices and merge/build/test automation. Then, it becomes a BOF where everyone can share their ideas, suggestions and practices for Living Downstream Without Drowning! Lightning Talk Abstracts BoF Abstracts Poster Abstracts Reception The reception will be held on Thursday, October 29 from 6PM-10PM at SP2 Communal Bar & Restaurant A reception ticket is required to attend this event. Drinks and food will be provided. SP2 Communal Bar & Restaurant 72 N Almaden Ave. San Jose, CA 95110 Hotel San Jose Marriott 301 South Market Street San Jose, CA 95113 We have negotiated a room block for our attendees: LLVM Foundation Developers Meeting Start date: 10/28/15 End date: 10/31/15 Last day to book: 10/7/15 Marriott hotel(s) offering your special group rate: San Jose Marriott for 229.00 USD per night Book your group rate for LLVM Foundation Developers Meeting Parking You can find parking at the San Jose Marriott (valet only) and the San Jose Convention Center. Rates: San Jose Marriott Valet parking: First 30 Minutes $8 Up to 1 hour $14 1 to 2 hours $20 2 to 4 hours $26 4-5 hours $32 5-24 hours $34 San Jose Convention Center Parking: $1 per 20 min, $20 daily maximum Monday - Sunday, special rates as posted at facility may apply during special event (http://www.sanjose.org/maps-more/parking/).",
      "videoUrl": "https://youtu.be/XvkLHIASlp8",
      "videoId": "XvkLHIASlp8",
      "slidesUrl": "https://llvm.org/devmtg/2015-10/slides/NemetZolotukhin-AdvancesInLoopAnalysisFrameworksAndOptimizations.pdf",
      "projectGithub": "",
      "tags": [
        "Clang",
        "Community Building",
        "Optimizations"
      ]
    }
  ]
}
